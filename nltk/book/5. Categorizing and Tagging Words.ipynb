{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Using a Tagger\n",
    "- A part-of-speech tagger, or POS-tagger, processes a sequence of words, and attaches a part of speech tag to each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "text = word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lexical categories like \"noun\" and part-of-speech tags like NN seem to have their uses, but the details will be obscure to many readers\n",
    "- Many of these categories arise from superficial analysis the distribution of words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "# The text.similar() method takes a word w, \n",
    "# finds all words w' that appear in the same context\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made said done put had seen found given left heard was been brought\n",
      "set got that took in told felt\n"
     ]
    }
   ],
   "source": [
    "text.similar('bought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in on to of and for with from at by that into as up out down through\n",
      "is all about\n"
     ]
    }
   ],
   "source": [
    "text.similar('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a his this their its her an that our any all one these my in your no\n",
      "some other and\n"
     ]
    }
   ],
   "source": [
    "text.similar('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Representing Tagged Tokens\n",
    "- A tagged token is represented using a tuple consisting of the token and the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fly', 'NN')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('grand', 'JJ'), ('jury', 'NN'), ('commented', 'VBD'), ('on', 'IN'), ('a', 'AT'), ('number', 'NN'), ('of', 'IN'), ('other', 'AP'), ('topics', 'NNS'), (',', ','), ('AMONG', 'IN'), ('them', 'PPO'), ('the', 'AT'), ('Atlanta', 'NP'), ('and', 'CC'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('purchasing', 'VBG'), ('departments', 'NNS'), ('which', 'WDT'), ('it', 'PPS'), ('said', 'VBD'), ('``', '``'), ('ARE', 'BER'), ('well', 'QL'), ('operated', 'VBN'), ('and', 'CC'), ('follow', 'VB'), ('generally', 'RB'), ('accepted', 'VBN'), ('practices', 'NNS'), ('which', 'WDT'), ('inure', 'VB'), ('to', 'IN'), ('the', 'AT'), ('best', 'JJT'), ('interest', 'NN'), ('of', 'IN'), ('both', 'ABX'), ('governments', 'NNS'), (\"''\", \"''\"), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# tokenize the string to access the individual word/tag strings\n",
    "sent = '''\n",
    "The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
    "other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
    "Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
    "said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
    "accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
    "interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
    "'''\n",
    "\n",
    "print([nltk.tag.str2tuple(t) for t in sent.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 A Universal Part-of-Speech Tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 30654),\n",
       " ('VERB', 14399),\n",
       " ('ADP', 12355),\n",
       " ('.', 11928),\n",
       " ('DET', 11389),\n",
       " ('ADJ', 6706),\n",
       " ('ADV', 3349),\n",
       " ('CONJ', 2717),\n",
       " ('PRON', 2535),\n",
       " ('PRT', 2264),\n",
       " ('NUM', 2166),\n",
       " ('X', 92)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Nouns\n",
    "- Nouns generally refer to people, places, things, or concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " '.',\n",
       " 'VERB',\n",
       " 'CONJ',\n",
       " 'NUM',\n",
       " 'ADV',\n",
       " 'PRT',\n",
       " 'PRON',\n",
       " 'X']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n",
    "fdist = nltk.FreqDist(noun_preceders)\n",
    "[tag for (tag, _) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Verbs\n",
    "- Verbs are words that describe events and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2633\n",
      "['is', 'said', 'was', 'are', 'be', 'has', 'have', 'will', 'says', 'would']\n"
     ]
    }
   ],
   "source": [
    "# sort all the verbs by frequency\n",
    "wsj = nltk.corpus.treebank.tagged_words(tagset='universal')\n",
    "word_tag_fd = nltk.FreqDist(wsj)\n",
    "verbs = [wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == 'VERB']\n",
    "\n",
    "print(len(verbs))\n",
    "print(verbs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 28), ('NOUN', 20)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# items being counted in the frequency distribution are word-tag pairs\n",
    "cfd1 = nltk.ConditionalFreqDist(wsj)\n",
    "cfd1['yield'].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['named',\n",
       " 'used',\n",
       " 'caused',\n",
       " 'exposed',\n",
       " 'reported',\n",
       " 'replaced',\n",
       " 'sold',\n",
       " 'died',\n",
       " 'expected',\n",
       " 'diagnosed']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse the order of the pairs, so that the tags are the conditions, and the words are the events\n",
    "wsj = nltk.corpus.treebank.tagged_words()\n",
    "cfd2 = nltk.ConditionalFreqDist((tag, word) for (word, tag) in wsj)\n",
    "\n",
    "list(cfd2['VBN'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find words which can be both VBD and VBN\n",
    "[w for w in cfd1.conditions() if 'VBD' in cfd1[w] and 'VBN' in cfd1[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('While', 'IN'),\n",
       " ('program', 'NN'),\n",
       " ('trades', 'NNS'),\n",
       " ('swiftly', 'RB'),\n",
       " ('kicked', 'VBD')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx1 = wsj.index(('kicked', 'VBD'))\n",
    "wsj[idx1-4:idx1+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('head', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('state', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('kicked', 'VBN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = wsj.index(('kicked', 'VBN'))\n",
    "wsj[idx2-4:idx2+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Adjectives and Adverbs\n",
    "- Adjectives describe nouns, and can be used as modifiers\n",
    "- Adverbs modify verbs to specify the time, manner, place or direction of the event described by the verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 Unsimplified Tags\n",
    "- $ for possessive nouns\n",
    "- S for plural nouns\n",
    "- P for proper nouns\n",
    "- -NC for citations\n",
    "- -HL for words in headlines \n",
    "- -TL for titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN [('year', 137), ('time', 97), ('state', 88), ('week', 85), ('man', 72)]\n",
      "NN$ [(\"year's\", 13), (\"world's\", 8), (\"state's\", 7), (\"nation's\", 6), (\"city's\", 6)]\n",
      "NN$-HL [(\"Golf's\", 1), (\"Navy's\", 1)]\n",
      "NN$-TL [(\"President's\", 11), (\"Administration's\", 3), (\"Army's\", 3), (\"League's\", 3), (\"University's\", 3)]\n",
      "NN-HL [('sp.', 2), ('problem', 2), ('Question', 2), ('cut', 2), ('party', 2)]\n",
      "NN-NC [('ova', 1), ('eva', 1), ('aya', 1)]\n",
      "NN-TL [('President', 88), ('House', 68), ('State', 59), ('University', 42), ('City', 41)]\n",
      "NN-TL-HL [('Fort', 2), ('Mayor', 1), ('Commissioner', 1), ('City', 1), ('Oak', 1)]\n",
      "NNS [('years', 101), ('members', 69), ('people', 52), ('sales', 51), ('men', 46)]\n",
      "NNS$ [(\"children's\", 7), (\"women's\", 5), (\"men's\", 3), (\"janitors'\", 3), (\"taxpayers'\", 2)]\n",
      "NNS$-HL [(\"Dealers'\", 1), (\"Idols'\", 1)]\n",
      "NNS$-TL [(\"Women's\", 4), (\"States'\", 3), (\"Giants'\", 2), (\"Princes'\", 1), (\"Bombers'\", 1)]\n",
      "NNS-HL [('Wards', 1), ('deputies', 1), ('bonds', 1), ('aspects', 1), ('Decisions', 1)]\n",
      "NNS-TL [('States', 38), ('Nations', 11), ('Masters', 10), ('Communists', 9), ('Rules', 9)]\n",
      "NNS-TL-HL [('Nations', 1)]\n"
     ]
    }
   ],
   "source": [
    "def findtags(tag_prefix, tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].most_common(5)) for tag in cfd.conditions())\n",
    "\n",
    "\n",
    "tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='news'))\n",
    "for tag in sorted(tagdict):\n",
    "    print(tag, tagdict[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.8 Exploring Tagged Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'accomplished', 'analytically', 'appear', 'apt', 'associated', 'assuming', 'became', 'become', 'been', 'began', 'call', 'called', 'carefully', 'chose', 'classified', 'colorful', 'composed', 'contain', 'differed', 'difficult', 'encountered', 'enough', 'equate', 'extremely', 'found', 'happens', 'have', 'ignored', 'in', 'involved', 'more', 'needed', 'nightly', 'observed', 'of', 'on', 'out', 'quite', 'represent', 'responsible', 'revamped', 'seclude', 'set', 'shortened', 'sing', 'sounded', 'stated', 'still', 'sung', 'supported', 'than', 'to', 'when', 'work']\n"
     ]
    }
   ],
   "source": [
    "# Suppose we're studying the word often and want to see how it is used in text\n",
    "brown_learned_text = brown.words(categories='learned')\n",
    "print(sorted(set(b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB  ADV  ADP  ADJ    .  PRT \n",
      "  37    8    7    6    4    2 \n"
     ]
    }
   ],
   "source": [
    "# tagged_words() method to look at the part-of-speech tag\n",
    "brown_lrnd_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
    "tags = [b[1] for (a, b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'often']\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find words involving particular sequences of tags and words (in this case \"<Verb> to <Verb>\")\n",
    "from nltk.corpus import brown\n",
    "def process(sentence):\n",
    "    for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence):\n",
    "        if (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\n",
    "            print(w1, w2, w3)\n",
    "\n",
    "## The print is long\n",
    "# for tagged_sent in brown.tagged_sents():\n",
    "#     process(tagged_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Complex Keys and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'ADJ': 1, 'X': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "pos = defaultdict(lambda: defaultdict(int))\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "# brown_news_tagged\n",
    "\n",
    "for ((w1, t1), (w2, t2)) in nltk.bigrams(brown_news_tagged):\n",
    "#     print((w1, t1), (w2, t2))\n",
    "    pos[(t1, w2)][t2] += 1\n",
    "\n",
    "# pos\n",
    "pos[('NOUN', 'Grand')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 Inverting a Dictionary\n",
    "- If d is a dictionary and k is a key, we type d[k] and immediately obtain the value. \n",
    "- Finding a key given a value is slower and more cumbersome\n",
    "- We just get all the key-value pairs in the dictionary, and create a new dictionary of value-key pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': 'colorless', 'ADV': 'furiously', 'N': 'ideas', 'V': 'sleep'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
    "pos2 = dict((value, key) for (key, value) in pos.items())\n",
    "pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'ADJ': ['colorless', 'old'],\n",
       "             'ADV': ['furiously', 'peacefully'],\n",
       "             'N': ['ideas', 'cats'],\n",
       "             'V': ['sleep', 'scratch']})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.update({'cats': 'N', 'scratch': 'V', 'peacefully': 'ADV', 'old': 'ADJ'})\n",
    "pos2 = defaultdict(list)\n",
    "for key, value in pos.items():\n",
    "    pos2[value].append(key)\n",
    "\n",
    "pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(list,\n",
       "      {'ADJ': ['colorless', 'old'],\n",
       "       'ADV': ['furiously', 'peacefully'],\n",
       "       'N': ['ideas', 'cats'],\n",
       "       'V': ['sleep', 'scratch']})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos2 = nltk.Index((value, key) for (key, value) in pos.items())\n",
    "pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 The Default Tagger\n",
    "- The simplest possible tagger assigns the same tag to each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# Find the most frequent tag\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'NN'), ('do', 'NN'), ('not', 'NN'), ('like', 'NN'), ('green', 'NN'), ('eggs', 'NN'), ('and', 'NN'), ('ham', 'NN'), (',', 'NN'), ('I', 'NN'), ('do', 'NN'), ('not', 'NN'), ('like', 'NN'), ('them', 'NN'), ('Sam', 'NN'), ('I', 'NN'), ('am', 'NN'), ('!', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# create a tagger that tags everything as NN\n",
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "print(default_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13% of tokens tagged correctly\n",
    "default_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 The Regular Expression Tagger\n",
    "- The regular expression tagger assigns tags to tokens on the basis of matching patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', 'NN'), ('Only', 'NN'), ('a', 'NN'), ('relative', 'NN'), ('handful', 'NN'), ('of', 'NN'), ('such', 'NN'), ('reports', 'NNS'), ('was', 'NNS'), ('received', 'VBD'), (\"''\", 'NN'), (',', 'NN'), ('the', 'NN'), ('jury', 'NN'), ('said', 'NN'), (',', 'NN'), ('``', 'NN'), ('considering', 'VBG'), ('the', 'NN'), ('widespread', 'NN'), ('interest', 'NN'), ('in', 'NN'), ('the', 'NN'), ('election', 'NN'), (',', 'NN'), ('the', 'NN'), ('number', 'NN'), ('of', 'NN'), ('voters', 'NNS'), ('and', 'NN'), ('the', 'NN'), ('size', 'NN'), ('of', 'NN'), ('this', 'NNS'), ('city', 'NN'), (\"''\", 'NN'), ('.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),               # gerunds\n",
    "    (r'.*ed$', 'VBD'),                # simple past\n",
    "    (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),               # modals\n",
    "    (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                 # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN')                     # nouns (default)\n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "print(regexp_tagger.tag(brown_sents[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20326391789486245"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20% of tokens tagged correctly\n",
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 The Lookup Tagger\n",
    "1. Let's find the hundred most frequent words and store their most likely tag. \n",
    "2. We can then use this information as the model for a \"lookup tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45578495136941344"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Point 1\n",
    "fd = nltk.FreqDist(brown.words(categories='news'))\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "most_freq_words = fd.most_common(100)\n",
    "\n",
    "# Point 2\n",
    "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "\n",
    "# 46% of tokens tagged correctly\n",
    "baseline_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('Only', None), ('a', 'AT'), ('relative', None), ('handful', None), ('of', 'IN'), ('such', None), ('reports', None), ('was', 'BEDZ'), ('received', None), (\"''\", \"''\"), (',', ','), ('the', 'AT'), ('jury', None), ('said', 'VBD'), (',', ','), ('``', '``'), ('considering', None), ('the', 'AT'), ('widespread', None), ('interest', None), ('in', 'IN'), ('the', 'AT'), ('election', None), (',', ','), ('the', 'AT'), ('number', None), ('of', 'IN'), ('voters', None), ('and', 'CC'), ('the', 'AT'), ('size', None), ('of', 'IN'), ('this', 'DT'), ('city', None), (\"''\", \"''\"), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Many words have been assigned a tag of None, \n",
    "because they were not among the 100 most frequent words\n",
    "\"\"\"\n",
    "sent = brown.sents(categories='news')[3]\n",
    "print(baseline_tagger.tag(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags,\n",
    "                                     backoff=nltk.DefaultTagger('NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3173f554a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def performance(cfd, wordlist):\n",
    "    lt = dict((word, cfd[word].max()) for word in wordlist)\n",
    "    baseline_tagger = nltk.UnigramTagger(model=lt, backoff=nltk.DefaultTagger('NN'))\n",
    "    return baseline_tagger.evaluate(brown.tagged_sents(categories='news'))\n",
    "\n",
    "def display():\n",
    "    import pylab\n",
    "    word_freqs = nltk.FreqDist(brown.words(categories='news')).most_common()\n",
    "    words_by_freq = [w for (w, _) in word_freqs]\n",
    "    cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "    sizes = 2 ** pylab.arange(15)\n",
    "    perfs = [performance(cfd, words_by_freq[:size]) for size in sizes]\n",
    "    pylab.plot(sizes, perfs, '-bo')\n",
    "    pylab.title('Lookup Tagger Performance with Varying Model Size')\n",
    "    pylab.xlabel('Model Size')\n",
    "    pylab.ylabel('Performance')\n",
    "    pylab.show()\n",
    "\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Unigram Tagging\n",
    "A unigram tagger behaves just like a lookup tagger, except there is a more convenient technique for setting it up, called training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Various', 'JJ'), ('of', 'IN'), ('the', 'AT'), ('apartments', 'NNS'), ('are', 'BER'), ('of', 'IN'), ('the', 'AT'), ('terrace', 'NN'), ('type', 'NN'), (',', ','), ('being', 'BEG'), ('on', 'IN'), ('the', 'AT'), ('ground', 'NN'), ('floor', 'NN'), ('so', 'QL'), ('that', 'CS'), ('entrance', 'NN'), ('is', 'BEZ'), ('direct', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "print(unigram_tagger.tag(brown_sents[2007]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 93% of tokens tagged correctly\n",
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Separating the Training and Testing Data\n",
    "- Split the data, training on 90% and testing on the remaining 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121200039868434"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "size\n",
    "\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "\n",
    "# 81% of tokens tagged correctly\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 General N-Gram Tagging\n",
    "- An n-gram tagger is a generalization of a unigram tagger whose context is the current word together with the part-of-speech tags of the n-1 preceding tokens\n",
    "- An n-gram tagger picks the tag that is most likely in the given context\n",
    "\n",
    "![Image](http://www.nltk.org/images/tag-context.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10206319146815508"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])\n",
    "\n",
    "# Testing data\n",
    "unseen_sent = brown_sents[4203]\n",
    "bigram_tagger.tag(unseen_sent)\n",
    "\n",
    "# 10% of tokens tagged correctly\n",
    "bigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Combining Taggers\n",
    "1. Try tagging the token with the bigram tagger.\n",
    "2. If the bigram tagger is unable to find a tag for the token, try the unigram tagger.\n",
    "3. If the unigram tagger is also unable to find a tag, use a default tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452108043456593"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "\n",
    "# 84% of tokens tagged correctly\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Storing Taggers\n",
    "- Convenient to save a trained tagger in a file for later re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save our tagger t2 to a file t2.pkl\n",
    "from pickle import dump\n",
    "output = open('t2.pkl', 'wb')\n",
    "dump(t2, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load our saved tagger\n",
    "from pickle import load\n",
    "input = open('t2.pkl', 'rb')\n",
    "tagger = load(input)\n",
    "input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), (\"board's\", 'NN$'), ('action', 'NN'), ('shows', 'NNS'), ('what', 'WDT'), ('free', 'JJ'), ('enterprise', 'NN'), ('is', 'BEZ'), ('up', 'RP'), ('against', 'IN'), ('in', 'IN'), ('our', 'PP$'), ('complex', 'JJ'), ('maze', 'NN'), ('of', 'IN'), ('regulatory', 'NN'), ('laws', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"The board's action shows what free enterprise\n",
    "    is up against in our complex maze of regulatory laws .\"\"\"\n",
    "tokens = text.split()\n",
    "print(tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Summary\n",
    "- Words can be grouped into classes, such as nouns, verbs, adjectives, and adverbs. These classes are known as lexical categories or parts of speech. Parts of speech are assigned short labels, or tags, such as NN, VB,\n",
    "- The process of automatically assigning parts of speech to words in text is called part-of-speech tagging, POS tagging, or just tagging.\n",
    "- Automatic tagging is an important step in the NLP pipeline, and is useful in a variety of situations including: predicting the behavior of previously unseen words, analyzing word usage in corpora, and text-to-speech systems.\n",
    "- Some linguistic corpora, such as the Brown Corpus, have been POS tagged.\n",
    "- A variety of tagging methods are possible, e.g. default tagger, regular expression tagger, unigram tagger and n-gram taggers. These can be combined using a technique known as backoff.\n",
    "- Taggers can be trained and evaluated using tagged corpora.\n",
    "- Backoff is a method for combining models: when a more specialized model (such as a bigram tagger) cannot assign a tag in a given context, we backoff to a more general model (such as a unigram tagger).\n",
    "- Part-of-speech tagging is an important, early example of a sequence classification task in NLP: a classification decision at any one point in the sequence makes use of words and tags in the local context.\n",
    "- A dictionary is used to map between arbitrary types of information, such as a string and a number: freq['cat'] = 12. We create dictionaries using the brace notation: pos = {}, pos = {'furiously': 'adv', 'ideas': 'n', 'colorless': 'adj'}.\n",
    "- N-gram taggers can be defined for large values of n, but once n is larger than 3 we usually encounter the sparse data problem; even with a large quantity of training data we only see a tiny fraction of possible contexts.\n",
    "- Transformation-based tagging involves learning a series of repair rules of the form \"change tag s to tag t in context c\", where each rule fixes mistakes and possibly introduces a (smaller) number of errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
