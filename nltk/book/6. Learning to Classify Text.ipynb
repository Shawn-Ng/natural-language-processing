{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Supervised Classification\n",
    "![Image](images/supervised-classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Gender Identification\n",
    "- Names ending in a, e and i are likely to be female\n",
    "- Names ending in k, o, r, s and t are likely to be male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extractor function\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "\n",
    "# returned dictionary, known as a feature set\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of examples and corresponding class labels\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "# training set is used to train a new \"naive Bayes\" classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Trinity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742\n"
     ]
    }
   ],
   "source": [
    "# percent of names classified gender correctly\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'k'              male : female =     33.9 : 1.0\n",
      "             last_letter = 'a'            female : male   =     33.0 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.7 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.6 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# features most effective for distinguishing the names' genders\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.2 Choosing The Right Features\n",
    "- Feature extractors are built through a process of trial-and-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_letter': 'j', 'last_letter': 'n', 'count(a)': 0, 'has(a)': False, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 0, 'has(d)': False, 'count(e)': 0, 'has(e)': False, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 1, 'has(h)': True, 'count(i)': 0, 'has(i)': False, 'count(j)': 1, 'has(j)': True, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 1, 'has(n)': True, 'count(o)': 1, 'has(o)': True, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 0, 'has(r)': False, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}\n"
     ]
    }
   ],
   "source": [
    "print(gender_features2('John'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7944\n",
      "('Barron', 'male')\n",
      "[({'first_letter': 'b', 'last_letter': 'n', 'count(a)': 1, 'has(a)': True, 'count(b)': 1, 'has(b)': True, 'count(c)': 0, 'has(c)': False, 'count(d)': 0, 'has(d)': False, 'count(e)': 0, 'has(e)': False, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 0, 'has(h)': False, 'count(i)': 0, 'has(i)': False, 'count(j)': 0, 'has(j)': False, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 1, 'has(n)': True, 'count(o)': 1, 'has(o)': True, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 2, 'has(r)': True, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}, 'male')]\n"
     ]
    }
   ],
   "source": [
    "print(len(labeled_names))\n",
    "\n",
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "print(labeled_names[0])\n",
    "print(featuresets[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# accuracy\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](images/corpus-org.png)\n",
    "- Very productive method for refining the feature set is error analysis\n",
    "- The training set is used to train the model, and the dev-test set is used to perform error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751\n"
     ]
    }
   ],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]\n",
    "\n",
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Aleen                         \n",
      "correct=female   guess=male     name=Alexis                        \n",
      "correct=female   guess=male     name=Alisun                        \n",
      "correct=female   guess=male     name=Alyson                        \n",
      "correct=female   guess=male     name=Anet                          \n",
      "correct=female   guess=male     name=Annabel                       \n",
      "correct=female   guess=male     name=Annabell                      \n",
      "correct=female   guess=male     name=Arden                         \n",
      "correct=female   guess=male     name=Avril                         \n",
      "correct=female   guess=male     name=Bev                           \n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )\n",
    "\n",
    "\n",
    "for (tag, guess, name) in sorted(errors)[:10]:\n",
    "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking through this list of errors\n",
    "- Names ending in yn appear to be predominantly female, despite the fact that names ending in n tend to be male\n",
    "- Names ending in ch are usually male, even though names that end in h tend to be female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "\n",
    "# the performance on the dev-test dataset improves\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[(['as', 'african', 'american', 'detective', 'vergil', 'tibbs', 'questions', 'a', 'suspected', 'white', 'murderer', 'inside', 'a', 'jail', 'cell', ',', 'there', 'is', 'a', 'wonderful', ',', 'eye', '-', 'catching', 'shot', 'which', 'instantaneously', 'presents', 'the', 'main', 'message', 'of', 'the', 'entire', 'film', '.', 'the', 'shot', 'has', 'tibbs', \"'\", 'face', 'completely', 'covered', 'by', 'the', 'shadows', 'of', 'the', 'prison', 'bars', '.', 'to', 'see', 'these', 'bars', 'blocking', 'his', 'face', ',', 'we', 'see', 'how', 'separated', 'tibbs', 'is', 'from', 'the', 'rest', 'of', 'the', 'characters', 'in', 'the', 'film', '.', 'as', 'a', 'black', 'detective', 'conducting', 'an', 'investigation', 'in', 'a', 'southern', 'town', 'full', 'of', 'violent', 'white', 'bigots', ',', 'no', 'matter', 'how', 'innocent', 'tibbs', 'is', ',', 'he', 'is', 'still', 'seen', 'by', 'these', 'bigots', 'as', 'a', 'threat', 'simply', 'because', 'of', 'the', 'color', 'of', 'his', 'skin', '.', 'the', 'bars', 'show', 'that', 'tibbs', 'has', 'not', 'been', 'given', 'a', 'fair', 'chance', 'to', 'show', 'exactly', 'who', 'he', 'is', ',', 'instead', 'others', 'have', 'chosen', 'him', 'as', 'different', 'and', 'dangerous', '.', 'this', 'one', 'shot', 'amazes', 'me', 'because', 'it', 'captures', 'a', 'whole', 'theme', 'in', 'a', 'matter', 'of', 'seconds', '.', 'it', 'perhaps', 'may', 'be', 'the', 'most', 'powerful', 'image', 'i', 'have', 'seen', 'in', 'a', 'film', '.', '\"', 'in', 'the', 'heat', 'of', 'the', 'night', '\"', 'was', 'the', 'first', 'and', 'the', 'best', 'of', 'the', 'three', 'films', 'norman', 'jewison', 'directed', 'concerning', 'racism', 'in', 'america', '.', 'jewison', 'has', 'a', 'very', 'keen', 'style', 'of', 'displaying', 'various', 'cases', 'of', 'racism', 'as', 'he', 'is', 'neither', 'pedantic', 'nor', 'overly', 'sentimental', '.', 'in', 'these', 'three', 'films', 'he', 'does', 'an', 'excellent', 'job', 'creating', 'very', 'detailed', 'equal', 'analyses', 'of', 'characters', 'from', 'the', 'abused', 'to', 'the', 'abusers', '.', 'he', 'is', 'also', 'not', 'afraid', 'to', 'tell', 'the', 'absolute', 'truth', 'about', 'how', 'corrupt', 'society', 'was', 'in', 'the', 'past', 'and', 'is', 'in', 'the', 'present', '.', 'preceding', 'the', 'very', 'original', '\"', 'a', 'soldier', \"'\", 's', 'story', '\"', 'and', 'the', 'recently', 'released', '\"', 'the', 'hurricane', ',', '\"', '\"', 'in', 'the', 'heat', 'of', 'the', 'night', 'contains', 'some', 'classic', 'lines', 'and', 'some', 'very', 'memorable', 'characters', '.', 'the', 'film', ',', 'which', 'won', 'best', 'picture', 'in', '1967', 'focuses', 'on', 'vergil', 'tibbs', ',', 'played', 'superbly', 'by', 'sidney', 'poitier', 'as', 'a', 'fearless', 'african', 'american', 'police', 'officer', 'from', 'philadelphia', 'who', 'refuses', 'to', 'give', 'up', 'on', 'an', 'investigation', 'in', 'a', 'white', 'town', 'where', 'is', 'he', 'not', 'wanted', '.', 'tibbs', 'is', 'a', 'man', 'who', 'rarely', 'loses', 'his', 'temper', 'and', 'that', 'is', 'worth', 'mentioning', 'because', 'he', 'is', 'constantly', 'facing', 'abuse', 'from', 'those', 'around', 'him', '.', 'as', 'a', 'hero', 'who', 'is', 'not', 'afraid', 'to', 'face', 'off', 'against', 'five', 'men', 'with', 'chains', ',', 'tibbs', 'is', 'the', 'perfect', 'protagonist', '.', 'poitier', 'also', 'gives', 'an', 'excellent', ',', 'noteworthy', 'voice', 'to', 'his', 'character', '.', 'never', 'nervous', 'and', 'always', 'commanding', ',', 'his', 'speech', 'patterns', 'are', 'very', 'manipulative', 'as', 'they', 'range', 'from', 'stentorian', 'to', 'soothing', '.', 'however', ',', 'unlike', '\"', 'the', 'hurricane', '\"', 'where', 'denzel', 'washington', 'dominated', 'over', 'the', 'rest', 'of', 'the', 'cast', ',', 'poitier', 'shares', 'the', 'spotlight', 'with', 'rod', 'steiger', ',', 'who', 'won', 'best', 'actor', 'for', 'his', 'excellent', 'performance', '.', 'as', 'a', 'sheriff', 'who', 'helps', 'tibbs', 'and', 'warns', 'him', 'of', 'the', 'dangers', 'around', 'him', ',', 'steiger', 'shows', 'a', 'great', 'amount', 'of', 'skill', 'in', 'his', 'role', '.', 'he', 'starts', 'off', 'as', 'racist', 'and', 'blind', 'as', 'the', 'other', 'townspeople', '.', 'he', 'would', 'refer', 'to', 'tibbs', 'as', '\"', 'boy', '\"', 'and', 'would', 'always', 'suspiciously', 'keep', 'an', 'eye', 'on', 'him', '.', 'as', 'the', 'film', 'progresses', 'though', ',', 'there', 'is', 'a', 'very', 'gradual', 'change', 'in', 'the', 'sheriff', '.', 'he', 'begins', 'to', 'see', 'the', 'hardships', 'tibbs', 'faces', 'and', 'he', 'sees', 'the', 'foolishness', 'of', 'his', 'own', 'neighbors', '.', 'what', 'i', 'really', 'enjoyed', 'about', 'steiger', \"'\", 's', 'character', 'was', 'that', 'he', 'did', 'not', 'completely', 'abandon', 'his', 'friends', 'or', 'connect', 'with', 'tibbs', 'at', 'the', 'end', 'of', 'the', 'film', '.', 'he', 'still', 'could', 'not', 'refer', 'to', 'tibbs', 'as', 'mister', 'tibbs', 'or', 'officer', 'tibbs', 'but', 'rather', 'settled', 'for', 'virgil', '.', 'instead', ',', 'it', 'was', 'apparent', 'that', 'he', 'was', 'eventually', 'going', 'to', 'see', 'the', 'world', 'differently', 'in', 'the', 'future', '.', 'most', 'movies', 'would', 'have', 'a', 'character', 'reversing', 'all', 'of', 'his', 'beliefs', 'and', 'influences', 'in', 'a', 'matter', 'of', 'minutes', '.', 'this', 'action', 'would', 'not', 'have', 'been', 'realistic', 'at', 'all', 'since', 'it', 'is', 'nearly', 'impossible', 'for', 'someone', 'to', 'believe', 'something', 'one', 'day', 'and', 'believe', 'something', 'else', 'the', 'next', 'day', '.', 'jewison', \"'\", 's', 'determination', 'to', 'make', 'this', 'film', 'as', 'realistic', 'as', 'possible', 'is', 'very', 'obvious', 'here', 'and', 'also', 'very', 'appropriate', '.', '\"', 'in', 'the', 'heat', 'of', 'the', 'night', '\"', 'shows', 'the', 'difference', 'between', 'the', 'north', 'and', 'the', 'south', 'or', 'a', 'major', 'city', 'and', 'a', 'small', 'town', 'in', 'the', 'united', 'states', 'during', 'the', '1960', \"'\", 's', '.', 'it', 'displays', 'this', 'perfectly', '.', 'however', ',', 'the', 'actual', 'investigation', ',', 'although', 'it', 'is', 'not', 'the', 'main', 'focus', 'of', 'the', 'film', ',', 'lacks', 'interest', '.', 'it', 'seemed', 'rushed', 'especially', 'towards', 'the', 'end', 'as', 'if', 'jewison', 'had', 'given', 'his', 'message', 'about', 'racism', 'and', 'did', 'not', 'feel', 'like', 'giving', 'a', 'credible', 'explanation', 'involving', 'the', 'murder', 'victim', '.', 'there', 'were', 'way', 'too', 'many', 'characters', 'added', 'during', 'the', 'last', 'fifteen', 'minutes', 'and', 'some', 'of', 'the', 'scenes', 'during', 'this', 'time', 'period', 'were', 'inane', '(', 'police', 'officer', 'sam', 'being', 'a', 'suspect', 'was', 'not', 'needed', ')', '.', 'also', ',', 'it', 'is', 'given', 'that', 'tibbs', 'is', 'a', 'vigilant', 'homicide', 'detective', 'who', 'is', 'the', 'best', 'at', 'what', 'he', 'does', ',', 'but', 'some', 'of', 'his', 'discoveries', 'came', 'out', 'of', 'nowhere', 'and', 'how', 'he', 'found', 'out', 'some', 'of', 'the', 'important', 'case', 'details', 'towards', 'the', 'end', 'were', 'never', 'answered', '.', 'the', 'rushed', 'ending', 'was', 'the', 'only', 'mistake', 'of', 'this', 'otherwise', 'memorable', 'jewison', 'classic', '.', '(', 'a', 'congratulations', 'has', 'to', 'be', 'given', 'to', 'actor', 'scott', 'wilson', '.', 'he', 'managed', 'to', 'be', 'in', 'the', 'two', 'best', 'movies', 'of', '1967', ',', '\"', 'in', 'the', 'heat', 'of', 'the', 'night', '\"', 'and', 'the', 'even', 'better', '\"', 'in', 'cold', 'blood', '.', '\"', ')'], 'pos')]\n"
     ]
    }
   ],
   "source": [
    "# Movie Reviews Corpus, which categorizes each review as positive or negative\n",
    "from nltk.corpus import movie_reviews\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "# print(movie_reviews.categories())\n",
    "# print(movie_reviews.fileids())\n",
    "# print(movie_reviews.words())\n",
    "print(len(documents))\n",
    "print(documents[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constructing a list of the 2000 most frequent words\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "# feature extractor that simply checks whether each of these words is present in a given document\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(:)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(church)': False,\n",
       " 'contains(couples)': False,\n",
       " 'contains(go)': False,\n",
       " 'contains(party)': False,\n",
       " 'contains(plot)': True,\n",
       " 'contains(teen)': False,\n",
       " 'contains(to)': True,\n",
       " 'contains(two)': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = document_features(movie_reviews.words('pos/cv957_8737.txt'))\n",
    "\n",
    "# preview 1st 10 items of features (dictionary)\n",
    "dict(list(features.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n",
      "Most Informative Features\n",
      "       contains(martian) = True              neg : pos    =      7.6 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =      7.4 : 1.0\n",
      "     contains(atrocious) = True              neg : pos    =      6.6 : 1.0\n",
      "        contains(turkey) = True              neg : pos    =      6.5 : 1.0\n",
      "       contains(singers) = True              pos : neg    =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Part-of-Speech Tagging\n",
    "- We can train a classifier to work out which suffixes are most informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1\n",
    "\n",
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100554\n",
      "({'endswith(e)': True, 'endswith(,)': False, 'endswith(.)': False, 'endswith(s)': False, 'endswith(d)': False, 'endswith(t)': False, 'endswith(he)': True, 'endswith(n)': False, 'endswith(a)': False, 'endswith(of)': False, 'endswith(the)': True, 'endswith(y)': False, 'endswith(r)': False, 'endswith(to)': False, 'endswith(in)': False, 'endswith(f)': False, 'endswith(o)': False, 'endswith(ed)': False, 'endswith(nd)': False, 'endswith(is)': False, 'endswith(on)': False, 'endswith(l)': False, 'endswith(g)': False, 'endswith(and)': False, 'endswith(ng)': False, 'endswith(er)': False, 'endswith(as)': False, 'endswith(ing)': False, 'endswith(h)': False, 'endswith(at)': False, 'endswith(es)': False, 'endswith(or)': False, 'endswith(re)': False, 'endswith(it)': False, 'endswith(``)': False, 'endswith(an)': False, \"endswith('')\": False, 'endswith(m)': False, 'endswith(;)': False, 'endswith(i)': False, 'endswith(ly)': False, 'endswith(ion)': False, 'endswith(en)': False, 'endswith(al)': False, 'endswith(?)': False, 'endswith(nt)': False, 'endswith(be)': False, 'endswith(hat)': False, 'endswith(st)': False, 'endswith(his)': False, 'endswith(th)': False, 'endswith(ll)': False, 'endswith(le)': False, 'endswith(ce)': False, 'endswith(by)': False, 'endswith(ts)': False, 'endswith(me)': False, 'endswith(ve)': False, \"endswith(')\": False, 'endswith(se)': False, 'endswith(ut)': False, 'endswith(was)': False, 'endswith(for)': False, 'endswith(ent)': False, 'endswith(ch)': False, 'endswith(k)': False, 'endswith(w)': False, 'endswith(ld)': False, 'endswith(`)': False, 'endswith(rs)': False, 'endswith(ted)': False, 'endswith(ere)': False, 'endswith(her)': False, 'endswith(ne)': False, 'endswith(ns)': False, 'endswith(ith)': False, 'endswith(ad)': False, 'endswith(ry)': False, 'endswith())': False, 'endswith(()': False, 'endswith(te)': False, 'endswith(--)': False, 'endswith(ay)': False, 'endswith(ty)': False, 'endswith(ot)': False, 'endswith(p)': False, 'endswith(nce)': False, \"endswith('s)\": False, 'endswith(ter)': False, 'endswith(om)': False, 'endswith(ss)': False, 'endswith(:)': False, 'endswith(we)': False, 'endswith(are)': False, 'endswith(c)': False, 'endswith(ers)': False, 'endswith(uld)': False, 'endswith(had)': False, 'endswith(so)': False, 'endswith(ey)': False}, 'AT')\n"
     ]
    }
   ],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
    "\n",
    "print(len(featuresets))\n",
    "print(featuresets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6270512182993535\n",
      "NNS\n",
      "CPU times: user 10min 59s, sys: 17.7 s, total: 11min 17s\n",
      "Wall time: 11min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "# size\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "\n",
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "print(classifier.classify(pos_features('cats')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: \n",
      "    if endswith(s) == False: \n",
      "      if endswith(.) == False: return '.'\n",
      "      if endswith(.) == True: return '.'\n",
      "    if endswith(s) == True: \n",
      "      if endswith(is) == False: return 'PP$'\n",
      "      if endswith(is) == True: return 'BEZ'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier.pseudocode(depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Exploiting Context\n",
    "- We will pass in a complete (untagged) sentence, along with the index of the target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_features(sentence, i):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'an', 'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7891596220785678"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 Sequence Classification\n",
    "- Use joint classifier models to capture the dependencies between related classification tasks\n",
    "- Sequence classifier models can be used to jointly choose part-of-speech tags for all the words in a given sentence\n",
    "- Consecutive classification / greedy sequence classification\n",
    "    1. Find the most likely class label for the first input\n",
    "    2. Then to use that answer to help find the best label for the next input\n",
    "    3. Process can then be repeated until all of the inputs have been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# provides a list of the tags that we've predicted for the sentence so far\n",
    "def pos_features(sentence, i, history):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "        features[\"prev-tag\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        features[\"prev-tag\"] = history[i-1]\n",
    "    return features\n",
    "\n",
    "\n",
    "# sequence classifier\n",
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.58 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7980528511821975"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "\n",
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Sentence Segmentation\n",
    "- Classification task for punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "\n",
    "\"\"\"\n",
    "Tokens is a merged list of tokens from the individual sentences\n",
    "Boundaries is a set containing the indexes of all sentence-boundary tokens\n",
    "\"\"\"\n",
    "tokens = []\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i-1]) == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.34 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'next-word-capitalized': False,\n",
       "  'prev-word': 'nov',\n",
       "  'prev-word-is-one-char': False,\n",
       "  'punct': '.'},\n",
       " False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "               for i in range(1, len(tokens)-1)\n",
    "               if tokens[i] in '.?!']\n",
    "\n",
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.34 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Summary\n",
    "- Modeling the linguistic data found in corpora can help us to understand linguistic patterns, and can be used to make predictions about new language data.\n",
    "- Supervised classifiers use labeled training corpora to build models that predict the label of an input based on specific features of that input.\n",
    "- Supervised classifiers can perform a wide variety of NLP tasks, including document classification, part-of-speech tagging, sentence segmentation, dialogue act type identification, and determining entailment relations, and many other tasks.\n",
    "- When training a supervised classifier, you should split your corpus into three datasets: a training set for building the classifier model; a dev-test set for helping select and tune the model's features; and a test set for evaluating the final model's performance.\n",
    "- When evaluating a supervised classifier, it is important that you use fresh data, that was not included in the training or dev-test set. Otherwise, your evaluation results may be unrealistically optimistic.\n",
    "- Decision trees are automatically constructed tree-structured flowcharts that are used to assign labels to input values based on their features. Although they're easy to interpret, they are not very good at handling cases where feature values interact in determining the proper label.\n",
    "- In naive Bayes classifiers, each feature independently contributes to the decision of which label should be used. This allows feature values to interact, but can be problematic when two or more features are highly correlated with one another.\n",
    "- Maximum Entropy classifiers use a basic model that is similar to the model used by naive Bayes; however, they employ iterative optimization to find the set of feature weights that maximizes the probability of the training set.\n",
    "- Most of the models that are automatically constructed from a corpus are descriptive — they let us know which features are relevant to a given patterns or construction, but they don't give any information about causal relationships between those features and patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
