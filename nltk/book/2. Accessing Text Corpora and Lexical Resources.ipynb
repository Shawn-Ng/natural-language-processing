{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Gutenberg Corpus\n",
    "A text corpus is a large body of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.StreamBackedCorpusView"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "type(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Emma by Jane Austen 1816>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 37 matches:\n",
      "er father , was sometimes taken by surprize at his being still able to pity ` \n",
      "hem do the other any good .\" \" You surprize me ! Emma must do Harriet good : a\n",
      "Knightley actually looked red with surprize and displeasure , as he stood up ,\n",
      "r . Elton , and found to his great surprize , that Mr . Elton was actually on \n",
      "d aid .\" Emma saw Mrs . Weston ' s surprize , and felt that it must be great ,\n",
      "father was quite taken up with the surprize of so sudden a journey , and his f\n",
      "y , in all the favouring warmth of surprize and conjecture . She was , moreove\n",
      "he appeared , to have her share of surprize , introduction , and pleasure . Th\n",
      "ir plans ; and it was an agreeable surprize to her , therefore , to perceive t\n",
      "talking aunt had taken me quite by surprize , it must have been the death of m\n",
      "f all the dialogue which ensued of surprize , and inquiry , and congratulation\n",
      " the present . They might chuse to surprize her .\" Mrs . Cole had many to agre\n",
      "the mode of it , the mystery , the surprize , is more like a young woman ' s s\n",
      " to her song took her agreeably by surprize -- a second , slightly but correct\n",
      "\" \" Oh ! no -- there is nothing to surprize one at all .-- A pretty fortune ; \n",
      "t to be considered . Emma ' s only surprize was that Jane Fairfax should accep\n",
      "of your admiration may take you by surprize some day or other .\" Mr . Knightle\n",
      "ation for her will ever take me by surprize .-- I never had a thought of her i\n",
      " expected by the best judges , for surprize -- but there was great joy . Mr . \n",
      " sound of at first , without great surprize . \" So unreasonably early !\" she w\n",
      "d Frank Churchill , with a look of surprize and displeasure .-- \" That is easy\n",
      "; and Emma could imagine with what surprize and mortification she must be retu\n",
      "tled that Jane should go . Quite a surprize to me ! I had not the least idea !\n",
      " . It is impossible to express our surprize . He came to speak to his father o\n",
      "g engaged !\" Emma even jumped with surprize ;-- and , horror - struck , exclai\n"
     ]
    }
   ],
   "source": [
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25 26 austen-emma.txt\n",
      "5 26 17 austen-persuasion.txt\n",
      "5 28 22 austen-sense.txt\n",
      "4 34 79 bible-kjv.txt\n",
      "5 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "4 20 13 carroll-alice.txt\n",
      "5 20 12 chesterton-ball.txt\n",
      "5 23 11 chesterton-brown.txt\n",
      "5 18 11 chesterton-thursday.txt\n",
      "4 21 25 edgeworth-parents.txt\n",
      "5 26 15 melville-moby_dick.txt\n",
      "5 52 11 milton-paradise.txt\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "for fileid in gutenberg.fileids():\n",
    "    \"\"\"\n",
    "    ===== DESCRIPTION =====\n",
    "    This program displays three statistics for each text: \n",
    "    average word length, average sentence length, \n",
    "    and the number of times each vocabulary item \n",
    "    appears in the text on average (our lexical diversity score)\n",
    "    \n",
    "    ===== FUNCTIONS =====\n",
    "    raw() function gives us the contents of the file without any linguistic processing\n",
    "    sents() function divides the text up into its sentences\n",
    "    \"\"\"\n",
    "\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macbeth_sentences is a list of 1907 lists\n",
    "len(macbeth_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Double',\n",
       " ',',\n",
       " 'double',\n",
       " ',',\n",
       " 'toile',\n",
       " 'and',\n",
       " 'trouble',\n",
       " ';',\n",
       " 'Fire',\n",
       " 'burne',\n",
       " ',',\n",
       " 'and',\n",
       " 'Cauldron',\n",
       " 'bubble']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect list #1116\n",
    "macbeth_sentences[1116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Doubtfull',\n",
       "  'it',\n",
       "  'stood',\n",
       "  ',',\n",
       "  'As',\n",
       "  'two',\n",
       "  'spent',\n",
       "  'Swimmers',\n",
       "  ',',\n",
       "  'that',\n",
       "  'doe',\n",
       "  'cling',\n",
       "  'together',\n",
       "  ',',\n",
       "  'And',\n",
       "  'choake',\n",
       "  'their',\n",
       "  'Art',\n",
       "  ':',\n",
       "  'The',\n",
       "  'mercilesse',\n",
       "  'Macdonwald',\n",
       "  '(',\n",
       "  'Worthie',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'Rebell',\n",
       "  ',',\n",
       "  'for',\n",
       "  'to',\n",
       "  'that',\n",
       "  'The',\n",
       "  'multiplying',\n",
       "  'Villanies',\n",
       "  'of',\n",
       "  'Nature',\n",
       "  'Doe',\n",
       "  'swarme',\n",
       "  'vpon',\n",
       "  'him',\n",
       "  ')',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Westerne',\n",
       "  'Isles',\n",
       "  'Of',\n",
       "  'Kernes',\n",
       "  'and',\n",
       "  'Gallowgrosses',\n",
       "  'is',\n",
       "  'supply',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  ',',\n",
       "  'And',\n",
       "  'Fortune',\n",
       "  'on',\n",
       "  'his',\n",
       "  'damned',\n",
       "  'Quarry',\n",
       "  'smiling',\n",
       "  ',',\n",
       "  'Shew',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'a',\n",
       "  'Rebells',\n",
       "  'Whore',\n",
       "  ':',\n",
       "  'but',\n",
       "  'all',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'weake',\n",
       "  ':',\n",
       "  'For',\n",
       "  'braue',\n",
       "  'Macbeth',\n",
       "  '(',\n",
       "  'well',\n",
       "  'hee',\n",
       "  'deserues',\n",
       "  'that',\n",
       "  'Name',\n",
       "  ')',\n",
       "  'Disdayning',\n",
       "  'Fortune',\n",
       "  ',',\n",
       "  'with',\n",
       "  'his',\n",
       "  'brandisht',\n",
       "  'Steele',\n",
       "  ',',\n",
       "  'Which',\n",
       "  'smoak',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'with',\n",
       "  'bloody',\n",
       "  'execution',\n",
       "  '(',\n",
       "  'Like',\n",
       "  'Valours',\n",
       "  'Minion',\n",
       "  ')',\n",
       "  'caru',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'out',\n",
       "  'his',\n",
       "  'passage',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'hee',\n",
       "  'fac',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'the',\n",
       "  'Slaue',\n",
       "  ':',\n",
       "  'Which',\n",
       "  'neu',\n",
       "  \"'\",\n",
       "  'r',\n",
       "  'shooke',\n",
       "  'hands',\n",
       "  ',',\n",
       "  'nor',\n",
       "  'bad',\n",
       "  'farwell',\n",
       "  'to',\n",
       "  'him',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'he',\n",
       "  'vnseam',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'him',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Naue',\n",
       "  'toth',\n",
       "  \"'\",\n",
       "  'Chops',\n",
       "  ',',\n",
       "  'And',\n",
       "  'fix',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'his',\n",
       "  'Head',\n",
       "  'vpon',\n",
       "  'our',\n",
       "  'Battlements']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for list with longest sentence\n",
    "longest_len = max(len(s) for s in macbeth_sentences)\n",
    "[s for s in macbeth_sentences if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Web and Chat Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to se ...\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop ...\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl ...\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr ...\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun ...\n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb ...\n"
     ]
    }
   ],
   "source": [
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'hot',\n",
       " 'pics',\n",
       " 'of',\n",
       " 'a',\n",
       " 'female',\n",
       " ',',\n",
       " 'I',\n",
       " 'can',\n",
       " 'look',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mirror',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Brown Corpus\n",
    "The Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(fileids=['cg22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents(categories=['news', 'editorial', 'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94 could: 87 may: 93 might: 38 must: 53 will: 389 "
     ]
    }
   ],
   "source": [
    "news_text = brown.words(categories='news')\n",
    "# # nltk.corpus.reader.util.ConcatenatedCorpusView\n",
    "# type(news_text)\n",
    "\n",
    "fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
    "\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "\n",
    "for m in modals:\n",
    "    \"\"\"\n",
    "    We need to include end=' ' \n",
    "    in order for the print function to put its output on a single line.\n",
    "    \"\"\"\n",
    "    print(m + ':', fdist[m], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "            (genre, word)\n",
    "            for genre in brown.categories()\n",
    "            for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reuters Corpus\n",
    "Unlike the Brown Corpus, categories in the Reuters corpus overlap with each other, simply because a news story often covers multiple topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14826',\n",
       " 'test/14828',\n",
       " 'test/14829',\n",
       " 'test/14832',\n",
       " 'test/14833',\n",
       " 'test/14839',\n",
       " 'test/14840',\n",
       " 'test/14841',\n",
       " 'test/14842',\n",
       " 'test/14843',\n",
       " 'test/14844',\n",
       " 'test/14849',\n",
       " 'test/14852',\n",
       " 'test/14854',\n",
       " 'test/14858',\n",
       " 'test/14859',\n",
       " 'test/14860',\n",
       " 'test/14861',\n",
       " 'test/14862',\n",
       " 'test/14863',\n",
       " 'test/14865',\n",
       " 'test/14867',\n",
       " 'test/14872',\n",
       " 'test/14873',\n",
       " 'test/14875',\n",
       " 'test/14876',\n",
       " 'test/14877',\n",
       " 'test/14881',\n",
       " 'test/14882',\n",
       " 'test/14885',\n",
       " 'test/14886',\n",
       " 'test/14888',\n",
       " 'test/14890',\n",
       " 'test/14891',\n",
       " 'test/14892',\n",
       " 'test/14899',\n",
       " 'test/14900',\n",
       " 'test/14903',\n",
       " 'test/14904',\n",
       " 'test/14907',\n",
       " 'test/14909',\n",
       " 'test/14911',\n",
       " 'test/14912',\n",
       " 'test/14913',\n",
       " 'test/14918',\n",
       " 'test/14919',\n",
       " 'test/14921',\n",
       " 'test/14922',\n",
       " 'test/14923',\n",
       " 'test/14926',\n",
       " 'test/14928',\n",
       " 'test/14930',\n",
       " 'test/14931',\n",
       " 'test/14932',\n",
       " 'test/14933',\n",
       " 'test/14934',\n",
       " 'test/14941',\n",
       " 'test/14943',\n",
       " 'test/14949',\n",
       " 'test/14951',\n",
       " 'test/14954',\n",
       " 'test/14957',\n",
       " 'test/14958',\n",
       " 'test/14959',\n",
       " 'test/14960',\n",
       " 'test/14962',\n",
       " 'test/14963',\n",
       " 'test/14964',\n",
       " 'test/14965',\n",
       " 'test/14967',\n",
       " 'test/14968',\n",
       " 'test/14969',\n",
       " 'test/14970',\n",
       " 'test/14971',\n",
       " 'test/14974',\n",
       " 'test/14975',\n",
       " 'test/14978',\n",
       " 'test/14981',\n",
       " 'test/14982',\n",
       " 'test/14983',\n",
       " 'test/14984',\n",
       " 'test/14985',\n",
       " 'test/14986',\n",
       " 'test/14987',\n",
       " 'test/14988',\n",
       " 'test/14993',\n",
       " 'test/14995',\n",
       " 'test/14998',\n",
       " 'test/15000',\n",
       " 'test/15001',\n",
       " 'test/15002',\n",
       " 'test/15004',\n",
       " 'test/15005',\n",
       " 'test/15006',\n",
       " 'test/15011',\n",
       " 'test/15012',\n",
       " 'test/15013',\n",
       " 'test/15016',\n",
       " 'test/15017',\n",
       " 'test/15020',\n",
       " 'test/15023',\n",
       " 'test/15024',\n",
       " 'test/15026',\n",
       " 'test/15027',\n",
       " 'test/15028',\n",
       " 'test/15029',\n",
       " 'test/15031',\n",
       " 'test/15032',\n",
       " 'test/15033',\n",
       " 'test/15037',\n",
       " 'test/15038',\n",
       " 'test/15043',\n",
       " 'test/15045',\n",
       " 'test/15046',\n",
       " 'test/15048',\n",
       " 'test/15049',\n",
       " 'test/15052',\n",
       " 'test/15053',\n",
       " 'test/15055',\n",
       " 'test/15056',\n",
       " 'test/15060',\n",
       " 'test/15061',\n",
       " 'test/15062',\n",
       " 'test/15063',\n",
       " 'test/15065',\n",
       " 'test/15067',\n",
       " 'test/15069',\n",
       " 'test/15070',\n",
       " 'test/15074',\n",
       " 'test/15077',\n",
       " 'test/15078',\n",
       " 'test/15079',\n",
       " 'test/15082',\n",
       " 'test/15090',\n",
       " 'test/15091',\n",
       " 'test/15092',\n",
       " 'test/15093',\n",
       " 'test/15094',\n",
       " 'test/15095',\n",
       " 'test/15096',\n",
       " 'test/15097',\n",
       " 'test/15103',\n",
       " 'test/15104',\n",
       " 'test/15106',\n",
       " 'test/15107',\n",
       " 'test/15109',\n",
       " 'test/15110',\n",
       " 'test/15111',\n",
       " 'test/15112',\n",
       " 'test/15118',\n",
       " 'test/15119',\n",
       " 'test/15120',\n",
       " 'test/15121',\n",
       " 'test/15122',\n",
       " 'test/15124',\n",
       " 'test/15126',\n",
       " 'test/15128',\n",
       " 'test/15129',\n",
       " 'test/15130',\n",
       " 'test/15132',\n",
       " 'test/15136',\n",
       " 'test/15138',\n",
       " 'test/15141',\n",
       " 'test/15144',\n",
       " 'test/15145',\n",
       " 'test/15146',\n",
       " 'test/15149',\n",
       " 'test/15152',\n",
       " 'test/15153',\n",
       " 'test/15154',\n",
       " 'test/15156',\n",
       " 'test/15157',\n",
       " 'test/15161',\n",
       " 'test/15162',\n",
       " 'test/15171',\n",
       " 'test/15172',\n",
       " 'test/15175',\n",
       " 'test/15179',\n",
       " 'test/15180',\n",
       " 'test/15185',\n",
       " 'test/15188',\n",
       " 'test/15189',\n",
       " 'test/15190',\n",
       " 'test/15193',\n",
       " 'test/15194',\n",
       " 'test/15197',\n",
       " 'test/15198',\n",
       " 'test/15200',\n",
       " 'test/15204',\n",
       " 'test/15205',\n",
       " 'test/15206',\n",
       " 'test/15207',\n",
       " 'test/15208',\n",
       " 'test/15210',\n",
       " 'test/15211',\n",
       " 'test/15212',\n",
       " 'test/15213',\n",
       " 'test/15217',\n",
       " 'test/15219',\n",
       " 'test/15220',\n",
       " 'test/15221',\n",
       " 'test/15222',\n",
       " 'test/15223',\n",
       " 'test/15226',\n",
       " 'test/15227',\n",
       " 'test/15230',\n",
       " 'test/15233',\n",
       " 'test/15234',\n",
       " 'test/15237',\n",
       " 'test/15238',\n",
       " 'test/15239',\n",
       " 'test/15240',\n",
       " 'test/15242',\n",
       " 'test/15243',\n",
       " 'test/15244',\n",
       " 'test/15246',\n",
       " 'test/15247',\n",
       " 'test/15250',\n",
       " 'test/15253',\n",
       " 'test/15254',\n",
       " 'test/15255',\n",
       " 'test/15258',\n",
       " 'test/15259',\n",
       " 'test/15262',\n",
       " 'test/15263',\n",
       " 'test/15264',\n",
       " 'test/15265',\n",
       " 'test/15270',\n",
       " 'test/15271',\n",
       " 'test/15273',\n",
       " 'test/15274',\n",
       " 'test/15276',\n",
       " 'test/15278',\n",
       " 'test/15280',\n",
       " 'test/15281',\n",
       " 'test/15283',\n",
       " 'test/15287',\n",
       " 'test/15290',\n",
       " 'test/15292',\n",
       " 'test/15294',\n",
       " 'test/15295',\n",
       " 'test/15296',\n",
       " 'test/15299',\n",
       " 'test/15300',\n",
       " 'test/15302',\n",
       " 'test/15303',\n",
       " 'test/15306',\n",
       " 'test/15307',\n",
       " 'test/15308',\n",
       " 'test/15309',\n",
       " 'test/15310',\n",
       " 'test/15311',\n",
       " 'test/15312',\n",
       " 'test/15313',\n",
       " 'test/15314',\n",
       " 'test/15315',\n",
       " 'test/15321',\n",
       " 'test/15322',\n",
       " 'test/15324',\n",
       " 'test/15325',\n",
       " 'test/15326',\n",
       " 'test/15327',\n",
       " 'test/15329',\n",
       " 'test/15335',\n",
       " 'test/15336',\n",
       " 'test/15337',\n",
       " 'test/15339',\n",
       " 'test/15341',\n",
       " 'test/15344',\n",
       " 'test/15345',\n",
       " 'test/15348',\n",
       " 'test/15349',\n",
       " 'test/15351',\n",
       " 'test/15352',\n",
       " 'test/15354',\n",
       " 'test/15356',\n",
       " 'test/15357',\n",
       " 'test/15359',\n",
       " 'test/15363',\n",
       " 'test/15364',\n",
       " 'test/15365',\n",
       " 'test/15366',\n",
       " 'test/15367',\n",
       " 'test/15368',\n",
       " 'test/15372',\n",
       " 'test/15375',\n",
       " 'test/15378',\n",
       " 'test/15379',\n",
       " 'test/15380',\n",
       " 'test/15383',\n",
       " 'test/15384',\n",
       " 'test/15386',\n",
       " 'test/15387',\n",
       " 'test/15388',\n",
       " 'test/15389',\n",
       " 'test/15391',\n",
       " 'test/15394',\n",
       " 'test/15396',\n",
       " 'test/15397',\n",
       " 'test/15400',\n",
       " 'test/15404',\n",
       " 'test/15406',\n",
       " 'test/15409',\n",
       " 'test/15410',\n",
       " 'test/15411',\n",
       " 'test/15413',\n",
       " 'test/15415',\n",
       " 'test/15416',\n",
       " 'test/15417',\n",
       " 'test/15420',\n",
       " 'test/15421',\n",
       " 'test/15424',\n",
       " 'test/15425',\n",
       " 'test/15427',\n",
       " 'test/15428',\n",
       " 'test/15429',\n",
       " 'test/15430',\n",
       " 'test/15431',\n",
       " 'test/15432',\n",
       " 'test/15436',\n",
       " 'test/15438',\n",
       " 'test/15441',\n",
       " 'test/15442',\n",
       " 'test/15444',\n",
       " 'test/15446',\n",
       " 'test/15447',\n",
       " 'test/15448',\n",
       " 'test/15449',\n",
       " 'test/15450',\n",
       " 'test/15451',\n",
       " 'test/15452',\n",
       " 'test/15453',\n",
       " 'test/15454',\n",
       " 'test/15455',\n",
       " 'test/15457',\n",
       " 'test/15459',\n",
       " 'test/15460',\n",
       " 'test/15462',\n",
       " 'test/15464',\n",
       " 'test/15467',\n",
       " 'test/15468',\n",
       " 'test/15471',\n",
       " 'test/15472',\n",
       " 'test/15476',\n",
       " 'test/15477',\n",
       " 'test/15478',\n",
       " 'test/15479',\n",
       " 'test/15481',\n",
       " 'test/15482',\n",
       " 'test/15483',\n",
       " 'test/15484',\n",
       " 'test/15485',\n",
       " 'test/15487',\n",
       " 'test/15489',\n",
       " 'test/15494',\n",
       " 'test/15495',\n",
       " 'test/15496',\n",
       " 'test/15500',\n",
       " 'test/15501',\n",
       " 'test/15503',\n",
       " 'test/15504',\n",
       " 'test/15510',\n",
       " 'test/15511',\n",
       " 'test/15515',\n",
       " 'test/15520',\n",
       " 'test/15521',\n",
       " 'test/15522',\n",
       " 'test/15523',\n",
       " 'test/15527',\n",
       " 'test/15528',\n",
       " 'test/15531',\n",
       " 'test/15532',\n",
       " 'test/15535',\n",
       " 'test/15536',\n",
       " 'test/15539',\n",
       " 'test/15540',\n",
       " 'test/15542',\n",
       " 'test/15543',\n",
       " 'test/15544',\n",
       " 'test/15545',\n",
       " 'test/15547',\n",
       " 'test/15548',\n",
       " 'test/15549',\n",
       " 'test/15550',\n",
       " 'test/15551',\n",
       " 'test/15552',\n",
       " 'test/15553',\n",
       " 'test/15556',\n",
       " 'test/15558',\n",
       " 'test/15559',\n",
       " 'test/15560',\n",
       " 'test/15561',\n",
       " 'test/15562',\n",
       " 'test/15563',\n",
       " 'test/15565',\n",
       " 'test/15566',\n",
       " 'test/15567',\n",
       " 'test/15568',\n",
       " 'test/15569',\n",
       " 'test/15570',\n",
       " 'test/15571',\n",
       " 'test/15572',\n",
       " 'test/15573',\n",
       " 'test/15574',\n",
       " 'test/15575',\n",
       " 'test/15578',\n",
       " 'test/15579',\n",
       " 'test/15580',\n",
       " 'test/15581',\n",
       " 'test/15582',\n",
       " 'test/15583',\n",
       " 'test/15584',\n",
       " 'test/15585',\n",
       " 'test/15590',\n",
       " 'test/15591',\n",
       " 'test/15593',\n",
       " 'test/15594',\n",
       " 'test/15595',\n",
       " 'test/15596',\n",
       " 'test/15597',\n",
       " 'test/15598',\n",
       " 'test/15600',\n",
       " 'test/15601',\n",
       " 'test/15602',\n",
       " 'test/15603',\n",
       " 'test/15605',\n",
       " 'test/15607',\n",
       " 'test/15610',\n",
       " 'test/15613',\n",
       " 'test/15615',\n",
       " 'test/15616',\n",
       " 'test/15617',\n",
       " 'test/15618',\n",
       " 'test/15620',\n",
       " 'test/15621',\n",
       " 'test/15623',\n",
       " 'test/15624',\n",
       " 'test/15625',\n",
       " 'test/15626',\n",
       " 'test/15629',\n",
       " 'test/15632',\n",
       " 'test/15634',\n",
       " 'test/15636',\n",
       " 'test/15637',\n",
       " 'test/15639',\n",
       " 'test/15640',\n",
       " 'test/15641',\n",
       " 'test/15642',\n",
       " 'test/15643',\n",
       " 'test/15646',\n",
       " 'test/15648',\n",
       " 'test/15649',\n",
       " 'test/15651',\n",
       " 'test/15653',\n",
       " 'test/15655',\n",
       " 'test/15656',\n",
       " 'test/15664',\n",
       " 'test/15666',\n",
       " 'test/15667',\n",
       " 'test/15668',\n",
       " 'test/15669',\n",
       " 'test/15672',\n",
       " 'test/15674',\n",
       " 'test/15675',\n",
       " 'test/15676',\n",
       " 'test/15677',\n",
       " 'test/15679',\n",
       " 'test/15680',\n",
       " 'test/15682',\n",
       " 'test/15686',\n",
       " 'test/15688',\n",
       " 'test/15689',\n",
       " 'test/15691',\n",
       " 'test/15692',\n",
       " 'test/15694',\n",
       " 'test/15695',\n",
       " 'test/15696',\n",
       " 'test/15698',\n",
       " 'test/15702',\n",
       " 'test/15703',\n",
       " 'test/15704',\n",
       " 'test/15707',\n",
       " 'test/15708',\n",
       " 'test/15709',\n",
       " 'test/15710',\n",
       " 'test/15713',\n",
       " 'test/15715',\n",
       " 'test/15717',\n",
       " 'test/15719',\n",
       " 'test/15720',\n",
       " 'test/15721',\n",
       " 'test/15723',\n",
       " 'test/15725',\n",
       " 'test/15726',\n",
       " 'test/15727',\n",
       " 'test/15728',\n",
       " 'test/15729',\n",
       " 'test/15732',\n",
       " 'test/15733',\n",
       " 'test/15736',\n",
       " 'test/15737',\n",
       " 'test/15739',\n",
       " 'test/15742',\n",
       " 'test/15749',\n",
       " 'test/15751',\n",
       " 'test/15753',\n",
       " 'test/15757',\n",
       " 'test/15759',\n",
       " 'test/15762',\n",
       " 'test/15767',\n",
       " 'test/15768',\n",
       " 'test/15769',\n",
       " 'test/15772',\n",
       " 'test/15777',\n",
       " 'test/15778',\n",
       " 'test/15780',\n",
       " 'test/15782',\n",
       " 'test/15785',\n",
       " 'test/15790',\n",
       " 'test/15793',\n",
       " 'test/15797',\n",
       " 'test/15798',\n",
       " 'test/15800',\n",
       " 'test/15801',\n",
       " 'test/15803',\n",
       " 'test/15804',\n",
       " 'test/15805',\n",
       " 'test/15807',\n",
       " 'test/15808',\n",
       " 'test/15810',\n",
       " 'test/15811',\n",
       " 'test/15816',\n",
       " 'test/15817',\n",
       " 'test/15819',\n",
       " 'test/15821',\n",
       " 'test/15822',\n",
       " 'test/15823',\n",
       " 'test/15829',\n",
       " 'test/15831',\n",
       " 'test/15832',\n",
       " 'test/15833',\n",
       " 'test/15834',\n",
       " 'test/15836',\n",
       " 'test/15838',\n",
       " 'test/15840',\n",
       " 'test/15841',\n",
       " 'test/15842',\n",
       " 'test/15844',\n",
       " 'test/15845',\n",
       " 'test/15846',\n",
       " 'test/15847',\n",
       " 'test/15851',\n",
       " 'test/15852',\n",
       " 'test/15853',\n",
       " 'test/15854',\n",
       " 'test/15855',\n",
       " 'test/15856',\n",
       " 'test/15858',\n",
       " 'test/15859',\n",
       " 'test/15860',\n",
       " 'test/15861',\n",
       " 'test/15863',\n",
       " 'test/15864',\n",
       " 'test/15865',\n",
       " 'test/15866',\n",
       " 'test/15867',\n",
       " 'test/15868',\n",
       " 'test/15869',\n",
       " 'test/15870',\n",
       " 'test/15871',\n",
       " 'test/15872',\n",
       " 'test/15874',\n",
       " 'test/15875',\n",
       " 'test/15876',\n",
       " 'test/15877',\n",
       " 'test/15878',\n",
       " 'test/15879',\n",
       " 'test/15881',\n",
       " 'test/15885',\n",
       " 'test/15886',\n",
       " 'test/15888',\n",
       " 'test/15889',\n",
       " 'test/15890',\n",
       " 'test/15892',\n",
       " 'test/15893',\n",
       " 'test/15894',\n",
       " 'test/15895',\n",
       " 'test/15896',\n",
       " 'test/15897',\n",
       " 'test/15898',\n",
       " 'test/15899',\n",
       " 'test/15900',\n",
       " 'test/15901',\n",
       " 'test/15902',\n",
       " 'test/15903',\n",
       " 'test/15904',\n",
       " 'test/15906',\n",
       " 'test/15908',\n",
       " 'test/15909',\n",
       " 'test/15910',\n",
       " 'test/15911',\n",
       " 'test/15912',\n",
       " 'test/15913',\n",
       " 'test/15914',\n",
       " 'test/15916',\n",
       " 'test/15917',\n",
       " 'test/15918',\n",
       " 'test/15920',\n",
       " 'test/15921',\n",
       " 'test/15922',\n",
       " 'test/15923',\n",
       " 'test/15924',\n",
       " 'test/15925',\n",
       " 'test/15927',\n",
       " 'test/15928',\n",
       " 'test/15929',\n",
       " 'test/15930',\n",
       " 'test/15932',\n",
       " 'test/15933',\n",
       " 'test/15934',\n",
       " 'test/15937',\n",
       " 'test/15939',\n",
       " 'test/15942',\n",
       " 'test/15944',\n",
       " 'test/15949',\n",
       " 'test/15950',\n",
       " 'test/15951',\n",
       " 'test/15952',\n",
       " 'test/15953',\n",
       " 'test/15956',\n",
       " 'test/15959',\n",
       " 'test/15960',\n",
       " 'test/15961',\n",
       " 'test/15963',\n",
       " 'test/15964',\n",
       " 'test/15967',\n",
       " 'test/15968',\n",
       " 'test/15969',\n",
       " 'test/15970',\n",
       " 'test/15973',\n",
       " 'test/15975',\n",
       " 'test/15976',\n",
       " 'test/15977',\n",
       " 'test/15978',\n",
       " 'test/15979',\n",
       " 'test/15980',\n",
       " 'test/15981',\n",
       " 'test/15984',\n",
       " 'test/15985',\n",
       " 'test/15987',\n",
       " 'test/15988',\n",
       " 'test/15989',\n",
       " 'test/15993',\n",
       " 'test/15995',\n",
       " 'test/15996',\n",
       " 'test/15997',\n",
       " 'test/15999',\n",
       " 'test/16002',\n",
       " 'test/16003',\n",
       " 'test/16004',\n",
       " 'test/16005',\n",
       " 'test/16006',\n",
       " 'test/16007',\n",
       " 'test/16009',\n",
       " 'test/16012',\n",
       " 'test/16013',\n",
       " 'test/16014',\n",
       " 'test/16015',\n",
       " 'test/16016',\n",
       " 'test/16021',\n",
       " 'test/16022',\n",
       " 'test/16023',\n",
       " 'test/16026',\n",
       " 'test/16029',\n",
       " 'test/16030',\n",
       " 'test/16033',\n",
       " 'test/16037',\n",
       " 'test/16040',\n",
       " 'test/16041',\n",
       " 'test/16045',\n",
       " 'test/16052',\n",
       " 'test/16053',\n",
       " 'test/16055',\n",
       " 'test/16063',\n",
       " 'test/16066',\n",
       " 'test/16067',\n",
       " 'test/16068',\n",
       " 'test/16069',\n",
       " 'test/16071',\n",
       " 'test/16072',\n",
       " 'test/16074',\n",
       " 'test/16075',\n",
       " 'test/16076',\n",
       " 'test/16077',\n",
       " 'test/16079',\n",
       " 'test/16080',\n",
       " 'test/16083',\n",
       " 'test/16086',\n",
       " 'test/16088',\n",
       " 'test/16091',\n",
       " 'test/16093',\n",
       " 'test/16094',\n",
       " 'test/16095',\n",
       " 'test/16096',\n",
       " 'test/16097',\n",
       " 'test/16098',\n",
       " 'test/16099',\n",
       " 'test/16100',\n",
       " 'test/16103',\n",
       " 'test/16106',\n",
       " 'test/16107',\n",
       " 'test/16108',\n",
       " 'test/16110',\n",
       " 'test/16111',\n",
       " 'test/16112',\n",
       " 'test/16115',\n",
       " 'test/16117',\n",
       " 'test/16118',\n",
       " 'test/16119',\n",
       " 'test/16120',\n",
       " 'test/16122',\n",
       " 'test/16123',\n",
       " 'test/16125',\n",
       " 'test/16126',\n",
       " 'test/16130',\n",
       " 'test/16133',\n",
       " 'test/16134',\n",
       " 'test/16136',\n",
       " 'test/16139',\n",
       " 'test/16140',\n",
       " 'test/16141',\n",
       " 'test/16142',\n",
       " 'test/16143',\n",
       " 'test/16144',\n",
       " 'test/16145',\n",
       " 'test/16146',\n",
       " 'test/16147',\n",
       " 'test/16148',\n",
       " 'test/16149',\n",
       " 'test/16150',\n",
       " 'test/16152',\n",
       " 'test/16155',\n",
       " 'test/16158',\n",
       " 'test/16159',\n",
       " 'test/16161',\n",
       " 'test/16162',\n",
       " 'test/16163',\n",
       " 'test/16164',\n",
       " 'test/16166',\n",
       " 'test/16170',\n",
       " 'test/16171',\n",
       " 'test/16172',\n",
       " 'test/16173',\n",
       " 'test/16175',\n",
       " 'test/16176',\n",
       " 'test/16177',\n",
       " 'test/16179',\n",
       " 'test/16180',\n",
       " 'test/16185',\n",
       " 'test/16188',\n",
       " 'test/16189',\n",
       " 'test/16190',\n",
       " 'test/16193',\n",
       " 'test/16194',\n",
       " 'test/16195',\n",
       " 'test/16196',\n",
       " 'test/16197',\n",
       " 'test/16200',\n",
       " 'test/16201',\n",
       " 'test/16202',\n",
       " 'test/16203',\n",
       " 'test/16206',\n",
       " 'test/16207',\n",
       " 'test/16210',\n",
       " 'test/16211',\n",
       " 'test/16212',\n",
       " 'test/16213',\n",
       " 'test/16214',\n",
       " 'test/16215',\n",
       " 'test/16216',\n",
       " 'test/16219',\n",
       " 'test/16221',\n",
       " 'test/16223',\n",
       " 'test/16225',\n",
       " 'test/16226',\n",
       " 'test/16228',\n",
       " 'test/16230',\n",
       " 'test/16232',\n",
       " 'test/16233',\n",
       " 'test/16234',\n",
       " 'test/16236',\n",
       " 'test/16238',\n",
       " 'test/16241',\n",
       " 'test/16243',\n",
       " 'test/16244',\n",
       " 'test/16246',\n",
       " 'test/16247',\n",
       " 'test/16248',\n",
       " 'test/16250',\n",
       " 'test/16251',\n",
       " 'test/16252',\n",
       " 'test/16255',\n",
       " 'test/16256',\n",
       " 'test/16257',\n",
       " 'test/16258',\n",
       " 'test/16260',\n",
       " 'test/16262',\n",
       " 'test/16263',\n",
       " 'test/16264',\n",
       " 'test/16265',\n",
       " 'test/16266',\n",
       " 'test/16268',\n",
       " 'test/16269',\n",
       " 'test/16270',\n",
       " 'test/16271',\n",
       " 'test/16274',\n",
       " 'test/16275',\n",
       " 'test/16277',\n",
       " 'test/16278',\n",
       " 'test/16279',\n",
       " 'test/16281',\n",
       " 'test/16282',\n",
       " 'test/16283',\n",
       " 'test/16284',\n",
       " 'test/16285',\n",
       " 'test/16286',\n",
       " 'test/16287',\n",
       " 'test/16288',\n",
       " 'test/16289',\n",
       " 'test/16291',\n",
       " 'test/16294',\n",
       " 'test/16297',\n",
       " 'test/16298',\n",
       " 'test/16299',\n",
       " 'test/16300',\n",
       " 'test/16301',\n",
       " 'test/16302',\n",
       " 'test/16303',\n",
       " 'test/16304',\n",
       " 'test/16307',\n",
       " 'test/16310',\n",
       " 'test/16311',\n",
       " 'test/16312',\n",
       " 'test/16314',\n",
       " 'test/16315',\n",
       " 'test/16316',\n",
       " 'test/16317',\n",
       " 'test/16318',\n",
       " 'test/16319',\n",
       " 'test/16320',\n",
       " 'test/16324',\n",
       " 'test/16327',\n",
       " 'test/16331',\n",
       " 'test/16332',\n",
       " 'test/16336',\n",
       " 'test/16337',\n",
       " 'test/16339',\n",
       " 'test/16342',\n",
       " 'test/16343',\n",
       " 'test/16346',\n",
       " 'test/16347',\n",
       " 'test/16348',\n",
       " 'test/16350',\n",
       " 'test/16354',\n",
       " 'test/16357',\n",
       " 'test/16359',\n",
       " 'test/16360',\n",
       " 'test/16362',\n",
       " 'test/16363',\n",
       " 'test/16365',\n",
       " 'test/16366',\n",
       " 'test/16367',\n",
       " 'test/16369',\n",
       " 'test/16370',\n",
       " 'test/16371',\n",
       " 'test/16372',\n",
       " 'test/16374',\n",
       " 'test/16376',\n",
       " 'test/16377',\n",
       " 'test/16379',\n",
       " 'test/16380',\n",
       " 'test/16383',\n",
       " 'test/16385',\n",
       " 'test/16386',\n",
       " 'test/16388',\n",
       " 'test/16390',\n",
       " 'test/16392',\n",
       " 'test/16393',\n",
       " 'test/16394',\n",
       " 'test/16395',\n",
       " 'test/16396',\n",
       " 'test/16398',\n",
       " 'test/16399',\n",
       " 'test/16400',\n",
       " 'test/16401',\n",
       " 'test/16402',\n",
       " 'test/16403',\n",
       " 'test/16404',\n",
       " 'test/16405',\n",
       " 'test/16406',\n",
       " 'test/16407',\n",
       " 'test/16409',\n",
       " 'test/16410',\n",
       " 'test/16415',\n",
       " 'test/16417',\n",
       " 'test/16418',\n",
       " 'test/16419',\n",
       " 'test/16420',\n",
       " 'test/16421',\n",
       " 'test/16422',\n",
       " 'test/16424',\n",
       " 'test/16426',\n",
       " 'test/16427',\n",
       " 'test/16428',\n",
       " 'test/16429',\n",
       " 'test/16430',\n",
       " 'test/16432',\n",
       " 'test/16433',\n",
       " 'test/16434',\n",
       " 'test/16437',\n",
       " 'test/16438',\n",
       " 'test/16440',\n",
       " 'test/16441',\n",
       " 'test/16442',\n",
       " 'test/16443',\n",
       " 'test/16444',\n",
       " 'test/16448',\n",
       " 'test/16449',\n",
       " 'test/16450',\n",
       " 'test/16454',\n",
       " 'test/16457',\n",
       " 'test/16458',\n",
       " 'test/16459',\n",
       " 'test/16460',\n",
       " 'test/16461',\n",
       " 'test/16463',\n",
       " 'test/16465',\n",
       " 'test/16468',\n",
       " 'test/16469',\n",
       " 'test/16470',\n",
       " 'test/16471',\n",
       " 'test/16472',\n",
       " 'test/16473',\n",
       " 'test/16475',\n",
       " 'test/16476',\n",
       " 'test/16478',\n",
       " 'test/16479',\n",
       " 'test/16480',\n",
       " 'test/16481',\n",
       " 'test/16483',\n",
       " 'test/16486',\n",
       " 'test/16487',\n",
       " 'test/16488',\n",
       " 'test/16490',\n",
       " 'test/16492',\n",
       " 'test/16493',\n",
       " 'test/16495',\n",
       " 'test/16496',\n",
       " 'test/16499',\n",
       " 'test/16502',\n",
       " 'test/16505',\n",
       " 'test/16510',\n",
       " 'test/16512',\n",
       " 'test/16513',\n",
       " 'test/16518',\n",
       " 'test/16519',\n",
       " 'test/16521',\n",
       " 'test/16522',\n",
       " 'test/16523',\n",
       " 'test/16525',\n",
       " 'test/16527',\n",
       " 'test/16530',\n",
       " 'test/16531',\n",
       " 'test/16533',\n",
       " 'test/16538',\n",
       " 'test/16539',\n",
       " 'test/16545',\n",
       " 'test/16546',\n",
       " 'test/16549',\n",
       " 'test/16551',\n",
       " 'test/16554',\n",
       " 'test/16555',\n",
       " 'test/16561',\n",
       " 'test/16563',\n",
       " 'test/16564',\n",
       " 'test/16565',\n",
       " 'test/16568',\n",
       " 'test/16569',\n",
       " 'test/16570',\n",
       " 'test/16574',\n",
       " 'test/16577',\n",
       " 'test/16581',\n",
       " 'test/16583',\n",
       " 'test/16584',\n",
       " 'test/16585',\n",
       " 'test/16587',\n",
       " 'test/16588',\n",
       " 'test/16589',\n",
       " 'test/16590',\n",
       " 'test/16591',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acq',\n",
       " 'alum',\n",
       " 'barley',\n",
       " 'bop',\n",
       " 'carcass',\n",
       " 'castor-oil',\n",
       " 'cocoa',\n",
       " 'coconut',\n",
       " 'coconut-oil',\n",
       " 'coffee',\n",
       " 'copper',\n",
       " 'copra-cake',\n",
       " 'corn',\n",
       " 'cotton',\n",
       " 'cotton-oil',\n",
       " 'cpi',\n",
       " 'cpu',\n",
       " 'crude',\n",
       " 'dfl',\n",
       " 'dlr',\n",
       " 'dmk',\n",
       " 'earn',\n",
       " 'fuel',\n",
       " 'gas',\n",
       " 'gnp',\n",
       " 'gold',\n",
       " 'grain',\n",
       " 'groundnut',\n",
       " 'groundnut-oil',\n",
       " 'heat',\n",
       " 'hog',\n",
       " 'housing',\n",
       " 'income',\n",
       " 'instal-debt',\n",
       " 'interest',\n",
       " 'ipi',\n",
       " 'iron-steel',\n",
       " 'jet',\n",
       " 'jobs',\n",
       " 'l-cattle',\n",
       " 'lead',\n",
       " 'lei',\n",
       " 'lin-oil',\n",
       " 'livestock',\n",
       " 'lumber',\n",
       " 'meal-feed',\n",
       " 'money-fx',\n",
       " 'money-supply',\n",
       " 'naphtha',\n",
       " 'nat-gas',\n",
       " 'nickel',\n",
       " 'nkr',\n",
       " 'nzdlr',\n",
       " 'oat',\n",
       " 'oilseed',\n",
       " 'orange',\n",
       " 'palladium',\n",
       " 'palm-oil',\n",
       " 'palmkernel',\n",
       " 'pet-chem',\n",
       " 'platinum',\n",
       " 'potato',\n",
       " 'propane',\n",
       " 'rand',\n",
       " 'rape-oil',\n",
       " 'rapeseed',\n",
       " 'reserves',\n",
       " 'retail',\n",
       " 'rice',\n",
       " 'rubber',\n",
       " 'rye',\n",
       " 'ship',\n",
       " 'silver',\n",
       " 'sorghum',\n",
       " 'soy-meal',\n",
       " 'soy-oil',\n",
       " 'soybean',\n",
       " 'strategic-metal',\n",
       " 'sugar',\n",
       " 'sun-meal',\n",
       " 'sun-oil',\n",
       " 'sunseed',\n",
       " 'tea',\n",
       " 'tin',\n",
       " 'trade',\n",
       " 'veg-oil',\n",
       " 'wheat',\n",
       " 'wpi',\n",
       " 'yen',\n",
       " 'zinc']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barley', 'corn', 'grain', 'wheat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories('training/9865')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barley', 'corn', 'grain', 'money-fx', 'wheat']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/15618',\n",
       " 'test/15649',\n",
       " 'test/15676',\n",
       " 'test/15728',\n",
       " 'test/15871',\n",
       " 'test/15875',\n",
       " 'test/15952',\n",
       " 'test/17767',\n",
       " 'test/17769',\n",
       " 'test/18024',\n",
       " 'test/18263',\n",
       " 'test/18908',\n",
       " 'test/19275',\n",
       " 'test/19668',\n",
       " 'training/10175',\n",
       " 'training/1067',\n",
       " 'training/11208',\n",
       " 'training/11316',\n",
       " 'training/11885',\n",
       " 'training/12428',\n",
       " 'training/13099',\n",
       " 'training/13744',\n",
       " 'training/13795',\n",
       " 'training/13852',\n",
       " 'training/13856',\n",
       " 'training/1652',\n",
       " 'training/1970',\n",
       " 'training/2044',\n",
       " 'training/2171',\n",
       " 'training/2172',\n",
       " 'training/2191',\n",
       " 'training/2217',\n",
       " 'training/2232',\n",
       " 'training/3132',\n",
       " 'training/3324',\n",
       " 'training/395',\n",
       " 'training/4280',\n",
       " 'training/4296',\n",
       " 'training/5',\n",
       " 'training/501',\n",
       " 'training/5467',\n",
       " 'training/5610',\n",
       " 'training/5640',\n",
       " 'training/6626',\n",
       " 'training/7205',\n",
       " 'training/7579',\n",
       " 'training/8213',\n",
       " 'training/8257',\n",
       " 'training/8759',\n",
       " 'training/9865',\n",
       " 'training/9958']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids('barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14832',\n",
       " 'test/14858',\n",
       " 'test/15033',\n",
       " 'test/15043',\n",
       " 'test/15106',\n",
       " 'test/15287',\n",
       " 'test/15341',\n",
       " 'test/15618',\n",
       " 'test/15648',\n",
       " 'test/15649',\n",
       " 'test/15676',\n",
       " 'test/15686',\n",
       " 'test/15720',\n",
       " 'test/15728',\n",
       " 'test/15845',\n",
       " 'test/15856',\n",
       " 'test/15860',\n",
       " 'test/15863',\n",
       " 'test/15871',\n",
       " 'test/15875',\n",
       " 'test/15877',\n",
       " 'test/15890',\n",
       " 'test/15904',\n",
       " 'test/15906',\n",
       " 'test/15910',\n",
       " 'test/15911',\n",
       " 'test/15917',\n",
       " 'test/15952',\n",
       " 'test/15999',\n",
       " 'test/16012',\n",
       " 'test/16071',\n",
       " 'test/16099',\n",
       " 'test/16147',\n",
       " 'test/16525',\n",
       " 'test/16624',\n",
       " 'test/16751',\n",
       " 'test/16765',\n",
       " 'test/17503',\n",
       " 'test/17509',\n",
       " 'test/17722',\n",
       " 'test/17767',\n",
       " 'test/17769',\n",
       " 'test/18024',\n",
       " 'test/18035',\n",
       " 'test/18263',\n",
       " 'test/18482',\n",
       " 'test/18614',\n",
       " 'test/18908',\n",
       " 'test/18954',\n",
       " 'test/18973',\n",
       " 'test/19165',\n",
       " 'test/19275',\n",
       " 'test/19668',\n",
       " 'test/19721',\n",
       " 'test/19821',\n",
       " 'test/20018',\n",
       " 'test/20366',\n",
       " 'test/20637',\n",
       " 'test/20645',\n",
       " 'test/20649',\n",
       " 'test/20723',\n",
       " 'test/20763',\n",
       " 'test/21091',\n",
       " 'test/21243',\n",
       " 'test/21493',\n",
       " 'training/10120',\n",
       " 'training/10139',\n",
       " 'training/10172',\n",
       " 'training/10175',\n",
       " 'training/10319',\n",
       " 'training/10339',\n",
       " 'training/10487',\n",
       " 'training/10489',\n",
       " 'training/10519',\n",
       " 'training/1067',\n",
       " 'training/10701',\n",
       " 'training/10882',\n",
       " 'training/10956',\n",
       " 'training/11012',\n",
       " 'training/11085',\n",
       " 'training/11091',\n",
       " 'training/11208',\n",
       " 'training/11269',\n",
       " 'training/1131',\n",
       " 'training/11316',\n",
       " 'training/11392',\n",
       " 'training/11436',\n",
       " 'training/11607',\n",
       " 'training/11612',\n",
       " 'training/11729',\n",
       " 'training/11739',\n",
       " 'training/11769',\n",
       " 'training/11885',\n",
       " 'training/11936',\n",
       " 'training/11939',\n",
       " 'training/11964',\n",
       " 'training/12002',\n",
       " 'training/12052',\n",
       " 'training/12055',\n",
       " 'training/1215',\n",
       " 'training/12160',\n",
       " 'training/12311',\n",
       " 'training/12323',\n",
       " 'training/12372',\n",
       " 'training/12417',\n",
       " 'training/12428',\n",
       " 'training/12436',\n",
       " 'training/12500',\n",
       " 'training/12583',\n",
       " 'training/12587',\n",
       " 'training/1268',\n",
       " 'training/1273',\n",
       " 'training/12872',\n",
       " 'training/13099',\n",
       " 'training/13173',\n",
       " 'training/13179',\n",
       " 'training/1369',\n",
       " 'training/13744',\n",
       " 'training/13795',\n",
       " 'training/1385',\n",
       " 'training/13852',\n",
       " 'training/13856',\n",
       " 'training/1395',\n",
       " 'training/1399',\n",
       " 'training/14483',\n",
       " 'training/1582',\n",
       " 'training/1652',\n",
       " 'training/1777',\n",
       " 'training/1843',\n",
       " 'training/193',\n",
       " 'training/1952',\n",
       " 'training/197',\n",
       " 'training/1970',\n",
       " 'training/2044',\n",
       " 'training/2171',\n",
       " 'training/2172',\n",
       " 'training/2183',\n",
       " 'training/2191',\n",
       " 'training/2217',\n",
       " 'training/2232',\n",
       " 'training/2264',\n",
       " 'training/235',\n",
       " 'training/2382',\n",
       " 'training/2436',\n",
       " 'training/2456',\n",
       " 'training/2595',\n",
       " 'training/2599',\n",
       " 'training/2617',\n",
       " 'training/2727',\n",
       " 'training/2741',\n",
       " 'training/2749',\n",
       " 'training/2777',\n",
       " 'training/2848',\n",
       " 'training/2913',\n",
       " 'training/2922',\n",
       " 'training/2947',\n",
       " 'training/3132',\n",
       " 'training/3138',\n",
       " 'training/3191',\n",
       " 'training/327',\n",
       " 'training/3282',\n",
       " 'training/3299',\n",
       " 'training/3306',\n",
       " 'training/3324',\n",
       " 'training/3330',\n",
       " 'training/3337',\n",
       " 'training/3358',\n",
       " 'training/3401',\n",
       " 'training/3429',\n",
       " 'training/3847',\n",
       " 'training/3855',\n",
       " 'training/3881',\n",
       " 'training/3949',\n",
       " 'training/395',\n",
       " 'training/3979',\n",
       " 'training/3981',\n",
       " 'training/4047',\n",
       " 'training/4133',\n",
       " 'training/4280',\n",
       " 'training/4289',\n",
       " 'training/4296',\n",
       " 'training/4382',\n",
       " 'training/4490',\n",
       " 'training/4599',\n",
       " 'training/4825',\n",
       " 'training/4905',\n",
       " 'training/4939',\n",
       " 'training/4988',\n",
       " 'training/5',\n",
       " 'training/5003',\n",
       " 'training/501',\n",
       " 'training/5017',\n",
       " 'training/5033',\n",
       " 'training/5109',\n",
       " 'training/516',\n",
       " 'training/5185',\n",
       " 'training/5338',\n",
       " 'training/5467',\n",
       " 'training/5518',\n",
       " 'training/5531',\n",
       " 'training/5606',\n",
       " 'training/5610',\n",
       " 'training/5636',\n",
       " 'training/5637',\n",
       " 'training/5640',\n",
       " 'training/57',\n",
       " 'training/5847',\n",
       " 'training/5933',\n",
       " 'training/6',\n",
       " 'training/6142',\n",
       " 'training/6221',\n",
       " 'training/6236',\n",
       " 'training/6239',\n",
       " 'training/6259',\n",
       " 'training/6269',\n",
       " 'training/6386',\n",
       " 'training/6585',\n",
       " 'training/6588',\n",
       " 'training/6626',\n",
       " 'training/6735',\n",
       " 'training/6890',\n",
       " 'training/6897',\n",
       " 'training/694',\n",
       " 'training/7062',\n",
       " 'training/7205',\n",
       " 'training/7215',\n",
       " 'training/7336',\n",
       " 'training/7387',\n",
       " 'training/7389',\n",
       " 'training/7390',\n",
       " 'training/7395',\n",
       " 'training/7579',\n",
       " 'training/7700',\n",
       " 'training/7792',\n",
       " 'training/7917',\n",
       " 'training/7934',\n",
       " 'training/7943',\n",
       " 'training/8004',\n",
       " 'training/8140',\n",
       " 'training/8161',\n",
       " 'training/8166',\n",
       " 'training/8213',\n",
       " 'training/8257',\n",
       " 'training/8273',\n",
       " 'training/8400',\n",
       " 'training/8443',\n",
       " 'training/8446',\n",
       " 'training/8535',\n",
       " 'training/855',\n",
       " 'training/8759',\n",
       " 'training/8941',\n",
       " 'training/8983',\n",
       " 'training/8993',\n",
       " 'training/9058',\n",
       " 'training/9093',\n",
       " 'training/9094',\n",
       " 'training/934',\n",
       " 'training/9470',\n",
       " 'training/9521',\n",
       " 'training/9667',\n",
       " 'training/97',\n",
       " 'training/9865',\n",
       " 'training/9958',\n",
       " 'training/9989']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids(['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH',\n",
       " 'FREE',\n",
       " 'MARKET',\n",
       " 'CEREAL',\n",
       " 'EXPORT',\n",
       " 'BIDS',\n",
       " 'DETAILED',\n",
       " 'French',\n",
       " 'operators',\n",
       " 'have',\n",
       " 'requested',\n",
       " 'licences',\n",
       " 'to',\n",
       " 'export']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words('training/9865')[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(categories='barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THAI', 'TRADE', 'DEFICIT', 'WIDENS', 'IN', 'FIRST', ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(categories=['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Inaugural Address Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "\n",
    "# Get all files\n",
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789',\n",
       " '1793',\n",
       " '1797',\n",
       " '1801',\n",
       " '1805',\n",
       " '1809',\n",
       " '1813',\n",
       " '1817',\n",
       " '1821',\n",
       " '1825',\n",
       " '1829',\n",
       " '1833',\n",
       " '1837',\n",
       " '1841',\n",
       " '1845',\n",
       " '1849',\n",
       " '1853',\n",
       " '1857',\n",
       " '1861',\n",
       " '1865',\n",
       " '1869',\n",
       " '1873',\n",
       " '1877',\n",
       " '1881',\n",
       " '1885',\n",
       " '1889',\n",
       " '1893',\n",
       " '1897',\n",
       " '1901',\n",
       " '1905',\n",
       " '1909',\n",
       " '1913',\n",
       " '1917',\n",
       " '1921',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1937',\n",
       " '1941',\n",
       " '1945',\n",
       " '1949',\n",
       " '1953',\n",
       " '1957',\n",
       " '1961',\n",
       " '1965',\n",
       " '1969',\n",
       " '1973',\n",
       " '1977',\n",
       " '1981',\n",
       " '1985',\n",
       " '1989',\n",
       " '1993',\n",
       " '1997',\n",
       " '2001',\n",
       " '2005',\n",
       " '2009']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the years of files\n",
    "[fileid[:4] for fileid in inaugural.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEZCAYAAACaWyIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwxMEHjx48NDJ8f8Bzez5W1xtKIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf3c043b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (target, fileid[:4])\n",
    "           for fileid in inaugural.fileids()\n",
    "           for w in inaugural.words(fileid)\n",
    "           for target in ['america', 'citizen']\n",
    "           if w.lower().startswith(target))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.7 Corpora in Other Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El', 'grupo', 'estatal', 'Electricit_de_France', ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.cess_esp.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.8 Text Corpus Structure\n",
    "![Types of corpus](http://www.nltk.org/images/text-corpus-structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.corpus.reader in nltk.corpus:\n",
      "\n",
      "NAME\n",
      "    nltk.corpus.reader\n",
      "\n",
      "DESCRIPTION\n",
      "    NLTK corpus readers.  The modules in this package provide functions\n",
      "    that can be used to read corpus fileids in a variety of formats.  These\n",
      "    functions can be used to read both the corpus fileids that are\n",
      "    distributed in the NLTK corpus package, and corpus fileids that are part\n",
      "    of external corpora.\n",
      "    \n",
      "    Corpus Reader Functions\n",
      "    =======================\n",
      "    Each corpus module defines one or more \"corpus reader functions\",\n",
      "    which can be used to read documents from that corpus.  These functions\n",
      "    take an argument, ``item``, which is used to indicate which document\n",
      "    should be read from the corpus:\n",
      "    \n",
      "    - If ``item`` is one of the unique identifiers listed in the corpus\n",
      "      module's ``items`` variable, then the corresponding document will\n",
      "      be loaded from the NLTK corpus package.\n",
      "    - If ``item`` is a fileid, then that file will be read.\n",
      "    \n",
      "    Additionally, corpus reader functions can be given lists of item\n",
      "    names; in which case, they will return a concatenation of the\n",
      "    corresponding documents.\n",
      "    \n",
      "    Corpus reader functions are named based on the type of information\n",
      "    they return.  Some common examples, and their return types, are:\n",
      "    \n",
      "    - words(): list of str\n",
      "    - sents(): list of (list of str)\n",
      "    - paras(): list of (list of (list of str))\n",
      "    - tagged_words(): list of (str,str) tuple\n",
      "    - tagged_sents(): list of (list of (str,str))\n",
      "    - tagged_paras(): list of (list of (list of (str,str)))\n",
      "    - chunked_sents(): list of (Tree w/ (str,str) leaves)\n",
      "    - parsed_sents(): list of (Tree with str leaves)\n",
      "    - parsed_paras(): list of (list of (Tree with str leaves))\n",
      "    - xml(): A single xml ElementTree\n",
      "    - raw(): unprocessed corpus contents\n",
      "    \n",
      "    For example, to read a list of the words in the Brown Corpus, use\n",
      "    ``nltk.corpus.brown.words()``:\n",
      "    \n",
      "        >>> from nltk.corpus import brown\n",
      "        >>> print(\", \".join(brown.words()))\n",
      "        The, Fulton, County, Grand, Jury, said, ...\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    aligned\n",
      "    api\n",
      "    bnc\n",
      "    bracket_parse\n",
      "    categorized_sents\n",
      "    chasen\n",
      "    childes\n",
      "    chunked\n",
      "    cmudict\n",
      "    comparative_sents\n",
      "    conll\n",
      "    crubadan\n",
      "    dependency\n",
      "    framenet\n",
      "    ieer\n",
      "    indian\n",
      "    ipipan\n",
      "    knbc\n",
      "    lin\n",
      "    mte\n",
      "    nkjp\n",
      "    nombank\n",
      "    nps_chat\n",
      "    opinion_lexicon\n",
      "    panlex_lite\n",
      "    pl196x\n",
      "    plaintext\n",
      "    ppattach\n",
      "    propbank\n",
      "    pros_cons\n",
      "    reviews\n",
      "    rte\n",
      "    semcor\n",
      "    senseval\n",
      "    sentiwordnet\n",
      "    sinica_treebank\n",
      "    string_category\n",
      "    switchboard\n",
      "    tagged\n",
      "    timit\n",
      "    toolbox\n",
      "    twitter\n",
      "    udhr\n",
      "    util\n",
      "    verbnet\n",
      "    wordlist\n",
      "    wordnet\n",
      "    xmldocs\n",
      "    ycoe\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "            nltk.corpus.reader.bracket_parse.CategorizedBracketParseCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.bracket_parse.BracketParseCorpusReader)\n",
      "            nltk.corpus.reader.categorized_sents.CategorizedSentencesCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "            nltk.corpus.reader.pl196x.Pl196xCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "            nltk.corpus.reader.plaintext.CategorizedPlaintextCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.plaintext.PlaintextCorpusReader)\n",
      "                nltk.corpus.reader.plaintext.PortugueseCategorizedPlaintextCorpusReader\n",
      "            nltk.corpus.reader.pros_cons.ProsConsCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "            nltk.corpus.reader.tagged.CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.tagged.TaggedCorpusReader)\n",
      "        nltk.corpus.reader.api.CorpusReader\n",
      "            nltk.corpus.reader.aligned.AlignedCorpusReader\n",
      "            nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "                nltk.corpus.reader.bracket_parse.BracketParseCorpusReader\n",
      "                    nltk.corpus.reader.bracket_parse.AlpinoCorpusReader\n",
      "                nltk.corpus.reader.dependency.DependencyCorpusReader\n",
      "                nltk.corpus.reader.knbc.KNBCorpusReader\n",
      "                nltk.corpus.reader.sinica_treebank.SinicaTreebankCorpusReader\n",
      "            nltk.corpus.reader.chasen.ChasenCorpusReader\n",
      "            nltk.corpus.reader.chunked.ChunkedCorpusReader\n",
      "            nltk.corpus.reader.cmudict.CMUDictCorpusReader\n",
      "            nltk.corpus.reader.comparative_sents.ComparativeSentencesCorpusReader\n",
      "            nltk.corpus.reader.conll.ConllCorpusReader\n",
      "                nltk.corpus.reader.conll.ConllChunkCorpusReader\n",
      "            nltk.corpus.reader.crubadan.CrubadanCorpusReader\n",
      "            nltk.corpus.reader.ieer.IEERCorpusReader\n",
      "            nltk.corpus.reader.indian.IndianCorpusReader\n",
      "            nltk.corpus.reader.ipipan.IPIPANCorpusReader\n",
      "            nltk.corpus.reader.lin.LinThesaurusCorpusReader\n",
      "            nltk.corpus.reader.nombank.NombankCorpusReader\n",
      "            nltk.corpus.reader.panlex_lite.PanLexLiteCorpusReader\n",
      "            nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
      "                nltk.corpus.reader.plaintext.EuroparlCorpusReader\n",
      "                nltk.corpus.reader.udhr.UdhrCorpusReader\n",
      "            nltk.corpus.reader.ppattach.PPAttachmentCorpusReader\n",
      "            nltk.corpus.reader.propbank.PropbankCorpusReader\n",
      "            nltk.corpus.reader.reviews.ReviewsCorpusReader\n",
      "            nltk.corpus.reader.senseval.SensevalCorpusReader\n",
      "            nltk.corpus.reader.sentiwordnet.SentiWordNetCorpusReader\n",
      "            nltk.corpus.reader.string_category.StringCategoryCorpusReader\n",
      "            nltk.corpus.reader.switchboard.SwitchboardCorpusReader\n",
      "            nltk.corpus.reader.tagged.TaggedCorpusReader\n",
      "                nltk.corpus.reader.mte.MTECorpusReader\n",
      "                nltk.corpus.reader.tagged.MacMorphoCorpusReader\n",
      "                nltk.corpus.reader.tagged.TimitTaggedCorpusReader\n",
      "            nltk.corpus.reader.timit.TimitCorpusReader\n",
      "            nltk.corpus.reader.toolbox.ToolboxCorpusReader\n",
      "            nltk.corpus.reader.twitter.TwitterCorpusReader\n",
      "            nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "                nltk.corpus.reader.opinion_lexicon.OpinionLexiconCorpusReader\n",
      "                nltk.corpus.reader.wordlist.MWAPPDBCorpusReader\n",
      "                nltk.corpus.reader.wordlist.NonbreakingPrefixesCorpusReader\n",
      "                nltk.corpus.reader.wordlist.SwadeshCorpusReader\n",
      "                nltk.corpus.reader.wordlist.UnicharsCorpusReader\n",
      "            nltk.corpus.reader.wordnet.WordNetCorpusReader\n",
      "            nltk.corpus.reader.wordnet.WordNetICCorpusReader\n",
      "            nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "                nltk.corpus.reader.bnc.BNCCorpusReader\n",
      "                nltk.corpus.reader.childes.CHILDESCorpusReader\n",
      "                nltk.corpus.reader.framenet.FramenetCorpusReader\n",
      "                nltk.corpus.reader.nkjp.NKJPCorpusReader\n",
      "                nltk.corpus.reader.nps_chat.NPSChatCorpusReader\n",
      "                nltk.corpus.reader.rte.RTECorpusReader\n",
      "                nltk.corpus.reader.semcor.SemcorCorpusReader\n",
      "                nltk.corpus.reader.verbnet.VerbnetCorpusReader\n",
      "            nltk.corpus.reader.ycoe.YCOECorpusReader\n",
      "        nltk.corpus.reader.sentiwordnet.SentiSynset\n",
      "    nltk.corpus.reader.util.StreamBackedCorpusView(nltk.collections.AbstractLazySequence)\n",
      "        nltk.corpus.reader.pl196x.TEICorpusView\n",
      "    \n",
      "    class AlignedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for corpora of word-aligned sentences.  Tokens are assumed\n",
      "     |  to be separated by whitespace.  Sentences begin on separate lines.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlignedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), alignedsent_block_reader=<function read_alignedsent_block at 0x7fdf40904510>, encoding='latin1')\n",
      "     |      Construct a new Aligned Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = AlignedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  aligned_sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of AlignedSent objects.\n",
      "     |      :rtype: list(AlignedSent)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class AlpinoCorpusReader(BracketParseCorpusReader)\n",
      "     |  Reader for the Alpino Dutch Treebank.\n",
      "     |  This corpus has a lexical breakdown structure embedded, as read by _parse\n",
      "     |  Unfortunately this puts punctuation and some other words out of the sentence\n",
      "     |  order in the xml element tree. This is no good for tag_ and word_\n",
      "     |  _tag and _word will be overridden to use a non-default new parameter 'ordered'\n",
      "     |  to the overridden _normalize function. The _parse function can then remain \n",
      "     |  untouched.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlpinoCorpusReader\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='ISO-8859-1', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param comment_char: The character which can appear at the start of\n",
      "     |          a line to indicate that the rest of the line is a comment.\n",
      "     |      :param detect_blocks: The method that is used to find blocks\n",
      "     |        in the corpus; can be 'unindented_paren' (every unindented\n",
      "     |        parenthesis starts a new parse) or 'sexpr' (brackets are\n",
      "     |        matched).\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class BNCCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Corpus reader for the XML version of the British National Corpus.\n",
      "     |  \n",
      "     |  For access to the complete XML data structure, use the ``xml()``\n",
      "     |  method.  For access to simple word lists and tagged word lists, use\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  You can obtain the full version of the BNC corpus at\n",
      "     |  http://www.ota.ox.ac.uk/desc/2554\n",
      "     |  \n",
      "     |  If you extracted the archive to a directory called `BNC`, then you can\n",
      "     |  instantiate the reader as::\n",
      "     |  \n",
      "     |      BNCCorpusReader(root='BNC/Texts/', fileids=r'[A-K]/\\w*/\\w*\\.xml')\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BNCCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |      \n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, c5=False, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |      \n",
      "     |      :param c5: If true, then the tags used will be the more detailed\n",
      "     |          c5 tags.  Otherwise, the simplified tags will be used.\n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, c5=False, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |      \n",
      "     |      :param c5: If true, then the tags used will be the more detailed\n",
      "     |          c5 tags.  Otherwise, the simplified tags will be used.\n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  words(self, fileids=None, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |      \n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class BracketParseCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  Reader for corpora that consist of parenthesis-delineated parse trees,\n",
      "     |  like those found in the \"combined\" section of the Penn Treebank,\n",
      "     |  e.g. \"(S (NP (DT the) (JJ little) (NN dog)) (VP (VBD barked)))\".\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, comment_char=None, detect_blocks='unindented_paren', encoding='utf8', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param comment_char: The character which can appear at the start of\n",
      "     |          a line to indicate that the rest of the line is a comment.\n",
      "     |      :param detect_blocks: The method that is used to find blocks\n",
      "     |        in the corpus; can be 'unindented_paren' (every unindented\n",
      "     |        parenthesis starts a new parse) or 'sexpr' (brackets are\n",
      "     |        matched).\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CHILDESCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Corpus reader for the XML version of the CHILDES corpus.\n",
      "     |  The CHILDES corpus is available at ``http://childes.psy.cmu.edu/``. The XML\n",
      "     |  version of CHILDES is located at ``http://childes.psy.cmu.edu/data-xml/``.\n",
      "     |  Copy the needed parts of the CHILDES XML corpus into the NLTK data directory\n",
      "     |  (``nltk_data/corpora/CHILDES/``).\n",
      "     |  \n",
      "     |  For access to the file text use the usual nltk functions,\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()`` and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CHILDESCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  MLU(self, fileids=None, speaker='CHI')\n",
      "     |      :return: the given file(s) as a floating number\n",
      "     |      :rtype: list(float)\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  age(self, fileids=None, speaker='CHI', month=False)\n",
      "     |      :return: the given file(s) as string or int\n",
      "     |      :rtype: list or int\n",
      "     |      \n",
      "     |      :param month: If true, return months instead of year-month-date\n",
      "     |  \n",
      "     |  convert_age(self, age_year)\n",
      "     |      Caclculate age in months from a string in CHILDES format\n",
      "     |  \n",
      "     |  corpus(self, fileids=None)\n",
      "     |      :return: the given file(s) as a dict of ``(corpus_property_key, value)``\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  participants(self, fileids=None)\n",
      "     |      :return: the given file(s) as a dict of\n",
      "     |          ``(participant_property_key, value)``\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, speaker='ALL', stem=False, relation=None, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |          encoded as a list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of ``(str,pos,relation_list)``.\n",
      "     |          If there is manually-annotated relation info, it will return\n",
      "     |          tuples of ``(str,pos,test_relation_list,str,pos,gold_relation_list)``\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, speaker='ALL', stem=False, relation=None, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of ``(str,pos,relation_list)``.\n",
      "     |          If there is manually-annotated relation info, it will return\n",
      "     |          tuples of ``(str,pos,test_relation_list,str,pos,gold_relation_list)``\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, speaker='ALL', stem=False, relation=False, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of (stem, index,\n",
      "     |          dependent_index)\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  webview_file(self, fileid, urlbase=None)\n",
      "     |      Map a corpus file to its web version on the CHILDES website,\n",
      "     |      and open it in a web browser.\n",
      "     |      \n",
      "     |      The complete URL to be used is:\n",
      "     |          childes.childes_url_base + urlbase + fileid.replace('.xml', '.cha')\n",
      "     |      \n",
      "     |      If no urlbase is passed, we try to calculate it.  This\n",
      "     |      requires that the childes corpus was set up to mirror the\n",
      "     |      folder hierarchy under childes.psy.cmu.edu/data-xml/, e.g.:\n",
      "     |      nltk_data/corpora/childes/Eng-USA/Cornell/??? or\n",
      "     |      nltk_data/corpora/childes/Romance/Spanish/Aguirre/???\n",
      "     |      \n",
      "     |      The function first looks (as a special case) if \"Eng-USA\" is\n",
      "     |      on the path consisting of <corpus root>+fileid; then if\n",
      "     |      \"childes\", possibly followed by \"data-xml\", appears. If neither\n",
      "     |      one is found, we use the unmodified fileid and hope for the best.\n",
      "     |      If this is not right, specify urlbase explicitly, e.g., if the\n",
      "     |      corpus root points to the Cornell folder, urlbase='Eng-USA/Cornell'.\n",
      "     |  \n",
      "     |  words(self, fileids=None, speaker='ALL', stem=False, relation=False, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |      :rtype: list(str)\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of (stem, index,\n",
      "     |          dependent_index)\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  childes_url_base = 'http://childes.psy.cmu.edu/browser/index.php?url='\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CMUDictCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CMUDictCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  dict(self)\n",
      "     |      :return: the cmudict lexicon as a dictionary, whose keys are\n",
      "     |      lowercase words and whose values are lists of pronunciations.\n",
      "     |  \n",
      "     |  entries(self)\n",
      "     |      :return: the cmudict lexicon as a list of entries\n",
      "     |      containing (word, transcriptions) tuples.\n",
      "     |  \n",
      "     |  raw(self)\n",
      "     |      :return: the cmudict lexicon as a raw string.\n",
      "     |  \n",
      "     |  words(self)\n",
      "     |      :return: a list of all words defined in the cmudict lexicon.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedBracketParseCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, BracketParseCorpusReader)\n",
      "     |  A reader for parsed corpora whose documents are\n",
      "     |  divided into categories based on their file identifiers.\n",
      "     |  @author: Nathan Schneider <nschneid@cs.cmu.edu>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedBracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (C{cat_pattern}, C{cat_map}, and C{cat_file}) are passed to\n",
      "     |      the L{CategorizedCorpusReader constructor\n",
      "     |      <CategorizedCorpusReader.__init__>}.  The remaining arguments\n",
      "     |      are passed to the L{BracketParseCorpusReader constructor\n",
      "     |      <BracketParseCorpusReader.__init__>}.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_paras(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_words(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedCorpusReader(builtins.object)\n",
      "     |  A mixin class used to aid in the implementation of corpus readers\n",
      "     |  for categorized corpora.  This class defines the method\n",
      "     |  ``categories()``, which returns a list of the categories for the\n",
      "     |  corpus or for a specified set of fileids; and overrides ``fileids()``\n",
      "     |  to take a ``categories`` argument, restricting the set of fileids to\n",
      "     |  be returned.\n",
      "     |  \n",
      "     |  Subclasses are expected to:\n",
      "     |  \n",
      "     |    - Call ``__init__()`` to set up the mapping.\n",
      "     |  \n",
      "     |    - Override all view methods to accept a ``categories`` parameter,\n",
      "     |      which can be used *instead* of the ``fileids`` parameter, to\n",
      "     |      select which fileids should be included in the returned view.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, kwargs)\n",
      "     |      Initialize this mapping based on keyword arguments, as\n",
      "     |      follows:\n",
      "     |      \n",
      "     |        - cat_pattern: A regular expression pattern used to find the\n",
      "     |          category for each file identifier.  The pattern will be\n",
      "     |          applied to each file identifier, and the first matching\n",
      "     |          group will be used as the category label for that file.\n",
      "     |      \n",
      "     |        - cat_map: A dictionary, mapping from file identifiers to\n",
      "     |          category labels.\n",
      "     |      \n",
      "     |        - cat_file: The name of a file that contains the mapping\n",
      "     |          from file identifiers to categories.  The argument\n",
      "     |          ``cat_delimiter`` can be used to specify a delimiter.\n",
      "     |      \n",
      "     |      The corresponding argument will be deleted from ``kwargs``.  If\n",
      "     |      more than one argument is specified, an exception will be\n",
      "     |      raised.\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CategorizedPlaintextCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, PlaintextCorpusReader)\n",
      "     |  A reader for plaintext corpora whose documents are divided into\n",
      "     |  categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedPlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``PlaintextCorpusReader`` constructor.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedSentencesCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A reader for corpora in which each row represents a single instance, mainly\n",
      "     |  a sentence. Istances are divided into categories based on their file identifiers\n",
      "     |  (see CategorizedCorpusReader).\n",
      "     |  Since many corpora allow rows that contain more than one sentence, it is\n",
      "     |  possible to specify a sentence tokenizer to retrieve all sentences instead\n",
      "     |  than all rows.\n",
      "     |  \n",
      "     |  Examples using the Subjectivity Dataset:\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import subjectivity\n",
      "     |  >>> subjectivity.sents()[23]\n",
      "     |  ['television', 'made', 'him', 'famous', ',', 'but', 'his', 'biggest', 'hits',\n",
      "     |  'happened', 'off', 'screen', '.']\n",
      "     |  >>> subjectivity.categories()\n",
      "     |  ['obj', 'subj']\n",
      "     |  >>> subjectivity.words(categories='subj')\n",
      "     |  ['smart', 'and', 'alert', ',', 'thirteen', ...]\n",
      "     |  \n",
      "     |  Examples using the Sentence Polarity Dataset:\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import sentence_polarity\n",
      "     |  >>> sentence_polarity.sents()\n",
      "     |  [['simplistic', ',', 'silly', 'and', 'tedious', '.'], [\"it's\", 'so', 'laddish',\n",
      "     |  'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find',\n",
      "     |  'it', 'funny', '.'], ...]\n",
      "     |  >>> sentence_polarity.categories()\n",
      "     |  ['neg', 'pos']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedSentencesCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8', **kwargs)\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param sent_tokenizer: a tokenizer for breaking paragraphs into sentences.\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |      :param kwargs: additional parameters passed to CategorizedCorpusReader.\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids that have to be\n",
      "     |          returned as a raw string.\n",
      "     |      :param categories: a list specifying the categories whose files have to\n",
      "     |          be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus Readme.txt file.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      Return all sentences in the corpus or in the specified file(s).\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose sentences have\n",
      "     |          to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences.\n",
      "     |          Each sentence is tokenized using the specified word_tokenizer.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      file(s).\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose words have to\n",
      "     |          be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, TaggedCorpusReader)\n",
      "     |  A reader for part-of-speech tagged corpora whose documents are\n",
      "     |  divided into categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedTaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``TaggedCorpusReader``.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ChasenCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChasenCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', sent_splitter=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ChunkedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for chunked (and optionally tagged) corpora.  Paragraphs\n",
      "     |  are split using a block reader.  They are then tokenized into\n",
      "     |  sentences using a sentence tokenizer.  Finally, these sentences\n",
      "     |  are parsed into chunk trees using a string-to-chunktree conversion\n",
      "     |  function.  Each of these steps can be performed using a default\n",
      "     |  function or a custom function.  By default, paragraphs are split\n",
      "     |  on blank lines; sentences are listed one per line; and sentences\n",
      "     |  are parsed into chunk trees using ``nltk.chunk.tagstr2tree``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChunkedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, extension='', str2chunktree=<function tagstr2tree at 0x7fdf40a4c6a8>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x7fdf40904488>, encoding='utf8', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  chunked_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as a shallow Tree.  The leaves of these\n",
      "     |          trees are encoded as ``(word, tag)`` tuples (if the corpus\n",
      "     |          has tags) or word strings (if the corpus has no tags).\n",
      "     |      :rtype: list(list(Tree))\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a shallow Tree.  The leaves\n",
      "     |          of these trees are encoded as ``(word, tag)`` tuples (if\n",
      "     |          the corpus has tags) or word strings (if the corpus has no\n",
      "     |          tags).\n",
      "     |      :rtype: list(Tree)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and chunks.  Words are encoded as ``(word, tag)``\n",
      "     |          tuples (if the corpus has tags) or word strings (if the\n",
      "     |          corpus has no tags).  Chunks are encoded as depth-one\n",
      "     |          trees over ``(word,tag)`` tuples or word strings.\n",
      "     |      :rtype: list(tuple(str,str) and Tree)\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ComparativeSentencesCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for the Comparative Sentence Dataset by Jindal and Liu (2006).\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import comparative_sentences\n",
      "     |      >>> comparison = comparative_sentences.comparisons()[0]\n",
      "     |      >>> comparison.text\n",
      "     |      ['its', 'fast-forward', 'and', 'rewind', 'work', 'much', 'more', 'smoothly',\n",
      "     |      'and', 'consistently', 'than', 'those', 'of', 'other', 'models', 'i', \"'ve\",\n",
      "     |      'had', '.']\n",
      "     |      >>> comparison.entity_2\n",
      "     |      'models'\n",
      "     |      >>> (comparison.feature, comparison.keyword)\n",
      "     |      ('rewind', 'more')\n",
      "     |      >>> len(comparative_sentences.comparisons())\n",
      "     |      853\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ComparativeSentencesCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param sent_tokenizer: tokenizer for breaking paragraphs into sentences.\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  comparisons(self, fileids=None)\n",
      "     |      Return all comparisons in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          comparisons have to be returned.\n",
      "     |      :return: the given file(s) as a list of Comparison objects.\n",
      "     |      :rtype: list(Comparison)\n",
      "     |  \n",
      "     |  keywords(self, fileids=None)\n",
      "     |      Return a set of all keywords used in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          keywords have to be returned.\n",
      "     |      :return: the set of keywords and comparative phrases used in the corpus.\n",
      "     |      :rtype: set(str)\n",
      "     |  \n",
      "     |  keywords_readme(self)\n",
      "     |      Return the list of words and constituents considered as clues of a\n",
      "     |      comparison (from listOfkeywords.txt).\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids that have to be\n",
      "     |          returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus readme file.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: all sentences of the corpus as lists of tokens (or as plain\n",
      "     |          strings, if no word tokenizer is specified).\n",
      "     |      :rtype: list(list(str)) or list(str)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ConllChunkCorpusReader(ConllCorpusReader)\n",
      "     |  A ConllCorpusReader whose data file contains three columns: words,\n",
      "     |  pos, and chunk.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConllChunkCorpusReader\n",
      "     |      ConllCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, chunk_types, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ConllCorpusReader:\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  iob_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of lists of word/tag/IOB tuples\n",
      "     |      :rtype: list(list)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  iob_words(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of word/tag/IOB tuples\n",
      "     |      :rtype: list(tuple)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, pos_in_tree=None, tagset=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  srl_instances(self, fileids=None, pos_in_tree=None, flatten=True)\n",
      "     |  \n",
      "     |  srl_spans(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ConllCorpusReader:\n",
      "     |  \n",
      "     |  CHUNK = 'chunk'\n",
      "     |  \n",
      "     |  COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore'...\n",
      "     |  \n",
      "     |  IGNORE = 'ignore'\n",
      "     |  \n",
      "     |  NE = 'ne'\n",
      "     |  \n",
      "     |  POS = 'pos'\n",
      "     |  \n",
      "     |  SRL = 'srl'\n",
      "     |  \n",
      "     |  TREE = 'tree'\n",
      "     |  \n",
      "     |  WORDS = 'words'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ConllCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A corpus reader for CoNLL-style files.  These files consist of a\n",
      "     |  series of sentences, separated by blank lines.  Each sentence is\n",
      "     |  encoded using a table (or \"grid\") of values, where each line\n",
      "     |  corresponds to a single word, and each column corresponds to an\n",
      "     |  annotation type.  The set of columns used by CoNLL-style files can\n",
      "     |  vary from corpus to corpus; the ``ConllCorpusReader`` constructor\n",
      "     |  therefore takes an argument, ``columntypes``, which is used to\n",
      "     |  specify the columns that are used by a given corpus.\n",
      "     |  \n",
      "     |  @todo: Add support for reading from corpora where different\n",
      "     |      parallel files contain different columns.\n",
      "     |  @todo: Possibly add caching of the grid corpus view?  This would\n",
      "     |      allow the same grid view to be used by different data access\n",
      "     |      methods (eg words() and parsed_sents() could both share the\n",
      "     |      same grid corpus view object).\n",
      "     |  @todo: Better support for -DOCSTART-.  Currently, we just ignore\n",
      "     |      it, but it could be used to define methods that retrieve a\n",
      "     |      document at a time (eg parsed_documents()).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConllCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, columntypes, chunk_types=None, root_label='S', pos_in_tree=False, srl_includes_roleset=True, encoding='utf8', tree_class=<class 'nltk.tree.Tree'>, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  iob_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of lists of word/tag/IOB tuples\n",
      "     |      :rtype: list(list)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  iob_words(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of word/tag/IOB tuples\n",
      "     |      :rtype: list(tuple)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, pos_in_tree=None, tagset=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  srl_instances(self, fileids=None, pos_in_tree=None, flatten=True)\n",
      "     |  \n",
      "     |  srl_spans(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CHUNK = 'chunk'\n",
      "     |  \n",
      "     |  COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore'...\n",
      "     |  \n",
      "     |  IGNORE = 'ignore'\n",
      "     |  \n",
      "     |  NE = 'ne'\n",
      "     |  \n",
      "     |  POS = 'pos'\n",
      "     |  \n",
      "     |  SRL = 'srl'\n",
      "     |  \n",
      "     |  TREE = 'tree'\n",
      "     |  \n",
      "     |  WORDS = 'words'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CorpusReader(builtins.object)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CrubadanCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A corpus reader used to access language An Crubadan n-gram files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CrubadanCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  crubadan_to_iso(self, lang)\n",
      "     |      Return ISO 639-3 code given internal Crubadan code\n",
      "     |  \n",
      "     |  iso_to_crubadan(self, lang)\n",
      "     |      Return internal Crubadan code based on ISO 639-3 code\n",
      "     |  \n",
      "     |  lang_freq(self, lang)\n",
      "     |      Return n-gram FreqDist for a specific language\n",
      "     |      given ISO 639-3 language code\n",
      "     |  \n",
      "     |  langs(self)\n",
      "     |      Return a list of supported languages as ISO 639-3 codes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class DependencyCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  An abstract base class for reading corpora consisting of\n",
      "     |  syntactically parsed text.  Subclasses should define:\n",
      "     |  \n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DependencyCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', word_tokenizer=<nltk.tokenize.simple.TabTokenizer object at 0x7fdf40831c50>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x7fdf40904488>)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class EuroparlCorpusReader(PlaintextCorpusReader)\n",
      "     |  Reader for Europarl corpora that consist of plaintext documents.\n",
      "     |  Documents are divided into chapters instead of paragraphs as\n",
      "     |  for regular plaintext documents. Chapters are separated using blank\n",
      "     |  lines. Everything is inherited from ``PlaintextCorpusReader`` except\n",
      "     |  that:\n",
      "     |    - Since the corpus is pre-processed and pre-tokenized, the\n",
      "     |      word tokenizer should just split the line at whitespaces.\n",
      "     |    - For the same reason, the sentence tokenizer should just\n",
      "     |      split the paragraph at line breaks.\n",
      "     |    - There is a new 'chapters()' method that returns chapters instead\n",
      "     |      instead of paragraphs.\n",
      "     |    - The 'paras()' method inherited from PlaintextCorpusReader is\n",
      "     |      made non-functional to remove any confusion between chapters\n",
      "     |      and paragraphs for Europarl.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EuroparlCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  chapters(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          chapters, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x7fdf408efe10>, para_block_reader=<function read_blankline_block at 0x7fdf40904488>, encoding='utf8')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class FramenetCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  A corpus reader for the Framenet Corpus.\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import framenet as fn\n",
      "     |  >>> fn.lu(3238).frame.lexUnit['glint.v'] is fn.lu(3238)\n",
      "     |  True\n",
      "     |  >>> fn.frame_by_name('Replacing') is fn.lus('replace.v')[0].frame\n",
      "     |  True\n",
      "     |  >>> fn.lus('prejudice.n')[0].frame.frameRelations == fn.frame_relations('Partiality')\n",
      "     |  True\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FramenetCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  annotations(self, luNamePattern=None, exemplars=True, full_text=True)\n",
      "     |      Frame annotation sets matching the specified criteria.\n",
      "     |  \n",
      "     |  buildindexes(self)\n",
      "     |      Build the internal indexes to make look-ups faster.\n",
      "     |  \n",
      "     |  doc(self, fn_docid)\n",
      "     |      Returns the annotated document whose id number is\n",
      "     |      ``fn_docid``. This id number can be obtained by calling the\n",
      "     |      Documents() function.\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain the\n",
      "     |      following keys:\n",
      "     |      \n",
      "     |      - '_type'      : 'fulltextannotation'\n",
      "     |      - 'sentence'   : a list of sentences in the document\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'ID'    : the ID number of the sentence\n",
      "     |            - '_type' : 'sentence'\n",
      "     |            - 'text'  : the text of the sentence\n",
      "     |            - 'paragNo' : the paragraph number\n",
      "     |            - 'sentNo'  : the sentence number\n",
      "     |            - 'docID'   : the document ID number\n",
      "     |            - 'corpID'  : the corpus ID number\n",
      "     |            - 'aPos'    : the annotation position\n",
      "     |            - 'annotationSet' : a list of annotation layers for the sentence\n",
      "     |               - Each item in the list is a dict containing the following keys:\n",
      "     |                  - 'ID'       : the ID number of the annotation set\n",
      "     |                  - '_type'    : 'annotationset'\n",
      "     |                  - 'status'   : either 'MANUAL' or 'UNANN'\n",
      "     |                  - 'luName'   : (only if status is 'MANUAL')\n",
      "     |                  - 'luID'     : (only if status is 'MANUAL')\n",
      "     |                  - 'frameID'  : (only if status is 'MANUAL')\n",
      "     |                  - 'frameName': (only if status is 'MANUAL')\n",
      "     |                  - 'layer' : a list of labels for the layer\n",
      "     |                     - Each item in the layer is a dict containing the\n",
      "     |                       following keys:\n",
      "     |                        - '_type': 'layer'\n",
      "     |                        - 'rank'\n",
      "     |                        - 'name'\n",
      "     |                        - 'label' : a list of labels in the layer\n",
      "     |                           - Each item is a dict containing the following keys:\n",
      "     |                              - 'start'\n",
      "     |                              - 'end'\n",
      "     |                              - 'name'\n",
      "     |                              - 'feID' (optional)\n",
      "     |      \n",
      "     |      :param fn_docid: The Framenet id number of the document\n",
      "     |      :type fn_docid: int\n",
      "     |      :return: Information about the annotated document\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  docs(self, name=None)\n",
      "     |      Return a list of the annotated full-text documents in FrameNet,\n",
      "     |      optionally filtered by a regex to be matched against the document name.\n",
      "     |  \n",
      "     |  docs_metadata(self, name=None)\n",
      "     |      Return an index of the annotated documents in Framenet.\n",
      "     |      \n",
      "     |      Details for a specific annotated document can be obtained using this\n",
      "     |      class's doc() function and pass it the value of the 'ID' field.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.docs()) in (78, 107) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> set([x.corpname for x in fn.docs_metadata()])>=set(['ANC', 'KBEval',                     'LUCorpus-v0.3', 'Miscellaneous', 'NTI', 'PropBank'])\n",
      "     |      True\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to search the\n",
      "     |          file name of each annotated document. The document's\n",
      "     |          file name contains the name of the corpus that the\n",
      "     |          document is from, followed by two underscores \"__\"\n",
      "     |          followed by the document name. So, for example, the\n",
      "     |          file name \"LUCorpus-v0.3__20000410_nyt-NEW.xml\" is\n",
      "     |          from the corpus named \"LUCorpus-v0.3\" and the\n",
      "     |          document name is \"20000410_nyt-NEW.xml\".\n",
      "     |      :type name: str\n",
      "     |      :return: A list of selected (or all) annotated documents\n",
      "     |      :rtype: list of dicts, where each dict object contains the following\n",
      "     |              keys:\n",
      "     |      \n",
      "     |              - 'name'\n",
      "     |              - 'ID'\n",
      "     |              - 'corpid'\n",
      "     |              - 'corpname'\n",
      "     |              - 'description'\n",
      "     |              - 'filename'\n",
      "     |  \n",
      "     |  exemplars(self, luNamePattern=None, frame=None, fe=None, fe2=None)\n",
      "     |      Lexicographic exemplar sentences, optionally filtered by LU name and/or 1-2 FEs that\n",
      "     |      are realized overtly. 'frame' may be a name pattern, frame ID, or frame instance.\n",
      "     |      'fe' may be a name pattern or FE instance; if specified, 'fe2' may also\n",
      "     |      be specified to retrieve sentences with both overt FEs (in either order).\n",
      "     |  \n",
      "     |  fe_relations(self)\n",
      "     |      Obtain a list of frame element relations.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> ferels = fn.fe_relations()\n",
      "     |      >>> isinstance(ferels, list)\n",
      "     |      True\n",
      "     |      >>> len(ferels) in (10020, 12393)   # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyDict(ferels[0], breakLines=True)\n",
      "     |      {'ID': 14642,\n",
      "     |      '_type': 'ferelation',\n",
      "     |      'frameRelation': <Parent=Abounding_with -- Inheritance -> Child=Lively_place>,\n",
      "     |      'subFE': <fe ID=11370 name=Degree>,\n",
      "     |      'subFEName': 'Degree',\n",
      "     |      'subFrame': <frame ID=1904 name=Lively_place>,\n",
      "     |      'subID': 11370,\n",
      "     |      'supID': 2271,\n",
      "     |      'superFE': <fe ID=2271 name=Degree>,\n",
      "     |      'superFEName': 'Degree',\n",
      "     |      'superFrame': <frame ID=262 name=Abounding_with>,\n",
      "     |      'type': <framerelationtype ID=1 name=Inheritance>}\n",
      "     |      \n",
      "     |      :return: A list of all of the frame element relations in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  fes(self, name=None, frame=None)\n",
      "     |      Lists frame element objects. If 'name' is provided, this is treated as\n",
      "     |      a case-insensitive regular expression to filter by frame name.\n",
      "     |      (Case-insensitivity is because casing of frame element names is not always\n",
      "     |      consistent across frames.) Specify 'frame' to filter by a frame name pattern,\n",
      "     |      ID, or object.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.fes('Noise_maker')\n",
      "     |      [<fe ID=6043 name=Noise_maker>]\n",
      "     |      >>> sorted([(fe.frame.name,fe.name) for fe in fn.fes('sound')])\n",
      "     |      [('Cause_to_make_noise', 'Sound_maker'), ('Make_noise', 'Sound'),\n",
      "     |       ('Make_noise', 'Sound_source'), ('Sound_movement', 'Location_of_sound_source'),\n",
      "     |       ('Sound_movement', 'Sound'), ('Sound_movement', 'Sound_source'),\n",
      "     |       ('Sounds', 'Component_sound'), ('Sounds', 'Location_of_sound_source'),\n",
      "     |       ('Sounds', 'Sound_source'), ('Vocalizations', 'Location_of_sound_source'),\n",
      "     |       ('Vocalizations', 'Sound_source')]\n",
      "     |      >>> sorted([(fe.frame.name,fe.name) for fe in fn.fes('sound',r'(?i)make_noise')])\n",
      "     |      [('Cause_to_make_noise', 'Sound_maker'),\n",
      "     |       ('Make_noise', 'Sound'),\n",
      "     |       ('Make_noise', 'Sound_source')]\n",
      "     |      >>> sorted(set(fe.name for fe in fn.fes('^sound')))\n",
      "     |      ['Sound', 'Sound_maker', 'Sound_source']\n",
      "     |      >>> len(fn.fes('^sound$'))\n",
      "     |      2\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to match against\n",
      "     |          frame element names. If 'name' is None, then a list of all\n",
      "     |          frame elements will be returned.\n",
      "     |      :type name: str\n",
      "     |      :return: A list of matching frame elements\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  frame(self, fn_fid_or_fname, ignorekeys=[])\n",
      "     |      Get the details for the specified Frame using the frame's name\n",
      "     |      or id number.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame(256)\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f = fn.frame('Medical_specialties')\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> # ensure non-ASCII character in definition doesn't trigger an encoding error:\n",
      "     |      >>> fn.frame('Imposing_obligation')\n",
      "     |      frame (1494): Imposing_obligation...\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain the\n",
      "     |      following information about the Frame:\n",
      "     |      \n",
      "     |      - 'name'       : the name of the Frame (e.g. 'Birth', 'Apply_heat', etc.)\n",
      "     |      - 'definition' : textual definition of the Frame\n",
      "     |      - 'ID'         : the internal ID number of the Frame\n",
      "     |      - 'semTypes'   : a list of semantic types for this frame\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'name' : can be used with the semtype() function\n",
      "     |            - 'ID'   : can be used with the semtype() function\n",
      "     |      \n",
      "     |      - 'lexUnit'    : a dict containing all of the LUs for this frame.\n",
      "     |                       The keys in this dict are the names of the LUs and\n",
      "     |                       the value for each key is itself a dict containing\n",
      "     |                       info about the LU (see the lu() function for more info.)\n",
      "     |      \n",
      "     |      - 'FE' : a dict containing the Frame Elements that are part of this frame\n",
      "     |               The keys in this dict are the names of the FEs (e.g. 'Body_system')\n",
      "     |               and the values are dicts containing the following keys\n",
      "     |            - 'definition' : The definition of the FE\n",
      "     |            - 'name'       : The name of the FE e.g. 'Body_system'\n",
      "     |            - 'ID'         : The id number\n",
      "     |            - '_type'      : 'fe'\n",
      "     |            - 'abbrev'     : Abbreviation e.g. 'bod'\n",
      "     |            - 'coreType'   : one of \"Core\", \"Peripheral\", or \"Extra-Thematic\"\n",
      "     |            - 'semType'    : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : name of the semantic type. can be used with\n",
      "     |                          the semtype() function\n",
      "     |               - 'ID'   : id number of the semantic type. can be used with\n",
      "     |                          the semtype() function\n",
      "     |            - 'requiresFE' : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : the name of another FE in this frame\n",
      "     |               - 'ID'   : the id of the other FE in this frame\n",
      "     |            - 'excludesFE' : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : the name of another FE in this frame\n",
      "     |               - 'ID'   : the id of the other FE in this frame\n",
      "     |      \n",
      "     |      - 'frameRelation'      : a list of objects describing frame relations\n",
      "     |      - 'FEcoreSets'  : a list of Frame Element core sets for this frame\n",
      "     |         - Each item in the list is a list of FE objects\n",
      "     |      \n",
      "     |      :param fn_fid_or_fname: The Framenet name or id number of the frame\n",
      "     |      :type fn_fid_or_fname: int or str\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  frame_by_id(self, fn_fid, ignorekeys=[])\n",
      "     |      Get the details for the specified Frame using the frame's id\n",
      "     |      number.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame_by_id(256)\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f.definition\n",
      "     |      \"This frame includes words that name ...\"\n",
      "     |      \n",
      "     |      :param fn_fid: The Framenet id number of the frame\n",
      "     |      :type fn_fid: int\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |      \n",
      "     |      Also see the ``frame()`` function for details about what is\n",
      "     |      contained in the dict that is returned.\n",
      "     |  \n",
      "     |  frame_by_name(self, fn_fname, ignorekeys=[], check_cache=True)\n",
      "     |      Get the details for the specified Frame using the frame's name.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame_by_name('Medical_specialties')\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f.definition\n",
      "     |      \"This frame includes words that name ...\"\n",
      "     |      \n",
      "     |      :param fn_fname: The name of the frame\n",
      "     |      :type fn_fname: str\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |      \n",
      "     |      Also see the ``frame()`` function for details about what is\n",
      "     |      contained in the dict that is returned.\n",
      "     |  \n",
      "     |  frame_ids_and_names(self, name=None)\n",
      "     |      Uses the frame index, which is much faster than looking up each frame definition\n",
      "     |      if only the names and IDs are needed.\n",
      "     |  \n",
      "     |  frame_relation_types(self)\n",
      "     |      Obtain a list of frame relation types.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> frts = list(fn.frame_relation_types())\n",
      "     |      >>> isinstance(frts, list)\n",
      "     |      True\n",
      "     |      >>> len(frts) in (9, 10)    # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyDict(frts[0], breakLines=True)\n",
      "     |      {'ID': 1,\n",
      "     |       '_type': 'framerelationtype',\n",
      "     |       'frameRelations': [<Parent=Event -- Inheritance -> Child=Change_of_consistency>, <Parent=Event -- Inheritance -> Child=Rotting>, ...],\n",
      "     |       'name': 'Inheritance',\n",
      "     |       'subFrameName': 'Child',\n",
      "     |       'superFrameName': 'Parent'}\n",
      "     |      \n",
      "     |      :return: A list of all of the frame relation types in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  frame_relations(self, frame=None, frame2=None, type=None)\n",
      "     |      :param frame: (optional) frame object, name, or ID; only relations involving\n",
      "     |      this frame will be returned\n",
      "     |      :param frame2: (optional; 'frame' must be a different frame) only show relations\n",
      "     |      between the two specified frames, in either direction\n",
      "     |      :param type: (optional) frame relation type (name or object); show only relations\n",
      "     |      of this type\n",
      "     |      :type frame: int or str or AttrDict\n",
      "     |      :return: A list of all of the frame relations in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> frels = fn.frame_relations()\n",
      "     |      >>> isinstance(frels, list)\n",
      "     |      True\n",
      "     |      >>> len(frels) in (1676, 2070)  # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation'), maxReprSize=0, breakLines=True)\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>,\n",
      "     |       <Parent=Apply_heat -- Using -> Child=Cooking_creation>,\n",
      "     |       <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>]\n",
      "     |      >>> PrettyList(fn.frame_relations(274), breakLines=True)\n",
      "     |      [<Parent=Avoiding -- Inheritance -> Child=Dodging>,\n",
      "     |       <Parent=Avoiding -- Inheritance -> Child=Evading>, ...]\n",
      "     |      >>> PrettyList(fn.frame_relations(fn.frame('Cooking_creation')), breakLines=True)\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>,\n",
      "     |       <Parent=Apply_heat -- Using -> Child=Cooking_creation>, ...]\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation', type='Inheritance'))\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>]\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation', 'Apply_heat'), breakLines=True)\n",
      "     |      [<Parent=Apply_heat -- Using -> Child=Cooking_creation>,\n",
      "     |      <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>]\n",
      "     |  \n",
      "     |  frames(self, name=None)\n",
      "     |      Obtain details for a specific frame.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.frames()) in (1019, 1221)    # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> x = PrettyList(fn.frames(r'(?i)crim'), maxReprSize=0, breakLines=True)\n",
      "     |      >>> x.sort(key=lambda f: f.ID)\n",
      "     |      >>> x\n",
      "     |      [<frame ID=200 name=Criminal_process>,\n",
      "     |       <frame ID=500 name=Criminal_investigation>,\n",
      "     |       <frame ID=692 name=Crime_scenario>,\n",
      "     |       <frame ID=700 name=Committing_crime>]\n",
      "     |      \n",
      "     |      A brief intro to Frames (excerpted from \"FrameNet II: Extended\n",
      "     |      Theory and Practice\" by Ruppenhofer et. al., 2010):\n",
      "     |      \n",
      "     |      A Frame is a script-like conceptual structure that describes a\n",
      "     |      particular type of situation, object, or event along with the\n",
      "     |      participants and props that are needed for that Frame. For\n",
      "     |      example, the \"Apply_heat\" frame describes a common situation\n",
      "     |      involving a Cook, some Food, and a Heating_Instrument, and is\n",
      "     |      evoked by words such as bake, blanch, boil, broil, brown,\n",
      "     |      simmer, steam, etc.\n",
      "     |      \n",
      "     |      We call the roles of a Frame \"frame elements\" (FEs) and the\n",
      "     |      frame-evoking words are called \"lexical units\" (LUs).\n",
      "     |      \n",
      "     |      FrameNet includes relations between Frames. Several types of\n",
      "     |      relations are defined, of which the most important are:\n",
      "     |      \n",
      "     |         - Inheritance: An IS-A relation. The child frame is a subtype\n",
      "     |           of the parent frame, and each FE in the parent is bound to\n",
      "     |           a corresponding FE in the child. An example is the\n",
      "     |           \"Revenge\" frame which inherits from the\n",
      "     |           \"Rewards_and_punishments\" frame.\n",
      "     |      \n",
      "     |         - Using: The child frame presupposes the parent frame as\n",
      "     |           background, e.g the \"Speed\" frame \"uses\" (or presupposes)\n",
      "     |           the \"Motion\" frame; however, not all parent FEs need to be\n",
      "     |           bound to child FEs.\n",
      "     |      \n",
      "     |         - Subframe: The child frame is a subevent of a complex event\n",
      "     |           represented by the parent, e.g. the \"Criminal_process\" frame\n",
      "     |           has subframes of \"Arrest\", \"Arraignment\", \"Trial\", and\n",
      "     |           \"Sentencing\".\n",
      "     |      \n",
      "     |         - Perspective_on: The child frame provides a particular\n",
      "     |           perspective on an un-perspectivized parent frame. A pair of\n",
      "     |           examples consists of the \"Hiring\" and \"Get_a_job\" frames,\n",
      "     |           which perspectivize the \"Employment_start\" frame from the\n",
      "     |           Employer's and the Employee's point of view, respectively.\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to match against\n",
      "     |          Frame names. If 'name' is None, then a list of all\n",
      "     |          Framenet Frames will be returned.\n",
      "     |      :type name: str\n",
      "     |      :return: A list of matching Frames (or all Frames).\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  frames_by_lemma(self, pat)\n",
      "     |      Returns a list of all frames that contain LUs in which the\n",
      "     |      ``name`` attribute of the LU matchs the given regular expression\n",
      "     |      ``pat``. Note that LU names are composed of \"lemma.POS\", where\n",
      "     |      the \"lemma\" part can be made up of either a single lexeme\n",
      "     |      (e.g. 'run') or multiple lexemes (e.g. 'a little').\n",
      "     |      \n",
      "     |      Note: if you are going to be doing a lot of this type of\n",
      "     |      searching, you'd want to build an index that maps from lemmas to\n",
      "     |      frames because each time frames_by_lemma() is called, it has to\n",
      "     |      search through ALL of the frame XML files in the db.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.frames_by_lemma(r'(?i)a little') # doctest: +ELLIPSIS\n",
      "     |      [<frame ID=189 name=Quanti...>, <frame ID=2001 name=Degree>]\n",
      "     |      \n",
      "     |      :return: A list of frame objects.\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  ft_sents(self, docNamePattern=None)\n",
      "     |      Full-text annotation sentences, optionally filtered by document name.\n",
      "     |  \n",
      "     |  help(self, attrname=None)\n",
      "     |      Display help information summarizing the main methods.\n",
      "     |  \n",
      "     |  lu(self, fn_luid, ignorekeys=[], luName=None, frameID=None, frameName=None)\n",
      "     |      Access a lexical unit by its ID. luName, frameID, and frameName are used\n",
      "     |      only in the event that the LU does not have a file in the database\n",
      "     |      (which is the case for LUs with \"Problem\" status); in this case,\n",
      "     |      a placeholder LU is created which just contains its name, ID, and frame.\n",
      "     |      \n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.lu(256).name\n",
      "     |      'foresee.v'\n",
      "     |      >>> fn.lu(256).definition\n",
      "     |      'COD: be aware of beforehand; predict.'\n",
      "     |      >>> fn.lu(256).frame.name\n",
      "     |      'Expectation'\n",
      "     |      >>> pprint(list(map(PrettyDict, fn.lu(256).lexemes)))\n",
      "     |      [{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}]\n",
      "     |      \n",
      "     |      >>> fn.lu(227).exemplars[23]\n",
      "     |      exemplar sentence (352962):\n",
      "     |      [sentNo] 0\n",
      "     |      [aPos] 59699508\n",
      "     |      <BLANKLINE>\n",
      "     |      [LU] (227) guess.v in Coming_to_believe\n",
      "     |      <BLANKLINE>\n",
      "     |      [frame] (23) Coming_to_believe\n",
      "     |      <BLANKLINE>\n",
      "     |      [annotationSet] 2 annotation sets\n",
      "     |      <BLANKLINE>\n",
      "     |      [POS] 18 tags\n",
      "     |      <BLANKLINE>\n",
      "     |      [POS_tagset] BNC\n",
      "     |      <BLANKLINE>\n",
      "     |      [GF] 3 relations\n",
      "     |      <BLANKLINE>\n",
      "     |      [PT] 3 phrases\n",
      "     |      <BLANKLINE>\n",
      "     |      [Other] 1 entry\n",
      "     |      <BLANKLINE>\n",
      "     |      [text] + [Target] + [FE]\n",
      "     |      <BLANKLINE>\n",
      "     |      When he was inside the house , Culley noticed the characteristic\n",
      "     |                                                    ------------------\n",
      "     |                                                    Content\n",
      "     |      <BLANKLINE>\n",
      "     |      he would n't have guessed at .\n",
      "     |      --                ******* --\n",
      "     |      Co                        C1 [Evidence:INI]\n",
      "     |       (Co=Cognizer, C1=Content)\n",
      "     |      <BLANKLINE>\n",
      "     |      <BLANKLINE>\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain most of the\n",
      "     |      following information about the LU. Note that some LUs do not contain\n",
      "     |      all of these pieces of information - particularly 'totalAnnotated' and\n",
      "     |      'incorporatedFE' may be missing in some LUs:\n",
      "     |      \n",
      "     |      - 'name'       : the name of the LU (e.g. 'merger.n')\n",
      "     |      - 'definition' : textual definition of the LU\n",
      "     |      - 'ID'         : the internal ID number of the LU\n",
      "     |      - '_type'      : 'lu'\n",
      "     |      - 'status'     : e.g. 'Created'\n",
      "     |      - 'frame'      : Frame that this LU belongs to\n",
      "     |      - 'POS'        : the part of speech of this LU (e.g. 'N')\n",
      "     |      - 'totalAnnotated' : total number of examples annotated with this LU\n",
      "     |      - 'incorporatedFE' : FE that incorporates this LU (e.g. 'Ailment')\n",
      "     |      - 'sentenceCount'  : a dict with the following two keys:\n",
      "     |               - 'annotated': number of sentences annotated with this LU\n",
      "     |               - 'total'    : total number of sentences with this LU\n",
      "     |      \n",
      "     |      - 'lexemes'  : a list of dicts describing the lemma of this LU.\n",
      "     |         Each dict in the list contains these keys:\n",
      "     |         - 'POS'     : part of speech e.g. 'N'\n",
      "     |         - 'name'    : either single-lexeme e.g. 'merger' or\n",
      "     |                       multi-lexeme e.g. 'a little'\n",
      "     |         - 'order': the order of the lexeme in the lemma (starting from 1)\n",
      "     |         - 'headword': a boolean ('true' or 'false')\n",
      "     |         - 'breakBefore': Can this lexeme be separated from the previous lexeme?\n",
      "     |              Consider: \"take over.v\" as in:\n",
      "     |                       Germany took over the Netherlands in 2 days.\n",
      "     |                       Germany took the Netherlands over in 2 days.\n",
      "     |              In this case, 'breakBefore' would be \"true\" for the lexeme\n",
      "     |              \"over\". Contrast this with \"take after.v\" as in:\n",
      "     |                       Mary takes after her grandmother.\n",
      "     |                      *Mary takes her grandmother after.\n",
      "     |              In this case, 'breakBefore' would be \"false\" for the lexeme \"after\"\n",
      "     |      \n",
      "     |      - 'lemmaID'    : Can be used to connect lemmas in different LUs\n",
      "     |      - 'semTypes'   : a list of semantic type objects for this LU\n",
      "     |      - 'subCorpus'  : a list of subcorpora\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'name' :\n",
      "     |            - 'sentence' : a list of sentences in the subcorpus\n",
      "     |               - each item in the list is a dict with the following keys:\n",
      "     |                  - 'ID':\n",
      "     |                  - 'sentNo':\n",
      "     |                  - 'text': the text of the sentence\n",
      "     |                  - 'aPos':\n",
      "     |                  - 'annotationSet': a list of annotation sets\n",
      "     |                     - each item in the list is a dict with the following keys:\n",
      "     |                        - 'ID':\n",
      "     |                        - 'status':\n",
      "     |                        - 'layer': a list of layers\n",
      "     |                           - each layer is a dict containing the following keys:\n",
      "     |                              - 'name': layer name (e.g. 'BNC')\n",
      "     |                              - 'rank':\n",
      "     |                              - 'label': a list of labels for the layer\n",
      "     |                                 - each label is a dict containing the following keys:\n",
      "     |                                    - 'start': start pos of label in sentence 'text' (0-based)\n",
      "     |                                    - 'end': end pos of label in sentence 'text' (0-based)\n",
      "     |                                    - 'name': name of label (e.g. 'NN1')\n",
      "     |      \n",
      "     |      Under the hood, this implementation looks up the lexical unit information\n",
      "     |      in the *frame* definition file. That file does not contain\n",
      "     |      corpus annotations, so the LU files will be accessed on demand if those are\n",
      "     |      needed. In principle, valence patterns could be loaded here too,\n",
      "     |      though these are not currently supported.\n",
      "     |      \n",
      "     |      :param fn_luid: The id number of the lexical unit\n",
      "     |      :type fn_luid: int\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: All information about the lexical unit\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  lu_basic(self, fn_luid)\n",
      "     |      Returns basic information about the LU whose id is\n",
      "     |      ``fn_luid``. This is basically just a wrapper around the\n",
      "     |      ``lu()`` function with \"subCorpus\" info excluded.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> lu = PrettyDict(fn.lu_basic(256), breakLines=True)\n",
      "     |      >>> # ellipses account for differences between FN 1.5 and 1.7\n",
      "     |      >>> lu # doctest: +ELLIPSIS\n",
      "     |      {'ID': 256,\n",
      "     |       'POS': 'V',\n",
      "     |       'URL': u'https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu256.xml',\n",
      "     |       '_type': 'lu',\n",
      "     |       'cBy': ...,\n",
      "     |       'cDate': '02/08/2001 01:27:50 PST Thu',\n",
      "     |       'definition': 'COD: be aware of beforehand; predict.',\n",
      "     |       'definitionMarkup': 'COD: be aware of beforehand; predict.',\n",
      "     |       'frame': <frame ID=26 name=Expectation>,\n",
      "     |       'lemmaID': 15082,\n",
      "     |       'lexemes': [{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}],\n",
      "     |       'name': 'foresee.v',\n",
      "     |       'semTypes': [],\n",
      "     |       'sentenceCount': {'annotated': ..., 'total': ...},\n",
      "     |       'status': 'FN1_Sent'}\n",
      "     |      \n",
      "     |      :param fn_luid: The id number of the desired LU\n",
      "     |      :type fn_luid: int\n",
      "     |      :return: Basic information about the lexical unit\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  lu_ids_and_names(self, name=None)\n",
      "     |      Uses the LU index, which is much faster than looking up each LU definition\n",
      "     |      if only the names and IDs are needed.\n",
      "     |  \n",
      "     |  lus(self, name=None, frame=None)\n",
      "     |      Obtain details for lexical units.\n",
      "     |      Optionally restrict by lexical unit name pattern, and/or to a certain frame\n",
      "     |      or frames whose name matches a pattern.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.lus()) in (11829, 13572) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyList(fn.lus(r'(?i)a little'), maxReprSize=0, breakLines=True)\n",
      "     |      [<lu ID=14744 name=a little bit.adv>,\n",
      "     |       <lu ID=14733 name=a little.n>,\n",
      "     |       <lu ID=14743 name=a little.adv>]\n",
      "     |      >>> fn.lus(r'interest', r'(?i)stimulus')\n",
      "     |      [<lu ID=14920 name=interesting.a>, <lu ID=14894 name=interested.a>]\n",
      "     |      \n",
      "     |      A brief intro to Lexical Units (excerpted from \"FrameNet II:\n",
      "     |      Extended Theory and Practice\" by Ruppenhofer et. al., 2010):\n",
      "     |      \n",
      "     |      A lexical unit (LU) is a pairing of a word with a meaning. For\n",
      "     |      example, the \"Apply_heat\" Frame describes a common situation\n",
      "     |      involving a Cook, some Food, and a Heating Instrument, and is\n",
      "     |      _evoked_ by words such as bake, blanch, boil, broil, brown,\n",
      "     |      simmer, steam, etc. These frame-evoking words are the LUs in the\n",
      "     |      Apply_heat frame. Each sense of a polysemous word is a different\n",
      "     |      LU.\n",
      "     |      \n",
      "     |      We have used the word \"word\" in talking about LUs. The reality\n",
      "     |      is actually rather complex. When we say that the word \"bake\" is\n",
      "     |      polysemous, we mean that the lemma \"bake.v\" (which has the\n",
      "     |      word-forms \"bake\", \"bakes\", \"baked\", and \"baking\") is linked to\n",
      "     |      three different frames:\n",
      "     |      \n",
      "     |         - Apply_heat: \"Michelle baked the potatoes for 45 minutes.\"\n",
      "     |      \n",
      "     |         - Cooking_creation: \"Michelle baked her mother a cake for her birthday.\"\n",
      "     |      \n",
      "     |         - Absorb_heat: \"The potatoes have to bake for more than 30 minutes.\"\n",
      "     |      \n",
      "     |      These constitute three different LUs, with different\n",
      "     |      definitions.\n",
      "     |      \n",
      "     |      Multiword expressions such as \"given name\" and hyphenated words\n",
      "     |      like \"shut-eye\" can also be LUs. Idiomatic phrases such as\n",
      "     |      \"middle of nowhere\" and \"give the slip (to)\" are also defined as\n",
      "     |      LUs in the appropriate frames (\"Isolated_places\" and \"Evading\",\n",
      "     |      respectively), and their internal structure is not analyzed.\n",
      "     |      \n",
      "     |      Framenet provides multiple annotated examples of each sense of a\n",
      "     |      word (i.e. each LU).  Moreover, the set of examples\n",
      "     |      (approximately 20 per LU) illustrates all of the combinatorial\n",
      "     |      possibilities of the lexical unit.\n",
      "     |      \n",
      "     |      Each LU is linked to a Frame, and hence to the other words which\n",
      "     |      evoke that Frame. This makes the FrameNet database similar to a\n",
      "     |      thesaurus, grouping together semantically similar words.\n",
      "     |      \n",
      "     |      In the simplest case, frame-evoking words are verbs such as\n",
      "     |      \"fried\" in:\n",
      "     |      \n",
      "     |         \"Matilde fried the catfish in a heavy iron skillet.\"\n",
      "     |      \n",
      "     |      Sometimes event nouns may evoke a Frame. For example,\n",
      "     |      \"reduction\" evokes \"Cause_change_of_scalar_position\" in:\n",
      "     |      \n",
      "     |         \"...the reduction of debt levels to $665 million from $2.6 billion.\"\n",
      "     |      \n",
      "     |      Adjectives may also evoke a Frame. For example, \"asleep\" may\n",
      "     |      evoke the \"Sleep\" frame as in:\n",
      "     |      \n",
      "     |         \"They were asleep for hours.\"\n",
      "     |      \n",
      "     |      Many common nouns, such as artifacts like \"hat\" or \"tower\",\n",
      "     |      typically serve as dependents rather than clearly evoking their\n",
      "     |      own frames.\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to search the LU\n",
      "     |          names. Note that LU names take the form of a dotted\n",
      "     |          string (e.g. \"run.v\" or \"a little.adv\") in which a\n",
      "     |          lemma preceeds the \".\" and a POS follows the\n",
      "     |          dot. The lemma may be composed of a single lexeme\n",
      "     |          (e.g. \"run\") or of multiple lexemes (e.g. \"a\n",
      "     |          little\"). If 'name' is not given, then all LUs will\n",
      "     |          be returned.\n",
      "     |      \n",
      "     |          The valid POSes are:\n",
      "     |      \n",
      "     |                 v    - verb\n",
      "     |                 n    - noun\n",
      "     |                 a    - adjective\n",
      "     |                 adv  - adverb\n",
      "     |                 prep - preposition\n",
      "     |                 num  - numbers\n",
      "     |                 intj - interjection\n",
      "     |                 art  - article\n",
      "     |                 c    - conjunction\n",
      "     |                 scon - subordinating conjunction\n",
      "     |      \n",
      "     |      :type name: str\n",
      "     |      :type frame: str or int or frame\n",
      "     |      :return: A list of selected (or all) lexical units\n",
      "     |      :rtype: list of LU objects (dicts). See the lu() function for info\n",
      "     |        about the specifics of LU objects.\n",
      "     |  \n",
      "     |  propagate_semtypes(self)\n",
      "     |      Apply inference rules to distribute semtypes over relations between FEs.\n",
      "     |      For FrameNet 1.5, this results in 1011 semtypes being propagated.\n",
      "     |      (Not done by default because it requires loading all frame files,\n",
      "     |      which takes several seconds. If this needed to be fast, it could be rewritten\n",
      "     |      to traverse the neighboring relations on demand for each FE semtype.)\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> x = sum(1 for f in fn.frames() for fe in f.FE.values() if fe.semType)\n",
      "     |      >>> fn.propagate_semtypes()\n",
      "     |      >>> y = sum(1 for f in fn.frames() for fe in f.FE.values() if fe.semType)\n",
      "     |      >>> y-x > 1000\n",
      "     |      True\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt (or README) file.\n",
      "     |  \n",
      "     |  semtype(self, key)\n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.semtype(233).name\n",
      "     |      'Temperature'\n",
      "     |      >>> fn.semtype(233).abbrev\n",
      "     |      'Temp'\n",
      "     |      >>> fn.semtype('Temperature').ID\n",
      "     |      233\n",
      "     |      \n",
      "     |      :param key: The name, abbreviation, or id number of the semantic type\n",
      "     |      :type key: string or int\n",
      "     |      :return: Information about a semantic type\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  semtype_inherits(self, st, superST)\n",
      "     |  \n",
      "     |  semtypes(self)\n",
      "     |      Obtain a list of semantic types.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> stypes = fn.semtypes()\n",
      "     |      >>> len(stypes) in (73, 109) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> sorted(stypes[0].keys())\n",
      "     |      ['ID', '_type', 'abbrev', 'definition', 'definitionMarkup', 'name', 'rootType', 'subTypes', 'superType']\n",
      "     |      \n",
      "     |      :return: A list of all of the semantic types in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  sents(self, exemplars=True, full_text=True)\n",
      "     |      Annotated sentences matching the specified criteria.\n",
      "     |  \n",
      "     |  warnings(self, v)\n",
      "     |      Enable or disable warnings of data integrity issues as they are encountered.\n",
      "     |      If v is truthy, warnings will be enabled.\n",
      "     |      \n",
      "     |      (This is a function rather than just an attribute/property to ensure that if\n",
      "     |      enabling warnings is the first action taken, the corpus reader is instantiated first.)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IEERCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Method resolution order:\n",
      "     |      IEERCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  docs(self, fileids=None)\n",
      "     |  \n",
      "     |  parsed_docs(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IPIPANCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Corpus reader designed to work with corpus created by IPI PAN.\n",
      "     |  See http://korpus.pl/en/ for more details about IPI PAN corpus.\n",
      "     |  \n",
      "     |  The corpus includes information about text domain, channel and categories.\n",
      "     |  You can access possible values using ``domains()``, ``channels()`` and\n",
      "     |  ``categories()``. You can use also this metadata to filter files, e.g.:\n",
      "     |  ``fileids(channel='prasa')``, ``fileids(categories='publicystyczny')``.\n",
      "     |  \n",
      "     |  The reader supports methods: words, sents, paras and their tagged versions.\n",
      "     |  You can get part of speech instead of full tag by giving \"simplify_tags=True\"\n",
      "     |  parameter, e.g.: ``tagged_sents(simplify_tags=True)``.\n",
      "     |  \n",
      "     |  Also you can get all tags disambiguated tags specifying parameter\n",
      "     |  \"one_tag=False\", e.g.: ``tagged_paras(one_tag=False)``.\n",
      "     |  \n",
      "     |  You can get all tags that were assigned by a morphological analyzer specifying\n",
      "     |  parameter \"disamb_only=False\", e.g. ``tagged_words(disamb_only=False)``.\n",
      "     |  \n",
      "     |  The IPIPAN Corpus contains tags indicating if there is a space between two\n",
      "     |  tokens. To add special \"no space\" markers, you should specify parameter\n",
      "     |  \"append_no_space=True\", e.g. ``tagged_words(append_no_space=True)``.\n",
      "     |  As a result in place where there should be no space between two tokens new\n",
      "     |  pair ('', 'no-space') will be inserted (for tagged data) and just '' for\n",
      "     |  methods without tags.\n",
      "     |  \n",
      "     |  The corpus reader can also try to append spaces between words. To enable this\n",
      "     |  option, specify parameter \"append_space=True\", e.g. ``words(append_space=True)``.\n",
      "     |  As a result either ' ' or (' ', 'space') will be inserted between tokens.\n",
      "     |  \n",
      "     |  By default, xml entities like &quot; and &amp; are replaced by corresponding\n",
      "     |  characters. You can turn off this feature, specifying parameter\n",
      "     |  \"replace_xmlentities=False\", e.g. ``words(replace_xmlentities=False)``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IPIPANCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |  \n",
      "     |  channels(self, fileids=None)\n",
      "     |  \n",
      "     |  domains(self, fileids=None)\n",
      "     |  \n",
      "     |  fileids(self, channels=None, domains=None, categories=None)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  words(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IndianCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndianCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class KNBCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  This class implements:\n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  The structure of tagged words:\n",
      "     |    tagged_word = (word(str), tags(tuple))\n",
      "     |    tags = (surface, reading, lemma, pos1, posid1, pos2, posid2, pos3, posid3, others ...)\n",
      "     |  \n",
      "     |  Usage example\n",
      "     |  -------------\n",
      "     |  \n",
      "     |  >>> from nltk.corpus.util import LazyCorpusLoader\n",
      "     |  >>> knbc = LazyCorpusLoader(\n",
      "     |  ...     'knbc/corpus1',\n",
      "     |  ...     KNBCorpusReader,\n",
      "     |  ...     r'.*/KN.*',\n",
      "     |  ...     encoding='euc-jp',\n",
      "     |  ... )\n",
      "     |  \n",
      "     |  >>> len(knbc.sents()[0])\n",
      "     |  9\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KNBCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', morphs2str=<function <lambda> at 0x7fdf40847510>)\n",
      "     |      Initialize KNBCorpusReader\n",
      "     |      morphs2str is a function to convert morphlist to str for tree representation\n",
      "     |      for _parse()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class LinThesaurusCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Wrapper for the LISP-formatted thesauruses distributed by Dekang Lin.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinThesaurusCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, ngram)\n",
      "     |      Determines whether or not the given ngram is in the thesaurus.\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :return: whether the given ngram is in the thesaurus.\n",
      "     |  \n",
      "     |  __init__(self, root, badscore=0.0)\n",
      "     |      Initialize the thesaurus.\n",
      "     |      \n",
      "     |      :param root: root directory containing thesaurus LISP files\n",
      "     |      :type root: C{string}\n",
      "     |      :param badscore: the score to give to words which do not appear in each other's sets of synonyms\n",
      "     |      :type badscore: C{float}\n",
      "     |  \n",
      "     |  scored_synonyms(self, ngram, fileid=None)\n",
      "     |      Returns a list of scored synonyms (tuples of synonyms and scores) for the current ngram\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, list of tuples of scores and synonyms; otherwise,\n",
      "     |               list of tuples of fileids and lists, where inner lists consist of tuples of\n",
      "     |               scores and synonyms.\n",
      "     |  \n",
      "     |  similarity(self, ngram1, ngram2, fileid=None)\n",
      "     |      Returns the similarity score for two ngrams.\n",
      "     |      \n",
      "     |      :param ngram1: first ngram to compare\n",
      "     |      :type ngram1: C{string}\n",
      "     |      :param ngram2: second ngram to compare\n",
      "     |      :type ngram2: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, just the score for the two ngrams; otherwise,\n",
      "     |               list of tuples of fileids and scores.\n",
      "     |  \n",
      "     |  synonyms(self, ngram, fileid=None)\n",
      "     |      Returns a list of synonyms for the current ngram.\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, list of synonyms; otherwise, list of tuples of fileids and\n",
      "     |               lists, where inner lists contain synonyms.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MTECorpusReader(nltk.corpus.reader.tagged.TaggedCorpusReader)\n",
      "     |  Reader for corpora following the TEI-p5 xml scheme, such as MULTEXT-East.\n",
      "     |  MULTEXT-East contains part-of-speech-tagged words with a quite precise tagging\n",
      "     |  scheme. These tags can be converted to the Universal tagset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MTECorpusReader\n",
      "     |      nltk.corpus.reader.tagged.TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root=None, fileids=None, encoding='utf8')\n",
      "     |      Construct a new MTECorpusreader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = MTECorpusReader(root, 'oana-*.xml', 'utf8') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus. (default points to location in multext config file)\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus. (default is oana-en.xml)\n",
      "     |      :param enconding: The encoding of the given files (default is utf8)\n",
      "     |  \n",
      "     |  lemma_paras(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a\n",
      "     |               list of sentences, which are in turn encoded as a list of\n",
      "     |               tuples of the word and the corresponding lemma (word, lemma)\n",
      "     |      :rtype: list(List(List(tuple(str, str))))\n",
      "     |  \n",
      "     |  lemma_sents(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |               encoded as a list of tuples of the word and the corresponding\n",
      "     |               lemma (word, lemma)\n",
      "     |      :rtype: list(list(tuple(str, str)))\n",
      "     |  \n",
      "     |  lemma_words(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of words, the corresponding lemmas\n",
      "     |               and punctuation symbols, encoded as tuples (word, lemma)\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a list\n",
      "     |               of sentences, which are in turn encoded as lists of word string\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Prints some information about this corpus.\n",
      "     |      :return: the content of the attached README file\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of sentences or utterances,\n",
      "     |               each encoded as a list of word strings\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a\n",
      "     |               list of sentences, which are in turn encoded as a list\n",
      "     |               of (word,tag) tuples\n",
      "     |      :rtype: list(list(list(tuple(str, str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |               each encoded as a list of (word,tag) tuples\n",
      "     |      :rtype: list(list(tuple(str, str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of tagged words and punctuation symbols\n",
      "     |               encoded as tuples (word, tag)\n",
      "     |      :rtype: list(tuple(str, str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MWAPPDBCorpusReader(WordListCorpusReader)\n",
      "     |  This class is used to read the list of word pairs from the subset of lexical\n",
      "     |  pairs of The Paraphrase Database (PPDB) XXXL used in the Monolingual Word\n",
      "     |  Alignment (MWA) algorithm described in Sultan et al. (2014a, 2014b, 2015):\n",
      "     |   - http://acl2014.org/acl2014/Q14/pdf/Q14-1017\n",
      "     |   - http://www.aclweb.org/anthology/S14-2039\n",
      "     |   - http://www.aclweb.org/anthology/S15-2027\n",
      "     |  \n",
      "     |  The original source of the full PPDB corpus can be found on\n",
      "     |  http://www.cis.upenn.edu/~ccb/ppdb/\n",
      "     |  \n",
      "     |  :return: a list of tuples of similar lexical terms.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MWAPPDBCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids='ppdb-1.0-xxxl-lexical.extended.synonyms.uniquepairs')\n",
      "     |      :return: a tuple of synonym word pairs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  mwa_ppdb_xxxl_file = 'ppdb-1.0-xxxl-lexical.extended.synonyms.uniquepa...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MacMorphoCorpusReader(TaggedCorpusReader)\n",
      "     |  A corpus reader for the MAC_MORPHO corpus.  Each line contains a\n",
      "     |  single tagged word, using '_' as a separator.  Sentence boundaries\n",
      "     |  are based on the end-sentence tag ('_.').  Paragraph information\n",
      "     |  is not included in the corpus, so each paragraph returned by\n",
      "     |  ``self.paras()`` and ``self.tagged_paras()`` contains a single\n",
      "     |  sentence.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MacMorphoCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TaggedCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NKJPCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NKJPCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids='.*')\n",
      "     |      Corpus reader designed to work with National Corpus of Polish.\n",
      "     |      See http://nkjp.pl/ for more details about NKJP.\n",
      "     |      use example:\n",
      "     |      import nltk\n",
      "     |      import nkjp\n",
      "     |      from nkjp import NKJPCorpusReader\n",
      "     |      x = NKJPCorpusReader(root='/home/USER/nltk_data/corpora/nkjp/', fileids='') # obtain the whole corpus\n",
      "     |      x.header()\n",
      "     |      x.raw()\n",
      "     |      x.words()\n",
      "     |      x.tagged_words(tags=['subst', 'comp'])  #Link to find more tags: nkjp.pl/poliqarp/help/ense2.html\n",
      "     |      x.sents()\n",
      "     |      x = NKJPCorpusReader(root='/home/USER/nltk_data/corpora/nkjp/', fileids='Wilk*') # obtain particular file(s)\n",
      "     |      x.header(fileids=['WilkDom', '/home/USER/nltk_data/corpora/nkjp/WilkWilczy'])\n",
      "     |      x.tagged_words(fileids=['WilkDom', '/home/USER/nltk_data/corpora/nkjp/WilkWilczy'], tags=['subst', 'comp'])\n",
      "     |  \n",
      "     |  add_root(self, fileid)\n",
      "     |      Add root if necessary to specified fileid.\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Returns a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  get_paths(self)\n",
      "     |  \n",
      "     |  header(self, fileids=None, **kwargs)\n",
      "     |      Returns header(s) of specified fileids.\n",
      "     |  \n",
      "     |  raw(self, fileids=None, **kwargs)\n",
      "     |      Returns words in specified fileids.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, **kwargs)\n",
      "     |      Returns sentences in specified fileids.\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, **kwargs)\n",
      "     |      Call with specified tags as a list, e.g. tags=['subst', 'comp'].\n",
      "     |      Returns tagged words in specified fileids.\n",
      "     |  \n",
      "     |  words(self, fileids=None, **kwargs)\n",
      "     |      Returns words in specified fileids.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  HEADER_MODE = 2\n",
      "     |  \n",
      "     |  RAW_MODE = 3\n",
      "     |  \n",
      "     |  SENTS_MODE = 1\n",
      "     |  \n",
      "     |  WORDS_MODE = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NPSChatCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NPSChatCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  posts(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_posts(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml_posts(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NombankCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Corpus reader for the nombank corpus, which augments the Penn\n",
      "     |  Treebank with information about the predicate argument structure\n",
      "     |  of every noun instance.  The corpus consists of two parts: the\n",
      "     |  predicate-argument annotations themselves, and a set of \"frameset\n",
      "     |  files\" which define the argument labels used by the annotations,\n",
      "     |  on a per-noun basis.  Each \"frameset file\" contains one or more\n",
      "     |  predicates, such as ``'turn'`` or ``'turn_on'``, each of which is\n",
      "     |  divided into coarse-grained word senses called \"rolesets\".  For\n",
      "     |  each \"roleset\", the frameset file provides descriptions of the\n",
      "     |  argument roles, along with examples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NombankCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, nomfile, framefiles='', nounsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param nomfile: The name of the file containing the predicate-\n",
      "     |          argument annotations (relative to ``root``).\n",
      "     |      :param framefiles: A list or regexp specifying the frameset\n",
      "     |          fileids for this corpus.\n",
      "     |      :param parse_fileid_xform: A transform that should be applied\n",
      "     |          to the fileids in this corpus.  This should be a function\n",
      "     |          of one argument (a fileid) that returns a string (the new\n",
      "     |          fileid).\n",
      "     |      :param parse_corpus: The corpus containing the parse trees\n",
      "     |          corresponding to this corpus.  These parse trees are\n",
      "     |          necessary to resolve the tree pointers used by nombank.\n",
      "     |  \n",
      "     |  instances(self, baseform=None)\n",
      "     |      :return: a corpus view that acts as a list of\n",
      "     |      ``NombankInstance`` objects, one for each noun in the corpus.\n",
      "     |  \n",
      "     |  lines(self)\n",
      "     |      :return: a corpus view that acts as a list of strings, one for\n",
      "     |      each line in the predicate-argument annotation file.\n",
      "     |  \n",
      "     |  nouns(self)\n",
      "     |      :return: a corpus view that acts as a list of all noun lemmas\n",
      "     |      in this corpus (from the nombank.1.0.words file).\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  roleset(self, roleset_id)\n",
      "     |      :return: the xml description for the given roleset.\n",
      "     |  \n",
      "     |  rolesets(self, baseform=None)\n",
      "     |      :return: list of xml descriptions for rolesets.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NonbreakingPrefixesCorpusReader(WordListCorpusReader)\n",
      "     |  This is a class to read the nonbreaking prefixes textfiles from the\n",
      "     |  Moses Machine Translation toolkit. These lists are used in the Python port\n",
      "     |  of the Moses' word tokenizer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NonbreakingPrefixesCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  words(self, lang=None, fileids=None, ignore_lines_startswith='#')\n",
      "     |      This module returns a list of nonbreaking prefixes for the specified\n",
      "     |      language(s).\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import nonbreaking_prefixes as nbp\n",
      "     |      >>> nbp.words('en')[:10] == [u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'H', u'I', u'J']\n",
      "     |      True\n",
      "     |      >>> nbp.words('ta')[:5] == [u'', u'', u'', u'', u'']\n",
      "     |      True\n",
      "     |      \n",
      "     |      :return: a list words for the specified language(s).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  available_langs = {'ca': 'ca', 'catalan': 'ca', 'cs': 'cs', 'czech': '...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class OpinionLexiconCorpusReader(nltk.corpus.reader.wordlist.WordListCorpusReader)\n",
      "     |  Reader for Liu and Hu opinion lexicon.  Blank lines and readme are ignored.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import opinion_lexicon\n",
      "     |      >>> opinion_lexicon.words()\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', ...]\n",
      "     |  \n",
      "     |  The OpinionLexiconCorpusReader provides shortcuts to retrieve positive/negative\n",
      "     |  words:\n",
      "     |  \n",
      "     |      >>> opinion_lexicon.negative()\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', ...]\n",
      "     |  \n",
      "     |  Note that words from `words()` method are sorted by file id, not alphabetically:\n",
      "     |  \n",
      "     |      >>> opinion_lexicon.words()[0:10]\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably',\n",
      "     |      'abominate', 'abomination', 'abort', 'aborted']\n",
      "     |      >>> sorted(opinion_lexicon.words())[0:10]\n",
      "     |      ['2-faced', '2-faces', 'a+', 'abnormal', 'abolish', 'abominable', 'abominably',\n",
      "     |      'abominate', 'abomination', 'abort']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpinionLexiconCorpusReader\n",
      "     |      nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  negative(self)\n",
      "     |      Return all negative words in alphabetical order.\n",
      "     |      \n",
      "     |      :return: a list of negative words.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  positive(self)\n",
      "     |      Return all positive words in alphabetical order.\n",
      "     |      \n",
      "     |      :return: a list of positive words.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words in the opinion lexicon. Note that these words are not\n",
      "     |      sorted in alphabetical order.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.opinion_lexicon.IgnoreReadmeCo...\n",
      "     |      This CorpusView is used to skip the initial readme block of the corpus.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.wordlist.WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PPAttachmentCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  sentence_id verb noun1 preposition noun2 attachment\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PPAttachmentCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  attachments(self, fileids)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  tuples(self, fileids)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PanLexLiteCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PanLexLiteCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  language_varieties(self, lc=None)\n",
      "     |      Return a list of PanLex language varieties.\n",
      "     |      \n",
      "     |      :param lc: ISO 639 alpha-3 code. If specified, filters returned varieties\n",
      "     |          by this code. If unspecified, all varieties are returned.\n",
      "     |      :return: the specified language varieties as a list of tuples. The first\n",
      "     |          element is the language variety's seven-character uniform identifier,\n",
      "     |          and the second element is its default name.\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  meanings(self, expr_uid, expr_tt)\n",
      "     |      Return a list of meanings for an expression.\n",
      "     |      \n",
      "     |      :param expr_uid: the expression's language variety, as a seven-character\n",
      "     |          uniform identifier.\n",
      "     |      :param expr_tt: the expression's text.\n",
      "     |      :return: a list of Meaning objects.\n",
      "     |      :rtype: list(Meaning)\n",
      "     |  \n",
      "     |  translations(self, from_uid, from_tt, to_uid)\n",
      "     |      Return a list of translations for an expression into a single language\n",
      "     |          variety.\n",
      "     |      \n",
      "     |      :param from_uid: the source expression's language variety, as a\n",
      "     |          seven-character uniform identifier.\n",
      "     |      :param from_tt: the source expression's text.\n",
      "     |      :param to_uid: the target language variety, as a seven-character\n",
      "     |          uniform identifier.\n",
      "     |      :return a list of translation tuples. The first element is the expression \n",
      "     |          text and the second element is the translation quality.\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEANING_Q = '\\n        SELECT dnx2.mn, dnx2.uq, dnx2.ap, dnx2.... AND ...\n",
      "     |  \n",
      "     |  TRANSLATION_Q = '\\n        SELECT s.tt, sum(s.uq) AS trq FROM (\\n  ......\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class Pl196xCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  A mixin class used to aid in the implementation of corpus readers\n",
      "     |  for categorized corpora.  This class defines the method\n",
      "     |  ``categories()``, which returns a list of the categories for the\n",
      "     |  corpus or for a specified set of fileids; and overrides ``fileids()``\n",
      "     |  to take a ``categories`` argument, restricting the set of fileids to\n",
      "     |  be returned.\n",
      "     |  \n",
      "     |  Subclasses are expected to:\n",
      "     |  \n",
      "     |    - Call ``__init__()`` to set up the mapping.\n",
      "     |  \n",
      "     |    - Override all view methods to accept a ``categories`` parameter,\n",
      "     |      which can be used *instead* of the ``fileids`` parameter, to\n",
      "     |      select which fileids should be included in the returned view.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Pl196xCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize this mapping based on keyword arguments, as\n",
      "     |      follows:\n",
      "     |      \n",
      "     |        - cat_pattern: A regular expression pattern used to find the\n",
      "     |          category for each file identifier.  The pattern will be\n",
      "     |          applied to each file identifier, and the first matching\n",
      "     |          group will be used as the category label for that file.\n",
      "     |      \n",
      "     |        - cat_map: A dictionary, mapping from file identifiers to\n",
      "     |          category labels.\n",
      "     |      \n",
      "     |        - cat_file: The name of a file that contains the mapping\n",
      "     |          from file identifiers to categories.  The argument\n",
      "     |          ``cat_delimiter`` can be used to specify a delimiter.\n",
      "     |      \n",
      "     |      The corresponding argument will be deleted from ``kwargs``.  If\n",
      "     |      more than one argument is specified, an exception will be\n",
      "     |      raised.\n",
      "     |  \n",
      "     |  decode_tag(self, tag)\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  textids(self, fileids=None, categories=None)\n",
      "     |      In the pl196x corpus each category is stored in single\n",
      "     |      file and thus both methods provide identical functionality. In order\n",
      "     |      to accommodate finer granularity, a non-standard textids() method was\n",
      "     |      implemented. All the main functions can be supplied with a list\n",
      "     |      of required chunks---giving much more control to the user.\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None, textids=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  head_len = 2770\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PlaintextCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      "     |  are assumed to be split using blank lines.  Sentences and words can\n",
      "     |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specificed as parameters to the constructor.\n",
      "     |  \n",
      "     |  This corpus reader can be customized (e.g., to skip preface\n",
      "     |  sections of specific document formats) by creating a subclass and\n",
      "     |  overriding the ``CorpusView`` class variable.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x7fdf408efe10>, para_block_reader=<function read_blankline_block at 0x7fdf40904488>, encoding='utf8')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PortugueseCategorizedPlaintextCorpusReader(CategorizedPlaintextCorpusReader)\n",
      "     |  A reader for plaintext corpora whose documents are divided into\n",
      "     |  categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PortugueseCategorizedPlaintextCorpusReader\n",
      "     |      CategorizedPlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``PlaintextCorpusReader`` constructor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CategorizedPlaintextCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PropbankCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Corpus reader for the propbank corpus, which augments the Penn\n",
      "     |  Treebank with information about the predicate argument structure\n",
      "     |  of every verb instance.  The corpus consists of two parts: the\n",
      "     |  predicate-argument annotations themselves, and a set of \"frameset\n",
      "     |  files\" which define the argument labels used by the annotations,\n",
      "     |  on a per-verb basis.  Each \"frameset file\" contains one or more\n",
      "     |  predicates, such as ``'turn'`` or ``'turn_on'``, each of which is\n",
      "     |  divided into coarse-grained word senses called \"rolesets\".  For\n",
      "     |  each \"roleset\", the frameset file provides descriptions of the\n",
      "     |  argument roles, along with examples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PropbankCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, propfile, framefiles='', verbsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param propfile: The name of the file containing the predicate-\n",
      "     |          argument annotations (relative to ``root``).\n",
      "     |      :param framefiles: A list or regexp specifying the frameset\n",
      "     |          fileids for this corpus.\n",
      "     |      :param parse_fileid_xform: A transform that should be applied\n",
      "     |          to the fileids in this corpus.  This should be a function\n",
      "     |          of one argument (a fileid) that returns a string (the new\n",
      "     |          fileid).\n",
      "     |      :param parse_corpus: The corpus containing the parse trees\n",
      "     |          corresponding to this corpus.  These parse trees are\n",
      "     |          necessary to resolve the tree pointers used by propbank.\n",
      "     |  \n",
      "     |  instances(self, baseform=None)\n",
      "     |      :return: a corpus view that acts as a list of\n",
      "     |      ``PropBankInstance`` objects, one for each noun in the corpus.\n",
      "     |  \n",
      "     |  lines(self)\n",
      "     |      :return: a corpus view that acts as a list of strings, one for\n",
      "     |      each line in the predicate-argument annotation file.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  roleset(self, roleset_id)\n",
      "     |      :return: the xml description for the given roleset.\n",
      "     |  \n",
      "     |  rolesets(self, baseform=None)\n",
      "     |      :return: list of xml descriptions for rolesets.\n",
      "     |  \n",
      "     |  verbs(self)\n",
      "     |      :return: a corpus view that acts as a list of all verb lemmas\n",
      "     |      in this corpus (from the verbs.txt file).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ProsConsCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for the Pros and Cons sentence dataset.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import pros_cons\n",
      "     |      >>> pros_cons.sents(categories='Cons')\n",
      "     |      [['East', 'batteries', '!', 'On', '-', 'off', 'switch', 'too', 'easy',\n",
      "     |      'to', 'maneuver', '.'], ['Eats', '...', 'no', ',', 'GULPS', 'batteries'],\n",
      "     |      ...]\n",
      "     |      >>> pros_cons.words('IntegratedPros.txt')\n",
      "     |      ['Easy', 'to', 'use', ',', 'economical', '!', ...]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ProsConsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8', **kwargs)\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |      :param kwargs: additional parameters passed to CategorizedCorpusReader.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      Return all sentences in the corpus or in the specified files/categories.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose sentences\n",
      "     |          have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences. Each sentence is\n",
      "     |          tokenized using the specified word_tokenizer.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files/categories.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose words have\n",
      "     |          to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class RTECorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Corpus reader for corpora in RTE challenges.\n",
      "     |  \n",
      "     |  This is just a wrapper around the XMLCorpusReader. See module docstring above for the expected\n",
      "     |  structure of input documents.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RTECorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  pairs(self, fileids)\n",
      "     |      Build a list of RTEPairs from a RTE corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list of RTE corpus fileids\n",
      "     |      :type: list\n",
      "     |      :rtype: list(RTEPair)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ReviewsCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for the Customer Review Data dataset by Hu, Liu (2004).\n",
      "     |  Note: we are not applying any sentence tokenization at the moment, just word\n",
      "     |  tokenization.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import product_reviews_1\n",
      "     |      >>> camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
      "     |      >>> review = camera_reviews[0]\n",
      "     |      >>> review.sents()[0]\n",
      "     |      ['i', 'recently', 'purchased', 'the', 'canon', 'powershot', 'g3', 'and', 'am',\n",
      "     |      'extremely', 'satisfied', 'with', 'the', 'purchase', '.']\n",
      "     |      >>> review.features()\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ('picture', '+2'),\n",
      "     |      ('picture quality', '+1'), ('picture quality', '+1'), ('camera', '+2'),\n",
      "     |      ('use', '+2'), ('feature', '+1'), ('picture quality', '+3'), ('use', '+1'),\n",
      "     |      ('option', '+1')]\n",
      "     |  \n",
      "     |  We can also reach the same information directly from the stream:\n",
      "     |  \n",
      "     |      >>> product_reviews_1.features('Canon_G3.txt')\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ...]\n",
      "     |  \n",
      "     |  We can compute stats for specific product features:\n",
      "     |  \n",
      "     |      >>> from __future__ import division\n",
      "     |      >>> n_reviews = len([(feat,score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> tot = sum([int(score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> # We use float for backward compatibility with division in Python2.7\n",
      "     |      >>> mean = tot / n_reviews\n",
      "     |      >>> print(n_reviews, tot, mean)\n",
      "     |      15 24 1.6\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ReviewsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8')\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WordPunctTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  features(self, fileids=None)\n",
      "     |      Return a list of features. Each feature is a tuple made of the specific\n",
      "     |      item feature and the opinion strength about that feature.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          features have to be returned.\n",
      "     |      :return: all features for the item(s) in the given file(s).\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids of the files that\n",
      "     |          have to be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt file.\n",
      "     |  \n",
      "     |  reviews(self, fileids=None)\n",
      "     |      Return all the reviews as a list of Review objects. If `fileids` is\n",
      "     |      specified, return all the reviews from each of the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          reviews have to be returned.\n",
      "     |      :return: the given file(s) as a list of reviews.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus or in the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded as a\n",
      "     |          list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SemcorCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Corpus reader for the SemCor Corpus.\n",
      "     |  For access to the complete XML data structure, use the ``xml()``\n",
      "     |  method.  For access to simple word lists and tagged word lists, use\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SemcorCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wordnet, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  chunk_sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded\n",
      "     |          as a list of chunks.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  chunks(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of chunks,\n",
      "     |          each of which is a list of words and punctuation symbols\n",
      "     |          that form a unit.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded\n",
      "     |          as a list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_chunks(self, fileids=None, tag='pos')\n",
      "     |      :return: the given file(s) as a list of tagged chunks, represented\n",
      "     |          in tree form.\n",
      "     |      :rtype: list(Tree)\n",
      "     |      \n",
      "     |      :param tag: `'pos'` (part of speech), `'sem'` (semantic), or `'both'`\n",
      "     |          to indicate the kind of tags to include.  Semantic tags consist of\n",
      "     |          WordNet lemma IDs, plus an `'NE'` node if the chunk is a named entity\n",
      "     |          without a specific entry in WordNet.  (Named entities of type 'other'\n",
      "     |          have no lemma.  Other chunks not in WordNet have no semantic tag.\n",
      "     |          Punctuation tokens have `None` for their part of speech tag.)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tag='pos')\n",
      "     |      :return: the given file(s) as a list of sentences. Each sentence\n",
      "     |          is represented as a list of tagged chunks (in tree form).\n",
      "     |      :rtype: list(list(Tree))\n",
      "     |      \n",
      "     |      :param tag: `'pos'` (part of speech), `'sem'` (semantic), or `'both'`\n",
      "     |          to indicate the kind of tags to include.  Semantic tags consist of\n",
      "     |          WordNet lemma IDs, plus an `'NE'` node if the chunk is a named entity\n",
      "     |          without a specific entry in WordNet.  (Named entities of type 'other'\n",
      "     |          have no lemma.  Other chunks not in WordNet have no semantic tag.\n",
      "     |          Punctuation tokens have `None` for their part of speech tag.)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SensevalCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SensevalCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  instances(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SentiSynset(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, pos_score, neg_score, synset)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Prints just the Pos/Neg scores for now.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  neg_score(self)\n",
      "     |  \n",
      "     |  obj_score(self)\n",
      "     |  \n",
      "     |  pos_score(self)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SentiWordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SentiWordNetCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf-8')\n",
      "     |      Construct a new SentiWordNet Corpus Reader, using data from\n",
      "     |      the specified file.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  all_senti_synsets(self)\n",
      "     |  \n",
      "     |  senti_synset(self, *vals)\n",
      "     |  \n",
      "     |  senti_synsets(self, string, pos=None)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SinicaTreebankCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  Reader for the sinica treebank.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SinicaTreebankCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class StringCategoryCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StringCategoryCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, delimiter=' ', encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param delimiter: Field delimiter\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  tuples(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SwadeshCorpusReader(WordListCorpusReader)\n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SwadeshCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids=None)\n",
      "     |      :return: a tuple of words for the specified fileids.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SwitchboardCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SwitchboardCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  discourses(self)\n",
      "     |  \n",
      "     |  tagged_discourses(self, tagset=False)\n",
      "     |  \n",
      "     |  tagged_turns(self, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, tagset=None)\n",
      "     |  \n",
      "     |  turns(self)\n",
      "     |  \n",
      "     |  words(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SyntaxCorpusReader(CorpusReader)\n",
      "     |  An abstract base class for reading corpora consisting of\n",
      "     |  syntactically parsed text.  Subclasses should define:\n",
      "     |  \n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SyntaxCorpusReader\n",
      "     |      CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TEICorpusView(nltk.corpus.reader.util.StreamBackedCorpusView)\n",
      "     |  A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |  it can be accessed by index, iterated over, etc.  However, the\n",
      "     |  tokens are only constructed as-needed -- the entire corpus is\n",
      "     |  never stored in memory at once.\n",
      "     |  \n",
      "     |  The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |  a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |  and a block reader.  A \"block reader\" is a function that reads\n",
      "     |  zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |  very simple example of a block reader is:\n",
      "     |  \n",
      "     |      >>> def simple_block_reader(stream):\n",
      "     |      ...     return stream.readline().split()\n",
      "     |  \n",
      "     |  This simple block reader reads a single line at a time, and\n",
      "     |  returns a single token (consisting of a string) for each\n",
      "     |  whitespace-separated substring on the line.\n",
      "     |  \n",
      "     |  When deciding how to define the block reader for a given\n",
      "     |  corpus, careful consideration should be given to the size of\n",
      "     |  blocks handled by the block reader.  Smaller block sizes will\n",
      "     |  increase the memory requirements of the corpus view's internal\n",
      "     |  data structures (by 2 integers per block).  On the other hand,\n",
      "     |  larger block sizes may decrease performance for random access to\n",
      "     |  the corpus.  (But note that larger block sizes will *not*\n",
      "     |  decrease performance for iteration.)\n",
      "     |  \n",
      "     |  Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |  index to file position, with one entry per block.  When a token\n",
      "     |  with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |  it as follows:\n",
      "     |  \n",
      "     |    1. First, it searches the toknum/filepos mapping for the token\n",
      "     |       index closest to (but less than or equal to) *i*.\n",
      "     |  \n",
      "     |    2. Then, starting at the file position corresponding to that\n",
      "     |       index, it reads one block at a time using the block reader\n",
      "     |       until it reaches the requested token.\n",
      "     |  \n",
      "     |  The toknum/filepos mapping is created lazily: it is initially\n",
      "     |  empty, but every time a new block is read, the block's\n",
      "     |  initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |  map has one entry per block.)\n",
      "     |  \n",
      "     |  In order to increase efficiency for random access patterns that\n",
      "     |  have high degrees of locality, the corpus view may cache one or\n",
      "     |  more blocks.\n",
      "     |  \n",
      "     |  :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |      object for its underlying corpus file.  This file should be\n",
      "     |      automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |      but if you wish to close it manually, use the ``close()``\n",
      "     |      method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |      closed, the file object will be automatically re-opened.\n",
      "     |  \n",
      "     |  :warning: If the contents of the file are modified during the\n",
      "     |      lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |      is undefined.\n",
      "     |  \n",
      "     |  :warning: If a unicode encoding is specified when constructing a\n",
      "     |      ``CorpusView``, then the block reader may only call\n",
      "     |      ``stream.seek()`` with offsets that have been returned by\n",
      "     |      ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |      relative offsets, or with offsets based on string lengths, may\n",
      "     |      lead to incorrect behavior.\n",
      "     |  \n",
      "     |  :ivar _block_reader: The function used to read\n",
      "     |      a single block from the underlying file stream.\n",
      "     |  :ivar _toknum: A list containing the token index of each block\n",
      "     |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |      token index of the first token in block ``i``.  Together\n",
      "     |      with ``_filepos``, this forms a partial mapping between token\n",
      "     |      indices and file positions.\n",
      "     |  :ivar _filepos: A list containing the file position of each block\n",
      "     |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |      file position of the first character in block ``i``.  Together\n",
      "     |      with ``_toknum``, this forms a partial mapping between token\n",
      "     |      indices and file positions.\n",
      "     |  :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |  :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |      or None, if the number of tokens is not yet known.\n",
      "     |  :ivar _eofpos: The character position of the last character in the\n",
      "     |      file.  This is calculated when the corpus view is initialized,\n",
      "     |      and is used to decide when the end of file has been reached.\n",
      "     |  :ivar _cache: A cache of the most recently read block.  It\n",
      "     |     is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |     start_toknum is the token index of the first token in the block;\n",
      "     |     end_toknum is the token index of the first token not in the\n",
      "     |     block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TEICorpusView\n",
      "     |      nltk.corpus.reader.util.StreamBackedCorpusView\n",
      "     |      nltk.collections.AbstractLazySequence\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, corpus_file, tagged, group_by_sent, group_by_para, tagset=None, head_len=0, textids=None)\n",
      "     |      Create a new corpus view, based on the file ``fileid``, and\n",
      "     |      read with ``block_reader``.  See the class documentation\n",
      "     |      for more information.\n",
      "     |      \n",
      "     |      :param fileid: The path to the file that is read by this\n",
      "     |          corpus view.  ``fileid`` can either be a string or a\n",
      "     |          ``PathPointer``.\n",
      "     |      \n",
      "     |      :param startpos: The file position at which the view will\n",
      "     |          start reading.  This can be used to skip over preface\n",
      "     |          sections.\n",
      "     |      \n",
      "     |      :param encoding: The unicode encoding that should be used to\n",
      "     |          read the file's contents.  If no encoding is specified,\n",
      "     |          then the file's contents will be read as a non-unicode\n",
      "     |          string (i.e., a str).\n",
      "     |  \n",
      "     |  read_block(self, stream)\n",
      "     |      Read a block from the input stream.\n",
      "     |      \n",
      "     |      :return: a block of tokens from the input stream\n",
      "     |      :rtype: list(any)\n",
      "     |      :param stream: an input stream\n",
      "     |      :type stream: stream\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.util.StreamBackedCorpusView:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |      Return a list concatenating self with other.\n",
      "     |  \n",
      "     |  __getitem__(self, i)\n",
      "     |      Return the *i* th token in the corpus file underlying this\n",
      "     |      corpus view.  Negative indices and spans are both supported.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return the number of tokens in the corpus file underlying this\n",
      "     |      corpus view.\n",
      "     |  \n",
      "     |  __mul__(self, count)\n",
      "     |      Return a list concatenating self with itself ``count`` times.\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |      Return a list concatenating other with self.\n",
      "     |  \n",
      "     |  __rmul__(self, count)\n",
      "     |      Return a list concatenating self with itself ``count`` times.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close the file stream associated with this corpus view.  This\n",
      "     |      can be useful if you are worried about running out of file\n",
      "     |      handles (although the stream should automatically be closed\n",
      "     |      upon garbage collection of the corpus view).  If the corpus\n",
      "     |      view is accessed after it is closed, it will be automatically\n",
      "     |      re-opened.\n",
      "     |  \n",
      "     |  iterate_from(self, start_tok)\n",
      "     |      Return an iterator that generates the tokens in the corpus\n",
      "     |      file underlying this corpus view, starting at the token number\n",
      "     |      ``start``.  If ``start>=len(self)``, then this iterator will\n",
      "     |      generate no tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.util.StreamBackedCorpusView:\n",
      "     |  \n",
      "     |  fileid\n",
      "     |      The fileid of the file that is accessed by this view.\n",
      "     |      \n",
      "     |      :type: str or PathPointer\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.collections.AbstractLazySequence:\n",
      "     |  \n",
      "     |  __contains__(self, value)\n",
      "     |      Return true if this list contains ``value``.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a >= b.  Computed by @total_ordering from (not a < b).\n",
      "     |  \n",
      "     |  __gt__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      :raise ValueError: Corpus view objects are unhashable.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Return an iterator that generates the tokens in the corpus\n",
      "     |      file underlying this corpus view.\n",
      "     |  \n",
      "     |  __le__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for this corpus view that is\n",
      "     |      similar to a list's representation; but if it would be more\n",
      "     |      than 60 characters long, it is truncated.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  count(self, value)\n",
      "     |      Return the number of times this list contains ``value``.\n",
      "     |  \n",
      "     |  index(self, value, start=None, stop=None)\n",
      "     |      Return the index of the first occurrence of ``value`` in this\n",
      "     |      list that is greater than or equal to ``start`` and less than\n",
      "     |      ``stop``.  Negative start and stop values are treated like negative\n",
      "     |      slice bounds -- i.e., they count from the end of the list.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return a string representation for this corpus view that is\n",
      "     |      similar to a list's representation; but if it would be more\n",
      "     |      than 60 characters long, it is truncated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.collections.AbstractLazySequence:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TaggedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for simple part-of-speech tagged corpora.  Paragraphs are\n",
      "     |  assumed to be split using blank lines.  Sentences and words can be\n",
      "     |  tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specified as parameters to the constructor.  Words are parsed\n",
      "     |  using ``nltk.tag.str2tuple``.  By default, ``'/'`` is used as the\n",
      "     |  separator.  I.e., words should have the form::\n",
      "     |  \n",
      "     |     word1/tag1 word2/tag2 word3/tag3 ...\n",
      "     |  \n",
      "     |  But custom separators may be specified as parameters to the\n",
      "     |  constructor.  Part of speech tags are case-normalized to upper\n",
      "     |  case.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x7fdf40904488>, encoding='utf8', tagset=None)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TimitCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for the TIMIT corpus (or any other corpus with the same\n",
      "     |  file layout and use of file formats).  The corpus root directory\n",
      "     |  should contain the following files:\n",
      "     |  \n",
      "     |    - timitdic.txt: dictionary of standard transcriptions\n",
      "     |    - spkrinfo.txt: table of speaker information\n",
      "     |  \n",
      "     |  In addition, the root directory should contain one subdirectory\n",
      "     |  for each speaker, containing three files for each utterance:\n",
      "     |  \n",
      "     |    - <utterance-id>.txt: text content of utterances\n",
      "     |    - <utterance-id>.wrd: tokenized text content of utterances\n",
      "     |    - <utterance-id>.phn: phonetic transcription of utterances\n",
      "     |    - <utterance-id>.wav: utterance sound file\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimitCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='utf8')\n",
      "     |      Construct a new TIMIT corpus reader in the given directory.\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |  \n",
      "     |  audiodata(self, utterance, start=0, end=None)\n",
      "     |  \n",
      "     |  fileids(self, filetype=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus.\n",
      "     |      \n",
      "     |      :param filetype: If specified, then ``filetype`` indicates that\n",
      "     |          only the files that have the given type should be\n",
      "     |          returned.  Accepted values are: ``txt``, ``wrd``, ``phn``,\n",
      "     |          ``wav``, or ``metadata``,\n",
      "     |  \n",
      "     |  phone_times(self, utterances=None)\n",
      "     |      offset is represented as a number of 16kHz samples!\n",
      "     |  \n",
      "     |  phone_trees(self, utterances=None)\n",
      "     |  \n",
      "     |  phones(self, utterances=None)\n",
      "     |  \n",
      "     |  play(self, utterance, start=0, end=None)\n",
      "     |      Play the given audio sample.\n",
      "     |      \n",
      "     |      :param utterance: The utterance id of the sample to play\n",
      "     |  \n",
      "     |  sent_times(self, utterances=None)\n",
      "     |  \n",
      "     |  sentid(self, utterance)\n",
      "     |  \n",
      "     |  sents(self, utterances=None)\n",
      "     |  \n",
      "     |  spkrid(self, utterance)\n",
      "     |  \n",
      "     |  spkrinfo(self, speaker)\n",
      "     |      :return: A dictionary mapping .. something.\n",
      "     |  \n",
      "     |  spkrutteranceids(self, speaker)\n",
      "     |      :return: A list of all utterances associated with a given\n",
      "     |      speaker.\n",
      "     |  \n",
      "     |  transcription_dict(self)\n",
      "     |      :return: A dictionary giving the 'standard' transcription for\n",
      "     |      each word.\n",
      "     |  \n",
      "     |  utterance(self, spkrid, sentid)\n",
      "     |  \n",
      "     |  utteranceids(self, dialect=None, sex=None, spkrid=None, sent_type=None, sentid=None)\n",
      "     |      :return: A list of the utterance identifiers for all\n",
      "     |      utterances in this corpus, or for the given speaker, dialect\n",
      "     |      region, gender, sentence type, or sentence number, if\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  wav(self, utterance, start=0, end=None)\n",
      "     |      # [xx] NOTE: This is currently broken -- we're assuming that the\n",
      "     |      # fileids are WAV fileids (aka RIFF), but they're actually NIST SPHERE\n",
      "     |      # fileids.\n",
      "     |  \n",
      "     |  word_times(self, utterances=None)\n",
      "     |  \n",
      "     |  words(self, utterances=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TimitTaggedCorpusReader(TaggedCorpusReader)\n",
      "     |  A corpus reader for tagged sentences that are included in the TIMIT corpus.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimitTaggedCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  paras(self)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  tagged_paras(self)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TaggedCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ToolboxCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ToolboxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids, **kwargs)\n",
      "     |      # should probably be done lazily:\n",
      "     |  \n",
      "     |  fields(self, fileids, strip=True, unwrap=True, encoding='utf8', errors='strict', unicode_fields=None)\n",
      "     |  \n",
      "     |  raw(self, fileids)\n",
      "     |  \n",
      "     |  words(self, fileids, key='lx')\n",
      "     |  \n",
      "     |  xml(self, fileids, key=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TwitterCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Reader for corpora that consist of Tweets represented as a list of line-delimited JSON.\n",
      "     |  \n",
      "     |  Individual Tweets can be tokenized using the default tokenizer, or by a\n",
      "     |  custom tokenizer specified as a parameter to the constructor.\n",
      "     |  \n",
      "     |  Construct a new Tweet corpus reader for a set of documents\n",
      "     |  located at the given root directory.\n",
      "     |  \n",
      "     |  If you made your own tweet collection in a directory called\n",
      "     |  `twitter-files`, then you can initialise the reader as::\n",
      "     |  \n",
      "     |      from nltk.corpus import TwitterCorpusReader\n",
      "     |      reader = TwitterCorpusReader(root='/path/to/twitter-files', '.*\\.json')\n",
      "     |  \n",
      "     |  However, the recommended approach is to set the relevant directory as the\n",
      "     |  value of the environmental variable `TWITTER`, and then invoke the reader\n",
      "     |  as follows::\n",
      "     |  \n",
      "     |     root = os.environ['TWITTER']\n",
      "     |     reader = TwitterCorpusReader(root, '.*\\.json')\n",
      "     |  \n",
      "     |  If you want to work directly with the raw Tweets, the `json` library can\n",
      "     |  be used::\n",
      "     |  \n",
      "     |     import json\n",
      "     |     for tweet in reader.docs():\n",
      "     |         print(json.dumps(tweet, indent=1, sort_keys=True))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TwitterCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids=None, word_tokenizer=<nltk.tokenize.casual.TweetTokenizer object at 0x7fdf407aac88>, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      \n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      \n",
      "     |      :param word_tokenizer: Tokenizer for breaking the text of Tweets into\n",
      "     |      smaller units, including but not limited to words.\n",
      "     |  \n",
      "     |  docs(self, fileids=None)\n",
      "     |      Returns the full Tweet objects, as specified by `Twitter\n",
      "     |      documentation on Tweets\n",
      "     |      <https://dev.twitter.com/docs/platform-objects/tweets>`_\n",
      "     |      \n",
      "     |      :return: the given file(s) as a list of dictionaries deserialised\n",
      "     |      from JSON.\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      Return the corpora in their raw form.\n",
      "     |  \n",
      "     |  strings(self, fileids=None)\n",
      "     |      Returns only the text content of Tweets in the file(s)\n",
      "     |      \n",
      "     |      :return: the given file(s) as a list of Tweets.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  tokenized(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of the text content of Tweets as\n",
      "     |      as a list of words, screenanames, hashtags, URLs and punctuation symbols.\n",
      "     |      \n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class UdhrCorpusReader(nltk.corpus.reader.plaintext.PlaintextCorpusReader)\n",
      "     |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      "     |  are assumed to be split using blank lines.  Sentences and words can\n",
      "     |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specificed as parameters to the constructor.\n",
      "     |  \n",
      "     |  This corpus reader can be customized (e.g., to skip preface\n",
      "     |  sections of specific document formats) by creating a subclass and\n",
      "     |  overriding the ``CorpusView`` class variable.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UdhrCorpusReader\n",
      "     |      nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root='udhr')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ENCODINGS = [('.*-Latin1$', 'latin-1'), ('.*-Hebrew$', 'hebrew'), ('.*...\n",
      "     |  \n",
      "     |  SKIP = {'Amharic-Afenegus6..60375', 'Armenian-DallakHelv', 'Azeri_Azer...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.plaintext.PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from nltk.corpus.reader.plaintext.PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class UnicharsCorpusReader(WordListCorpusReader)\n",
      "     |  This class is used to read lists of characters from the Perl Unicode\n",
      "     |  Properties (see http://perldoc.perl.org/perluniprops.html).\n",
      "     |  The files in the perluniprop.zip are extracted using the Unicode::Tussle\n",
      "     |  module from http://search.cpan.org/~bdfoy/Unicode-Tussle-1.11/lib/Unicode/Tussle.pm\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnicharsCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  chars(self, category=None, fileids=None)\n",
      "     |      This module returns a list of characters from  the Perl Unicode Properties.\n",
      "     |      They are very useful when porting Perl tokenizers to Python.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import perluniprops as pup\n",
      "     |      >>> pup.chars('Open_Punctuation')[:5] == [u'(', u'[', u'{', u'', u'']\n",
      "     |      True\n",
      "     |      >>> pup.chars('Currency_Symbol')[:5] == [u'$', u'', u'', u'', u'']\n",
      "     |      True\n",
      "     |      >>> pup.available_categories\n",
      "     |      ['Close_Punctuation', 'Currency_Symbol', 'IsAlnum', 'IsAlpha', 'IsLower', 'IsN', 'IsSc', 'IsSo', 'Open_Punctuation']\n",
      "     |      \n",
      "     |      :return: a list of characters given the specific unicode character category\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  available_categories = ['Close_Punctuation', 'Currency_Symbol', 'IsAln...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class VerbnetCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  An NLTK interface to the VerbNet verb lexicon.\n",
      "     |  \n",
      "     |  From the VerbNet site: \"VerbNet (VN) (Kipper-Schuler 2006) is the largest\n",
      "     |  on-line verb lexicon currently available for English. It is a hierarchical\n",
      "     |  domain-independent, broad-coverage verb lexicon with mappings to other\n",
      "     |  lexical resources such as WordNet (Miller, 1990; Fellbaum, 1998), Xtag\n",
      "     |  (XTAG Research Group, 2001), and FrameNet (Baker et al., 1998).\"\n",
      "     |  \n",
      "     |  For details about VerbNet see:\n",
      "     |  http://verbs.colorado.edu/~mpalmer/projects/verbnet.html\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VerbnetCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  classids(self, lemma=None, wordnetid=None, fileid=None, classid=None)\n",
      "     |      Return a list of the verbnet class identifiers.  If a file\n",
      "     |      identifier is specified, then return only the verbnet class\n",
      "     |      identifiers for classes (and subclasses) defined by that file.\n",
      "     |      If a lemma is specified, then return only verbnet class\n",
      "     |      identifiers for classes that contain that lemma as a member.\n",
      "     |      If a wordnetid is specified, then return only identifiers for\n",
      "     |      classes that contain that wordnetid as a member.  If a classid\n",
      "     |      is specified, then return only identifiers for subclasses of\n",
      "     |      the specified verbnet class.\n",
      "     |  \n",
      "     |  fileids(self, vnclass_ids=None)\n",
      "     |      Return a list of fileids that make up this corpus.  If\n",
      "     |      ``vnclass_ids`` is specified, then return the fileids that make\n",
      "     |      up the specified verbnet class(es).\n",
      "     |  \n",
      "     |  lemmas(self, classid=None)\n",
      "     |      Return a list of all verb lemmas that appear in any class, or\n",
      "     |      in the ``classid`` if specified.\n",
      "     |  \n",
      "     |  longid(self, shortid)\n",
      "     |      Given a short verbnet class identifier (eg '37.10'), map it\n",
      "     |      to a long id (eg 'confess-37.10').  If ``shortid`` is already a\n",
      "     |      long id, then return it as-is\n",
      "     |  \n",
      "     |  pprint(self, vnclass)\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet class.\n",
      "     |      \n",
      "     |      :param vnclass: A verbnet class identifier; or an ElementTree\n",
      "     |      containing the xml contents of a verbnet class.\n",
      "     |  \n",
      "     |  pprint_description(self, vnframe, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet frame description.\n",
      "     |      \n",
      "     |      :param vnframe: An ElementTree containing the xml contents of\n",
      "     |          a verbnet frame.\n",
      "     |  \n",
      "     |  pprint_frame(self, vnframe, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet frame.\n",
      "     |      \n",
      "     |      :param vnframe: An ElementTree containing the xml contents of\n",
      "     |          a verbnet frame.\n",
      "     |  \n",
      "     |  pprint_members(self, vnclass, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet class's member verbs.\n",
      "     |      \n",
      "     |      :param vnclass: A verbnet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a verbnet class.\n",
      "     |  \n",
      "     |  pprint_semantics(self, vnframe, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet frame semantics.\n",
      "     |      \n",
      "     |      :param vnframe: An ElementTree containing the xml contents of\n",
      "     |          a verbnet frame.\n",
      "     |  \n",
      "     |  pprint_subclasses(self, vnclass, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet class's subclasses.\n",
      "     |      \n",
      "     |      :param vnclass: A verbnet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a verbnet class.\n",
      "     |  \n",
      "     |  pprint_syntax(self, vnframe, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet frame syntax.\n",
      "     |      \n",
      "     |      :param vnframe: An ElementTree containing the xml contents of\n",
      "     |          a verbnet frame.\n",
      "     |  \n",
      "     |  pprint_themroles(self, vnclass, indent='')\n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given verbnet class's thematic roles.\n",
      "     |      \n",
      "     |      :param vnclass: A verbnet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a verbnet class.\n",
      "     |  \n",
      "     |  shortid(self, longid)\n",
      "     |      Given a long verbnet class identifier (eg 'confess-37.10'),\n",
      "     |      map it to a short id (eg '37.10').  If ``longid`` is already a\n",
      "     |      short id, then return it as-is.\n",
      "     |  \n",
      "     |  vnclass(self, fileid_or_classid)\n",
      "     |      Return an ElementTree containing the xml for the specified\n",
      "     |      verbnet class.\n",
      "     |      \n",
      "     |      :param fileid_or_classid: An identifier specifying which class\n",
      "     |          should be returned.  Can be a file identifier (such as\n",
      "     |          ``'put-9.1.xml'``), or a verbnet class identifier (such as\n",
      "     |          ``'put-9.1'``) or a short verbnet class identifier (such as\n",
      "     |          ``'9.1'``).\n",
      "     |  \n",
      "     |  wordnetids(self, classid=None)\n",
      "     |      Return a list of all wordnet identifiers that appear in any\n",
      "     |      class, or in ``classid`` if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordListCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A corpus reader used to access wordnet or its variants.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordNetCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, omw_reader)\n",
      "     |      Construct a new wordnet corpus reader, with the given root\n",
      "     |      directory.\n",
      "     |  \n",
      "     |  all_lemma_names(self, pos=None, lang='eng')\n",
      "     |      Return all lemma names for all synsets for the given\n",
      "     |      part of speech tag and language or languages. If pos is\n",
      "     |      not specified, all synsets for all parts of speech will\n",
      "     |      be used.\n",
      "     |  \n",
      "     |  all_synsets(self, pos=None)\n",
      "     |      Iterate over all synsets with a given part of speech tag.\n",
      "     |      If no pos is specified, all synsets for all parts of speech\n",
      "     |      will be loaded.\n",
      "     |  \n",
      "     |  citation(self, lang='omw')\n",
      "     |      Return the contents of citation.bib file (for omw)\n",
      "     |      use lang=lang to get the citation for an individual language\n",
      "     |  \n",
      "     |  custom_lemmas(self, tab_file, lang)\n",
      "     |      Reads a custom tab file containing mappings of lemmas in the given\n",
      "     |      language to Princeton WordNet 3.0 synset offsets, allowing NLTK's\n",
      "     |      WordNet functions to then be used with that language.\n",
      "     |      \n",
      "     |      See the \"Tab files\" section at http://compling.hss.ntu.edu.sg/omw/ for\n",
      "     |      documentation on the Multilingual WordNet tab file format.\n",
      "     |      \n",
      "     |      :param tab_file: Tab file as a file or file-like object\n",
      "     |      :type  lang str\n",
      "     |      :param lang ISO 639-3 code of the language of the tab file\n",
      "     |  \n",
      "     |  get_version(self)\n",
      "     |  \n",
      "     |  ic(self, corpus, weight_senses_equally=False, smoothing=1.0)\n",
      "     |      Creates an information content lookup dictionary from a corpus.\n",
      "     |      \n",
      "     |      :type corpus: CorpusReader\n",
      "     |      :param corpus: The corpus from which we create an information\n",
      "     |      content dictionary.\n",
      "     |      :type weight_senses_equally: bool\n",
      "     |      :param weight_senses_equally: If this is True, gives all\n",
      "     |      possible senses equal weight rather than dividing by the\n",
      "     |      number of possible senses.  (If a word has 3 synses, each\n",
      "     |      sense gets 0.3333 per appearance when this is False, 1.0 when\n",
      "     |      it is true.)\n",
      "     |      :param smoothing: How much do we smooth synset counts (default is 1.0)\n",
      "     |      :type smoothing: float\n",
      "     |      :return: An information content dictionary\n",
      "     |  \n",
      "     |  jcn_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Jiang-Conrath Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node) and that of the two input Synsets. The relationship is\n",
      "     |      given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type  ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects.\n",
      "     |  \n",
      "     |  langs(self)\n",
      "     |      return a list of languages supported by Multilingual Wordnet\n",
      "     |  \n",
      "     |  lch_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Leacock Chodorow Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      shortest path that connects the senses (as above) and the maximum depth\n",
      "     |      of the taxonomy in which the senses occur. The relationship is given as\n",
      "     |      -log(p/2d) where p is the shortest path length and d is the taxonomy\n",
      "     |      depth.\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      "     |          normally greater than 0. None is returned if no connecting path\n",
      "     |          could be found. If a ``Synset`` is compared with itself, the\n",
      "     |          maximum score is returned, which varies depending on the taxonomy\n",
      "     |          depth.\n",
      "     |  \n",
      "     |  lemma(self, name, lang='eng')\n",
      "     |      Return lemma object that matches the name\n",
      "     |  \n",
      "     |  lemma_count(self, lemma)\n",
      "     |      Return the frequency count for this Lemma\n",
      "     |  \n",
      "     |  lemma_from_key(self, key)\n",
      "     |  \n",
      "     |  lemmas(self, lemma, pos=None, lang='eng')\n",
      "     |      Return all Lemma objects with a name matching the specified lemma\n",
      "     |      name and part of speech tag. Matches any part of speech tag if none is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  license(self, lang='eng')\n",
      "     |      Return the contents of LICENSE (for omw)\n",
      "     |      use lang=lang to get the license for an individual language\n",
      "     |  \n",
      "     |  lin_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Lin Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node) and that of the two input Synsets. The relationship is\n",
      "     |      given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
      "     |      \n",
      "     |      :type other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects, in the range 0 to 1.\n",
      "     |  \n",
      "     |  morphy(self, form, pos=None, check_exceptions=True)\n",
      "     |      Find a possible base form for the given form, with the given\n",
      "     |      part of speech, by checking WordNet's list of exceptional\n",
      "     |      forms, and by recursively stripping affixes for this part of\n",
      "     |      speech until a form in WordNet is found.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import wordnet as wn\n",
      "     |      >>> print(wn.morphy('dogs'))\n",
      "     |      dog\n",
      "     |      >>> print(wn.morphy('churches'))\n",
      "     |      church\n",
      "     |      >>> print(wn.morphy('aardwolves'))\n",
      "     |      aardwolf\n",
      "     |      >>> print(wn.morphy('abaci'))\n",
      "     |      abacus\n",
      "     |      >>> wn.morphy('hardrock', wn.ADV)\n",
      "     |      >>> print(wn.morphy('book', wn.NOUN))\n",
      "     |      book\n",
      "     |      >>> wn.morphy('book', wn.ADJ)\n",
      "     |  \n",
      "     |  of2ss(self, of)\n",
      "     |      take an id and return the synsets\n",
      "     |  \n",
      "     |  path_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Path Distance Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
      "     |      taxonomy. The score is in the range 0 to 1, except in those cases where\n",
      "     |      a path cannot be found (will only be true for verbs as there are many\n",
      "     |      distinct verb taxonomies), in which case None is returned. A score of\n",
      "     |      1 represents identity i.e. comparing a sense with itself will return 1.\n",
      "     |      \n",
      "     |      :type other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      "     |          normally between 0 and 1. None is returned if no connecting path\n",
      "     |          could be found. 1 is returned if a ``Synset`` is compared with\n",
      "     |          itself.\n",
      "     |  \n",
      "     |  readme(self, lang='omw')\n",
      "     |      Return the contents of README (for omw)\n",
      "     |      use lang=lang to get the readme for an individual language\n",
      "     |  \n",
      "     |  res_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Resnik Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node).\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects. Synsets whose LCS is the root node of the taxonomy will\n",
      "     |          have a score of 0 (e.g. N['dog'][0] and N['table'][0]).\n",
      "     |  \n",
      "     |  ss2of(self, ss)\n",
      "     |      return the ID of the synset\n",
      "     |  \n",
      "     |  synset(self, name)\n",
      "     |      #############################################################\n",
      "     |      # Loading Synsets\n",
      "     |      #############################################################\n",
      "     |  \n",
      "     |  synset_from_pos_and_offset(self, pos, offset)\n",
      "     |  \n",
      "     |  synsets(self, lemma, pos=None, lang='eng', check_exceptions=True)\n",
      "     |      Load all synsets with a given lemma and part of speech tag.\n",
      "     |      If no pos is specified, all synsets for all parts of speech\n",
      "     |      will be loaded.\n",
      "     |      If lang is specified, all the synsets associated with the lemma name\n",
      "     |      of that language will be returned.\n",
      "     |  \n",
      "     |  words(self, lang='eng')\n",
      "     |      return lemmas of the given language as list of words\n",
      "     |  \n",
      "     |  wup_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Wu-Palmer Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      depth of the two senses in the taxonomy and that of their Least Common\n",
      "     |      Subsumer (most specific ancestor node). Previously, the scores computed\n",
      "     |      by this implementation did _not_ always agree with those given by\n",
      "     |      Pedersen's Perl implementation of WordNet Similarity. However, with\n",
      "     |      the addition of the simulate_root flag (see below), the score for\n",
      "     |      verbs now almost always agree but not always for nouns.\n",
      "     |      \n",
      "     |      The LCS does not necessarily feature in the shortest path connecting\n",
      "     |      the two senses, as it is by definition the common ancestor deepest in\n",
      "     |      the taxonomy, not closest to the two senses. Typically, however, it\n",
      "     |      will so feature. Where multiple candidates for the LCS exist, that\n",
      "     |      whose shortest path to the root node is the longest will be selected.\n",
      "     |      Where the LCS has multiple paths to the root, the longer path is used\n",
      "     |      for the purposes of the calculation.\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects, normally greater than zero. If no connecting path between\n",
      "     |          the two senses can be found, None is returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADJ = 'a'\n",
      "     |  \n",
      "     |  ADJ_SAT = 's'\n",
      "     |  \n",
      "     |  ADV = 'r'\n",
      "     |  \n",
      "     |  MORPHOLOGICAL_SUBSTITUTIONS = {'a': [('er', ''), ('est', ''), ('er', '...\n",
      "     |  \n",
      "     |  NOUN = 'n'\n",
      "     |  \n",
      "     |  VERB = 'v'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordNetICCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  A corpus reader for the WordNet information content corpus.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordNetICCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ic(self, icfile)\n",
      "     |      Load an information content file from the wordnet_ic corpus\n",
      "     |      and return a dictionary.  This dictionary has just two keys,\n",
      "     |      NOUN and VERB, whose values are dictionaries that map from\n",
      "     |      synsets to information content values.\n",
      "     |      \n",
      "     |      :type icfile: str\n",
      "     |      :param icfile: The name of the wordnet_ic file (e.g. \"ic-brown.dat\")\n",
      "     |      :return: An information content dictionary\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class XMLCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class YCOECorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  Corpus reader for the York-Toronto-Helsinki Parsed Corpus of Old\n",
      "     |  English Prose (YCOE), a 1.5 million word syntactically-annotated\n",
      "     |  corpus of Old English prose texts.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      YCOECorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='utf8')\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  documents(self, fileids=None)\n",
      "     |      Return a list of document identifiers for all documents in\n",
      "     |      this corpus, or for the documents with the given file(s) if\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  fileids(self, documents=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that store the given document(s) if specified.\n",
      "     |  \n",
      "     |  paras(self, documents=None)\n",
      "     |  \n",
      "     |  parsed_sents(self, documents=None)\n",
      "     |  \n",
      "     |  sents(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_words(self, documents=None)\n",
      "     |  \n",
      "     |  words(self, documents=None)\n",
      "     |      # Delegate to one of our two sub-readers:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "\n",
      "FUNCTIONS\n",
      "    find_corpus_fileids(root, regexp)\n",
      "    \n",
      "    tagged_treebank_para_block_reader(stream)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['CorpusReader', 'CategorizedCorpusReader', 'PlaintextCorpus...\n",
      "\n",
      "FILE\n",
      "    /home/shawn/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.corpus.reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJ',\n",
       " 'ADJ_SAT',\n",
       " 'ADV',\n",
       " 'ANA',\n",
       " 'APPENDIX',\n",
       " 'AbstractLazySequence',\n",
       " 'AlignedCorpusReader',\n",
       " 'AlignedSent',\n",
       " 'AlignedSentCorpusView',\n",
       " 'Alignment',\n",
       " 'AlpinoCorpusReader',\n",
       " 'AttrDict',\n",
       " 'BNCCorpusReader',\n",
       " 'BNCSentence',\n",
       " 'BNCWordView',\n",
       " 'BlanklineTokenizer',\n",
       " 'BracketParseCorpusReader',\n",
       " 'CHILDESCorpusReader',\n",
       " 'CLOSE_COMPARISON',\n",
       " 'CMUDictCorpusReader',\n",
       " 'COMPARISON',\n",
       " 'CategorizedBracketParseCorpusReader',\n",
       " 'CategorizedCorpusReader',\n",
       " 'CategorizedPlaintextCorpusReader',\n",
       " 'CategorizedSentencesCorpusReader',\n",
       " 'CategorizedTaggedCorpusReader',\n",
       " 'ChasenCorpusReader',\n",
       " 'ChasenCorpusView',\n",
       " 'ChunkedCorpusReader',\n",
       " 'ChunkedCorpusView',\n",
       " 'ComparativeSentencesCorpusReader',\n",
       " 'Comparison',\n",
       " 'ConcatenatedCorpusView',\n",
       " 'ConllChunkCorpusReader',\n",
       " 'ConllCorpusReader',\n",
       " 'ConllSRLInstance',\n",
       " 'ConllSRLInstanceList',\n",
       " 'CorpusReader',\n",
       " 'CrubadanCorpusReader',\n",
       " 'DependencyCorpusReader',\n",
       " 'DependencyCorpusView',\n",
       " 'DependencyGraph',\n",
       " 'EMPTY_BRACKETS',\n",
       " 'ENTITIES_FEATS',\n",
       " 'ElementTree',\n",
       " 'ElementWrapper',\n",
       " 'EuroparlCorpusReader',\n",
       " 'FEATURES',\n",
       " 'FileSystemPathPointer',\n",
       " 'FramenetCorpusReader',\n",
       " 'FramenetError',\n",
       " 'FreqDist',\n",
       " 'Future',\n",
       " 'GRAD_COMPARISON',\n",
       " 'IDENTIFIER',\n",
       " 'IEERCorpusReader',\n",
       " 'IEERDocument',\n",
       " 'IPIPANCorpusReader',\n",
       " 'IPIPANCorpusView',\n",
       " 'IgnoreReadmeCorpusView',\n",
       " 'Index',\n",
       " 'IndianCorpusReader',\n",
       " 'IndianCorpusView',\n",
       " 'KEYWORD',\n",
       " 'KNBCorpusReader',\n",
       " 'LazyConcatenation',\n",
       " 'LazyIteratorList',\n",
       " 'LazyMap',\n",
       " 'LazySubsequence',\n",
       " 'Lemma',\n",
       " 'LinThesaurusCorpusReader',\n",
       " 'LineTokenizer',\n",
       " 'MTECorpusReader',\n",
       " 'MTECorpusView',\n",
       " 'MTEFileReader',\n",
       " 'MTETagConverter',\n",
       " 'MWAPPDBCorpusReader',\n",
       " 'MWETokenizer',\n",
       " 'MacMorphoCorpusReader',\n",
       " 'Meaning',\n",
       " 'NKJPCorpusReader',\n",
       " 'NKJPCorpus_Header_View',\n",
       " 'NKJPCorpus_Morph_View',\n",
       " 'NKJPCorpus_Segmentation_View',\n",
       " 'NKJPCorpus_Text_View',\n",
       " 'NON_GRAD_COMPARISON',\n",
       " 'NOTES',\n",
       " 'NOUN',\n",
       " 'NPSChatCorpusReader',\n",
       " 'NS',\n",
       " 'NombankChainTreePointer',\n",
       " 'NombankCorpusReader',\n",
       " 'NombankInstance',\n",
       " 'NombankPointer',\n",
       " 'NombankSplitTreePointer',\n",
       " 'NombankTreePointer',\n",
       " 'NonbreakingPrefixesCorpusReader',\n",
       " 'OpinionLexiconCorpusReader',\n",
       " 'OrderedDict',\n",
       " 'PARA',\n",
       " 'POS_LIST',\n",
       " 'PPAttachment',\n",
       " 'PPAttachmentCorpusReader',\n",
       " 'PY3',\n",
       " 'PanLexLiteCorpusReader',\n",
       " 'PathPointer',\n",
       " 'PickleCorpusView',\n",
       " 'Pl196xCorpusReader',\n",
       " 'PlaintextCorpusReader',\n",
       " 'PortugueseCategorizedPlaintextCorpusReader',\n",
       " 'PrettyDict',\n",
       " 'PrettyLazyConcatenation',\n",
       " 'PrettyLazyIteratorList',\n",
       " 'PrettyLazyMap',\n",
       " 'PrettyList',\n",
       " 'PropbankChainTreePointer',\n",
       " 'PropbankCorpusReader',\n",
       " 'PropbankInflection',\n",
       " 'PropbankInstance',\n",
       " 'PropbankPointer',\n",
       " 'PropbankSplitTreePointer',\n",
       " 'PropbankTreePointer',\n",
       " 'ProsConsCorpusReader',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RTECorpusReader',\n",
       " 'RTEPair',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'Review',\n",
       " 'ReviewLine',\n",
       " 'ReviewsCorpusReader',\n",
       " 'SENSENUM_RE',\n",
       " 'SENT',\n",
       " 'SExprTokenizer',\n",
       " 'SORTTAGWRD',\n",
       " 'STARS',\n",
       " 'SeekableUnicodeStreamReader',\n",
       " 'SemcorCorpusReader',\n",
       " 'SemcorSentence',\n",
       " 'SemcorWordView',\n",
       " 'SensevalCorpusReader',\n",
       " 'SensevalCorpusView',\n",
       " 'SensevalInstance',\n",
       " 'SentiSynset',\n",
       " 'SentiWordNetCorpusReader',\n",
       " 'SinicaTreebankCorpusReader',\n",
       " 'SpaceTokenizer',\n",
       " 'SpeakerInfo',\n",
       " 'SpecialList',\n",
       " 'StanfordSegmenter',\n",
       " 'StanfordTokenizer',\n",
       " 'StreamBackedCorpusView',\n",
       " 'StringCategoryCorpusReader',\n",
       " 'SwadeshCorpusReader',\n",
       " 'SwitchboardCorpusReader',\n",
       " 'SwitchboardTurn',\n",
       " 'Synset',\n",
       " 'SyntaxCorpusReader',\n",
       " 'TAGGEDWORD',\n",
       " 'TAGWORD',\n",
       " 'TEICorpusView',\n",
       " 'TEXTID',\n",
       " 'TITLE',\n",
       " 'TYPE',\n",
       " 'TabTokenizer',\n",
       " 'TaggedCorpusReader',\n",
       " 'TaggedCorpusView',\n",
       " 'TextTilingTokenizer',\n",
       " 'TimitCorpusReader',\n",
       " 'TimitTaggedCorpusReader',\n",
       " 'ToktokTokenizer',\n",
       " 'ToolboxCorpusReader',\n",
       " 'ToolboxData',\n",
       " 'Tree',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer',\n",
       " 'TwitterCorpusReader',\n",
       " 'UdhrCorpusReader',\n",
       " 'UnicharsCorpusReader',\n",
       " 'VERB',\n",
       " 'VERB_FRAME_STRINGS',\n",
       " 'VerbnetCorpusReader',\n",
       " 'WORD',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WordListCorpusReader',\n",
       " 'WordNetCorpusReader',\n",
       " 'WordNetError',\n",
       " 'WordNetICCorpusReader',\n",
       " 'WordPunctTokenizer',\n",
       " 'XMLCorpusReader',\n",
       " 'XMLCorpusView',\n",
       " 'XML_Tool',\n",
       " 'YCOECorpusReader',\n",
       " 'YCOEParseCorpusReader',\n",
       " 'YCOETaggedCorpusReader',\n",
       " 'ZipFilePathPointer',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'aligned',\n",
       " 'api',\n",
       " 'bisect',\n",
       " 'blankline_tokenize',\n",
       " 'bnc',\n",
       " 'bracket_parse',\n",
       " 'casual',\n",
       " 'casual_tokenize',\n",
       " 'categorized_sents',\n",
       " 'chain',\n",
       " 'chasen',\n",
       " 'childes',\n",
       " 'chunked',\n",
       " 'cmudict',\n",
       " 'codecs',\n",
       " 'comparative_sents',\n",
       " 'compat',\n",
       " 'concat',\n",
       " 'conll',\n",
       " 'crubadan',\n",
       " 'defaultdict',\n",
       " 'demo',\n",
       " 'dependency',\n",
       " 'deprecated',\n",
       " 'deque',\n",
       " 'division',\n",
       " 'documents',\n",
       " 'find_corpus_fileids',\n",
       " 'flatten',\n",
       " 'framenet',\n",
       " 'functools',\n",
       " 'ieer',\n",
       " 'import_from_stdlib',\n",
       " 'improved_close_quote_regex',\n",
       " 'improved_open_quote_regex',\n",
       " 'improved_punct_regex',\n",
       " 'indian',\n",
       " 'information_content',\n",
       " 'ipipan',\n",
       " 'islice',\n",
       " 'itemgetter',\n",
       " 'iteritems',\n",
       " 'itertools',\n",
       " 'jcn_similarity',\n",
       " 'json',\n",
       " 'knbc',\n",
       " 'lch_similarity',\n",
       " 'lin',\n",
       " 'lin_similarity',\n",
       " 'line_tokenize',\n",
       " 'load',\n",
       " 'map_tag',\n",
       " 'math',\n",
       " 'mimic_wrap',\n",
       " 'mte',\n",
       " 'mwe',\n",
       " 'nkjp',\n",
       " 'nltk',\n",
       " 'nombank',\n",
       " 'norm',\n",
       " 'nps_chat',\n",
       " 'opinion_lexicon',\n",
       " 'os',\n",
       " 'panlex_lite',\n",
       " 'path',\n",
       " 'path_similarity',\n",
       " 'pformat',\n",
       " 'pickle',\n",
       " 'pl196x',\n",
       " 'plaintext',\n",
       " 'ppattach',\n",
       " 'pprint',\n",
       " 'print_function',\n",
       " 'propbank',\n",
       " 'pros_cons',\n",
       " 'punkt',\n",
       " 'py25',\n",
       " 'python_2_unicode_compatible',\n",
       " 'raise_unorderable_types',\n",
       " 'range',\n",
       " 're',\n",
       " 'read_alignedsent_block',\n",
       " 'read_blankline_block',\n",
       " 'read_cmudict_block',\n",
       " 'read_line_block',\n",
       " 'read_regexp_block',\n",
       " 'read_sexpr_block',\n",
       " 'read_timit_block',\n",
       " 'read_whitespace_block',\n",
       " 'read_wordpunct_block',\n",
       " 'reduce',\n",
       " 'regexp',\n",
       " 'regexp_span_tokenize',\n",
       " 'regexp_tokenize',\n",
       " 'repp',\n",
       " 'res_similarity',\n",
       " 'reviews',\n",
       " 'rte',\n",
       " 'semcor',\n",
       " 'senseval',\n",
       " 'sent_tokenize',\n",
       " 'sentiwordnet',\n",
       " 'sexpr',\n",
       " 'sexpr_tokenize',\n",
       " 'simple',\n",
       " 'sinica_parse',\n",
       " 'sinica_treebank',\n",
       " 'slice_bounds',\n",
       " 'sqlite3',\n",
       " 'stanford',\n",
       " 'stanford_segmenter',\n",
       " 'str2tuple',\n",
       " 'string_category',\n",
       " 'string_span_tokenize',\n",
       " 'string_types',\n",
       " 'switchboard',\n",
       " 'sys',\n",
       " 'tagged',\n",
       " 'tagged_treebank_para_block_reader',\n",
       " 'tagstr2tree',\n",
       " 'teardown_module',\n",
       " 'tempfile',\n",
       " 'test',\n",
       " 'text_type',\n",
       " 'texttiling',\n",
       " 'textwrap',\n",
       " 'time',\n",
       " 'timit',\n",
       " 'titles',\n",
       " 'toktok',\n",
       " 'toolbox',\n",
       " 'total_ordering',\n",
       " 'treebank',\n",
       " 'twitter',\n",
       " 'types',\n",
       " 'udhr',\n",
       " 'unicode_literals',\n",
       " 'util',\n",
       " 'verbnet',\n",
       " 'word_tokenize',\n",
       " 'wordlist',\n",
       " 'wordnet',\n",
       " 'wordpunct_tokenize',\n",
       " 'wup_similarity',\n",
       " 'xmldocs',\n",
       " 'xpath',\n",
       " 'ycoe',\n",
       " 'zip_longest']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk.corpus.reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2.2 Counting Words by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.tagged.CategorizedTaggedCorpusReader'>\n",
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConditionalFreqDist(nltk.probability.FreqDist,\n",
       "                    {'adventure': FreqDist({'Dan': 23,\n",
       "                               'Morgan': 28,\n",
       "                               'told': 46,\n",
       "                               'himself': 75,\n",
       "                               'he': 761,\n",
       "                               'would': 191,\n",
       "                               'forget': 3,\n",
       "                               'Ann': 4,\n",
       "                               'Turner': 1,\n",
       "                               '.': 4057,\n",
       "                               'He': 522,\n",
       "                               'was': 914,\n",
       "                               'well': 28,\n",
       "                               'rid': 3,\n",
       "                               'of': 1322,\n",
       "                               'her': 444,\n",
       "                               'certainly': 4,\n",
       "                               \"didn't\": 70,\n",
       "                               'want': 43,\n",
       "                               'a': 1354,\n",
       "                               'wife': 25,\n",
       "                               'who': 91,\n",
       "                               'fickle': 1,\n",
       "                               'as': 310,\n",
       "                               'If': 48,\n",
       "                               'had': 591,\n",
       "                               'married': 8,\n",
       "                               ',': 3488,\n",
       "                               \"he'd\": 12,\n",
       "                               'have': 133,\n",
       "                               'been': 131,\n",
       "                               'asking': 4,\n",
       "                               'for': 331,\n",
       "                               'trouble': 17,\n",
       "                               'But': 119,\n",
       "                               'all': 167,\n",
       "                               'this': 203,\n",
       "                               'rationalization': 1,\n",
       "                               'Sometimes': 6,\n",
       "                               'woke': 3,\n",
       "                               'up': 226,\n",
       "                               'in': 847,\n",
       "                               'the': 3370,\n",
       "                               'middle': 5,\n",
       "                               'night': 30,\n",
       "                               'thinking': 20,\n",
       "                               'and': 1622,\n",
       "                               'then': 99,\n",
       "                               'could': 151,\n",
       "                               'not': 179,\n",
       "                               'get': 92,\n",
       "                               'back': 165,\n",
       "                               'to': 1309,\n",
       "                               'sleep': 12,\n",
       "                               'His': 70,\n",
       "                               'plans': 2,\n",
       "                               'dreams': 3,\n",
       "                               'revolved': 1,\n",
       "                               'around': 71,\n",
       "                               'so': 114,\n",
       "                               'much': 54,\n",
       "                               'long': 72,\n",
       "                               'that': 494,\n",
       "                               'now': 90,\n",
       "                               'felt': 34,\n",
       "                               'if': 91,\n",
       "                               'nothing': 38,\n",
       "                               'The': 410,\n",
       "                               'easiest': 1,\n",
       "                               'thing': 28,\n",
       "                               'be': 183,\n",
       "                               'sell': 4,\n",
       "                               'out': 266,\n",
       "                               'Al': 2,\n",
       "                               'Budd': 4,\n",
       "                               'leave': 18,\n",
       "                               'country': 16,\n",
       "                               'but': 197,\n",
       "                               'there': 133,\n",
       "                               'stubborn': 2,\n",
       "                               'streak': 5,\n",
       "                               'him': 415,\n",
       "                               \"wouldn't\": 25,\n",
       "                               'allow': 4,\n",
       "                               'it': 492,\n",
       "                               'best': 12,\n",
       "                               'antidote': 1,\n",
       "                               'bitterness': 3,\n",
       "                               'disappointment': 2,\n",
       "                               'poisoned': 1,\n",
       "                               'hard': 31,\n",
       "                               'work': 31,\n",
       "                               'found': 36,\n",
       "                               'tired': 4,\n",
       "                               'enough': 35,\n",
       "                               'at': 317,\n",
       "                               'went': 60,\n",
       "                               'simply': 8,\n",
       "                               'because': 25,\n",
       "                               'too': 64,\n",
       "                               'exhausted': 2,\n",
       "                               'stay': 19,\n",
       "                               'awake': 1,\n",
       "                               'Each': 3,\n",
       "                               'day': 39,\n",
       "                               'less': 13,\n",
       "                               'often': 10,\n",
       "                               ';': 216,\n",
       "                               'each': 26,\n",
       "                               'hurt': 11,\n",
       "                               'little': 67,\n",
       "                               'duller': 1,\n",
       "                               'poignant': 2,\n",
       "                               'plenty': 6,\n",
       "                               'do': 93,\n",
       "                               'Because': 3,\n",
       "                               'summer': 8,\n",
       "                               'unusually': 4,\n",
       "                               'dry': 9,\n",
       "                               'hot': 9,\n",
       "                               'spring': 12,\n",
       "                               'produced': 1,\n",
       "                               'smaller': 3,\n",
       "                               'stream': 2,\n",
       "                               'than': 60,\n",
       "                               'ordinary': 2,\n",
       "                               'years': 32,\n",
       "                               'grass': 13,\n",
       "                               'meadows': 3,\n",
       "                               'came': 79,\n",
       "                               'fast': 14,\n",
       "                               'warm': 9,\n",
       "                               'weather': 3,\n",
       "                               'here': 65,\n",
       "                               'afford': 4,\n",
       "                               'lose': 3,\n",
       "                               'drop': 8,\n",
       "                               'precious': 1,\n",
       "                               'water': 59,\n",
       "                               'spent': 11,\n",
       "                               'most': 27,\n",
       "                               'his': 776,\n",
       "                               'waking': 1,\n",
       "                               'hours': 13,\n",
       "                               'along': 26,\n",
       "                               'ditches': 2,\n",
       "                               'no': 125,\n",
       "                               'idea': 6,\n",
       "                               'how': 35,\n",
       "                               'time': 127,\n",
       "                               'give': 27,\n",
       "                               'In': 45,\n",
       "                               'any': 56,\n",
       "                               'case': 11,\n",
       "                               'intention': 4,\n",
       "                               'being': 19,\n",
       "                               'caught': 24,\n",
       "                               'asleep': 5,\n",
       "                               'carried': 15,\n",
       "                               'revolver': 4,\n",
       "                               'its': 65,\n",
       "                               'holster': 8,\n",
       "                               'on': 460,\n",
       "                               'hip': 2,\n",
       "                               'took': 65,\n",
       "                               'Winchester': 7,\n",
       "                               'with': 401,\n",
       "                               'leaned': 7,\n",
       "                               'against': 63,\n",
       "                               'fence': 6,\n",
       "                               'stopped': 17,\n",
       "                               'every': 20,\n",
       "                               'few': 39,\n",
       "                               'minutes': 27,\n",
       "                               'shovel': 2,\n",
       "                               'studied': 7,\n",
       "                               'horizon': 3,\n",
       "                               'happened': 16,\n",
       "                               'dragging': 4,\n",
       "                               'monotonous': 1,\n",
       "                               'calm': 6,\n",
       "                               'When': 47,\n",
       "                               'late': 9,\n",
       "                               'afternoon': 9,\n",
       "                               'last': 41,\n",
       "                               'June': 1,\n",
       "                               'saw': 67,\n",
       "                               'two': 80,\n",
       "                               'people': 24,\n",
       "                               'top': 15,\n",
       "                               'ridge': 3,\n",
       "                               'south': 8,\n",
       "                               'walk': 17,\n",
       "                               'toward': 48,\n",
       "                               'house': 60,\n",
       "                               'quit': 4,\n",
       "                               'immediately': 9,\n",
       "                               'strode': 2,\n",
       "                               'rifle': 30,\n",
       "                               'It': 145,\n",
       "                               'some': 51,\n",
       "                               'kind': 19,\n",
       "                               'trick': 6,\n",
       "                               'thought': 62,\n",
       "                               'No': 48,\n",
       "                               'one': 162,\n",
       "                               'walked': 28,\n",
       "                               'least': 15,\n",
       "                               'Ed': 6,\n",
       "                               'Dow': 1,\n",
       "                               'or': 115,\n",
       "                               'Dutch': 4,\n",
       "                               'Renfro': 1,\n",
       "                               'rest': 13,\n",
       "                               'Bar': 2,\n",
       "                               'B': 1,\n",
       "                               'crew': 4,\n",
       "                               'watched': 20,\n",
       "                               'figures': 4,\n",
       "                               'puzzled': 5,\n",
       "                               'they': 206,\n",
       "                               'were': 251,\n",
       "                               'closer': 9,\n",
       "                               'woman': 29,\n",
       "                               'more': 83,\n",
       "                               'ever': 27,\n",
       "                               'cleaned': 2,\n",
       "                               'left': 47,\n",
       "                               'picked': 12,\n",
       "                               'started': 38,\n",
       "                               'downstream': 1,\n",
       "                               'visitors': 1,\n",
       "                               'crawled': 7,\n",
       "                               'through': 78,\n",
       "                               'crossing': 5,\n",
       "                               'meadow': 8,\n",
       "                               'angling': 1,\n",
       "                               'Now': 37,\n",
       "                               'both': 29,\n",
       "                               'man': 165,\n",
       "                               'moving': 12,\n",
       "                               'slowly': 14,\n",
       "                               'irregularly': 1,\n",
       "                               'staggering': 2,\n",
       "                               'struggle': 5,\n",
       "                               'remain': 1,\n",
       "                               'their': 156,\n",
       "                               'feet': 49,\n",
       "                               'Reaching': 3,\n",
       "                               'ahead': 11,\n",
       "                               'them': 156,\n",
       "                               'waited': 12,\n",
       "                               'hands': 48,\n",
       "                               'They': 99,\n",
       "                               'north': 8,\n",
       "                               'young': 24,\n",
       "                               'nineteen': 1,\n",
       "                               'twenty': 7,\n",
       "                               'dirty': 9,\n",
       "                               'clothes': 11,\n",
       "                               'torn': 6,\n",
       "                               'girl': 53,\n",
       "                               'she': 240,\n",
       "                               'fell': 13,\n",
       "                               'when': 126,\n",
       "                               'still': 62,\n",
       "                               'from': 260,\n",
       "                               'front': 39,\n",
       "                               'door': 67,\n",
       "                               'She': 137,\n",
       "                               'lay': 15,\n",
       "                               'making': 13,\n",
       "                               'effort': 4,\n",
       "                               'boy': 42,\n",
       "                               'porch': 13,\n",
       "                               'sat': 23,\n",
       "                               'down': 153,\n",
       "                               'gaze': 3,\n",
       "                               'half': 20,\n",
       "                               'expecting': 3,\n",
       "                               'shoot': 7,\n",
       "                               'really': 18,\n",
       "                               'caring': 1,\n",
       "                               'hesitated': 6,\n",
       "                               'good': 37,\n",
       "                               'think': 44,\n",
       "                               'possible': 12,\n",
       "                               'couple': 9,\n",
       "                               'pretending': 5,\n",
       "                               'licked': 2,\n",
       "                               'lips': 21,\n",
       "                               'asked': 33,\n",
       "                               '``': 998,\n",
       "                               'Could': 3,\n",
       "                               'we': 87,\n",
       "                               'drink': 15,\n",
       "                               \"''\": 995,\n",
       "                               '?': 518,\n",
       "                               'jerked': 7,\n",
       "                               'head': 71,\n",
       "                               'kitchen': 7,\n",
       "                               'said': 287,\n",
       "                               'Leaning': 2,\n",
       "                               'Get': 9,\n",
       "                               \"There's\": 17,\n",
       "                               'move': 16,\n",
       "                               'say': 34,\n",
       "                               'anything': 28,\n",
       "                               'Her': 24,\n",
       "                               'eyes': 90,\n",
       "                               'glazed': 1,\n",
       "                               'hear': 23,\n",
       "                               'even': 66,\n",
       "                               'see': 79,\n",
       "                               'reached': 36,\n",
       "                               'point': 10,\n",
       "                               'which': 100,\n",
       "                               'care': 14,\n",
       "                               'looked': 62,\n",
       "                               'face': 74,\n",
       "                               'very': 41,\n",
       "                               'thin': 12,\n",
       "                               'burned': 10,\n",
       "                               'by': 147,\n",
       "                               'sun': 21,\n",
       "                               'until': 36,\n",
       "                               'skin': 9,\n",
       "                               'dead': 25,\n",
       "                               'peeling': 1,\n",
       "                               'new': 22,\n",
       "                               'under': 40,\n",
       "                               'red': 15,\n",
       "                               'angry': 8,\n",
       "                               'blond': 5,\n",
       "                               'hair': 37,\n",
       "                               'frowzy': 1,\n",
       "                               'dress': 9,\n",
       "                               'several': 21,\n",
       "                               'places': 6,\n",
       "                               'shoes': 3,\n",
       "                               'completely': 7,\n",
       "                               'worn': 2,\n",
       "                               'practically': 5,\n",
       "                               'protection': 5,\n",
       "                               'must': 27,\n",
       "                               'sole': 1,\n",
       "                               'off': 87,\n",
       "                               'foot': 10,\n",
       "                               'bruised': 1,\n",
       "                               'bleeding': 4,\n",
       "                               'sliding': 2,\n",
       "                               'hand': 65,\n",
       "                               'shoulders': 14,\n",
       "                               'other': 60,\n",
       "                               'knees': 8,\n",
       "                               'into': 180,\n",
       "                               'amazingly': 1,\n",
       "                               'light': 25,\n",
       "                               'relaxed': 2,\n",
       "                               'arms': 17,\n",
       "                               \"wasn't\": 17,\n",
       "                               'sure': 26,\n",
       "                               'conscious': 1,\n",
       "                               'Any': 2,\n",
       "                               'lingering': 1,\n",
       "                               'suspicion': 2,\n",
       "                               'dispelled': 1,\n",
       "                               'go': 73,\n",
       "                               'far': 30,\n",
       "                               'fool': 8,\n",
       "                               'kill': 13,\n",
       "                               'Besides': 7,\n",
       "                               'sweet': 7,\n",
       "                               'attracted': 2,\n",
       "                               'put': 23,\n",
       "                               'couch': 3,\n",
       "                               'going': 50,\n",
       "                               'dropped': 25,\n",
       "                               'chair': 9,\n",
       "                               'beside': 13,\n",
       "                               'table': 11,\n",
       "                               'deal': 6,\n",
       "                               'alike': 1,\n",
       "                               'Both': 4,\n",
       "                               'blonde': 9,\n",
       "                               'blue': 7,\n",
       "                               'faint': 7,\n",
       "                               'similarity': 2,\n",
       "                               'features': 4,\n",
       "                               'filled': 14,\n",
       "                               'dipper': 6,\n",
       "                               'bucket': 3,\n",
       "                               'shelf': 3,\n",
       "                               'room': 33,\n",
       "                               'lifted': 16,\n",
       "                               \"girl's\": 2,\n",
       "                               'held': 27,\n",
       "                               'edge': 10,\n",
       "                               'mouth': 23,\n",
       "                               'drank': 3,\n",
       "                               'greedily': 1,\n",
       "                               'murmured': 11,\n",
       "                               'Thank': 7,\n",
       "                               'you': 362,\n",
       "                               'lowered': 4,\n",
       "                               'stood': 36,\n",
       "                               'looking': 19,\n",
       "                               'moment': 32,\n",
       "                               'wondering': 4,\n",
       "                               'what': 110,\n",
       "                               'reduced': 1,\n",
       "                               'condition': 2,\n",
       "                               'seen': 33,\n",
       "                               'nester': 2,\n",
       "                               'wagons': 7,\n",
       "                               'families': 2,\n",
       "                               'almost': 36,\n",
       "                               'starving': 3,\n",
       "                               'death': 20,\n",
       "                               'never': 62,\n",
       "                               'bad': 9,\n",
       "                               'these': 28,\n",
       "                               'returned': 11,\n",
       "                               'built': 5,\n",
       "                               'fire': 35,\n",
       "                               'buckets': 2,\n",
       "                               'poured': 5,\n",
       "                               'copper': 1,\n",
       "                               'boiler': 1,\n",
       "                               'placed': 7,\n",
       "                               'stove': 2,\n",
       "                               'brought': 28,\n",
       "                               'faced': 6,\n",
       "                               'Who': 4,\n",
       "                               'are': 48,\n",
       "                               \"I'm\": 50,\n",
       "                               'Billy': 17,\n",
       "                               'Jones': 11,\n",
       "                               'answered': 6,\n",
       "                               \"That's\": 20,\n",
       "                               'my': 168,\n",
       "                               'Sharon': 2,\n",
       "                               'We': 32,\n",
       "                               'ran': 33,\n",
       "                               'money': 16,\n",
       "                               \"haven't\": 7,\n",
       "                               'eaten': 2,\n",
       "                               'days': 22,\n",
       "                               'What': 39,\n",
       "                               'doing': 18,\n",
       "                               'Are': 5,\n",
       "                               'Wyoming': 4,\n",
       "                               'nodded': 15,\n",
       "                               'About': 5,\n",
       "                               'five': 13,\n",
       "                               'miles': 14,\n",
       "                               'line': 25,\n",
       "                               'sighed': 3,\n",
       "                               'relieved': 5,\n",
       "                               \"We've\": 2,\n",
       "                               'ranchers': 6,\n",
       "                               'turned': 53,\n",
       "                               'us': 47,\n",
       "                               'You': 84,\n",
       "                               'mean': 19,\n",
       "                               'dragged': 4,\n",
       "                               'your': 59,\n",
       "                               'over': 118,\n",
       "                               \"hell's\": 2,\n",
       "                               'half-acre': 1,\n",
       "                               'demanded': 4,\n",
       "                               'town': 28,\n",
       "                               \"Buckhorn's\": 1,\n",
       "                               'only': 98,\n",
       "                               'about': 119,\n",
       "                               'six': 15,\n",
       "                               'Why': 17,\n",
       "                               'This': 36,\n",
       "                               'is': 98,\n",
       "                               'mighty': 7,\n",
       "                               'empty': 7,\n",
       "                               'ranch': 11,\n",
       "                               'three': 35,\n",
       "                               \"You'd\": 3,\n",
       "                               'starved': 2,\n",
       "                               \"you'd\": 7,\n",
       "                               'missed': 4,\n",
       "                               'Then': 38,\n",
       "                               \"we're\": 8,\n",
       "                               'lucky': 5,\n",
       "                               'got': 80,\n",
       "                               'job': 16,\n",
       "                               'Mr.': 22,\n",
       "                               'silent': 6,\n",
       "                               'use': 15,\n",
       "                               'year': 11,\n",
       "                               'cook': 2,\n",
       "                               'knew': 54,\n",
       "                               'might': 58,\n",
       "                               'dismissed': 2,\n",
       "                               'possibility': 3,\n",
       "                               'once': 32,\n",
       "                               'haunted': 3,\n",
       "                               'killer': 6,\n",
       "                               \"hadn't\": 14,\n",
       "                               'shaved': 2,\n",
       "                               'weeks': 6,\n",
       "                               'sparse': 1,\n",
       "                               'beard': 2,\n",
       "                               'giving': 8,\n",
       "                               'pathetic': 1,\n",
       "                               'woebegone': 1,\n",
       "                               'expression': 5,\n",
       "                               'There': 59,\n",
       "                               'running': 21,\n",
       "                               'something': 50,\n",
       "                               \"He'd\": 9,\n",
       "                               'an': 159,\n",
       "                               'idiot': 1,\n",
       "                               'let': 38,\n",
       "                               \"couldn't\": 26,\n",
       "                               'send': 5,\n",
       "                               'either': 15,\n",
       "                               'I': 652,\n",
       "                               'help': 17,\n",
       "                               'finally': 11,\n",
       "                               \"can't\": 17,\n",
       "                               'pay': 3,\n",
       "                               'guess': 11,\n",
       "                               'better': 30,\n",
       "                               'morning': 27,\n",
       "                               \"We'll\": 15,\n",
       "                               'our': 39,\n",
       "                               'keep': 15,\n",
       "                               'eagerly': 2,\n",
       "                               \"I've\": 24,\n",
       "                               'mucking': 1,\n",
       "                               'mine': 4,\n",
       "                               'San': 3,\n",
       "                               'Juan': 2,\n",
       "                               'used': 12,\n",
       "                               \"she's\": 1,\n",
       "                               'cooked': 1,\n",
       "                               'restaurant': 3,\n",
       "                               \"I'll\": 35,\n",
       "                               'Right': 1,\n",
       "                               'need': 14,\n",
       "                               'meal': 7,\n",
       "                               'bath': 10,\n",
       "                               'Your': 10,\n",
       "                               \"wife's\": 3,\n",
       "                               'terrible': 9,\n",
       "                               'shape': 8,\n",
       "                               'know': 58,\n",
       "                               'dejectedly': 1,\n",
       "                               'box': 6,\n",
       "                               'wood': 5,\n",
       "                               'again': 73,\n",
       "                               'supper': 5,\n",
       "                               'set': 17,\n",
       "                               'ready': 14,\n",
       "                               'wash': 4,\n",
       "                               'rubbed': 2,\n",
       "                               'stretched': 8,\n",
       "                               'mess': 3,\n",
       "                               'suddenly': 16,\n",
       "                               'alarmed': 2,\n",
       "                               'How': 21,\n",
       "                               'did': 84,\n",
       "                               'Rafter': 1,\n",
       "                               'Aj': 1,\n",
       "                               'gave': 23,\n",
       "                               'Oh': 17,\n",
       "                               'stared': 17,\n",
       "                               'wide': 13,\n",
       "                               ':': 71,\n",
       "                               \"You're\": 18,\n",
       "                               'Do': 6,\n",
       "                               'take': 38,\n",
       "                               'strays': 2,\n",
       "                               'come': 61,\n",
       "                               \"don't\": 65,\n",
       "                               'many': 22,\n",
       "                               'coming': 12,\n",
       "                               'Think': 1,\n",
       "                               'can': 46,\n",
       "                               'Of': 5,\n",
       "                               'course': 16,\n",
       "                               'staggered': 3,\n",
       "                               'arm': 23,\n",
       "                               'helped': 8,\n",
       "                               'shaking': 5,\n",
       "                               'sorry': 7,\n",
       "                               'usually': 4,\n",
       "                               'strong': 17,\n",
       "                               'awfully': 2,\n",
       "                               'And': 84,\n",
       "                               'hungry': 5,\n",
       "                               'Start': 3,\n",
       "                               \"It's\": 20,\n",
       "                               \"it's\": 15,\n",
       "                               'eat': 6,\n",
       "                               'Not': 24,\n",
       "                               'cried': 6,\n",
       "                               'best-looking': 1,\n",
       "                               'food': 6,\n",
       "                               'satisfied': 1,\n",
       "                               \"he's\": 13,\n",
       "                               'grateful': 3,\n",
       "                               'way': 65,\n",
       "                               'made': 77,\n",
       "                               'ashamed': 5,\n",
       "                               'Lord': 23,\n",
       "                               'looks': 5,\n",
       "                               'fools': 2,\n",
       "                               'drunkards': 2,\n",
       "                               'innocents': 1,\n",
       "                               'laughed': 10,\n",
       "                               'Which': 2,\n",
       "                               \"We're\": 8,\n",
       "                               'dishes': 5,\n",
       "                               'before': 83,\n",
       "                               'dark': 40,\n",
       "                               'tub': 5,\n",
       "                               'where': 53,\n",
       "                               'hung': 14,\n",
       "                               'nail': 1,\n",
       "                               'wall': 22,\n",
       "                               \"You'll\": 5,\n",
       "                               'feel': 19,\n",
       "                               'lot': 10,\n",
       "                               'after': 53,\n",
       "                               'Mrs.': 18,\n",
       "                               'doc': 1,\n",
       "                               \"she'll\": 2,\n",
       "                               'right': 79,\n",
       "                               'quickly': 13,\n",
       "                               'expect': 4,\n",
       "                               'just': 74,\n",
       "                               'find': 18,\n",
       "                               'me': 207,\n",
       "                               'needle': 2,\n",
       "                               'thread': 3,\n",
       "                               'My': 21,\n",
       "                               'needs': 2,\n",
       "                               'bedroom': 6,\n",
       "                               'scissors': 1,\n",
       "                               'bed': 17,\n",
       "                               'spare': 2,\n",
       "                               \"isn't\": 9,\n",
       "                               \"you'll\": 7,\n",
       "                               'blankets': 3,\n",
       "                               'Some': 6,\n",
       "                               'early': 8,\n",
       "                               'followed': 24,\n",
       "                               'closing': 4,\n",
       "                               'behind': 48,\n",
       "                               'slept': 5,\n",
       "                               'together': 15,\n",
       "                               'since': 15,\n",
       "                               'chances': 3,\n",
       "                               'getting': 16,\n",
       "                               'pregnant': 2,\n",
       "                               'sleeping': 5,\n",
       "                               'embarrassed': 3,\n",
       "                               'understand': 13,\n",
       "                               'savvy': 1,\n",
       "                               'why': 13,\n",
       "                               'jobs': 2,\n",
       "                               'first': 55,\n",
       "                               'place': 39,\n",
       "                               'fired': 6,\n",
       "                               'pair': 3,\n",
       "                               'lost': 10,\n",
       "                               'whipped': 3,\n",
       "                               'kids': 8,\n",
       "                               'Gavin': 13,\n",
       "                               'paused': 6,\n",
       "                               'wearily': 1,\n",
       "                               \"they'd\": 7,\n",
       "                               'dawn': 6,\n",
       "                               'make': 49,\n",
       "                               'sank': 3,\n",
       "                               'began': 39,\n",
       "                               'rock': 6,\n",
       "                               'Rittenhouse': 1,\n",
       "                               'Splendide': 1,\n",
       "                               'life': 29,\n",
       "                               'guilt': 2,\n",
       "                               'Beneath': 1,\n",
       "                               'black': 26,\n",
       "                               'shirt': 12,\n",
       "                               'frail': 1,\n",
       "                               'shook': 17,\n",
       "                               'croaks': 1,\n",
       "                               'pain': 9,\n",
       "                               'broke': 13,\n",
       "                               'throat': 11,\n",
       "                               'stored': 2,\n",
       "                               'shattering': 4,\n",
       "                               'free': 8,\n",
       "                               'slow': 4,\n",
       "                               'gasps': 3,\n",
       "                               'Clayton': 19,\n",
       "                               'tried': 16,\n",
       "                               'call': 8,\n",
       "                               'known': 14,\n",
       "                               'Against': 2,\n",
       "                               'rally': 2,\n",
       "                               'anger': 8,\n",
       "                               'bent': 5,\n",
       "                               'powerless': 1,\n",
       "                               \"Gavin's\": 8,\n",
       "                               'moved': 29,\n",
       "                               'stoop': 1,\n",
       "                               'catch': 10,\n",
       "                               'words': 22,\n",
       "                               'remember': 12,\n",
       "                               'Big': 5,\n",
       "                               'Charlie': 6,\n",
       "                               'whispered': 11,\n",
       "                               'stuck': 6,\n",
       "                               'Just': 22,\n",
       "                               'half-breed': 5,\n",
       "                               \"'pache\": 1,\n",
       "                               'meant': 14,\n",
       "                               'anythin': 1,\n",
       "                               'fight': 10,\n",
       "                               'Tom': 23,\n",
       "                               'English': 8,\n",
       "                               \"brother's\": 2,\n",
       "                               'son': 13,\n",
       "                               'fair': 5,\n",
       "                               'provoked': 2,\n",
       "                               '--': 213,\n",
       "                               'believed': 10,\n",
       "                               'killed': 15,\n",
       "                               'dumped': 3,\n",
       "                               'body': 31,\n",
       "                               'rose': 7,\n",
       "                               'garden': 4,\n",
       "                               'nights': 4,\n",
       "                               'ago': 17,\n",
       "                               'men': 81,\n",
       "                               'cleared': 4,\n",
       "                               'Clay': 5,\n",
       "                               'treated': 4,\n",
       "                               'wiped': 7,\n",
       "                               'sleeve': 6,\n",
       "                               'childish': 1,\n",
       "                               'wonder': 6,\n",
       "                               'shyly': 2,\n",
       "                               'wherever': 1,\n",
       "                               \"you're\": 20,\n",
       "                               'goin': 4,\n",
       "                               'Yes': 14,\n",
       "                               'hate': 8,\n",
       "                               'choked': 3,\n",
       "                               'murmuring': 2,\n",
       "                               'Come': 12,\n",
       "                               'old': 38,\n",
       "                               'beckoned': 1,\n",
       "                               'finger': 4,\n",
       "                               'forward': 19,\n",
       "                               'slipped': 10,\n",
       "                               'chest': 13,\n",
       "                               'hugged': 1,\n",
       "                               'fiercely': 3,\n",
       "                               'All': 24,\n",
       "                               'driftin': 1,\n",
       "                               'away': 71,\n",
       "                               'wanted': 20,\n",
       "                               'part': 21,\n",
       "                               \"there's\": 9,\n",
       "                               'nothin': 2,\n",
       "                               'Laurel': 1,\n",
       "                               'gone': 23,\n",
       "                               '!': 314,\n",
       "                               'God': 10,\n",
       "                               'Heaven': 1,\n",
       "                               'refuse': 1,\n",
       "                               'That': 39,\n",
       "                               'mock': 1,\n",
       "                               \"Can't\": 5,\n",
       "                               'closed': 11,\n",
       "                               'tears': 5,\n",
       "                               'freed': 2,\n",
       "                               'embrace': 2,\n",
       "                               'stepped': 11,\n",
       "                               'fearfully': 2,\n",
       "                               'horses': 34,\n",
       "                               'saddle': 14,\n",
       "                               'bring': 8,\n",
       "                               'round': 7,\n",
       "                               'burst': 6,\n",
       "                               'confinement': 1,\n",
       "                               'cold': 14,\n",
       "                               'air': 23,\n",
       "                               'stallion': 3,\n",
       "                               'barn': 13,\n",
       "                               'tightened': 5,\n",
       "                               'cinches': 1,\n",
       "                               'blanket': 8,\n",
       "                               'working': 5,\n",
       "                               'touch': 3,\n",
       "                               'darkness': 12,\n",
       "                               'comforting': 1,\n",
       "                               'animal': 4,\n",
       "                               'easy': 11,\n",
       "                               'finished': 11,\n",
       "                               'led': 12,\n",
       "                               'mare': 5,\n",
       "                               'smelled': 2,\n",
       "                               'heat': 7,\n",
       "                               'paw': 1,\n",
       "                               'turf': 1,\n",
       "                               'looped': 1,\n",
       "                               'reins': 5,\n",
       "                               'knot': 2,\n",
       "                               'veranda': 5,\n",
       "                               'post': 7,\n",
       "                               'patted': 1,\n",
       "                               'flesh': 9,\n",
       "                               'neck': 20,\n",
       "                               'backed': 6,\n",
       "                               \"doesn't\": 9,\n",
       "                               'will': 50,\n",
       "                               'figure': 14,\n",
       "                               'taken': 9,\n",
       "                               'carbine': 2,\n",
       "                               'trailed': 3,\n",
       "                               'stock': 5,\n",
       "                               'bumping': 1,\n",
       "                               'floor': 23,\n",
       "                               'called': 22,\n",
       "                               'steps': 18,\n",
       "                               'To': 13,\n",
       "                               'valley': 31,\n",
       "                               'someone': 11,\n",
       "                               'may': 5,\n",
       "                               'California': 6,\n",
       "                               'yet': 21,\n",
       "                               'crazy': 1,\n",
       "                               'nod': 3,\n",
       "                               'land': 16,\n",
       "                               'A': 78,\n",
       "                               'mark': 3,\n",
       "                               'Two': 8,\n",
       "                               'like': 136,\n",
       "                               'somethin': 1,\n",
       "                               'fine': 6,\n",
       "                               'maybe': 14,\n",
       "                               \"one's\": 2,\n",
       "                               'fresh': 7,\n",
       "                               'father': 15,\n",
       "                               'stand': 11,\n",
       "                               'approached': 5,\n",
       "                               'horse': 21,\n",
       "                               'laid': 8,\n",
       "                               \"stallion's\": 2,\n",
       "                               'quivering': 4,\n",
       "                               'Help': 5,\n",
       "                               'stiff': 6,\n",
       "                               'gently': 3,\n",
       "                               'child': 12,\n",
       "                               \"They'll\": 5,\n",
       "                               'trample': 1,\n",
       "                               'loved': 6,\n",
       "                               'grow': 2,\n",
       "                               'huskily': 1,\n",
       "                               'Lived': 2,\n",
       "                               'alone': 14,\n",
       "                               'river': 16,\n",
       "                               'nice': 8,\n",
       "                               'peaceful': 2,\n",
       "                               'quiet': 6,\n",
       "                               'swung': 17,\n",
       "                               'whacked': 1,\n",
       "                               'rump': 2,\n",
       "                               'yard': 3,\n",
       "                               'circle': 13,\n",
       "                               'cast': 1,\n",
       "                               'lamp': 2,\n",
       "                               'burning': 8,\n",
       "                               'Thirty-five': 1,\n",
       "                               'rode': 12,\n",
       "                               'measured': 2,\n",
       "                               'pace': 3,\n",
       "                               'Dawn': 1,\n",
       "                               'soon': 17,\n",
       "                               'coldest': 2,\n",
       "                               'moon': 2,\n",
       "                               'sunk': 1,\n",
       "                               'below': 8,\n",
       "                               'crest': 2,\n",
       "                               'mountains': 5,\n",
       "                               'grown': 1,\n",
       "                               'accustomed': 3,\n",
       "                               'absence': 1,\n",
       "                               'primeval': 1,\n",
       "                               'trespassed': 1,\n",
       "                               'those': 27,\n",
       "                               'campfire': 2,\n",
       "                               'waked': 1,\n",
       "                               'hoot': 1,\n",
       "                               'owl': 1,\n",
       "                               'rustle': 1,\n",
       "                               'blade': 5,\n",
       "                               \"moon's\": 1,\n",
       "                               'wind': 9,\n",
       "                               'savage': 5,\n",
       "                               'untenanted': 1,\n",
       "                               'brooding': 2,\n",
       "                               'broken': 6,\n",
       "                               'bitterly': 4,\n",
       "                               'inert': 2,\n",
       "                               'landscape': 1,\n",
       "                               'caravan': 1,\n",
       "                               'desires': 2,\n",
       "                               'passed': 21,\n",
       "                               'mind': 36,\n",
       "                               'ambushed': 1,\n",
       "                               'strewn': 1,\n",
       "                               'postures': 1,\n",
       "                               'dying': 5,\n",
       "                               'vain': 2,\n",
       "                               'groped': 2,\n",
       "                               'reassemble': 1,\n",
       "                               'bones': 5,\n",
       "                               'relationships': 1,\n",
       "                               'sought': 5,\n",
       "                               'desperately': 6,\n",
       "                               'silence': 7,\n",
       "                               'oppressed': 1,\n",
       "                               'bend': 7,\n",
       "                               'low': 9,\n",
       "                               \"horse's\": 1,\n",
       "                               'hide': 3,\n",
       "                               'begun': 1,\n",
       "                               'blow': 7,\n",
       "                               'twisting': 5,\n",
       "                               'search': 5,\n",
       "                               'ranches': 1,\n",
       "                               'framed': 2,\n",
       "                               'gray': 11,\n",
       "                               'hills': 11,\n",
       "                               'dissolve': 1,\n",
       "                               'bold': 5,\n",
       "                               'violet': 1,\n",
       "                               'loose': 11,\n",
       "                               'high': 19,\n",
       "                               'feathers': 2,\n",
       "                               'swept': 6,\n",
       "                               'stars': 1,\n",
       "                               'sky': 7,\n",
       "                               'wan': 1,\n",
       "                               'spread': 10,\n",
       "                               'ground': 29,\n",
       "                               'revealed': 2,\n",
       "                               'glimmer': 1,\n",
       "                               'contours': 1,\n",
       "                               'trees': 21,\n",
       "                               'fences': 1,\n",
       "                               'palely': 1,\n",
       "                               'shadowed': 1,\n",
       "                               'gullies': 1,\n",
       "                               'weary': 4,\n",
       "                               'though': 24,\n",
       "                               'watchful': 2,\n",
       "                               'posted': 2,\n",
       "                               'hundred': 16,\n",
       "                               'yards': 15,\n",
       "                               'windless': 1,\n",
       "                               'shelter': 1,\n",
       "                               'flung': 6,\n",
       "                               'themselves': 6,\n",
       "                               'saloon': 5,\n",
       "                               'crying': 3,\n",
       "                               'intelligence': 4,\n",
       "                               \"Pettigrew's\": 1,\n",
       "                               \"night's\": 3,\n",
       "                               'drinking': 6,\n",
       "                               'faces': 10,\n",
       "                               'baggy': 1,\n",
       "                               'liquor': 3,\n",
       "                               'flushed': 1,\n",
       "                               'courage': 1,\n",
       "                               'greeted': 1,\n",
       "                               'news': 4,\n",
       "                               'angrily': 1,\n",
       "                               'cheated': 1,\n",
       "                               'purpose': 5,\n",
       "                               'Lester': 4,\n",
       "                               'heard': 40,\n",
       "                               'muttering': 2,\n",
       "                               'reveal': 1,\n",
       "                               'desire': 3,\n",
       "                               'worked': 9,\n",
       "                               'tongue': 5,\n",
       "                               'hollow': 2,\n",
       "                               ...}),\n",
       "                     'belles_lettres': FreqDist({'Northern': 10,\n",
       "                               'liberals': 14,\n",
       "                               'are': 647,\n",
       "                               'the': 9726,\n",
       "                               'chief': 14,\n",
       "                               'supporters': 4,\n",
       "                               'of': 6289,\n",
       "                               'civil': 10,\n",
       "                               'rights': 17,\n",
       "                               'and': 4282,\n",
       "                               'integration': 9,\n",
       "                               '.': 6397,\n",
       "                               'They': 122,\n",
       "                               'have': 628,\n",
       "                               'also': 179,\n",
       "                               'led': 24,\n",
       "                               'nation': 34,\n",
       "                               'in': 3089,\n",
       "                               'direction': 17,\n",
       "                               'a': 3308,\n",
       "                               'welfare': 11,\n",
       "                               'state': 65,\n",
       "                               'And': 178,\n",
       "                               'both': 106,\n",
       "                               'their': 490,\n",
       "                               'objectives': 7,\n",
       "                               'non-discrimination': 1,\n",
       "                               'social': 93,\n",
       "                               'progress': 25,\n",
       "                               'they': 488,\n",
       "                               'had': 804,\n",
       "                               'ranged': 2,\n",
       "                               'against': 99,\n",
       "                               'them': 298,\n",
       "                               'Southerners': 19,\n",
       "                               'who': 452,\n",
       "                               'called': 62,\n",
       "                               'Bourbons': 6,\n",
       "                               'The': 1030,\n",
       "                               'name': 53,\n",
       "                               'presumably': 4,\n",
       "                               'derives': 2,\n",
       "                               'from': 649,\n",
       "                               'French': 41,\n",
       "                               'royal': 7,\n",
       "                               'house': 40,\n",
       "                               'which': 679,\n",
       "                               'never': 129,\n",
       "                               'learned': 30,\n",
       "                               'forgot': 2,\n",
       "                               ';': 888,\n",
       "                               'since': 69,\n",
       "                               'Bourbon': 2,\n",
       "                               'whiskey': 1,\n",
       "                               ',': 9166,\n",
       "                               'though': 67,\n",
       "                               'Kentucky': 3,\n",
       "                               'origin': 9,\n",
       "                               'is': 1799,\n",
       "                               'at': 634,\n",
       "                               'least': 59,\n",
       "                               'as': 1160,\n",
       "                               'much': 153,\n",
       "                               'favored': 5,\n",
       "                               'by': 795,\n",
       "                               'North': 40,\n",
       "                               'conservatives': 2,\n",
       "                               'South': 73,\n",
       "                               'nature': 59,\n",
       "                               'opposition': 10,\n",
       "                               'between': 146,\n",
       "                               'too': 114,\n",
       "                               'little': 129,\n",
       "                               'understood': 17,\n",
       "                               'race': 14,\n",
       "                               'problem': 40,\n",
       "                               'has': 402,\n",
       "                               'tended': 4,\n",
       "                               'to': 4084,\n",
       "                               'obscure': 7,\n",
       "                               'other': 262,\n",
       "                               'less': 67,\n",
       "                               'emotional': 17,\n",
       "                               'issues': 14,\n",
       "                               'may': 207,\n",
       "                               'fundamentally': 2,\n",
       "                               'be': 843,\n",
       "                               'even': 182,\n",
       "                               'more': 368,\n",
       "                               'divisive': 1,\n",
       "                               'It': 313,\n",
       "                               'these': 224,\n",
       "                               'differences': 17,\n",
       "                               '--': 455,\n",
       "                               'that': 1896,\n",
       "                               'than': 320,\n",
       "                               'those': 113,\n",
       "                               'concern': 23,\n",
       "                               'discrimination': 2,\n",
       "                               'or': 587,\n",
       "                               'I': 845,\n",
       "                               'chiefly': 5,\n",
       "                               'discuss': 8,\n",
       "                               'herein': 1,\n",
       "                               'write': 39,\n",
       "                               'about': 253,\n",
       "                               'considerable': 17,\n",
       "                               'personal': 59,\n",
       "                               'experience': 92,\n",
       "                               'A': 143,\n",
       "                               'Southerner': 5,\n",
       "                               'married': 12,\n",
       "                               'New': 115,\n",
       "                               'Englander': 3,\n",
       "                               'lived': 20,\n",
       "                               'for': 1191,\n",
       "                               'many': 141,\n",
       "                               'years': 156,\n",
       "                               'Connecticut': 4,\n",
       "                               'commuting': 2,\n",
       "                               'town': 35,\n",
       "                               'with': 1060,\n",
       "                               'high': 57,\n",
       "                               'percentage': 4,\n",
       "                               'artists': 6,\n",
       "                               'writers': 37,\n",
       "                               'publicity': 6,\n",
       "                               'men': 163,\n",
       "                               'business': 40,\n",
       "                               'executives': 1,\n",
       "                               'egghead': 1,\n",
       "                               'tastes': 1,\n",
       "                               'Most': 14,\n",
       "                               'Democrats': 11,\n",
       "                               'nearly': 13,\n",
       "                               'all': 441,\n",
       "                               'consider': 20,\n",
       "                               'themselves': 72,\n",
       "                               'viewed': 3,\n",
       "                               'This': 164,\n",
       "                               'puzzling': 4,\n",
       "                               'an': 583,\n",
       "                               'outsider': 1,\n",
       "                               'conscious': 14,\n",
       "                               'classic': 12,\n",
       "                               'tradition': 32,\n",
       "                               'liberalism': 8,\n",
       "                               'because': 145,\n",
       "                               'it': 1059,\n",
       "                               'clear': 36,\n",
       "                               'left-of-center': 1,\n",
       "                               'opposite': 16,\n",
       "                               'poles': 2,\n",
       "                               'liberal': 27,\n",
       "                               'Jefferson': 18,\n",
       "                               'held': 29,\n",
       "                               'best': 51,\n",
       "                               'government': 39,\n",
       "                               'was': 1467,\n",
       "                               'Yet': 30,\n",
       "                               'paradoxically': 3,\n",
       "                               'my': 209,\n",
       "                               'friends': 47,\n",
       "                               'continue': 20,\n",
       "                               'view': 34,\n",
       "                               'one': 475,\n",
       "                               'patron': 1,\n",
       "                               'saints': 1,\n",
       "                               'When': 93,\n",
       "                               'question': 45,\n",
       "                               'what': 244,\n",
       "                               'mean': 24,\n",
       "                               'concepts': 9,\n",
       "                               'like': 169,\n",
       "                               'liberty': 21,\n",
       "                               'democracy': 11,\n",
       "                               'find': 73,\n",
       "                               'fall': 22,\n",
       "                               'into': 246,\n",
       "                               'two': 182,\n",
       "                               'categories': 2,\n",
       "                               ':': 285,\n",
       "                               'simpler': 10,\n",
       "                               'ones': 16,\n",
       "                               'simply': 34,\n",
       "                               'accepted': 18,\n",
       "                               'shibboleths': 1,\n",
       "                               'faith': 22,\n",
       "                               'without': 114,\n",
       "                               'analysis': 16,\n",
       "                               'intelligent': 4,\n",
       "                               'cynical': 3,\n",
       "                               'scornfully': 1,\n",
       "                               'reply': 5,\n",
       "                               'things': 69,\n",
       "                               \"don't\": 19,\n",
       "                               'count': 6,\n",
       "                               'any': 210,\n",
       "                               'world': 165,\n",
       "                               'to-day': 4,\n",
       "                               'am': 57,\n",
       "                               'naive': 1,\n",
       "                               'say': 87,\n",
       "                               'make': 108,\n",
       "                               'use': 56,\n",
       "                               'such': 169,\n",
       "                               'words': 44,\n",
       "                               'take': 78,\n",
       "                               'this': 627,\n",
       "                               'therefore': 28,\n",
       "                               'necessarily': 10,\n",
       "                               '?': 470,\n",
       "                               'considers': 5,\n",
       "                               'need': 42,\n",
       "                               'national': 37,\n",
       "                               'economy': 15,\n",
       "                               'controls': 7,\n",
       "                               'will': 236,\n",
       "                               'assure': 8,\n",
       "                               'his': 1342,\n",
       "                               'conception': 12,\n",
       "                               'justice': 21,\n",
       "                               'so': 303,\n",
       "                               'great': 128,\n",
       "                               'individual': 49,\n",
       "                               'local': 16,\n",
       "                               'liberties': 6,\n",
       "                               'well': 146,\n",
       "                               'democratic': 16,\n",
       "                               'processes': 8,\n",
       "                               'yield': 4,\n",
       "                               'before': 140,\n",
       "                               'seems': 47,\n",
       "                               'attitude': 26,\n",
       "                               'favoring': 3,\n",
       "                               'sort': 40,\n",
       "                               'totalitarian': 1,\n",
       "                               'bureaucracy': 6,\n",
       "                               'under': 77,\n",
       "                               'President': 50,\n",
       "                               'same': 89,\n",
       "                               'stamp': 1,\n",
       "                               'would': 392,\n",
       "                               'try': 13,\n",
       "                               'coerce': 1,\n",
       "                               'uncooperative': 1,\n",
       "                               'Congress': 21,\n",
       "                               'Supreme': 5,\n",
       "                               'Court': 10,\n",
       "                               'As': 101,\n",
       "                               \"states'\": 1,\n",
       "                               'counted': 3,\n",
       "                               'thinking': 23,\n",
       "                               'except': 31,\n",
       "                               'irritations': 1,\n",
       "                               'minor': 7,\n",
       "                               'immoral': 2,\n",
       "                               'exist': 13,\n",
       "                               'now': 151,\n",
       "                               'only': 286,\n",
       "                               'anachronisms': 1,\n",
       "                               'American': 114,\n",
       "                               'strong': 27,\n",
       "                               'case': 50,\n",
       "                               'but': 523,\n",
       "                               'he': 1174,\n",
       "                               'presents': 6,\n",
       "                               'publicly': 3,\n",
       "                               'enmeshed': 1,\n",
       "                               'hypocrisy': 2,\n",
       "                               'not': 816,\n",
       "                               'honest': 8,\n",
       "                               'Why': 14,\n",
       "                               'first': 176,\n",
       "                               'place': 76,\n",
       "                               'call': 34,\n",
       "                               'himself': 134,\n",
       "                               'if': 209,\n",
       "                               'laissez-faire': 1,\n",
       "                               'favors': 1,\n",
       "                               'authoritarian': 2,\n",
       "                               'central': 18,\n",
       "                               'womb-to-tomb': 1,\n",
       "                               'over': 148,\n",
       "                               'everybody': 8,\n",
       "                               'If': 92,\n",
       "                               'attaches': 1,\n",
       "                               'importance': 15,\n",
       "                               'why': 36,\n",
       "                               'known': 48,\n",
       "                               'scornful': 1,\n",
       "                               'states': 31,\n",
       "                               'advocate': 1,\n",
       "                               'different': 36,\n",
       "                               'constitution': 6,\n",
       "                               'could': 213,\n",
       "                               'sincerely': 4,\n",
       "                               'support': 17,\n",
       "                               'concerned': 35,\n",
       "                               'here': 66,\n",
       "                               'however': 82,\n",
       "                               \"liberal's\": 1,\n",
       "                               'toward': 50,\n",
       "                               'appears': 13,\n",
       "                               'intense': 9,\n",
       "                               'dislike': 6,\n",
       "                               'makes': 27,\n",
       "                               'effort': 18,\n",
       "                               'conceal': 2,\n",
       "                               'presence': 10,\n",
       "                               'Southern': 68,\n",
       "                               'His': 105,\n",
       "                               'assumption': 11,\n",
       "                               'being': 136,\n",
       "                               'tolerable': 1,\n",
       "                               'humans': 1,\n",
       "                               'must': 170,\n",
       "                               'most': 200,\n",
       "                               'partly': 9,\n",
       "                               'sympathy': 7,\n",
       "                               'views': 10,\n",
       "                               \"Time's\": 1,\n",
       "                               'editor': 8,\n",
       "                               'Thomas': 45,\n",
       "                               'Griffith': 3,\n",
       "                               'book': 58,\n",
       "                               'Waist-High': 1,\n",
       "                               'Culture': 1,\n",
       "                               'wrote': 69,\n",
       "                               '``': 1320,\n",
       "                               '(': 249,\n",
       "                               'Deep': 1,\n",
       "                               ')': 251,\n",
       "                               'found': 81,\n",
       "                               'myself': 31,\n",
       "                               'unsympathetic': 2,\n",
       "                               \"''\": 1309,\n",
       "                               'know': 98,\n",
       "                               'understatement': 1,\n",
       "                               'Theirs': 1,\n",
       "                               'no': 282,\n",
       "                               'mere': 19,\n",
       "                               'lack': 22,\n",
       "                               'something': 49,\n",
       "                               'closer': 7,\n",
       "                               'passionate': 5,\n",
       "                               'hatred': 2,\n",
       "                               'directed': 6,\n",
       "                               'Fascism': 2,\n",
       "                               'do': 184,\n",
       "                               'think': 54,\n",
       "                               'typical': 18,\n",
       "                               'living': 37,\n",
       "                               'In': 320,\n",
       "                               'circles': 8,\n",
       "                               'usually': 31,\n",
       "                               'conservative': 10,\n",
       "                               'atmosphere': 10,\n",
       "                               'hardly': 15,\n",
       "                               'But': 249,\n",
       "                               'our': 281,\n",
       "                               'neither': 22,\n",
       "                               'wife': 33,\n",
       "                               'nor': 37,\n",
       "                               'extreme': 18,\n",
       "                               'on': 765,\n",
       "                               'we': 398,\n",
       "                               'given': 45,\n",
       "                               'outbursts': 1,\n",
       "                               'situation': 42,\n",
       "                               'ruined': 4,\n",
       "                               'valued': 3,\n",
       "                               'friendships': 2,\n",
       "                               'come': 88,\n",
       "                               'close': 26,\n",
       "                               'wrecking': 1,\n",
       "                               'several': 53,\n",
       "                               'fact': 110,\n",
       "                               'caused': 16,\n",
       "                               'us': 167,\n",
       "                               'give': 56,\n",
       "                               'serious': 20,\n",
       "                               'thought': 71,\n",
       "                               'moving': 7,\n",
       "                               'residence': 4,\n",
       "                               'south': 11,\n",
       "                               'easy': 13,\n",
       "                               'objective': 14,\n",
       "                               'sit': 9,\n",
       "                               'calmly': 1,\n",
       "                               'when': 252,\n",
       "                               'host': 10,\n",
       "                               'telling': 4,\n",
       "                               'roomful': 1,\n",
       "                               'people': 147,\n",
       "                               'way': 153,\n",
       "                               'deal': 25,\n",
       "                               'oppose': 3,\n",
       "                               'send': 15,\n",
       "                               'troops': 13,\n",
       "                               'shoot': 1,\n",
       "                               'bastards': 1,\n",
       "                               'down': 96,\n",
       "                               'Accounts': 1,\n",
       "                               'been': 375,\n",
       "                               'published': 21,\n",
       "                               'up': 179,\n",
       "                               'segregationist': 1,\n",
       "                               'prejudice': 5,\n",
       "                               'especially': 36,\n",
       "                               'state-supported': 1,\n",
       "                               'universities': 10,\n",
       "                               'where': 107,\n",
       "                               'pressure': 14,\n",
       "                               'uphold': 2,\n",
       "                               'majority': 13,\n",
       "                               'accounts': 11,\n",
       "                               'show': 30,\n",
       "                               'Northerners': 3,\n",
       "                               'subjected': 3,\n",
       "                               'embarrassment': 3,\n",
       "                               'provocation': 2,\n",
       "                               'Yankee-hatred': 1,\n",
       "                               'displayed': 7,\n",
       "                               'gatherings': 1,\n",
       "                               'From': 35,\n",
       "                               \"wife's\": 2,\n",
       "                               'sources': 16,\n",
       "                               'rarely': 6,\n",
       "                               'encountered': 10,\n",
       "                               'educated': 5,\n",
       "                               'feeling': 35,\n",
       "                               'certainly': 20,\n",
       "                               'there': 261,\n",
       "                               'leavening': 1,\n",
       "                               'among': 56,\n",
       "                               'college': 27,\n",
       "                               'graduates': 1,\n",
       "                               'throughout': 16,\n",
       "                               'studied': 12,\n",
       "                               'relations': 19,\n",
       "                               'arising': 2,\n",
       "                               'out': 239,\n",
       "                               'ties': 4,\n",
       "                               'impose': 4,\n",
       "                               'courtesy': 1,\n",
       "                               'resident': 3,\n",
       "                               'visiting': 8,\n",
       "                               'Also': 6,\n",
       "                               'latter': 25,\n",
       "                               'large': 38,\n",
       "                               'soon': 23,\n",
       "                               'acquire': 4,\n",
       "                               'prevalent': 2,\n",
       "                               'problems': 36,\n",
       "                               'There': 113,\n",
       "                               'course': 73,\n",
       "                               'Souths': 1,\n",
       "                               'discussion': 21,\n",
       "                               'important': 61,\n",
       "                               'division': 8,\n",
       "                               'reconstructed': 3,\n",
       "                               \"haven't\": 3,\n",
       "                               'My': 31,\n",
       "                               'definition': 9,\n",
       "                               'abused': 2,\n",
       "                               'adjective': 1,\n",
       "                               'rebel': 4,\n",
       "                               'glad': 4,\n",
       "                               'won': 10,\n",
       "                               'War': 54,\n",
       "                               'Nobody': 3,\n",
       "                               'knows': 17,\n",
       "                               'how': 96,\n",
       "                               'category': 1,\n",
       "                               'suspect': 6,\n",
       "                               'far': 70,\n",
       "                               'unreconstructed': 5,\n",
       "                               'likes': 3,\n",
       "                               'believe': 39,\n",
       "                               'heard': 16,\n",
       "                               'poll': 2,\n",
       "                               'taken': 48,\n",
       "                               'No': 41,\n",
       "                               'doubt': 17,\n",
       "                               'thing': 44,\n",
       "                               'considered': 23,\n",
       "                               'unpatriotic': 2,\n",
       "                               'Prior': 1,\n",
       "                               '1954': 10,\n",
       "                               'imagine': 11,\n",
       "                               'voted': 6,\n",
       "                               'Confederacy': 5,\n",
       "                               'Since': 20,\n",
       "                               \"Court's\": 1,\n",
       "                               'decision': 36,\n",
       "                               'year': 52,\n",
       "                               'doubtful': 5,\n",
       "                               'immediately': 18,\n",
       "                               'following': 29,\n",
       "                               'dispatch': 5,\n",
       "                               'Little': 15,\n",
       "                               'Rock': 8,\n",
       "                               'Old': 16,\n",
       "                               'Belief': 1,\n",
       "                               'traditional': 21,\n",
       "                               'life': 182,\n",
       "                               'persists': 2,\n",
       "                               'older': 15,\n",
       "                               'new': 163,\n",
       "                               'Probably': 3,\n",
       "                               'larger': 16,\n",
       "                               'Virginians': 1,\n",
       "                               'Carolinians': 1,\n",
       "                               'remain': 16,\n",
       "                               'elsewhere': 8,\n",
       "                               'Georgia': 5,\n",
       "                               'Carolina': 10,\n",
       "                               'Alabama': 2,\n",
       "                               'along': 51,\n",
       "                               'after': 123,\n",
       "                               'attitudes': 10,\n",
       "                               'tenaciously': 1,\n",
       "                               'Tidewater': 2,\n",
       "                               'Piedmont': 1,\n",
       "                               'line': 41,\n",
       "                               'running': 11,\n",
       "                               'length': 9,\n",
       "                               'marking': 3,\n",
       "                               'upper': 4,\n",
       "                               'limits': 7,\n",
       "                               'tidewater': 1,\n",
       "                               'roughly': 6,\n",
       "                               'divide': 1,\n",
       "                               'minority': 4,\n",
       "                               'enclaves': 1,\n",
       "                               'long-settled': 1,\n",
       "                               'areas': 17,\n",
       "                               'Virginia': 21,\n",
       "                               'developed': 22,\n",
       "                               'ante-bellum': 2,\n",
       "                               'culture': 25,\n",
       "                               'its': 293,\n",
       "                               'richest': 2,\n",
       "                               'flowering': 2,\n",
       "                               'memory': 25,\n",
       "                               'precious': 8,\n",
       "                               'consciousness': 10,\n",
       "                               'loss': 9,\n",
       "                               'greater': 24,\n",
       "                               'should': 102,\n",
       "                               'discount': 4,\n",
       "                               'region': 12,\n",
       "                               'coastal': 2,\n",
       "                               'lowlands': 1,\n",
       "                               'centering': 1,\n",
       "                               'Charleston': 1,\n",
       "                               'England': 55,\n",
       "                               'West': 20,\n",
       "                               'Indies': 2,\n",
       "                               'independence': 10,\n",
       "                               'psychological': 13,\n",
       "                               'consequences': 9,\n",
       "                               'affect': 5,\n",
       "                               'area': 21,\n",
       "                               'certain': 47,\n",
       "                               'respects': 7,\n",
       "                               'defeat': 8,\n",
       "                               'increased': 16,\n",
       "                               'persistent': 8,\n",
       "                               'Anglophilia': 1,\n",
       "                               'Poor': 1,\n",
       "                               'once': 73,\n",
       "                               'rich': 12,\n",
       "                               'humbled': 1,\n",
       "                               'arrogant': 1,\n",
       "                               'having': 59,\n",
       "                               'longer': 33,\n",
       "                               'hope': 27,\n",
       "                               'sharing': 3,\n",
       "                               'leadership': 17,\n",
       "                               'rebels': 3,\n",
       "                               'surrender': 3,\n",
       "                               'spirit': 26,\n",
       "                               'drew': 10,\n",
       "                               'comfort': 4,\n",
       "                               'felt': 54,\n",
       "                               'extended': 8,\n",
       "                               'mother': 38,\n",
       "                               'country': 59,\n",
       "                               'Carolinas': 1,\n",
       "                               'were': 524,\n",
       "                               'Tory': 13,\n",
       "                               'sentiment': 4,\n",
       "                               'eighteenth': 12,\n",
       "                               'century': 65,\n",
       "                               'bitterly': 2,\n",
       "                               'regretted': 5,\n",
       "                               'revolt': 4,\n",
       "                               'Crown': 1,\n",
       "                               'Among': 11,\n",
       "                               'racial': 5,\n",
       "                               'issue': 24,\n",
       "                               'remaining': 6,\n",
       "                               'factors': 18,\n",
       "                               'All': 36,\n",
       "                               'agree': 12,\n",
       "                               'slavery': 9,\n",
       "                               'go': 82,\n",
       "                               'historians': 11,\n",
       "                               'maintain': 12,\n",
       "                               'meddling': 1,\n",
       "                               'ended': 19,\n",
       "                               'did': 176,\n",
       "                               'resentment': 2,\n",
       "                               'method': 22,\n",
       "                               'ending': 5,\n",
       "                               'invasion': 4,\n",
       "                               'Reconstruction': 2,\n",
       "                               'fears': 18,\n",
       "                               'miscegenation': 1,\n",
       "                               'Negro': 24,\n",
       "                               'political': 85,\n",
       "                               'control': 35,\n",
       "                               'counties': 1,\n",
       "                               'apart': 7,\n",
       "                               'old': 89,\n",
       "                               'moderate': 2,\n",
       "                               'Mr.': 105,\n",
       "                               'finds': 19,\n",
       "                               'itself': 67,\n",
       "                               'civilization': 19,\n",
       "                               'effect': 36,\n",
       "                               'means': 47,\n",
       "                               'modern': 43,\n",
       "                               'America': 42,\n",
       "                               'hard': 27,\n",
       "                               'see': 94,\n",
       "                               'otherwise': 9,\n",
       "                               'therein': 3,\n",
       "                               'feel': 24,\n",
       "                               'delude': 2,\n",
       "                               'For': 101,\n",
       "                               'subject': 28,\n",
       "                               'often': 75,\n",
       "                               'discussed': 7,\n",
       "                               'analyzed': 3,\n",
       "                               'almost': 73,\n",
       "                               'conspiracy': 2,\n",
       "                               'silence': 10,\n",
       "                               'veiling': 1,\n",
       "                               'suppose': 18,\n",
       "                               'reason': 50,\n",
       "                               'kind': 67,\n",
       "                               'wishful': 3,\n",
       "                               'talk': 24,\n",
       "                               'final': 22,\n",
       "                               'stages': 2,\n",
       "                               'care': 12,\n",
       "                               'Or': 10,\n",
       "                               'else': 27,\n",
       "                               'really': 36,\n",
       "                               'believes': 7,\n",
       "                               'few': 89,\n",
       "                               'quaint': 2,\n",
       "                               'characters': 17,\n",
       "                               'around': 57,\n",
       "                               'realizing': 5,\n",
       "                               'errors': 11,\n",
       "                               'past': 44,\n",
       "                               'heart': 22,\n",
       "                               'sharers': 1,\n",
       "                               'Dream': 1,\n",
       "                               'circumstances': 14,\n",
       "                               'faced': 8,\n",
       "                               'frankly': 3,\n",
       "                               'reasonable': 8,\n",
       "                               'expect': 15,\n",
       "                               'true': 55,\n",
       "                               '1865': 2,\n",
       "                               'unique': 10,\n",
       "                               'western': 10,\n",
       "                               'Regardless': 1,\n",
       "                               'wrongs': 2,\n",
       "                               'population': 11,\n",
       "                               'appropriate': 13,\n",
       "                               'pre-World-War-': 1,\n",
       "                               '1': 18,\n",
       "                               'power': 59,\n",
       "                               'conquest': 5,\n",
       "                               'ruled': 2,\n",
       "                               'neighboring': 3,\n",
       "                               'imposed': 1,\n",
       "                               'upon': 107,\n",
       "                               'economic': 41,\n",
       "                               'Anglo-Saxon': 11,\n",
       "                               'Celtic': 7,\n",
       "                               'descent': 4,\n",
       "                               'history': 95,\n",
       "                               'Britannic': 1,\n",
       "                               'submitting': 4,\n",
       "                               'continued': 20,\n",
       "                               'struggle': 16,\n",
       "                               'foreign': 11,\n",
       "                               'domination': 1,\n",
       "                               'due': 8,\n",
       "                               'mainly': 3,\n",
       "                               'international': 17,\n",
       "                               'wars': 6,\n",
       "                               'hot': 5,\n",
       "                               'cold': 12,\n",
       "                               'every': 74,\n",
       "                               'war': 84,\n",
       "                               'United': 55,\n",
       "                               'States': 63,\n",
       "                               'Civil': 15,\n",
       "                               'belligerent': 2,\n",
       "                               'rest': 28,\n",
       "                               'So': 31,\n",
       "                               'instead': 20,\n",
       "                               'tests': 4,\n",
       "                               \"South's\": 3,\n",
       "                               'loyalty': 4,\n",
       "                               'Spanish': 7,\n",
       "                               'World': 31,\n",
       "                               'Wars': 1,\n",
       "                               'Korean': 1,\n",
       "                               'served': 20,\n",
       "                               'overcome': 3,\n",
       "                               'grievances': 1,\n",
       "                               'cement': 3,\n",
       "                               'reunion': 1,\n",
       "                               'section': 11,\n",
       "                               'ardent': 3,\n",
       "                               'Communism': 2,\n",
       "                               'Had': 5,\n",
       "                               'reversed': 4,\n",
       "                               'instance': 22,\n",
       "                               'enemy': 25,\n",
       "                               '1898': 2,\n",
       "                               'numbers': 11,\n",
       "                               'happily': 2,\n",
       "                               'put': 58,\n",
       "                               'Confederate': 8,\n",
       "                               'uniforms': 1,\n",
       "                               'fight': 13,\n",
       "                               'allies': 8,\n",
       "                               'Britain': 25,\n",
       "                               'extraordinary': 8,\n",
       "                               'proud': 8,\n",
       "                               'warlike': 1,\n",
       "                               'docile': 1,\n",
       "                               'thank': 3,\n",
       "                               'stars': 9,\n",
       "                               'time': 225,\n",
       "                               'draw': 7,\n",
       "                               'false': 8,\n",
       "                               'inferences': 1,\n",
       "                               'therefrom': 1,\n",
       "                               'main': 16,\n",
       "                               'charges': 11,\n",
       "                               'levelled': 2,\n",
       "                               'racists': 1,\n",
       "                               'reactionaries': 1,\n",
       "                               'truth': 51,\n",
       "                               'deny': 14,\n",
       "                               'Whatever': 6,\n",
       "                               'faults': 2,\n",
       "                               'hypocrites': 1,\n",
       "                               'pure': 19,\n",
       "                               'Many': 17,\n",
       "                               'Northeners': 1,\n",
       "                               'philosophy': 22,\n",
       "                               'moreover': 8,\n",
       "                               'very': 123,\n",
       "                               'further': 32,\n",
       "                               'let': 53,\n",
       "                               'alone': 19,\n",
       "                               'produced': 16,\n",
       "                               'superior': 7,\n",
       "                               'reaping': 1,\n",
       "                               'fruits': 3,\n",
       "                               'excess': 1,\n",
       "                               'egalitarianism': 1,\n",
       "                               'spite': 11,\n",
       "                               'standard': 12,\n",
       "                               'proved': 17,\n",
       "                               'inferior': 2,\n",
       "                               'English': 69,\n",
       "                               'Scandinavian': 1,\n",
       "                               'ways': 16,\n",
       "                               'although': 47,\n",
       "                               'disapprove': 1,\n",
       "                               'socialistic': 3,\n",
       "                               'features': 9,\n",
       "                               'antipathy': 1,\n",
       "                               'includes': 7,\n",
       "                               'poor': 13,\n",
       "                               'manners': 3,\n",
       "                               'harsh': 2,\n",
       "                               'accents': 1,\n",
       "                               'appreciation': 2,\n",
       "                               'arts': 17,\n",
       "                               'gastronomy': 1,\n",
       "                               'leisure': 4,\n",
       "                               'Their': 30,\n",
       "                               'own': 163,\n",
       "                               'easier': 4,\n",
       "                               'slower': 3,\n",
       "                               'tempo': 2,\n",
       "                               'dear': 11,\n",
       "                               'content': 16,\n",
       "                               'earn': 4,\n",
       "                               'half': 22,\n",
       "                               'third': 21,\n",
       "                               'prefer': 6,\n",
       "                               'quieter': 2,\n",
       "                               'habits': 7,\n",
       "                               'home': 54,\n",
       "                               'duties': 7,\n",
       "                               'Sir': 32,\n",
       "                               'Henry': 13,\n",
       "                               'Maine': 2,\n",
       "                               'noted': 8,\n",
       "                               'long': 107,\n",
       "                               'ago': 36,\n",
       "                               'number': 36,\n",
       "                               'internal': 11,\n",
       "                               'order': 93,\n",
       "                               'external': 14,\n",
       "                               'security': 17,\n",
       "                               'By': 38,\n",
       "                               'prevailing': 5,\n",
       "                               'claimants': 2,\n",
       "                               'loyalties': 1,\n",
       "                               'nation-state': 6,\n",
       "                               'maintained': 10,\n",
       "                               'adequate': 7,\n",
       "                               'measure': 24,\n",
       "                               'certainty': 3,\n",
       "                               'within': 63,\n",
       "                               'territorial': 9,\n",
       "                               'borders': 5,\n",
       "                               'Outside': 3,\n",
       "                               'asserted': 4,\n",
       "                               'position': 39,\n",
       "                               'sovereign': 18,\n",
       "                               'equality': 4,\n",
       "                               'peoples': 13,\n",
       "                               'non-Western': 1,\n",
       "                               'dominance': 2,\n",
       "                               'became': 54,\n",
       "                               'sole': 3,\n",
       "                               'law': 58,\n",
       "                               'term': 16,\n",
       "                               'pertinent': 5,\n",
       "                               'remember': 16,\n",
       "                               'coined': 2,\n",
       "                               'Bentham': 2,\n",
       "                               'body': 35,\n",
       "                               'legal': 20,\n",
       "                               'principle': 29,\n",
       "                               'made': 147,\n",
       "                               'Western': 24,\n",
       "                               'nations': 48,\n",
       "                               'arena': 7,\n",
       "                               'That': 63,\n",
       "                               'corpus': 1,\n",
       "                               'reflection': 12,\n",
       "                               'system': 35,\n",
       "                               'existence': 43,\n",
       "                               'during': 74,\n",
       "                               'nineteenth': 19,\n",
       "                               'centuries': 17,\n",
       "                               'Speaking': 6,\n",
       "                               'generally': 15,\n",
       "                               'furthered': 2,\n",
       "                               'still': 111,\n",
       "                               'tends': 13,\n",
       "                               'interests': 15,\n",
       "                               'powers': 20,\n",
       "                               'enormous': 8,\n",
       "                               'changes': 18,\n",
       "                               'politics': 16,\n",
       "                               'thrown': 12,\n",
       "                               'confusion': 12,\n",
       "                               'safe': 9,\n",
       "                               'reexamination': 1,\n",
       "                               'clarification': 2,\n",
       "                               'light': 35,\n",
       "                               'conditions': 14,\n",
       "                               'present': 73,\n",
       "                               'era': 3,\n",
       "                               'Beyond': 3,\n",
       "                               'basic': 30,\n",
       "                               'tasks': 7,\n",
       "                               'mentioned': 15,\n",
       "                               'above': 30,\n",
       "                               'attention': 36,\n",
       "                               'paid': 19,\n",
       "                               'statesman': 4,\n",
       "                               'scholar': 3,\n",
       "                               'idea': 49,\n",
       "                               'responsibility': 33,\n",
       "                               'either': 37,\n",
       "                               'internally': 6,\n",
       "                               'externally': 2,\n",
       "                               'particularly': 25,\n",
       "                               'anarchical': 2,\n",
       "                               'battleground': 1,\n",
       "                               'characterized': 6,\n",
       "                               'strife': 1,\n",
       "                               'avaricious': 1,\n",
       "                               'competition': 5,\n",
       "                               'colonial': 5,\n",
       "                               'empires': 2,\n",
       "                               'duty': 13,\n",
       "                               'owed': 7,\n",
       "                               'astonished': 2,\n",
       "                               'nineteenth-century': 5,\n",
       "                               'extension': 3,\n",
       "                               'beyond': 29,\n",
       "                               'boundaries': 1,\n",
       "                               'contemplated': 1,\n",
       "                               'Thus': 34,\n",
       "                               'cite': 3,\n",
       "                               'example': 53,\n",
       "                               'Pax': 1,\n",
       "                               'Britannica': 1,\n",
       "                               'whether': 41,\n",
       "                               'British': 21,\n",
       "                               'navy': 1,\n",
       "                               'ruling': 8,\n",
       "                               'seas': 1,\n",
       "                               'City': 10,\n",
       "                               'London': 32,\n",
       "                               'finance': 3,\n",
       "                               'strictly': 6,\n",
       "                               'motivation': 2,\n",
       "                               'e.g.': 10,\n",
       "                               'incidentally': 1,\n",
       "                               'benefited': 2,\n",
       "                               'At': 73,\n",
       "                               'suggestions': 3,\n",
       "                               'some': 232,\n",
       "                               'societal': 3,\n",
       "                               'existed': 10,\n",
       "                               'strongly': 3,\n",
       "                               'resisted': 3,\n",
       "                               'Social': 5,\n",
       "                               'Darwinism': 2,\n",
       "                               'able': 31,\n",
       "                               'stave': 1,\n",
       "                               'off': 53,\n",
       "                               'incipient': 2,\n",
       "                               'socialist': 4,\n",
       "                               'movement': 34,\n",
       "                               'until': 52,\n",
       "                               'However': 16,\n",
       "                               'recent': 33,\n",
       "                               'decades': 12,\n",
       "                               'doubtless': 1,\n",
       "                               'multiple': 4,\n",
       "                               'reasons': 16,\n",
       "                               'unannounced': 1,\n",
       "                               'nonetheless': 1,\n",
       "                               'readily': 6,\n",
       "                               'observable': 2,\n",
       "                               'shift': 8,\n",
       "                               'occurred': 8,\n",
       "                               'facets': 5,\n",
       "                               'activity': 13,\n",
       "                               'concept': 31,\n",
       "                               'process': 28,\n",
       "                               'articulation': 1,\n",
       "                               'establishment': 5,\n",
       "                               'Already': 4,\n",
       "                               'firmly': 12,\n",
       "                               'implanted': 1,\n",
       "                               'growing': 7,\n",
       "                               'factor': 5,\n",
       "                               'matters': 17,\n",
       "                               'twenty': 19,\n",
       "                               'turned': 28,\n",
       "                               'corner': 10,\n",
       "                               'aptly': 1,\n",
       "                               'constitutional': 7,\n",
       "                               'revolution': 19,\n",
       "                               'transformed': 4,\n",
       "                               'essentially': 8,\n",
       "                               'negative': 17,\n",
       "                               'night-watchman': 1,\n",
       "                               'affirmative': 3,\n",
       "                               'perform': 7,\n",
       "                               'positive': 15,\n",
       "                               'came': 96,\n",
       "                               'lawyers': 3,\n",
       "                               'reflecting': 2,\n",
       "                               'perhaps': 54,\n",
       "                               'parochial': 2,\n",
       "                               ...}),\n",
       "                     'editorial': FreqDist({'Assembly': 17,\n",
       "                               'session': 10,\n",
       "                               'brought': 8,\n",
       "                               'much': 54,\n",
       "                               'good': 58,\n",
       "                               'The': 453,\n",
       "                               'General': 24,\n",
       "                               ',': 2766,\n",
       "                               'which': 191,\n",
       "                               'adjourns': 1,\n",
       "                               'today': 15,\n",
       "                               'has': 261,\n",
       "                               'performed': 1,\n",
       "                               'in': 1001,\n",
       "                               'an': 184,\n",
       "                               'atmosphere': 12,\n",
       "                               'of': 1976,\n",
       "                               'crisis': 20,\n",
       "                               'and': 1302,\n",
       "                               'struggle': 10,\n",
       "                               'from': 214,\n",
       "                               'the': 3508,\n",
       "                               'day': 32,\n",
       "                               'it': 386,\n",
       "                               'convened': 1,\n",
       "                               '.': 2481,\n",
       "                               'It': 113,\n",
       "                               'was': 308,\n",
       "                               'faced': 3,\n",
       "                               'immediately': 7,\n",
       "                               'with': 316,\n",
       "                               'a': 1095,\n",
       "                               'showdown': 2,\n",
       "                               'on': 336,\n",
       "                               'schools': 24,\n",
       "                               'issue': 18,\n",
       "                               'met': 8,\n",
       "                               'squarely': 2,\n",
       "                               'conjunction': 1,\n",
       "                               'governor': 2,\n",
       "                               'decision': 4,\n",
       "                               'not': 301,\n",
       "                               'to': 1554,\n",
       "                               'risk': 9,\n",
       "                               'abandoning': 2,\n",
       "                               'public': 58,\n",
       "                               'education': 6,\n",
       "                               'There': 38,\n",
       "                               'followed': 4,\n",
       "                               'historic': 1,\n",
       "                               'appropriations': 4,\n",
       "                               'budget': 24,\n",
       "                               'fight': 10,\n",
       "                               'decided': 9,\n",
       "                               'tackle': 1,\n",
       "                               'executive': 5,\n",
       "                               'powers': 10,\n",
       "                               'final': 3,\n",
       "                               'went': 9,\n",
       "                               'but': 175,\n",
       "                               'way': 43,\n",
       "                               'been': 151,\n",
       "                               'opened': 9,\n",
       "                               'for': 509,\n",
       "                               'strengthening': 1,\n",
       "                               'budgeting': 1,\n",
       "                               'procedures': 3,\n",
       "                               'provide': 14,\n",
       "                               'legislators': 1,\n",
       "                               'information': 7,\n",
       "                               'they': 148,\n",
       "                               'need': 29,\n",
       "                               'Long-range': 1,\n",
       "                               'planning': 13,\n",
       "                               'programs': 11,\n",
       "                               'ways': 7,\n",
       "                               'finance': 2,\n",
       "                               'them': 67,\n",
       "                               'have': 275,\n",
       "                               'become': 26,\n",
       "                               'musts': 1,\n",
       "                               'if': 69,\n",
       "                               'state': 48,\n",
       "                               'next': 25,\n",
       "                               'few': 40,\n",
       "                               'years': 63,\n",
       "                               'is': 744,\n",
       "                               'avoid': 8,\n",
       "                               'crisis-to-crisis': 1,\n",
       "                               'government': 49,\n",
       "                               'This': 67,\n",
       "                               'instance': 8,\n",
       "                               'may': 74,\n",
       "                               'insured': 1,\n",
       "                               'financial': 7,\n",
       "                               'two': 59,\n",
       "                               'now': 76,\n",
       "                               'In': 90,\n",
       "                               'all': 144,\n",
       "                               'turmoil': 2,\n",
       "                               'some': 88,\n",
       "                               'legislation': 4,\n",
       "                               'passed': 9,\n",
       "                               'Some': 17,\n",
       "                               'other': 91,\n",
       "                               'bills': 3,\n",
       "                               'were': 109,\n",
       "                               'lost': 15,\n",
       "                               'shuffle': 2,\n",
       "                               'await': 1,\n",
       "                               'future': 24,\n",
       "                               'action': 25,\n",
       "                               'Certainly': 4,\n",
       "                               'can': 121,\n",
       "                               'applaud': 1,\n",
       "                               'passage': 2,\n",
       "                               'auto': 2,\n",
       "                               'title': 4,\n",
       "                               'law': 23,\n",
       "                               'school': 32,\n",
       "                               'increase': 22,\n",
       "                               'teacher': 3,\n",
       "                               'pensions': 2,\n",
       "                               'ban': 2,\n",
       "                               'drag': 2,\n",
       "                               'racing': 1,\n",
       "                               'acceptance': 2,\n",
       "                               'by': 299,\n",
       "                               'responsibility': 15,\n",
       "                               'maintenance': 5,\n",
       "                               'roads': 2,\n",
       "                               'municipalities': 2,\n",
       "                               'at': 201,\n",
       "                               'same': 27,\n",
       "                               'rate': 11,\n",
       "                               'as': 356,\n",
       "                               'outside': 10,\n",
       "                               'city': 40,\n",
       "                               'limits': 2,\n",
       "                               'repeal': 6,\n",
       "                               'college': 16,\n",
       "                               'age': 12,\n",
       "                               'limit': 3,\n",
       "                               'road': 10,\n",
       "                               'bond': 2,\n",
       "                               'No': 20,\n",
       "                               'taken': 13,\n",
       "                               'however': 16,\n",
       "                               'such': 60,\n",
       "                               'major': 10,\n",
       "                               'problems': 23,\n",
       "                               'ending': 5,\n",
       "                               'fee': 1,\n",
       "                               'system': 17,\n",
       "                               'penal': 1,\n",
       "                               'reform': 4,\n",
       "                               'modification': 1,\n",
       "                               'county': 20,\n",
       "                               'unit': 4,\n",
       "                               'outright': 2,\n",
       "                               'banning': 1,\n",
       "                               'fireworks': 1,\n",
       "                               'sales': 4,\n",
       "                               'Only': 4,\n",
       "                               'token': 3,\n",
       "                               'start': 16,\n",
       "                               'made': 45,\n",
       "                               'attacking': 3,\n",
       "                               'tax': 22,\n",
       "                               'reappraisal': 1,\n",
       "                               'question': 29,\n",
       "                               'its': 129,\n",
       "                               'companion': 1,\n",
       "                               'attracting': 1,\n",
       "                               'industry': 14,\n",
       "                               'legislature': 1,\n",
       "                               'expended': 1,\n",
       "                               'most': 70,\n",
       "                               'time': 72,\n",
       "                               'questions': 9,\n",
       "                               'Fortunately': 3,\n",
       "                               'spared': 2,\n",
       "                               'us': 64,\n",
       "                               'usual': 4,\n",
       "                               'spate': 1,\n",
       "                               'silly': 2,\n",
       "                               'resolutions': 2,\n",
       "                               'past': 16,\n",
       "                               'Georgia': 12,\n",
       "                               'look': 15,\n",
       "                               'like': 49,\n",
       "                               'anything': 8,\n",
       "                               '``': 396,\n",
       "                               'empire': 3,\n",
       "                               'South': 16,\n",
       "                               \"''\": 382,\n",
       "                               'We': 60,\n",
       "                               'congratulate': 3,\n",
       "                               'entire': 13,\n",
       "                               'membership': 6,\n",
       "                               'record': 15,\n",
       "                               'interim': 2,\n",
       "                               'between': 36,\n",
       "                               'year': 52,\n",
       "                               'we': 167,\n",
       "                               'trust': 5,\n",
       "                               'House': 20,\n",
       "                               'Senate': 8,\n",
       "                               'will': 233,\n",
       "                               'put': 27,\n",
       "                               'their': 124,\n",
       "                               'minds': 6,\n",
       "                               'studying': 2,\n",
       "                               \"Georgia's\": 2,\n",
       "                               'very': 48,\n",
       "                               'real': 15,\n",
       "                               'economic': 26,\n",
       "                               'fiscal': 10,\n",
       "                               'social': 10,\n",
       "                               'come': 35,\n",
       "                               'up': 75,\n",
       "                               'answers': 2,\n",
       "                               'without': 29,\n",
       "                               'political': 36,\n",
       "                               'heroics': 1,\n",
       "                               'League': 5,\n",
       "                               'regularly': 2,\n",
       "                               'stands': 9,\n",
       "                               'side': 16,\n",
       "                               'right': 40,\n",
       "                               'Women': 1,\n",
       "                               'Voters': 1,\n",
       "                               '40': 5,\n",
       "                               'admitting': 2,\n",
       "                               'proudly': 1,\n",
       "                               'inviting': 1,\n",
       "                               'contributions': 4,\n",
       "                               'windup': 1,\n",
       "                               'fund': 3,\n",
       "                               'drive': 6,\n",
       "                               \"It's\": 6,\n",
       "                               'use': 30,\n",
       "                               'money': 15,\n",
       "                               'These': 19,\n",
       "                               'women': 5,\n",
       "                               'whose': 11,\n",
       "                               'organization': 15,\n",
       "                               'grew': 3,\n",
       "                               'out': 85,\n",
       "                               'old': 40,\n",
       "                               'suffrage': 1,\n",
       "                               'movement': 5,\n",
       "                               'are': 294,\n",
       "                               'dedicated': 5,\n",
       "                               'Thomas': 4,\n",
       "                               \"Jefferson's\": 1,\n",
       "                               'dictum': 1,\n",
       "                               'that': 578,\n",
       "                               'one': 150,\n",
       "                               'must': 53,\n",
       "                               'cherish': 1,\n",
       "                               \"people's\": 4,\n",
       "                               'spirit': 8,\n",
       "                               'Keep': 1,\n",
       "                               'alive': 2,\n",
       "                               'attention': 14,\n",
       "                               'If': 65,\n",
       "                               'once': 22,\n",
       "                               'inattentive': 1,\n",
       "                               'affairs': 5,\n",
       "                               'Jefferson': 2,\n",
       "                               'said': 52,\n",
       "                               'you': 83,\n",
       "                               'I': 201,\n",
       "                               'Congress': 33,\n",
       "                               'assemblies': 1,\n",
       "                               'judges': 3,\n",
       "                               'governors': 1,\n",
       "                               'shall': 19,\n",
       "                               'wolves': 1,\n",
       "                               'Newspapermen': 1,\n",
       "                               'politicians': 3,\n",
       "                               'especially': 11,\n",
       "                               'aware': 3,\n",
       "                               'penetrating': 1,\n",
       "                               'expert': 2,\n",
       "                               'analysis': 4,\n",
       "                               'league': 4,\n",
       "                               'gives': 10,\n",
       "                               'workers': 6,\n",
       "                               'search': 1,\n",
       "                               'pros': 1,\n",
       "                               'cons': 1,\n",
       "                               'complex': 6,\n",
       "                               'issues': 7,\n",
       "                               'make': 53,\n",
       "                               'available': 14,\n",
       "                               'harder': 3,\n",
       "                               'choice': 21,\n",
       "                               'more': 138,\n",
       "                               'willing': 14,\n",
       "                               'wade': 1,\n",
       "                               'And': 55,\n",
       "                               'takes': 5,\n",
       "                               'stand': 14,\n",
       "                               'great': 38,\n",
       "                               'regularity': 1,\n",
       "                               'Look': 1,\n",
       "                               'Coosa': 2,\n",
       "                               'Valley': 2,\n",
       "                               'industrial': 18,\n",
       "                               'progress': 9,\n",
       "                               'Cities': 1,\n",
       "                               'counties': 3,\n",
       "                               'interested': 11,\n",
       "                               'development': 15,\n",
       "                               'would': 180,\n",
       "                               'do': 105,\n",
       "                               'well': 32,\n",
       "                               'months': 16,\n",
       "                               'ahead': 6,\n",
       "                               'keep': 15,\n",
       "                               'eyes': 8,\n",
       "                               'peeled': 1,\n",
       "                               'toward': 32,\n",
       "                               '13': 2,\n",
       "                               'northwest': 3,\n",
       "                               'members': 25,\n",
       "                               'Area': 1,\n",
       "                               'Planning': 2,\n",
       "                               'Development': 6,\n",
       "                               'Commission': 15,\n",
       "                               'Coupling': 1,\n",
       "                               'own': 48,\n",
       "                               '$83,750': 1,\n",
       "                               '$30,000': 1,\n",
       "                               'grant': 4,\n",
       "                               'authorized': 3,\n",
       "                               'Gov.': 9,\n",
       "                               'Vandiver': 2,\n",
       "                               'group': 19,\n",
       "                               'expects': 2,\n",
       "                               'sign': 6,\n",
       "                               'contract': 3,\n",
       "                               'March': 11,\n",
       "                               'Tech.': 1,\n",
       "                               'Then': 18,\n",
       "                               'full-time': 1,\n",
       "                               'office': 8,\n",
       "                               'be': 421,\n",
       "                               'established': 4,\n",
       "                               'Rome': 1,\n",
       "                               'work': 30,\n",
       "                               'five-member': 1,\n",
       "                               'Tech': 1,\n",
       "                               'research': 6,\n",
       "                               'staff': 7,\n",
       "                               'area': 19,\n",
       "                               'program': 37,\n",
       "                               'undertaking': 2,\n",
       "                               'abundant': 2,\n",
       "                               'promise': 3,\n",
       "                               'recognizes': 1,\n",
       "                               'fact': 36,\n",
       "                               'what': 84,\n",
       "                               'helps': 6,\n",
       "                               'neighbors': 4,\n",
       "                               'banding': 1,\n",
       "                               'together': 7,\n",
       "                               'area-wide': 2,\n",
       "                               'effort': 9,\n",
       "                               'better': 30,\n",
       "                               'results': 5,\n",
       "                               'accomplished': 5,\n",
       "                               'than': 109,\n",
       "                               'through': 23,\n",
       "                               'go-it-alone': 1,\n",
       "                               'approach': 6,\n",
       "                               'Rusk': 7,\n",
       "                               'idea': 12,\n",
       "                               'strengthens': 1,\n",
       "                               'United': 76,\n",
       "                               'States': 58,\n",
       "                               'defense': 7,\n",
       "                               'belief': 3,\n",
       "                               'balanced': 1,\n",
       "                               'replacing': 2,\n",
       "                               'Dulles': 1,\n",
       "                               'theory': 3,\n",
       "                               'massive': 3,\n",
       "                               'retaliation': 3,\n",
       "                               'removes': 2,\n",
       "                               'grave': 4,\n",
       "                               'danger': 9,\n",
       "                               'existed': 3,\n",
       "                               'lay': 4,\n",
       "                               'believing': 1,\n",
       "                               'our': 120,\n",
       "                               'A-bombs': 1,\n",
       "                               'deter': 1,\n",
       "                               \"Russia's\": 3,\n",
       "                               'hers': 1,\n",
       "                               ';': 196,\n",
       "                               'sound': 14,\n",
       "                               'American': 77,\n",
       "                               'delusion': 1,\n",
       "                               'nuclear': 40,\n",
       "                               'deterrence': 1,\n",
       "                               'enough': 28,\n",
       "                               'By': 9,\n",
       "                               'limiting': 1,\n",
       "                               'strength': 15,\n",
       "                               'too': 62,\n",
       "                               'this': 259,\n",
       "                               'country': 32,\n",
       "                               'limited': 5,\n",
       "                               'ability': 3,\n",
       "                               'any': 81,\n",
       "                               'kind': 10,\n",
       "                               'war': 54,\n",
       "                               'besides': 2,\n",
       "                               'strategy': 3,\n",
       "                               'heightened': 1,\n",
       "                               'possibility': 9,\n",
       "                               'also': 43,\n",
       "                               'weakened': 1,\n",
       "                               'diplomatic': 6,\n",
       "                               'stance': 2,\n",
       "                               'because': 44,\n",
       "                               'Russia': 21,\n",
       "                               'could': 56,\n",
       "                               'easily': 8,\n",
       "                               'guess': 3,\n",
       "                               'did': 35,\n",
       "                               'desire': 9,\n",
       "                               'except': 6,\n",
       "                               'ultimate': 3,\n",
       "                               'extremity': 1,\n",
       "                               'left': 27,\n",
       "                               'Soviets': 6,\n",
       "                               'plenty': 3,\n",
       "                               'leeway': 1,\n",
       "                               'low-grade': 1,\n",
       "                               'brushfire': 1,\n",
       "                               'aggressions': 3,\n",
       "                               'considerable': 5,\n",
       "                               'impunity': 1,\n",
       "                               'maintaining': 4,\n",
       "                               'deterrent': 3,\n",
       "                               'gearing': 1,\n",
       "                               'military': 22,\n",
       "                               'forces': 9,\n",
       "                               'conventional': 7,\n",
       "                               'wars': 4,\n",
       "                               'Secretary': 24,\n",
       "                               'State': 21,\n",
       "                               'junks': 1,\n",
       "                               'bluff': 1,\n",
       "                               'brinkmanship': 1,\n",
       "                               'builds': 2,\n",
       "                               'muscle': 3,\n",
       "                               'greater': 7,\n",
       "                               'safety': 3,\n",
       "                               'into': 78,\n",
       "                               'position': 15,\n",
       "                               'DeKalb': 6,\n",
       "                               'shows': 7,\n",
       "                               'beam': 1,\n",
       "                               \"DeKalb's\": 1,\n",
       "                               '1961': 8,\n",
       "                               'carries': 2,\n",
       "                               'no': 98,\n",
       "                               'balance': 9,\n",
       "                               'includes': 2,\n",
       "                               'raise': 3,\n",
       "                               'minimum': 3,\n",
       "                               'wage': 2,\n",
       "                               'creation': 2,\n",
       "                               'several': 17,\n",
       "                               'new': 80,\n",
       "                               'jobs': 10,\n",
       "                               'level': 4,\n",
       "                               'financing': 2,\n",
       "                               'beefed-up': 1,\n",
       "                               'efforts': 15,\n",
       "                               'increased': 9,\n",
       "                               'expenditures': 2,\n",
       "                               'essential': 4,\n",
       "                               'services': 11,\n",
       "                               'health': 9,\n",
       "                               'welfare': 9,\n",
       "                               'fire': 5,\n",
       "                               'protection': 9,\n",
       "                               'sanitation': 3,\n",
       "                               'That': 18,\n",
       "                               'expansion': 1,\n",
       "                               'obtained': 4,\n",
       "                               'taxes': 3,\n",
       "                               'due': 12,\n",
       "                               'growth': 11,\n",
       "                               'digest': 1,\n",
       "                               'part': 33,\n",
       "                               'board': 18,\n",
       "                               'commissioners': 6,\n",
       "                               'headed': 6,\n",
       "                               'Chairman': 6,\n",
       "                               'Charles': 4,\n",
       "                               'O.': 3,\n",
       "                               'Emmerich': 2,\n",
       "                               'who': 172,\n",
       "                               'demonstrating': 1,\n",
       "                               'he': 268,\n",
       "                               'given': 12,\n",
       "                               'placed': 7,\n",
       "                               'officials': 8,\n",
       "                               'Somewhere': 1,\n",
       "                               'somebody': 5,\n",
       "                               'bound': 2,\n",
       "                               'love': 13,\n",
       "                               'G.': 2,\n",
       "                               'Mennen': 1,\n",
       "                               'Williams': 2,\n",
       "                               'learning': 2,\n",
       "                               'difficulties': 5,\n",
       "                               'diplomacy': 1,\n",
       "                               'rapidly': 2,\n",
       "                               'Touring': 1,\n",
       "                               'Africa': 9,\n",
       "                               'U.S.': 22,\n",
       "                               'Assistant': 2,\n",
       "                               'observed': 4,\n",
       "                               'should': 88,\n",
       "                               'Africans': 2,\n",
       "                               'British': 18,\n",
       "                               'promptly': 2,\n",
       "                               'denounced': 2,\n",
       "                               'him': 106,\n",
       "                               'arrived': 4,\n",
       "                               'Zanzibar': 1,\n",
       "                               'found': 18,\n",
       "                               'carrying': 7,\n",
       "                               'signs': 6,\n",
       "                               'saying': 5,\n",
       "                               'imperialists': 1,\n",
       "                               'go': 28,\n",
       "                               'home': 14,\n",
       "                               'Chin': 1,\n",
       "                               'Soapy': 1,\n",
       "                               'Power': 2,\n",
       "                               'company': 6,\n",
       "                               'backs': 3,\n",
       "                               'confidence': 4,\n",
       "                               'dollars': 13,\n",
       "                               'Confidence': 1,\n",
       "                               \"state's\": 3,\n",
       "                               'reflected': 1,\n",
       "                               \"Company's\": 2,\n",
       "                               'construction': 6,\n",
       "                               'firm': 7,\n",
       "                               'does': 29,\n",
       "                               'large': 19,\n",
       "                               'amount': 11,\n",
       "                               'forecasts': 1,\n",
       "                               'meaning': 14,\n",
       "                               'know': 43,\n",
       "                               'continue': 7,\n",
       "                               'sufficient': 6,\n",
       "                               'electrical': 1,\n",
       "                               'power': 28,\n",
       "                               'only': 76,\n",
       "                               'meet': 8,\n",
       "                               'demands': 6,\n",
       "                               'normal': 8,\n",
       "                               'encourage': 3,\n",
       "                               'rapid': 2,\n",
       "                               'industrialization': 1,\n",
       "                               'mental': 4,\n",
       "                               'received': 11,\n",
       "                               'badly': 1,\n",
       "                               'needed': 13,\n",
       "                               'boost': 3,\n",
       "                               'form': 9,\n",
       "                               '$1,750,000': 1,\n",
       "                               'Milledgeville': 1,\n",
       "                               'Hospital': 2,\n",
       "                               'Actually': 4,\n",
       "                               'amounts': 2,\n",
       "                               '$1,250,000': 1,\n",
       "                               'above': 8,\n",
       "                               'institution': 2,\n",
       "                               'already': 17,\n",
       "                               'receiving': 4,\n",
       "                               'considering': 5,\n",
       "                               'additional': 9,\n",
       "                               'half-million': 1,\n",
       "                               'allocated': 1,\n",
       "                               'last': 59,\n",
       "                               'surplus': 4,\n",
       "                               'Either': 2,\n",
       "                               'sounds': 3,\n",
       "                               'sizable': 2,\n",
       "                               'hunk': 1,\n",
       "                               'But': 118,\n",
       "                               'exactly': 5,\n",
       "                               'how': 43,\n",
       "                               'far': 36,\n",
       "                               'improving': 2,\n",
       "                               'conditions': 11,\n",
       "                               'another': 31,\n",
       "                               'there': 82,\n",
       "                               'so': 96,\n",
       "                               'needs': 12,\n",
       "                               'doing': 18,\n",
       "                               'practice': 7,\n",
       "                               'charging': 1,\n",
       "                               'employes': 5,\n",
       "                               'meals': 1,\n",
       "                               'whether': 24,\n",
       "                               'eat': 4,\n",
       "                               'hospital': 12,\n",
       "                               'or': 194,\n",
       "                               'abolished': 1,\n",
       "                               'week': 29,\n",
       "                               'attendants': 2,\n",
       "                               'duty': 4,\n",
       "                               '65': 1,\n",
       "                               'hours': 8,\n",
       "                               'per': 29,\n",
       "                               'reduced': 6,\n",
       "                               'More': 6,\n",
       "                               'nurses': 3,\n",
       "                               'doctors': 2,\n",
       "                               'hired': 1,\n",
       "                               'Patients': 1,\n",
       "                               'deserve': 4,\n",
       "                               'getting': 9,\n",
       "                               'Even': 12,\n",
       "                               'funds': 5,\n",
       "                               'spending': 4,\n",
       "                               'around': 20,\n",
       "                               '$3.15': 1,\n",
       "                               'patient': 9,\n",
       "                               'national': 25,\n",
       "                               'average': 8,\n",
       "                               '$4': 1,\n",
       "                               'figure': 6,\n",
       "                               'considered': 8,\n",
       "                               'experts': 2,\n",
       "                               'field': 13,\n",
       "                               'low': 8,\n",
       "                               'Kansas': 2,\n",
       "                               'regarded': 2,\n",
       "                               'tops': 1,\n",
       "                               'nation': 10,\n",
       "                               'treatment': 4,\n",
       "                               'mentally': 4,\n",
       "                               'ill': 2,\n",
       "                               'spends': 1,\n",
       "                               '$9': 1,\n",
       "                               'reforms': 2,\n",
       "                               'true': 7,\n",
       "                               'intensive': 1,\n",
       "                               'working': 12,\n",
       "                               'many': 63,\n",
       "                               'areas': 18,\n",
       "                               'still': 41,\n",
       "                               'dragging': 2,\n",
       "                               'Considering': 1,\n",
       "                               'being': 45,\n",
       "                               'done': 24,\n",
       "                               'compared': 2,\n",
       "                               'behooves': 1,\n",
       "                               'management': 3,\n",
       "                               'mighty': 1,\n",
       "                               'careful': 4,\n",
       "                               'making': 14,\n",
       "                               'best': 21,\n",
       "                               'possible': 18,\n",
       "                               'granted': 5,\n",
       "                               'helpful': 6,\n",
       "                               'inadequate': 3,\n",
       "                               'end': 25,\n",
       "                               'Trujillo': 12,\n",
       "                               'Assassination': 1,\n",
       "                               'even': 55,\n",
       "                               'tyrant': 1,\n",
       "                               'repulsive': 1,\n",
       "                               'men': 38,\n",
       "                               'conscience': 4,\n",
       "                               'Rafael': 1,\n",
       "                               'often': 17,\n",
       "                               'blood-thirsty': 1,\n",
       "                               'dictator': 1,\n",
       "                               'Dominican': 13,\n",
       "                               'Republic': 7,\n",
       "                               '31': 5,\n",
       "                               'perhaps': 14,\n",
       "                               'deserved': 1,\n",
       "                               'his': 244,\n",
       "                               'fate': 2,\n",
       "                               'even-handed': 1,\n",
       "                               'appraisal': 3,\n",
       "                               'history': 19,\n",
       "                               'murder': 2,\n",
       "                               'El': 3,\n",
       "                               'Benefactor': 1,\n",
       "                               'Ciudad': 3,\n",
       "                               'means': 17,\n",
       "                               'freedom': 15,\n",
       "                               'people': 75,\n",
       "                               'Caribbean': 2,\n",
       "                               'fiefdom': 1,\n",
       "                               'cannot': 32,\n",
       "                               'answered': 5,\n",
       "                               'knew': 4,\n",
       "                               'deal': 8,\n",
       "                               'about': 63,\n",
       "                               'assassination': 1,\n",
       "                               'scores': 1,\n",
       "                               'deaths': 2,\n",
       "                               'including': 12,\n",
       "                               'abduction': 1,\n",
       "                               'Jesus': 14,\n",
       "                               'Maria': 1,\n",
       "                               'Galindez': 1,\n",
       "                               'professor': 3,\n",
       "                               'Columbia': 3,\n",
       "                               'University': 8,\n",
       "                               'New': 54,\n",
       "                               'York': 24,\n",
       "                               'laid': 4,\n",
       "                               'door': 5,\n",
       "                               'He': 96,\n",
       "                               'had': 128,\n",
       "                               'involved': 3,\n",
       "                               'countless': 2,\n",
       "                               'schemes': 2,\n",
       "                               'away': 12,\n",
       "                               'democratic': 6,\n",
       "                               'leaders': 24,\n",
       "                               'neighboring': 4,\n",
       "                               'countries': 8,\n",
       "                               'President': 51,\n",
       "                               'Romulo': 1,\n",
       "                               'Betancourt': 2,\n",
       "                               'Venezuela': 2,\n",
       "                               'sort': 5,\n",
       "                               'poetic': 4,\n",
       "                               'justice': 6,\n",
       "                               'demise': 1,\n",
       "                               'plot': 4,\n",
       "                               'overthrow': 2,\n",
       "                               'Venezuelan': 2,\n",
       "                               'reportedly': 1,\n",
       "                               'involving': 3,\n",
       "                               'arms': 9,\n",
       "                               'former': 12,\n",
       "                               'Dictator': 2,\n",
       "                               'Marcos': 1,\n",
       "                               'Perez': 1,\n",
       "                               'Jimenez': 1,\n",
       "                               'uncovered': 2,\n",
       "                               'quashed': 1,\n",
       "                               'recent': 22,\n",
       "                               'almost': 26,\n",
       "                               'classical': 2,\n",
       "                               'study': 11,\n",
       "                               'professedly': 1,\n",
       "                               'benevolent': 1,\n",
       "                               'dictatorship': 7,\n",
       "                               'tends': 5,\n",
       "                               'oppressive': 1,\n",
       "                               'Unquestionably': 1,\n",
       "                               'things': 20,\n",
       "                               ':': 154,\n",
       "                               'improved': 4,\n",
       "                               'facilities': 4,\n",
       "                               'attracted': 2,\n",
       "                               'investment': 3,\n",
       "                               'raised': 9,\n",
       "                               'standard': 1,\n",
       "                               'living': 9,\n",
       "                               'notably': 3,\n",
       "                               'price': 5,\n",
       "                               'silence': 2,\n",
       "                               'criticism': 5,\n",
       "                               'opposition': 10,\n",
       "                               \"Benefactor's\": 1,\n",
       "                               'vanity': 2,\n",
       "                               'personal': 9,\n",
       "                               'wealth': 2,\n",
       "                               'jails': 1,\n",
       "                               'filled': 5,\n",
       "                               'overflowing': 2,\n",
       "                               'prisoners': 2,\n",
       "                               'incurred': 1,\n",
       "                               'displeasure': 1,\n",
       "                               'maintained': 1,\n",
       "                               'amply': 1,\n",
       "                               'financed': 1,\n",
       "                               'lobbies': 1,\n",
       "                               'elsewhere': 5,\n",
       "                               'sycophantically': 1,\n",
       "                               'chanted': 1,\n",
       "                               'praise': 3,\n",
       "                               'influence': 6,\n",
       "                               'extended': 2,\n",
       "                               'Until': 4,\n",
       "                               'profession': 4,\n",
       "                               'friendship': 1,\n",
       "                               'article': 17,\n",
       "                               'faith': 5,\n",
       "                               'altogether': 2,\n",
       "                               'accepted': 7,\n",
       "                               'here': 24,\n",
       "                               'evidence': 8,\n",
       "                               'character': 2,\n",
       "                               'Tardily': 1,\n",
       "                               'Government': 11,\n",
       "                               'came': 21,\n",
       "                               'understand': 11,\n",
       "                               \"country's\": 3,\n",
       "                               'reputation': 3,\n",
       "                               'tarnished': 1,\n",
       "                               'association': 4,\n",
       "                               'repression': 1,\n",
       "                               'Last': 4,\n",
       "                               'after': 26,\n",
       "                               'cited': 2,\n",
       "                               'numerous': 3,\n",
       "                               'Organization': 8,\n",
       "                               'broke': 2,\n",
       "                               'relations': 5,\n",
       "                               'Thereupon': 1,\n",
       "                               'demonstration': 5,\n",
       "                               'tyranny': 2,\n",
       "                               'knows': 12,\n",
       "                               'ideological': 4,\n",
       "                               'confines': 1,\n",
       "                               \"Trujillo's\": 2,\n",
       "                               'along': 14,\n",
       "                               'conservative': 5,\n",
       "                               'right-wing': 1,\n",
       "                               'lines': 6,\n",
       "                               'censure': 1,\n",
       "                               'propaganda': 10,\n",
       "                               'started': 5,\n",
       "                               'mouthing': 1,\n",
       "                               'Communist': 29,\n",
       "                               'slogans': 1,\n",
       "                               'tacit': 1,\n",
       "                               'rapprochement': 1,\n",
       "                               'Castro': 10,\n",
       "                               'Cuba': 6,\n",
       "                               'previously': 5,\n",
       "                               'bete': 1,\n",
       "                               'noire': 1,\n",
       "                               '--': 192,\n",
       "                               'thus': 10,\n",
       "                               'illustrating': 1,\n",
       "                               'totalitarianism': 2,\n",
       "                               'coalesces': 1,\n",
       "                               'What': 29,\n",
       "                               'comes': 10,\n",
       "                               'puzzle': 1,\n",
       "                               'known': 11,\n",
       "                               'institutions': 5,\n",
       "                               'precious': 1,\n",
       "                               'little': 36,\n",
       "                               'generation': 5,\n",
       "                               'alternative': 1,\n",
       "                               'leadership': 13,\n",
       "                               'suppressed': 1,\n",
       "                               'Perhaps': 7,\n",
       "                               'army': 11,\n",
       "                               'able': 14,\n",
       "                               'maintain': 3,\n",
       "                               'stability': 1,\n",
       "                               'vacuum': 1,\n",
       "                               'free': 23,\n",
       "                               'creates': 2,\n",
       "                               'turn': 6,\n",
       "                               'Communist-type': 1,\n",
       "                               'authoritarianism': 2,\n",
       "                               'Western': 16,\n",
       "                               'Such': 5,\n",
       "                               'twist': 1,\n",
       "                               'tragedy': 4,\n",
       "                               'breathe': 1,\n",
       "                               'fear': 9,\n",
       "                               'For': 32,\n",
       "                               'reason': 23,\n",
       "                               'bring': 12,\n",
       "                               'genuine': 2,\n",
       "                               'representative': 5,\n",
       "                               'greatest': 7,\n",
       "                               'sympathy': 3,\n",
       "                               'help': 31,\n",
       "                               'Start': 1,\n",
       "                               'transit': 1,\n",
       "                               'High-speed': 1,\n",
       "                               'buses': 4,\n",
       "                               'George': 5,\n",
       "                               'Washington': 32,\n",
       "                               'Memorial': 3,\n",
       "                               'Parkway': 3,\n",
       "                               'operating': 2,\n",
       "                               'downtown': 3,\n",
       "                               'Cabin': 1,\n",
       "                               'John': 26,\n",
       "                               'Glen': 1,\n",
       "                               'Echo': 1,\n",
       "                               'Brookmont': 1,\n",
       "                               'constitute': 2,\n",
       "                               'alluring': 1,\n",
       "                               'sample': 2,\n",
       "                               'National': 13,\n",
       "                               'Capital': 1,\n",
       "                               'Transportation': 1,\n",
       "                               'Agency': 1,\n",
       "                               'presenting': 1,\n",
       "                               'plans': 9,\n",
       "                               'express': 7,\n",
       "                               'before': 33,\n",
       "                               'Montgomery': 1,\n",
       "                               'County': 11,\n",
       "                               'Council': 17,\n",
       "                               'administrator': 1,\n",
       "                               'NCTA': 3,\n",
       "                               'C.': 6,\n",
       "                               'Darwin': 1,\n",
       "                               'Stolzenbach': 1,\n",
       "                               'frankly': 1,\n",
       "                               'seeking': 5,\n",
       "                               'support': 22,\n",
       "                               'projects': 2,\n",
       "                               'agency': 4,\n",
       "                               'soon': 9,\n",
       "                               'launching': 1,\n",
       "                               'difficult': 12,\n",
       "                               'presented': 4,\n",
       "                               'attractive': 2,\n",
       "                               'outline': 1,\n",
       "                               'coming': 8,\n",
       "                               'Because': 2,\n",
       "                               'stop': 10,\n",
       "                               'parkway': 2,\n",
       "                               'land': 18,\n",
       "                               'bus': 4,\n",
       "                               'stations': 10,\n",
       "                               'parking': 1,\n",
       "                               'nearby': 4,\n",
       "                               'advised': 1,\n",
       "                               'seek': 15,\n",
       "                               'purpose': 10,\n",
       "                               'present': 25,\n",
       "                               'Must': 2,\n",
       "                               'Berlin': 50,\n",
       "                               'remain': 6,\n",
       "                               'divided': 2,\n",
       "                               '?': 294,\n",
       "                               'inference': 1,\n",
       "                               'widely': 5,\n",
       "                               'Communists': 14,\n",
       "                               'succeeded': 1,\n",
       "                               'building': 4,\n",
       "                               'barricades': 2,\n",
       "                               'across': 8,\n",
       "                               'world': 66,\n",
       "                               'acquiesce': 2,\n",
       "                               'dismemberment': 2,\n",
       "                               'So': 15,\n",
       "                               'concerned': 9,\n",
       "                               'acquiesced': 1,\n",
       "                               'Though': 3,\n",
       "                               'Walter': 8,\n",
       "                               'Ulbricht': 2,\n",
       "                               'grace': 3,\n",
       "                               'Soviet': 41,\n",
       "                               'tanks': 2,\n",
       "                               'head': 10,\n",
       "                               'man': 56,\n",
       "                               'East': 52,\n",
       "                               'Germany': 24,\n",
       "                               'give': 20,\n",
       "                               'usurp': 1,\n",
       "                               'absorb': 1,\n",
       "                               'semi-city': 1,\n",
       "                               'zone': 3,\n",
       "                               'wartime': 1,\n",
       "                               'protocol': 1,\n",
       "                               'September': 4,\n",
       "                               '12': 6,\n",
       "                               '1944': 1,\n",
       "                               'designated': 1,\n",
       "                               'special': 13,\n",
       "                               'Greater': 3,\n",
       "                               'comprising': 1,\n",
       "                               'under': 30,\n",
       "                               'joint': 3,\n",
       "                               ...}),\n",
       "                     'fiction': FreqDist({'Thirty-three': 1,\n",
       "                               'Scotty': 32,\n",
       "                               'did': 117,\n",
       "                               'not': 290,\n",
       "                               'go': 72,\n",
       "                               'back': 102,\n",
       "                               'to': 1489,\n",
       "                               'school': 18,\n",
       "                               '.': 3639,\n",
       "                               'His': 60,\n",
       "                               'parents': 7,\n",
       "                               'talked': 12,\n",
       "                               'seriously': 2,\n",
       "                               'and': 1696,\n",
       "                               'lengthily': 1,\n",
       "                               'their': 162,\n",
       "                               'own': 55,\n",
       "                               'doctor': 33,\n",
       "                               'a': 1281,\n",
       "                               'specialist': 1,\n",
       "                               'at': 360,\n",
       "                               'the': 3423,\n",
       "                               'University': 1,\n",
       "                               'Hospital': 1,\n",
       "                               '--': 176,\n",
       "                               'Mr.': 39,\n",
       "                               'McKinley': 6,\n",
       "                               'was': 1082,\n",
       "                               'entitled': 2,\n",
       "                               'discount': 1,\n",
       "                               'for': 392,\n",
       "                               'members': 8,\n",
       "                               'of': 1419,\n",
       "                               'his': 735,\n",
       "                               'family': 13,\n",
       "                               'it': 458,\n",
       "                               'decided': 9,\n",
       "                               'would': 287,\n",
       "                               'be': 254,\n",
       "                               'best': 12,\n",
       "                               'him': 375,\n",
       "                               'take': 48,\n",
       "                               'remainder': 1,\n",
       "                               'term': 2,\n",
       "                               'off': 62,\n",
       "                               ',': 3654,\n",
       "                               'spend': 7,\n",
       "                               'lot': 8,\n",
       "                               'time': 99,\n",
       "                               'in': 916,\n",
       "                               'bed': 28,\n",
       "                               'rest': 15,\n",
       "                               'do': 86,\n",
       "                               'pretty': 10,\n",
       "                               'much': 50,\n",
       "                               'as': 306,\n",
       "                               'he': 813,\n",
       "                               'chose': 4,\n",
       "                               'provided': 1,\n",
       "                               'course': 17,\n",
       "                               'nothing': 26,\n",
       "                               'too': 58,\n",
       "                               'exciting': 3,\n",
       "                               'or': 167,\n",
       "                               'debilitating': 1,\n",
       "                               'teacher': 4,\n",
       "                               'principal': 1,\n",
       "                               'were': 238,\n",
       "                               'conferred': 1,\n",
       "                               'with': 468,\n",
       "                               'everyone': 11,\n",
       "                               'agreed': 7,\n",
       "                               'that': 530,\n",
       "                               'if': 97,\n",
       "                               'kept': 15,\n",
       "                               'up': 191,\n",
       "                               'certain': 8,\n",
       "                               'amount': 2,\n",
       "                               'work': 32,\n",
       "                               'home': 49,\n",
       "                               'there': 150,\n",
       "                               'little': 81,\n",
       "                               'danger': 3,\n",
       "                               'losing': 1,\n",
       "                               'accepted': 9,\n",
       "                               'decision': 6,\n",
       "                               'indifference': 2,\n",
       "                               'enter': 3,\n",
       "                               'arguments': 2,\n",
       "                               'He': 495,\n",
       "                               'discharged': 1,\n",
       "                               'from': 222,\n",
       "                               'hospital': 5,\n",
       "                               'after': 54,\n",
       "                               'two-day': 2,\n",
       "                               'checkup': 1,\n",
       "                               'had': 726,\n",
       "                               'what': 128,\n",
       "                               'described': 4,\n",
       "                               '``': 703,\n",
       "                               'celebration': 1,\n",
       "                               'lunch': 3,\n",
       "                               \"''\": 698,\n",
       "                               'cafeteria': 2,\n",
       "                               'on': 431,\n",
       "                               'campus': 2,\n",
       "                               'Rachel': 18,\n",
       "                               'wore': 16,\n",
       "                               'smart': 5,\n",
       "                               'hat': 9,\n",
       "                               'because': 40,\n",
       "                               'she': 280,\n",
       "                               'been': 157,\n",
       "                               'warned': 2,\n",
       "                               'recently': 4,\n",
       "                               'about': 170,\n",
       "                               'smoking': 3,\n",
       "                               'puffed': 2,\n",
       "                               'her': 397,\n",
       "                               'cigarettes': 3,\n",
       "                               'through': 60,\n",
       "                               'long': 53,\n",
       "                               'ivory': 3,\n",
       "                               'holder': 1,\n",
       "                               'stained': 1,\n",
       "                               'lipstick': 1,\n",
       "                               \"Scotty's\": 9,\n",
       "                               'father': 18,\n",
       "                               'sat': 37,\n",
       "                               'sprawled': 3,\n",
       "                               'chair': 17,\n",
       "                               'angular': 1,\n",
       "                               'alert': 5,\n",
       "                               'cricket': 1,\n",
       "                               'looking': 19,\n",
       "                               'huge': 4,\n",
       "                               'stainless-steel': 1,\n",
       "                               'appointments': 1,\n",
       "                               'room': 63,\n",
       "                               'an': 156,\n",
       "                               'expression': 8,\n",
       "                               'proprietorship': 1,\n",
       "                               'Teachers': 1,\n",
       "                               'men': 72,\n",
       "                               'who': 103,\n",
       "                               'brown': 6,\n",
       "                               'suits': 2,\n",
       "                               'gray': 16,\n",
       "                               'hair': 26,\n",
       "                               'pleasant': 6,\n",
       "                               'smiles': 2,\n",
       "                               'came': 91,\n",
       "                               'table': 20,\n",
       "                               'talk': 14,\n",
       "                               'shop': 4,\n",
       "                               'introduced': 2,\n",
       "                               'polite': 1,\n",
       "                               'indifferent': 3,\n",
       "                               'They': 83,\n",
       "                               'ate': 6,\n",
       "                               'food': 6,\n",
       "                               'its': 53,\n",
       "                               'orange': 1,\n",
       "                               'sauces': 1,\n",
       "                               'gazed': 2,\n",
       "                               'without': 27,\n",
       "                               'interest': 8,\n",
       "                               'teachers': 1,\n",
       "                               'heroic': 2,\n",
       "                               'baronial': 1,\n",
       "                               'windows': 7,\n",
       "                               'bright': 4,\n",
       "                               'ranks': 3,\n",
       "                               'college': 3,\n",
       "                               'banners': 1,\n",
       "                               'tried': 26,\n",
       "                               'make': 49,\n",
       "                               'topic': 1,\n",
       "                               'The': 369,\n",
       "                               'blueberry': 1,\n",
       "                               'pie': 1,\n",
       "                               'is': 144,\n",
       "                               'good': 55,\n",
       "                               'I': 511,\n",
       "                               'recommend': 1,\n",
       "                               'looked': 72,\n",
       "                               'son': 17,\n",
       "                               'face': 58,\n",
       "                               'worried': 6,\n",
       "                               'murmured': 2,\n",
       "                               'No': 33,\n",
       "                               'thanks': 1,\n",
       "                               'so': 115,\n",
       "                               'softly': 8,\n",
       "                               'bend': 4,\n",
       "                               'gaunt': 2,\n",
       "                               'height': 1,\n",
       "                               'across': 32,\n",
       "                               'turn': 8,\n",
       "                               'round': 6,\n",
       "                               'ear': 5,\n",
       "                               'regarded': 3,\n",
       "                               'grizzled': 1,\n",
       "                               'around': 71,\n",
       "                               'moment': 36,\n",
       "                               'said': 192,\n",
       "                               'more': 82,\n",
       "                               'loudly': 7,\n",
       "                               \"I'm\": 28,\n",
       "                               'full': 14,\n",
       "                               'old': 75,\n",
       "                               'Pop': 1,\n",
       "                               'eaten': 1,\n",
       "                               'almost': 26,\n",
       "                               'crested': 1,\n",
       "                               'three-sectioned': 1,\n",
       "                               'plate': 2,\n",
       "                               'drunk': 6,\n",
       "                               'half': 12,\n",
       "                               'milk': 5,\n",
       "                               'paper': 13,\n",
       "                               'container': 1,\n",
       "                               \"He's\": 13,\n",
       "                               'all': 182,\n",
       "                               'right': 43,\n",
       "                               'Craig': 1,\n",
       "                               'can': 37,\n",
       "                               'fix': 4,\n",
       "                               'something': 45,\n",
       "                               'later': 14,\n",
       "                               'afternoon': 17,\n",
       "                               'when': 133,\n",
       "                               'we': 85,\n",
       "                               'get': 78,\n",
       "                               'Since': 9,\n",
       "                               'seizure': 2,\n",
       "                               'appetite': 3,\n",
       "                               ';': 318,\n",
       "                               'yet': 23,\n",
       "                               'changed': 7,\n",
       "                               'appearance': 4,\n",
       "                               'surprisingly': 2,\n",
       "                               'one': 168,\n",
       "                               'plumpness': 4,\n",
       "                               'fuller': 1,\n",
       "                               'lips': 15,\n",
       "                               'usually': 3,\n",
       "                               'sharp': 10,\n",
       "                               'lines': 9,\n",
       "                               'jaw': 2,\n",
       "                               'become': 17,\n",
       "                               'swollen-looking': 1,\n",
       "                               'breathed': 1,\n",
       "                               'now': 100,\n",
       "                               'mouth': 17,\n",
       "                               'open': 27,\n",
       "                               'showing': 1,\n",
       "                               'whitely': 1,\n",
       "                               'curving': 1,\n",
       "                               'section': 6,\n",
       "                               'lower': 3,\n",
       "                               'teeth': 6,\n",
       "                               'eyes': 60,\n",
       "                               'blurred': 1,\n",
       "                               'lids': 2,\n",
       "                               'always': 49,\n",
       "                               'lowered': 5,\n",
       "                               'though': 35,\n",
       "                               'apparently': 3,\n",
       "                               'focusing': 2,\n",
       "                               'Even': 6,\n",
       "                               'neck': 13,\n",
       "                               'seemed': 55,\n",
       "                               'thicker': 1,\n",
       "                               'therefore': 3,\n",
       "                               'shorter': 1,\n",
       "                               'hands': 30,\n",
       "                               'which': 123,\n",
       "                               'quick': 11,\n",
       "                               'pair': 8,\n",
       "                               'fluttering': 1,\n",
       "                               'birds': 5,\n",
       "                               'neither': 9,\n",
       "                               'active': 2,\n",
       "                               'nor': 7,\n",
       "                               'really': 25,\n",
       "                               'relaxed': 1,\n",
       "                               'lay': 20,\n",
       "                               'lap': 7,\n",
       "                               'palms': 1,\n",
       "                               'stiffly': 5,\n",
       "                               'motionless': 1,\n",
       "                               'tapered': 1,\n",
       "                               'fingers': 13,\n",
       "                               'thick': 12,\n",
       "                               'joints': 1,\n",
       "                               'Altogether': 1,\n",
       "                               'since': 28,\n",
       "                               'boy': 33,\n",
       "                               'overindulged': 1,\n",
       "                               'took': 44,\n",
       "                               'no': 129,\n",
       "                               'exercise': 2,\n",
       "                               'lazy': 4,\n",
       "                               'spoiled': 1,\n",
       "                               'querulous': 1,\n",
       "                               'say': 36,\n",
       "                               'She': 145,\n",
       "                               'greeted': 6,\n",
       "                               \"husband's\": 3,\n",
       "                               'colleagues': 1,\n",
       "                               'smiling': 7,\n",
       "                               'politeness': 1,\n",
       "                               'offering': 1,\n",
       "                               'sprawling': 2,\n",
       "                               'easy': 13,\n",
       "                               'familiarity': 1,\n",
       "                               'completely': 3,\n",
       "                               'still': 55,\n",
       "                               'jumping': 1,\n",
       "                               'anticipate': 1,\n",
       "                               'desires': 2,\n",
       "                               'It': 149,\n",
       "                               'strained': 3,\n",
       "                               'silent': 14,\n",
       "                               \"I'd\": 11,\n",
       "                               'better': 27,\n",
       "                               'doctors': 2,\n",
       "                               'suggested': 5,\n",
       "                               'remain': 7,\n",
       "                               'most': 33,\n",
       "                               'every': 33,\n",
       "                               'until': 24,\n",
       "                               'stronger': 4,\n",
       "                               'give': 22,\n",
       "                               'lecture': 1,\n",
       "                               'drove': 9,\n",
       "                               'alone': 16,\n",
       "                               'Plymouth': 1,\n",
       "                               'speak': 11,\n",
       "                               'out': 222,\n",
       "                               'ugly': 1,\n",
       "                               'slums': 1,\n",
       "                               'Look': 5,\n",
       "                               'those': 30,\n",
       "                               'stupid': 3,\n",
       "                               'kids': 3,\n",
       "                               'Negro': 8,\n",
       "                               'peeling': 1,\n",
       "                               'row': 5,\n",
       "                               'houses': 7,\n",
       "                               'store-front': 1,\n",
       "                               'churches': 3,\n",
       "                               'ragged': 3,\n",
       "                               'children': 20,\n",
       "                               'toward': 23,\n",
       "                               'ask': 16,\n",
       "                               'repeat': 4,\n",
       "                               'Nothing': 7,\n",
       "                               'And': 74,\n",
       "                               'then': 76,\n",
       "                               ':': 84,\n",
       "                               'There': 69,\n",
       "                               'are': 50,\n",
       "                               'lots': 1,\n",
       "                               'here': 60,\n",
       "                               'slightly': 5,\n",
       "                               'opened': 17,\n",
       "                               'dull': 4,\n",
       "                               'felt': 58,\n",
       "                               'tired': 9,\n",
       "                               'calm': 6,\n",
       "                               'Thirty-four': 1,\n",
       "                               'days': 35,\n",
       "                               'short': 11,\n",
       "                               'perhaps': 11,\n",
       "                               'routine': 3,\n",
       "                               'each': 33,\n",
       "                               'day': 52,\n",
       "                               'same': 51,\n",
       "                               'rose': 11,\n",
       "                               'late': 10,\n",
       "                               'went': 79,\n",
       "                               'down': 128,\n",
       "                               'bathrobe': 2,\n",
       "                               'slippers': 3,\n",
       "                               'have': 165,\n",
       "                               'breakfast': 8,\n",
       "                               'either': 6,\n",
       "                               'Virginia': 8,\n",
       "                               'treated': 2,\n",
       "                               'attention': 6,\n",
       "                               'tempt': 1,\n",
       "                               'special': 5,\n",
       "                               'biscuits': 1,\n",
       "                               'cookies': 1,\n",
       "                               'candies': 1,\n",
       "                               'result': 2,\n",
       "                               'devoted': 5,\n",
       "                               'hours': 10,\n",
       "                               'tiled': 1,\n",
       "                               'kitchen': 21,\n",
       "                               'hover': 2,\n",
       "                               'over': 99,\n",
       "                               'like': 147,\n",
       "                               'brother': 7,\n",
       "                               'anxiously': 4,\n",
       "                               'watch': 9,\n",
       "                               'progress': 2,\n",
       "                               'fork': 4,\n",
       "                               'spoon': 1,\n",
       "                               'You': 46,\n",
       "                               \"don't\": 55,\n",
       "                               'eat': 5,\n",
       "                               'enough': 34,\n",
       "                               'honey': 4,\n",
       "                               'Try': 1,\n",
       "                               'observing': 1,\n",
       "                               'has': 27,\n",
       "                               'rediscover': 1,\n",
       "                               'capacity': 1,\n",
       "                               \"It'll\": 1,\n",
       "                               'other': 48,\n",
       "                               'quietly': 7,\n",
       "                               'allies': 1,\n",
       "                               'political': 2,\n",
       "                               'rather': 14,\n",
       "                               'than': 47,\n",
       "                               'natural': 3,\n",
       "                               'might': 44,\n",
       "                               'war': 24,\n",
       "                               'atmosphere': 3,\n",
       "                               'Both': 6,\n",
       "                               'watched': 19,\n",
       "                               'constantly': 3,\n",
       "                               'seeming': 2,\n",
       "                               'openly': 6,\n",
       "                               'filled': 13,\n",
       "                               'concern': 5,\n",
       "                               'neutral': 3,\n",
       "                               'resent': 1,\n",
       "                               'supervision': 1,\n",
       "                               \"Virginia's\": 2,\n",
       "                               'sometimes': 14,\n",
       "                               'tiring': 1,\n",
       "                               'sympathy': 2,\n",
       "                               'slept': 11,\n",
       "                               'pleased': 6,\n",
       "                               'moved': 25,\n",
       "                               'draughty': 1,\n",
       "                               'rooms': 8,\n",
       "                               'house': 54,\n",
       "                               'slow': 7,\n",
       "                               'dubious': 1,\n",
       "                               'steps': 18,\n",
       "                               'elderly': 4,\n",
       "                               'tourist': 1,\n",
       "                               'cathedral': 1,\n",
       "                               'energy': 3,\n",
       "                               'gone': 28,\n",
       "                               'able': 7,\n",
       "                               'sit': 13,\n",
       "                               'living': 17,\n",
       "                               'stare': 2,\n",
       "                               'bleak': 2,\n",
       "                               'yard': 7,\n",
       "                               'moving': 13,\n",
       "                               'loosely': 3,\n",
       "                               'they': 230,\n",
       "                               'wax': 5,\n",
       "                               'lifelike': 2,\n",
       "                               'quite': 16,\n",
       "                               'folded': 4,\n",
       "                               'hung': 14,\n",
       "                               'When': 59,\n",
       "                               'asked': 50,\n",
       "                               'question': 6,\n",
       "                               'addressed': 5,\n",
       "                               'such': 27,\n",
       "                               'way': 62,\n",
       "                               'some': 88,\n",
       "                               'response': 2,\n",
       "                               'inescapable': 1,\n",
       "                               'answer': 11,\n",
       "                               'often': 12,\n",
       "                               'happened': 13,\n",
       "                               'spoken': 6,\n",
       "                               'words': 18,\n",
       "                               'emphasis': 1,\n",
       "                               'impatience': 3,\n",
       "                               'only': 74,\n",
       "                               'louder': 2,\n",
       "                               'mentioned': 4,\n",
       "                               'Kate': 40,\n",
       "                               'even': 57,\n",
       "                               'thought': 76,\n",
       "                               'except': 11,\n",
       "                               'once': 38,\n",
       "                               'twice': 4,\n",
       "                               'night': 53,\n",
       "                               'slowly': 14,\n",
       "                               'ranging': 1,\n",
       "                               'thoughts': 7,\n",
       "                               'abruptly': 3,\n",
       "                               'accidentally': 1,\n",
       "                               'encounter': 2,\n",
       "                               'At': 37,\n",
       "                               'these': 40,\n",
       "                               'times': 17,\n",
       "                               'kind': 17,\n",
       "                               'pain': 10,\n",
       "                               'upper': 6,\n",
       "                               'chest': 9,\n",
       "                               'but': 207,\n",
       "                               'objective': 3,\n",
       "                               'different': 12,\n",
       "                               'others': 16,\n",
       "                               'intensity': 2,\n",
       "                               'bandaged': 2,\n",
       "                               'wound': 4,\n",
       "                               'head': 54,\n",
       "                               'occasionally': 4,\n",
       "                               'throbbed': 1,\n",
       "                               'merely': 10,\n",
       "                               'another': 47,\n",
       "                               'part': 26,\n",
       "                               'weakness': 4,\n",
       "                               'drugged': 3,\n",
       "                               'care': 22,\n",
       "                               'notice': 6,\n",
       "                               'girl': 20,\n",
       "                               'street': 17,\n",
       "                               \"hasn't\": 2,\n",
       "                               'bothered': 1,\n",
       "                               'phone': 7,\n",
       "                               'visit': 14,\n",
       "                               \"That's\": 14,\n",
       "                               \"Kate's\": 4,\n",
       "                               'briefly': 5,\n",
       "                               'deliberately': 1,\n",
       "                               'turned': 43,\n",
       "                               'else': 15,\n",
       "                               'Once': 10,\n",
       "                               'sitting': 17,\n",
       "                               'front': 30,\n",
       "                               'window': 26,\n",
       "                               \"parents'\": 2,\n",
       "                               'saw': 58,\n",
       "                               'come': 55,\n",
       "                               'Elizabeth': 3,\n",
       "                               'far': 22,\n",
       "                               'tiny': 4,\n",
       "                               'heavy': 11,\n",
       "                               'branches': 1,\n",
       "                               'hide': 3,\n",
       "                               'reveal': 1,\n",
       "                               'them': 172,\n",
       "                               'bottom': 5,\n",
       "                               'direction': 5,\n",
       "                               'park': 1,\n",
       "                               'awakened': 2,\n",
       "                               'interested': 5,\n",
       "                               'held': 23,\n",
       "                               'leash': 2,\n",
       "                               'hand': 50,\n",
       "                               'fuzzy': 1,\n",
       "                               'puppy': 1,\n",
       "                               'end': 21,\n",
       "                               'Then': 43,\n",
       "                               'disappeared': 6,\n",
       "                               'got': 51,\n",
       "                               'into': 147,\n",
       "                               'By': 10,\n",
       "                               'under': 24,\n",
       "                               'covers': 6,\n",
       "                               'forgotten': 4,\n",
       "                               'seeing': 13,\n",
       "                               'longer': 12,\n",
       "                               'allowed': 4,\n",
       "                               'regular': 3,\n",
       "                               'trips': 2,\n",
       "                               'town': 19,\n",
       "                               'see': 57,\n",
       "                               'informally': 1,\n",
       "                               'slim-waisted': 1,\n",
       "                               'spare': 3,\n",
       "                               'edge': 10,\n",
       "                               'legs': 11,\n",
       "                               'crossed': 10,\n",
       "                               'elaborately': 1,\n",
       "                               'foot': 12,\n",
       "                               'could': 166,\n",
       "                               'tap': 1,\n",
       "                               'floor': 18,\n",
       "                               'mind': 31,\n",
       "                               \"doctor's\": 10,\n",
       "                               'unsmiling': 2,\n",
       "                               'teasing': 1,\n",
       "                               'used': 19,\n",
       "                               'Husky': 1,\n",
       "                               'young': 26,\n",
       "                               'man': 111,\n",
       "                               'mock': 2,\n",
       "                               'distaste': 1,\n",
       "                               'imagine': 7,\n",
       "                               \"you're\": 8,\n",
       "                               'battling': 1,\n",
       "                               'any': 54,\n",
       "                               'Pardon': 1,\n",
       "                               '?': 564,\n",
       "                               'close': 16,\n",
       "                               'hear': 24,\n",
       "                               'delicate': 4,\n",
       "                               'veined': 1,\n",
       "                               \"moth's\": 1,\n",
       "                               'wing': 2,\n",
       "                               'rested': 1,\n",
       "                               'absently': 3,\n",
       "                               'Oh': 19,\n",
       "                               'Well': 19,\n",
       "                               \"we're\": 3,\n",
       "                               'taking': 12,\n",
       "                               'vacation': 3,\n",
       "                               \"that's\": 9,\n",
       "                               'unsmilingly': 1,\n",
       "                               'think': 43,\n",
       "                               'by': 163,\n",
       "                               'next': 29,\n",
       "                               'week': 15,\n",
       "                               'air': 25,\n",
       "                               'very': 42,\n",
       "                               'definite': 3,\n",
       "                               'exhaust': 1,\n",
       "                               'further': 2,\n",
       "                               'unnecessarily': 1,\n",
       "                               \"He'll\": 5,\n",
       "                               'soon': 14,\n",
       "                               'stethoscope': 2,\n",
       "                               'picked': 9,\n",
       "                               'wagged': 1,\n",
       "                               'fussily': 1,\n",
       "                               'Just': 5,\n",
       "                               'keep': 19,\n",
       "                               'cap': 4,\n",
       "                               'strong': 7,\n",
       "                               'emotions': 8,\n",
       "                               'glinted': 2,\n",
       "                               'silver': 5,\n",
       "                               'darkening': 2,\n",
       "                               \"I'll\": 15,\n",
       "                               'drop': 4,\n",
       "                               'again': 67,\n",
       "                               'few': 28,\n",
       "                               'stayed': 9,\n",
       "                               'smoothed': 3,\n",
       "                               'things': 31,\n",
       "                               'touch': 10,\n",
       "                               'disinterest': 1,\n",
       "                               'desire': 10,\n",
       "                               'Do': 9,\n",
       "                               'you': 236,\n",
       "                               \"you'll\": 4,\n",
       "                               'miss': 3,\n",
       "                               'noticed': 3,\n",
       "                               'how': 54,\n",
       "                               'formal': 3,\n",
       "                               'irritably': 1,\n",
       "                               'exact': 1,\n",
       "                               'grown': 4,\n",
       "                               'irritability': 1,\n",
       "                               'knew': 59,\n",
       "                               'shook': 11,\n",
       "                               \"We've\": 3,\n",
       "                               'number': 6,\n",
       "                               'calls': 2,\n",
       "                               'win': 6,\n",
       "                               'popularity': 2,\n",
       "                               'contest': 1,\n",
       "                               'trouble': 11,\n",
       "                               'Miss': 29,\n",
       "                               'Estherson': 1,\n",
       "                               'called': 28,\n",
       "                               'wants': 5,\n",
       "                               'pay': 2,\n",
       "                               'says': 7,\n",
       "                               'Apparently': 1,\n",
       "                               'light': 20,\n",
       "                               'lives': 4,\n",
       "                               'shrugged': 2,\n",
       "                               'bent': 4,\n",
       "                               'kiss': 6,\n",
       "                               'away': 55,\n",
       "                               'frowning': 1,\n",
       "                               'That': 42,\n",
       "                               'annoys': 1,\n",
       "                               'me': 137,\n",
       "                               'herself': 20,\n",
       "                               'suppose': 5,\n",
       "                               'self-consciousness': 1,\n",
       "                               'characteristic': 2,\n",
       "                               'new': 33,\n",
       "                               'professionals': 1,\n",
       "                               'general': 2,\n",
       "                               'Mrs.': 41,\n",
       "                               'Charles': 7,\n",
       "                               'Sally': 1,\n",
       "                               'phoned': 2,\n",
       "                               \"Rachel's\": 2,\n",
       "                               'tone': 2,\n",
       "                               'dry': 3,\n",
       "                               \"didn't\": 53,\n",
       "                               'glanced': 5,\n",
       "                               'swooped': 1,\n",
       "                               'gracefully': 2,\n",
       "                               'mean': 13,\n",
       "                               'feel': 18,\n",
       "                               'know': 75,\n",
       "                               'true': 6,\n",
       "                               'slight': 3,\n",
       "                               'throbbing': 2,\n",
       "                               \"there's\": 3,\n",
       "                               'case': 10,\n",
       "                               \"We'll\": 1,\n",
       "                               'wait': 11,\n",
       "                               'till': 7,\n",
       "                               'put': 37,\n",
       "                               'slipper': 1,\n",
       "                               'neatly': 2,\n",
       "                               'mate': 2,\n",
       "                               'Okay': 1,\n",
       "                               'This': 29,\n",
       "                               'kissed': 2,\n",
       "                               'lightly': 2,\n",
       "                               'forehead': 2,\n",
       "                               'constant': 3,\n",
       "                               'visitor': 2,\n",
       "                               'door': 47,\n",
       "                               'evening': 17,\n",
       "                               \"father's\": 5,\n",
       "                               'deep': 10,\n",
       "                               'voice': 35,\n",
       "                               'floated': 1,\n",
       "                               'stairs': 15,\n",
       "                               \"How's\": 2,\n",
       "                               'reply': 6,\n",
       "                               'getting': 21,\n",
       "                               'plenty': 2,\n",
       "                               'Is': 7,\n",
       "                               'improved': 1,\n",
       "                               'Or': 6,\n",
       "                               'Does': 1,\n",
       "                               'exchange': 2,\n",
       "                               'invariable': 1,\n",
       "                               'word': 18,\n",
       "                               'never': 71,\n",
       "                               'smiled': 10,\n",
       "                               'required': 2,\n",
       "                               'possessed': 3,\n",
       "                               'satirical': 1,\n",
       "                               'upstairs': 12,\n",
       "                               'stand': 7,\n",
       "                               'self-consciously': 1,\n",
       "                               'look': 39,\n",
       "                               'After': 12,\n",
       "                               'pause': 2,\n",
       "                               'during': 10,\n",
       "                               'studied': 8,\n",
       "                               'study': 12,\n",
       "                               'questions': 11,\n",
       "                               'downstairs': 3,\n",
       "                               'apologetically': 2,\n",
       "                               'eating': 3,\n",
       "                               'walk': 18,\n",
       "                               'Perhaps': 8,\n",
       "                               'should': 35,\n",
       "                               'supposed': 3,\n",
       "                               'irritated': 1,\n",
       "                               'useless': 1,\n",
       "                               'kindly': 1,\n",
       "                               'lined': 1,\n",
       "                               'vague': 3,\n",
       "                               'noting': 1,\n",
       "                               'grew': 9,\n",
       "                               'examined': 2,\n",
       "                               'everything': 18,\n",
       "                               'critical': 1,\n",
       "                               'seeking': 4,\n",
       "                               'material': 5,\n",
       "                               'blame': 3,\n",
       "                               \"son's\": 1,\n",
       "                               'illness': 1,\n",
       "                               'Have': 4,\n",
       "                               'blankets': 2,\n",
       "                               'accusation': 1,\n",
       "                               'scarf': 2,\n",
       "                               'bought': 10,\n",
       "                               'Where': 13,\n",
       "                               'edges': 2,\n",
       "                               'restless': 1,\n",
       "                               'sea': 13,\n",
       "                               'waves': 2,\n",
       "                               'thrusting': 1,\n",
       "                               'themselves': 5,\n",
       "                               'upward': 2,\n",
       "                               'angry': 4,\n",
       "                               'motion': 2,\n",
       "                               'Papa-san': 8,\n",
       "                               'glacier-like': 1,\n",
       "                               'smooth': 5,\n",
       "                               'solidity': 2,\n",
       "                               'immobility': 1,\n",
       "                               'defying': 1,\n",
       "                               'turmoil': 2,\n",
       "                               'Our': 2,\n",
       "                               'colonel': 7,\n",
       "                               'briefing': 1,\n",
       "                               'brooding': 2,\n",
       "                               'Gouge': 1,\n",
       "                               'burn': 2,\n",
       "                               'blast': 1,\n",
       "                               'insult': 1,\n",
       "                               'anyone': 8,\n",
       "                               'Between': 2,\n",
       "                               'ponderous': 1,\n",
       "                               'hulk': 1,\n",
       "                               'himself': 69,\n",
       "                               'valley': 8,\n",
       "                               'reigned': 1,\n",
       "                               'hidden': 4,\n",
       "                               'high': 19,\n",
       "                               'explosives': 1,\n",
       "                               'booby': 2,\n",
       "                               'traps': 3,\n",
       "                               'mines': 1,\n",
       "                               'raped': 1,\n",
       "                               'pregnant': 1,\n",
       "                               'womb': 1,\n",
       "                               'awaiting': 3,\n",
       "                               'abortion': 1,\n",
       "                               'On': 19,\n",
       "                               'forward': 6,\n",
       "                               'slope': 2,\n",
       "                               'post': 3,\n",
       "                               'stretched': 4,\n",
       "                               'two': 68,\n",
       "                               'rows': 1,\n",
       "                               'barbed': 3,\n",
       "                               'wire': 6,\n",
       "                               \"slope's\": 1,\n",
       "                               'base': 2,\n",
       "                               'coils': 1,\n",
       "                               'concertina': 1,\n",
       "                               'eye': 17,\n",
       "                               'range': 1,\n",
       "                               'wild': 7,\n",
       "                               'tangle': 1,\n",
       "                               \"children's\": 1,\n",
       "                               'hoops': 1,\n",
       "                               'stopped': 24,\n",
       "                               'simultaneously': 1,\n",
       "                               'weirdly': 1,\n",
       "                               'poised': 2,\n",
       "                               'magic': 2,\n",
       "                               \"child's\": 2,\n",
       "                               'start': 6,\n",
       "                               'rolling': 5,\n",
       "                               'Closer': 1,\n",
       "                               'barricades': 1,\n",
       "                               'timber': 2,\n",
       "                               'supports': 1,\n",
       "                               'Was': 9,\n",
       "                               'vain': 2,\n",
       "                               'labor': 7,\n",
       "                               'Who': 9,\n",
       "                               'clean': 12,\n",
       "                               'mess': 2,\n",
       "                               'Smiling': 2,\n",
       "                               'quixotic': 1,\n",
       "                               'Warren': 16,\n",
       "                               'opening': 2,\n",
       "                               'lit': 4,\n",
       "                               'cigarette': 4,\n",
       "                               'before': 74,\n",
       "                               'Tonight': 1,\n",
       "                               'group': 12,\n",
       "                               'tomorrow': 8,\n",
       "                               'somewhere': 5,\n",
       "                               'If': 31,\n",
       "                               'White': 3,\n",
       "                               'just': 54,\n",
       "                               'listening': 4,\n",
       "                               'dark': 32,\n",
       "                               'point': 10,\n",
       "                               'between': 13,\n",
       "                               'ever': 27,\n",
       "                               'deeper': 2,\n",
       "                               'enemy': 6,\n",
       "                               'land': 15,\n",
       "                               'behind': 38,\n",
       "                               'itself': 14,\n",
       "                               'this': 147,\n",
       "                               'expected': 5,\n",
       "                               \"hadn't\": 14,\n",
       "                               'realized': 4,\n",
       "                               'many': 28,\n",
       "                               'lulls': 1,\n",
       "                               'Somehow': 3,\n",
       "                               'must': 55,\n",
       "                               'told': 48,\n",
       "                               'combat': 1,\n",
       "                               'intermittent': 1,\n",
       "                               'activity': 3,\n",
       "                               'Now': 30,\n",
       "                               'illuminated': 1,\n",
       "                               'vision': 5,\n",
       "                               'train': 12,\n",
       "                               'approached': 9,\n",
       "                               'place': 36,\n",
       "                               'occur': 4,\n",
       "                               'months': 7,\n",
       "                               'Time': 4,\n",
       "                               'afraid': 10,\n",
       "                               \"White's\": 3,\n",
       "                               'suggestion': 3,\n",
       "                               'flattered': 3,\n",
       "                               'identity': 2,\n",
       "                               'spill': 1,\n",
       "                               'hatred': 2,\n",
       "                               'seen': 27,\n",
       "                               'Pressing': 1,\n",
       "                               'earth': 9,\n",
       "                               'walked': 22,\n",
       "                               'slit': 4,\n",
       "                               'scanned': 2,\n",
       "                               'jagged': 2,\n",
       "                               'hills': 6,\n",
       "                               'life': 44,\n",
       "                               'stood': 41,\n",
       "                               'peering': 3,\n",
       "                               'unlovely': 1,\n",
       "                               'gaze': 4,\n",
       "                               'continually': 3,\n",
       "                               'returning': 4,\n",
       "                               'order': 13,\n",
       "                               'test': 3,\n",
       "                               'While': 4,\n",
       "                               'beliefs': 2,\n",
       "                               'unsettled': 1,\n",
       "                               'believe': 12,\n",
       "                               'killing': 2,\n",
       "                               'Yet': 8,\n",
       "                               'live': 9,\n",
       "                               'feeling': 18,\n",
       "                               'coward': 1,\n",
       "                               'ten': 17,\n",
       "                               'patrol': 8,\n",
       "                               'Sergeant': 3,\n",
       "                               'Prevot': 9,\n",
       "                               'led': 10,\n",
       "                               'beaming': 1,\n",
       "                               'ROK': 1,\n",
       "                               'carrying': 5,\n",
       "                               'thirty-caliber': 1,\n",
       "                               'machine': 7,\n",
       "                               'gun': 13,\n",
       "                               'lugged': 1,\n",
       "                               'tripod': 1,\n",
       "                               'box': 17,\n",
       "                               'ammunition': 3,\n",
       "                               'carried': 13,\n",
       "                               'addition': 2,\n",
       "                               'weapons': 1,\n",
       "                               'ammo': 3,\n",
       "                               \"ROK's\": 1,\n",
       "                               'Others': 1,\n",
       "                               'extra': 2,\n",
       "                               'clips': 1,\n",
       "                               'Browning': 1,\n",
       "                               'Automatic': 1,\n",
       "                               'Rifle': 1,\n",
       "                               'Mexican': 1,\n",
       "                               'named': 7,\n",
       "                               'Martinez': 1,\n",
       "                               'briefed': 1,\n",
       "                               'We': 33,\n",
       "                               'quiet': 3,\n",
       "                               'Be': 2,\n",
       "                               'sure': 23,\n",
       "                               'nearest': 2,\n",
       "                               'awake': 6,\n",
       "                               'Joe': 20,\n",
       "                               \"doesn't\": 5,\n",
       "                               'show': 10,\n",
       "                               \"we'll\": 1,\n",
       "                               '0600': 1,\n",
       "                               'Otherwise': 1,\n",
       "                               'hold': 16,\n",
       "                               'reception': 2,\n",
       "                               'pull': 8,\n",
       "                               'our': 42,\n",
       "                               ...}),\n",
       "                     'government': FreqDist({'The': 478,\n",
       "                               'Office': 18,\n",
       "                               'of': 3031,\n",
       "                               'Business': 18,\n",
       "                               'Economics': 2,\n",
       "                               '(': 342,\n",
       "                               'OBE': 1,\n",
       "                               ')': 345,\n",
       "                               'the': 4143,\n",
       "                               'U.S.': 28,\n",
       "                               'Department': 73,\n",
       "                               'Commerce': 16,\n",
       "                               'provides': 14,\n",
       "                               'basic': 25,\n",
       "                               'measures': 11,\n",
       "                               'national': 19,\n",
       "                               'economy': 15,\n",
       "                               'and': 1923,\n",
       "                               'current': 21,\n",
       "                               'analysis': 6,\n",
       "                               'short-run': 2,\n",
       "                               'changes': 12,\n",
       "                               'in': 1319,\n",
       "                               'economic': 21,\n",
       "                               'situation': 15,\n",
       "                               'business': 97,\n",
       "                               'outlook': 5,\n",
       "                               '.': 2493,\n",
       "                               'It': 106,\n",
       "                               'develops': 1,\n",
       "                               'analyzes': 1,\n",
       "                               'income': 42,\n",
       "                               ',': 3405,\n",
       "                               'balance': 8,\n",
       "                               'international': 22,\n",
       "                               'payments': 27,\n",
       "                               'many': 81,\n",
       "                               'other': 191,\n",
       "                               'indicators': 1,\n",
       "                               'Such': 13,\n",
       "                               'are': 415,\n",
       "                               'essential': 17,\n",
       "                               'to': 1829,\n",
       "                               'its': 143,\n",
       "                               'job': 8,\n",
       "                               'presenting': 2,\n",
       "                               'Government': 76,\n",
       "                               'with': 358,\n",
       "                               'facts': 7,\n",
       "                               'required': 35,\n",
       "                               'meet': 17,\n",
       "                               'objective': 15,\n",
       "                               'expanding': 5,\n",
       "                               'improving': 3,\n",
       "                               'operation': 32,\n",
       "                               'Contact': 5,\n",
       "                               'For': 52,\n",
       "                               'further': 27,\n",
       "                               'information': 39,\n",
       "                               'contact': 4,\n",
       "                               'Director': 12,\n",
       "                               'Washington': 29,\n",
       "                               '25': 22,\n",
       "                               'D.C.': 12,\n",
       "                               'Printed': 5,\n",
       "                               'material': 11,\n",
       "                               'Economic': 12,\n",
       "                               'is': 649,\n",
       "                               'made': 118,\n",
       "                               'available': 51,\n",
       "                               'businessmen': 3,\n",
       "                               'economists': 2,\n",
       "                               'promptly': 4,\n",
       "                               'through': 56,\n",
       "                               'monthly': 7,\n",
       "                               'Survey': 1,\n",
       "                               'Of': 28,\n",
       "                               'Current': 1,\n",
       "                               'weekly': 4,\n",
       "                               'supplement': 4,\n",
       "                               'This': 96,\n",
       "                               'periodical': 2,\n",
       "                               'including': 25,\n",
       "                               'statistical': 2,\n",
       "                               'supplements': 1,\n",
       "                               'for': 806,\n",
       "                               '$4': 3,\n",
       "                               'per': 56,\n",
       "                               'year': 183,\n",
       "                               'from': 244,\n",
       "                               'Field': 4,\n",
       "                               'Offices': 5,\n",
       "                               'or': 399,\n",
       "                               'Superintendent': 3,\n",
       "                               'Documents': 2,\n",
       "                               'Printing': 2,\n",
       "                               'Technical': 2,\n",
       "                               'assistance': 43,\n",
       "                               'small': 54,\n",
       "                               'community': 18,\n",
       "                               'Small': 13,\n",
       "                               'Administration': 20,\n",
       "                               'SBA': 25,\n",
       "                               'guidance': 3,\n",
       "                               'advice': 10,\n",
       "                               'on': 401,\n",
       "                               'sources': 14,\n",
       "                               'technical': 18,\n",
       "                               'relating': 9,\n",
       "                               'management': 35,\n",
       "                               'research': 40,\n",
       "                               'development': 112,\n",
       "                               'products': 21,\n",
       "                               'Practical': 1,\n",
       "                               'problems': 37,\n",
       "                               'their': 174,\n",
       "                               'suggested': 3,\n",
       "                               'solutions': 5,\n",
       "                               'dealt': 2,\n",
       "                               'a': 867,\n",
       "                               'series': 9,\n",
       "                               'publications': 10,\n",
       "                               'These': 49,\n",
       "                               'written': 5,\n",
       "                               'especially': 4,\n",
       "                               'managers': 1,\n",
       "                               'owners': 3,\n",
       "                               'businesses': 7,\n",
       "                               'indirectly': 2,\n",
       "                               'aid': 28,\n",
       "                               'programs': 36,\n",
       "                               'They': 27,\n",
       "                               'by': 428,\n",
       "                               'specialists': 5,\n",
       "                               'numerous': 4,\n",
       "                               'types': 17,\n",
       "                               'enterprises': 2,\n",
       "                               'cover': 8,\n",
       "                               'wide': 9,\n",
       "                               'range': 15,\n",
       "                               'subjects': 6,\n",
       "                               'directed': 15,\n",
       "                               'needs': 16,\n",
       "                               'interests': 14,\n",
       "                               'firm': 7,\n",
       "                               'offers': 9,\n",
       "                               'Administrative': 2,\n",
       "                               'Management': 3,\n",
       "                               'Courses': 2,\n",
       "                               'which': 263,\n",
       "                               'designed': 18,\n",
       "                               'improve': 3,\n",
       "                               'efficiency': 7,\n",
       "                               '``': 125,\n",
       "                               'know-how': 1,\n",
       "                               \"''\": 122,\n",
       "                               'concerns': 19,\n",
       "                               'within': 41,\n",
       "                               'cosponsors': 1,\n",
       "                               'these': 107,\n",
       "                               'courses': 4,\n",
       "                               'educational': 11,\n",
       "                               'institutions': 16,\n",
       "                               'groups': 12,\n",
       "                               'Through': 4,\n",
       "                               \"SBA's\": 2,\n",
       "                               'Counseling': 1,\n",
       "                               'Program': 8,\n",
       "                               'practical': 4,\n",
       "                               'personalized': 1,\n",
       "                               'sound': 14,\n",
       "                               'principles': 7,\n",
       "                               'upon': 46,\n",
       "                               'request': 16,\n",
       "                               'both': 53,\n",
       "                               'prospective': 5,\n",
       "                               'established': 24,\n",
       "                               'One-day': 1,\n",
       "                               'conferences': 4,\n",
       "                               'covering': 3,\n",
       "                               'some': 56,\n",
       "                               'specific': 9,\n",
       "                               'phase': 9,\n",
       "                               'also': 85,\n",
       "                               'part': 40,\n",
       "                               'continuing': 13,\n",
       "                               'activities': 35,\n",
       "                               'short': 9,\n",
       "                               'streamlined': 1,\n",
       "                               'meetings': 6,\n",
       "                               'usually': 9,\n",
       "                               'sponsored': 11,\n",
       "                               'local': 55,\n",
       "                               'banks': 4,\n",
       "                               'Chambers': 1,\n",
       "                               'trade': 18,\n",
       "                               'associations': 2,\n",
       "                               'civic': 4,\n",
       "                               'organizations': 19,\n",
       "                               'Product': 4,\n",
       "                               'Production': 6,\n",
       "                               'regional': 14,\n",
       "                               'offices': 7,\n",
       "                               'help': 24,\n",
       "                               'individual': 23,\n",
       "                               'production': 45,\n",
       "                               'Guidance': 1,\n",
       "                               'new': 100,\n",
       "                               'product': 10,\n",
       "                               ';': 444,\n",
       "                               'potential': 9,\n",
       "                               'processing': 4,\n",
       "                               'methods': 13,\n",
       "                               'market': 32,\n",
       "                               'developments': 12,\n",
       "                               'industrial': 26,\n",
       "                               'uses': 14,\n",
       "                               'raw': 3,\n",
       "                               'semi-processed': 1,\n",
       "                               'waste': 4,\n",
       "                               'materials': 14,\n",
       "                               'agricultural': 15,\n",
       "                               'serves': 4,\n",
       "                               'as': 453,\n",
       "                               'clearing': 4,\n",
       "                               'house': 4,\n",
       "                               'processes': 12,\n",
       "                               'particularly': 14,\n",
       "                               'adaptable': 1,\n",
       "                               'exploitation': 1,\n",
       "                               'firms': 17,\n",
       "                               'may': 153,\n",
       "                               'be': 600,\n",
       "                               'helpful': 3,\n",
       "                               'competitive': 12,\n",
       "                               'position': 18,\n",
       "                               'diversification': 2,\n",
       "                               'expansion': 12,\n",
       "                               'more': 118,\n",
       "                               'economical': 7,\n",
       "                               'utilization': 6,\n",
       "                               'plant': 30,\n",
       "                               'capacity': 12,\n",
       "                               'frequently': 5,\n",
       "                               'arise': 2,\n",
       "                               'where': 46,\n",
       "                               'making': 25,\n",
       "                               'items': 11,\n",
       "                               'not': 207,\n",
       "                               'directly': 11,\n",
       "                               'along': 7,\n",
       "                               'lines': 11,\n",
       "                               'normal': 9,\n",
       "                               'civilian': 10,\n",
       "                               'specifications': 2,\n",
       "                               'require': 17,\n",
       "                               'operations': 19,\n",
       "                               'that': 489,\n",
       "                               'did': 18,\n",
       "                               'understand': 4,\n",
       "                               'when': 56,\n",
       "                               'it': 218,\n",
       "                               'undertook': 1,\n",
       "                               'contract': 13,\n",
       "                               'often': 9,\n",
       "                               'takes': 6,\n",
       "                               'form': 16,\n",
       "                               'locating': 4,\n",
       "                               'tools': 5,\n",
       "                               'urgently': 2,\n",
       "                               'needed': 20,\n",
       "                               'Advice': 1,\n",
       "                               'given': 23,\n",
       "                               'location': 16,\n",
       "                               'space': 9,\n",
       "                               'Property': 1,\n",
       "                               'sales': 30,\n",
       "                               'property': 71,\n",
       "                               'program': 79,\n",
       "                               'assist': 10,\n",
       "                               'wish': 5,\n",
       "                               'buy': 2,\n",
       "                               'offered': 7,\n",
       "                               'sale': 17,\n",
       "                               'Federal': 43,\n",
       "                               'Under': 12,\n",
       "                               'this': 344,\n",
       "                               'locate': 2,\n",
       "                               'insure': 6,\n",
       "                               'have': 223,\n",
       "                               'opportunity': 26,\n",
       "                               'bid': 5,\n",
       "                               'competitively': 1,\n",
       "                               'surplus': 8,\n",
       "                               'personal': 31,\n",
       "                               'real': 7,\n",
       "                               'certain': 18,\n",
       "                               'natural': 7,\n",
       "                               'resources': 28,\n",
       "                               'timber': 10,\n",
       "                               'forests': 1,\n",
       "                               'works': 3,\n",
       "                               'closely': 8,\n",
       "                               'principal': 24,\n",
       "                               'disposal': 5,\n",
       "                               'installations': 3,\n",
       "                               'reviewing': 1,\n",
       "                               'proposed': 27,\n",
       "                               'identifying': 2,\n",
       "                               'those': 61,\n",
       "                               'most': 52,\n",
       "                               'likely': 8,\n",
       "                               'interested': 18,\n",
       "                               'purchasing': 6,\n",
       "                               'Proposed': 2,\n",
       "                               'general': 34,\n",
       "                               'interest': 45,\n",
       "                               'publicized': 1,\n",
       "                               'news': 4,\n",
       "                               'releases': 1,\n",
       "                               'flyers': 1,\n",
       "                               'Each': 6,\n",
       "                               'office': 10,\n",
       "                               'maintains': 5,\n",
       "                               'want': 8,\n",
       "                               'list': 3,\n",
       "                               'principally': 2,\n",
       "                               'machinery': 13,\n",
       "                               'equipment': 38,\n",
       "                               'desired': 5,\n",
       "                               'area': 18,\n",
       "                               'When': 12,\n",
       "                               'suitable': 7,\n",
       "                               'located': 14,\n",
       "                               'representative': 6,\n",
       "                               'concern': 10,\n",
       "                               'contacted': 1,\n",
       "                               'advised': 4,\n",
       "                               'how': 16,\n",
       "                               'such': 182,\n",
       "                               'Facilities': 1,\n",
       "                               'inventory': 14,\n",
       "                               'Section': 33,\n",
       "                               '8-b-2': 1,\n",
       "                               'Act': 68,\n",
       "                               'amended': 11,\n",
       "                               'authorizes': 1,\n",
       "                               'make': 52,\n",
       "                               'complete': 16,\n",
       "                               'productive': 6,\n",
       "                               'facilities': 31,\n",
       "                               'voluntarily': 1,\n",
       "                               'registered': 6,\n",
       "                               'kept': 4,\n",
       "                               'each': 71,\n",
       "                               'Regional': 3,\n",
       "                               'region': 5,\n",
       "                               'Purpose': 1,\n",
       "                               'include': 24,\n",
       "                               'all': 158,\n",
       "                               'eligible': 5,\n",
       "                               'register': 1,\n",
       "                               'so': 78,\n",
       "                               'an': 208,\n",
       "                               'avail': 1,\n",
       "                               'themselves': 19,\n",
       "                               'services': 49,\n",
       "                               'authorized': 23,\n",
       "                               'Congress': 34,\n",
       "                               'establishing': 9,\n",
       "                               'procurement': 16,\n",
       "                               'notice': 5,\n",
       "                               'invitations': 3,\n",
       "                               'contracts': 5,\n",
       "                               \"registrants'\": 1,\n",
       "                               'field': 19,\n",
       "                               'can': 117,\n",
       "                               'inventories': 4,\n",
       "                               'labor': 3,\n",
       "                               'areas': 29,\n",
       "                               'budgetary': 2,\n",
       "                               'staff': 21,\n",
       "                               'limitations': 7,\n",
       "                               'Atlanta': 2,\n",
       "                               'Ga.': 2,\n",
       "                               'Boston': 4,\n",
       "                               'Mass.': 2,\n",
       "                               'Chicago': 4,\n",
       "                               'Ill.': 4,\n",
       "                               'Cleveland': 3,\n",
       "                               'Ohio': 10,\n",
       "                               'Dallas': 2,\n",
       "                               'Tex.': 2,\n",
       "                               'Denver': 2,\n",
       "                               'Colo.': 2,\n",
       "                               'Detroit': 2,\n",
       "                               'Mich.': 2,\n",
       "                               'Kansas': 3,\n",
       "                               'City': 8,\n",
       "                               'Mo.': 2,\n",
       "                               'Los': 3,\n",
       "                               'Angeles': 3,\n",
       "                               'Calif.': 4,\n",
       "                               'Minneapolis': 2,\n",
       "                               'Minn.': 2,\n",
       "                               'New': 50,\n",
       "                               'York': 33,\n",
       "                               'N.Y.': 2,\n",
       "                               'Philadelphia': 3,\n",
       "                               'Pa.': 2,\n",
       "                               'Richmond': 3,\n",
       "                               'Va.': 2,\n",
       "                               'San': 2,\n",
       "                               'Francisco': 2,\n",
       "                               'Seattle': 2,\n",
       "                               'Wash.': 2,\n",
       "                               'Branch': 2,\n",
       "                               'large': 33,\n",
       "                               'cities': 26,\n",
       "                               'What': 15,\n",
       "                               'Is': 8,\n",
       "                               'Does': 2,\n",
       "                               'Services': 6,\n",
       "                               'Community': 2,\n",
       "                               'Development': 13,\n",
       "                               'various': 21,\n",
       "                               'useful': 5,\n",
       "                               'currently': 9,\n",
       "                               'important': 44,\n",
       "                               'marketing': 7,\n",
       "                               'topics': 2,\n",
       "                               'Introduction': 1,\n",
       "                               'Owners': 1,\n",
       "                               '30': 28,\n",
       "                               'cents': 8,\n",
       "                               'Developing': 1,\n",
       "                               'And': 25,\n",
       "                               'Selling': 1,\n",
       "                               'Products': 7,\n",
       "                               '45': 3,\n",
       "                               'Purchasing': 2,\n",
       "                               'Specifications': 1,\n",
       "                               'Sales': 6,\n",
       "                               'Directory': 3,\n",
       "                               '60': 3,\n",
       "                               'Loans': 3,\n",
       "                               'makes': 7,\n",
       "                               'loans': 22,\n",
       "                               'providing': 10,\n",
       "                               'them': 63,\n",
       "                               'financing': 21,\n",
       "                               'otherwise': 17,\n",
       "                               'private': 12,\n",
       "                               'lending': 2,\n",
       "                               'reasonable': 14,\n",
       "                               'terms': 11,\n",
       "                               'Many': 5,\n",
       "                               'been': 130,\n",
       "                               'establish': 12,\n",
       "                               'growth': 22,\n",
       "                               'thereby': 5,\n",
       "                               'contributing': 5,\n",
       "                               'substantially': 13,\n",
       "                               'Loan': 3,\n",
       "                               'policies': 22,\n",
       "                               'manufacturers': 9,\n",
       "                               'pools': 1,\n",
       "                               'wholesalers': 1,\n",
       "                               'retailers': 2,\n",
       "                               'service': 68,\n",
       "                               'establishments': 1,\n",
       "                               'finance': 10,\n",
       "                               'construction': 21,\n",
       "                               'conversion': 5,\n",
       "                               'purchase': 22,\n",
       "                               'supplies': 6,\n",
       "                               'supply': 8,\n",
       "                               'working': 9,\n",
       "                               'capital': 16,\n",
       "                               'Evidence': 1,\n",
       "                               'unavailable': 1,\n",
       "                               'must': 102,\n",
       "                               'provided': 31,\n",
       "                               'Types': 2,\n",
       "                               'two': 62,\n",
       "                               ':': 110,\n",
       "                               'participation': 13,\n",
       "                               'direct': 14,\n",
       "                               'Participation': 1,\n",
       "                               'jointly': 3,\n",
       "                               'Direct': 1,\n",
       "                               'alone': 8,\n",
       "                               'To': 30,\n",
       "                               'qualify': 3,\n",
       "                               'either': 16,\n",
       "                               'type': 14,\n",
       "                               'loan': 22,\n",
       "                               'applicant': 6,\n",
       "                               'approved': 10,\n",
       "                               'pool': 19,\n",
       "                               'credit': 16,\n",
       "                               'requirements': 25,\n",
       "                               'A': 104,\n",
       "                               'defined': 2,\n",
       "                               'one': 111,\n",
       "                               'independently': 1,\n",
       "                               'owned': 5,\n",
       "                               'operated': 7,\n",
       "                               'dominant': 7,\n",
       "                               'In': 148,\n",
       "                               'addition': 30,\n",
       "                               'criteria': 3,\n",
       "                               'number': 35,\n",
       "                               'employees': 25,\n",
       "                               'dollar': 5,\n",
       "                               'volume': 3,\n",
       "                               'Credit': 9,\n",
       "                               'stipulate': 1,\n",
       "                               'ability': 6,\n",
       "                               'operate': 18,\n",
       "                               'successfully': 3,\n",
       "                               'enough': 7,\n",
       "                               'will': 244,\n",
       "                               'able': 11,\n",
       "                               'financial': 28,\n",
       "                               'basis': 38,\n",
       "                               'purposes': 38,\n",
       "                               'sufficiently': 6,\n",
       "                               'secured': 2,\n",
       "                               'assure': 8,\n",
       "                               'chance': 1,\n",
       "                               'repayment': 2,\n",
       "                               'record': 14,\n",
       "                               'past': 13,\n",
       "                               'earnings': 6,\n",
       "                               'prospects': 5,\n",
       "                               'future': 25,\n",
       "                               'indicate': 10,\n",
       "                               'has': 153,\n",
       "                               'repay': 2,\n",
       "                               'out': 57,\n",
       "                               'anticipated': 2,\n",
       "                               'amount': 43,\n",
       "                               'borrowed': 2,\n",
       "                               'depends': 6,\n",
       "                               'much': 27,\n",
       "                               'carry': 14,\n",
       "                               'intended': 3,\n",
       "                               'purpose': 22,\n",
       "                               'maximum': 16,\n",
       "                               'any': 142,\n",
       "                               'borrower': 1,\n",
       "                               '$350,000': 1,\n",
       "                               'generally': 6,\n",
       "                               'repayable': 1,\n",
       "                               'regular': 10,\n",
       "                               'installments': 2,\n",
       "                               '--': 139,\n",
       "                               'at': 235,\n",
       "                               'rate': 22,\n",
       "                               '5-1/2': 1,\n",
       "                               'percent': 21,\n",
       "                               'annum': 1,\n",
       "                               'unpaid': 5,\n",
       "                               'maturity': 3,\n",
       "                               '10': 19,\n",
       "                               'years': 106,\n",
       "                               'term': 14,\n",
       "                               '6': 18,\n",
       "                               'Pooling': 1,\n",
       "                               'cooperatives': 3,\n",
       "                               'Farm': 8,\n",
       "                               'independent': 7,\n",
       "                               'agency': 16,\n",
       "                               'Agriculture': 5,\n",
       "                               'supervises': 1,\n",
       "                               'coordinates': 1,\n",
       "                               'cooperative': 7,\n",
       "                               'system': 34,\n",
       "                               'agriculture': 2,\n",
       "                               'composed': 2,\n",
       "                               'three': 21,\n",
       "                               'Land': 2,\n",
       "                               'Banks': 6,\n",
       "                               'National': 47,\n",
       "                               'Associations': 2,\n",
       "                               'Intermediate': 1,\n",
       "                               'short-term': 7,\n",
       "                               'Cooperatives': 6,\n",
       "                               'long-': 1,\n",
       "                               'farmers': 3,\n",
       "                               'As': 27,\n",
       "                               'source': 11,\n",
       "                               'investment': 13,\n",
       "                               'beneficial': 4,\n",
       "                               'communities': 9,\n",
       "                               'encourages': 1,\n",
       "                               'industries': 5,\n",
       "                               'rural': 3,\n",
       "                               'provdied': 1,\n",
       "                               'first': 58,\n",
       "                               'outlined': 2,\n",
       "                               'above': 35,\n",
       "                               'primarily': 7,\n",
       "                               'third': 3,\n",
       "                               'exists': 4,\n",
       "                               'under': 89,\n",
       "                               'authority': 14,\n",
       "                               '1933': 3,\n",
       "                               'were': 126,\n",
       "                               'provide': 50,\n",
       "                               'permanent': 8,\n",
       "                               \"farmers'\": 2,\n",
       "                               'Three': 3,\n",
       "                               'distinct': 3,\n",
       "                               'classes': 7,\n",
       "                               'Commodity': 1,\n",
       "                               'operating': 20,\n",
       "                               'facility': 3,\n",
       "                               'Eligibility': 1,\n",
       "                               'borrow': 2,\n",
       "                               'Bank': 18,\n",
       "                               'association': 3,\n",
       "                               'act': 17,\n",
       "                               'together': 8,\n",
       "                               'farm': 3,\n",
       "                               'furnishing': 1,\n",
       "                               'set': 31,\n",
       "                               'forth': 9,\n",
       "                               'Interest': 6,\n",
       "                               'rates': 14,\n",
       "                               'determined': 18,\n",
       "                               'board': 34,\n",
       "                               'directors': 4,\n",
       "                               'bank': 4,\n",
       "                               'approval': 11,\n",
       "                               'serving': 5,\n",
       "                               'Research': 16,\n",
       "                               'Information': 2,\n",
       "                               'Division': 25,\n",
       "                               'Available': 1,\n",
       "                               'Cooperative': 2,\n",
       "                               'Can': 2,\n",
       "                               'Assist': 1,\n",
       "                               'Rural': 2,\n",
       "                               'Circular': 2,\n",
       "                               'No.': 4,\n",
       "                               '44': 2,\n",
       "                               'System': 6,\n",
       "                               '36-A': 1,\n",
       "                               'Minerals': 3,\n",
       "                               'exploration': 4,\n",
       "                               'encourage': 13,\n",
       "                               'domestic': 16,\n",
       "                               'minerals': 1,\n",
       "                               'Exploration': 2,\n",
       "                               'OME': 2,\n",
       "                               'Interior': 9,\n",
       "                               'individuals': 4,\n",
       "                               'who': 74,\n",
       "                               'desire': 5,\n",
       "                               'explore': 2,\n",
       "                               'properties': 6,\n",
       "                               'claims': 13,\n",
       "                               '1': 107,\n",
       "                               '32': 1,\n",
       "                               'mineral': 1,\n",
       "                               'commodities': 14,\n",
       "                               'listed': 4,\n",
       "                               'regulations': 8,\n",
       "                               'Requirements': 1,\n",
       "                               'applicants': 1,\n",
       "                               'ordinarily': 1,\n",
       "                               'would': 120,\n",
       "                               'undertake': 5,\n",
       "                               'present': 41,\n",
       "                               'conditions': 28,\n",
       "                               'circumstances': 9,\n",
       "                               'sole': 2,\n",
       "                               'expense': 2,\n",
       "                               'unable': 6,\n",
       "                               'obtain': 5,\n",
       "                               'funds': 29,\n",
       "                               'commercial': 11,\n",
       "                               'own': 44,\n",
       "                               'sufficient': 8,\n",
       "                               'explored': 2,\n",
       "                               'pay': 33,\n",
       "                               'up': 33,\n",
       "                               'one-half': 2,\n",
       "                               'cost': 34,\n",
       "                               'work': 44,\n",
       "                               'progresses': 1,\n",
       "                               'pays': 2,\n",
       "                               'rest': 7,\n",
       "                               'but': 93,\n",
       "                               'his': 141,\n",
       "                               'time': 103,\n",
       "                               'spent': 3,\n",
       "                               'charges': 5,\n",
       "                               'use': 85,\n",
       "                               'he': 120,\n",
       "                               'owns': 2,\n",
       "                               'applied': 8,\n",
       "                               'toward': 20,\n",
       "                               'share': 23,\n",
       "                               'Repayment': 1,\n",
       "                               'Funds': 4,\n",
       "                               'contributed': 8,\n",
       "                               'repaid': 2,\n",
       "                               'royalty': 4,\n",
       "                               'If': 45,\n",
       "                               'nothing': 6,\n",
       "                               'produced': 9,\n",
       "                               'there': 64,\n",
       "                               'no': 58,\n",
       "                               'obligation': 2,\n",
       "                               '5-percent': 1,\n",
       "                               'paid': 25,\n",
       "                               'during': 51,\n",
       "                               'period': 56,\n",
       "                               'effect': 15,\n",
       "                               'if': 68,\n",
       "                               'certifies': 1,\n",
       "                               'possible': 30,\n",
       "                               'continues': 10,\n",
       "                               '10-year': 5,\n",
       "                               'specified': 8,\n",
       "                               'until': 25,\n",
       "                               \"Government's\": 7,\n",
       "                               'contribution': 6,\n",
       "                               'applies': 3,\n",
       "                               'never': 12,\n",
       "                               'exceeds': 3,\n",
       "                               '5': 28,\n",
       "                               'application': 17,\n",
       "                               'forms': 5,\n",
       "                               'filing': 15,\n",
       "                               'obtained': 26,\n",
       "                               'appropriate': 12,\n",
       "                               'below': 25,\n",
       "                               'less': 31,\n",
       "                               'developed': 32,\n",
       "                               'countries': 36,\n",
       "                               'however': 21,\n",
       "                               'programing': 10,\n",
       "                               'best': 21,\n",
       "                               'inadequate': 5,\n",
       "                               'worst': 4,\n",
       "                               'nonexistent': 1,\n",
       "                               'Only': 4,\n",
       "                               'very': 22,\n",
       "                               'few': 18,\n",
       "                               'advanced': 9,\n",
       "                               'ones': 4,\n",
       "                               'India': 30,\n",
       "                               'Pakistan': 1,\n",
       "                               'systematic': 3,\n",
       "                               'techniques': 8,\n",
       "                               'Others': 2,\n",
       "                               'so-called': 1,\n",
       "                               'plans': 19,\n",
       "                               'little': 12,\n",
       "                               'than': 117,\n",
       "                               'lists': 1,\n",
       "                               'projects': 44,\n",
       "                               'collected': 4,\n",
       "                               'ministries': 1,\n",
       "                               'while': 17,\n",
       "                               'others': 20,\n",
       "                               'statements': 4,\n",
       "                               'goals': 8,\n",
       "                               'without': 18,\n",
       "                               'actions': 7,\n",
       "                               'attain': 3,\n",
       "                               'rarely': 2,\n",
       "                               'attention': 18,\n",
       "                               'accurate': 3,\n",
       "                               'progress': 21,\n",
       "                               'reports': 11,\n",
       "                               'evaluation': 8,\n",
       "                               'We': 33,\n",
       "                               'planning': 36,\n",
       "                               'process': 21,\n",
       "                               'Neither': 1,\n",
       "                               'nor': 15,\n",
       "                               'imposed': 2,\n",
       "                               'country': 38,\n",
       "                               'express': 3,\n",
       "                               \"nation's\": 2,\n",
       "                               'goal': 6,\n",
       "                               'Nevertheless': 3,\n",
       "                               'we': 112,\n",
       "                               'administer': 1,\n",
       "                               'manner': 5,\n",
       "                               'promote': 16,\n",
       "                               'responsible': 10,\n",
       "                               'First': 4,\n",
       "                               'responsibility': 21,\n",
       "                               'substantial': 24,\n",
       "                               'sustained': 5,\n",
       "                               'scale': 8,\n",
       "                               'definition': 1,\n",
       "                               'objectives': 15,\n",
       "                               'assessment': 14,\n",
       "                               'costs': 26,\n",
       "                               'Second': 2,\n",
       "                               'particular': 29,\n",
       "                               'conditional': 2,\n",
       "                               'consistency': 2,\n",
       "                               'Third': 1,\n",
       "                               'offer': 5,\n",
       "                               'formulation': 3,\n",
       "                               'adapted': 1,\n",
       "                               \"country's\": 5,\n",
       "                               'includes': 11,\n",
       "                               'assembling': 2,\n",
       "                               'technological': 6,\n",
       "                               'surveying': 1,\n",
       "                               'over': 53,\n",
       "                               'broad': 11,\n",
       "                               'sectors': 2,\n",
       "                               'transport': 6,\n",
       "                               'communication': 4,\n",
       "                               'industry': 21,\n",
       "                               'power': 17,\n",
       "                               'designing': 2,\n",
       "                               'mechanisms': 1,\n",
       "                               'ways': 5,\n",
       "                               'inflation': 2,\n",
       "                               'administrative': 21,\n",
       "                               'practices': 12,\n",
       "                               'effective': 21,\n",
       "                               'review': 17,\n",
       "                               'implementation': 1,\n",
       "                               'once': 6,\n",
       "                               'common': 13,\n",
       "                               'sense': 13,\n",
       "                               'applying': 1,\n",
       "                               'allocation': 9,\n",
       "                               'cannot': 12,\n",
       "                               'course': 15,\n",
       "                               'mechanical': 8,\n",
       "                               'recognized': 9,\n",
       "                               'different': 13,\n",
       "                               'stages': 2,\n",
       "                               'capabilities': 4,\n",
       "                               'meeting': 7,\n",
       "                               'insist': 4,\n",
       "                               'level': 23,\n",
       "                               'performance': 10,\n",
       "                               'budgeting': 4,\n",
       "                               'completely': 4,\n",
       "                               'beyond': 12,\n",
       "                               'recipient': 2,\n",
       "                               'result': 27,\n",
       "                               'frustration': 1,\n",
       "                               'our': 144,\n",
       "                               'rapid': 7,\n",
       "                               'primitive': 1,\n",
       "                               'absorb': 3,\n",
       "                               'utilize': 4,\n",
       "                               'external': 4,\n",
       "                               'limited': 6,\n",
       "                               'obvious': 5,\n",
       "                               'priority': 5,\n",
       "                               'decide': 3,\n",
       "                               'support': 31,\n",
       "                               'before': 40,\n",
       "                               'well': 41,\n",
       "                               'worked': 4,\n",
       "                               'Thus': 9,\n",
       "                               'might': 13,\n",
       "                               'fields': 12,\n",
       "                               'education': 12,\n",
       "                               'communications': 7,\n",
       "                               'improvement': 9,\n",
       "                               'despite': 5,\n",
       "                               'absence': 3,\n",
       "                               'acceptable': 1,\n",
       "                               'case': 25,\n",
       "                               'get': 9,\n",
       "                               'task': 11,\n",
       "                               'performing': 3,\n",
       "                               'plain': 1,\n",
       "                               'even': 27,\n",
       "                               'continuation': 2,\n",
       "                               'was': 223,\n",
       "                               'being': 42,\n",
       "                               'At': 18,\n",
       "                               'end': 23,\n",
       "                               'spectrum': 1,\n",
       "                               'relied': 2,\n",
       "                               'thought': 7,\n",
       "                               'decisions': 8,\n",
       "                               'project': 13,\n",
       "                               'priorities': 2,\n",
       "                               'consistent': 7,\n",
       "                               'should': 112,\n",
       "                               'prepared': 16,\n",
       "                               'depart': 1,\n",
       "                               'detailed': 5,\n",
       "                               'granting': 2,\n",
       "                               'move': 5,\n",
       "                               'long-term': 15,\n",
       "                               'cooperation': 12,\n",
       "                               'foreign': 35,\n",
       "                               'exchange': 7,\n",
       "                               'D': 13,\n",
       "                               'Encouraging': 2,\n",
       "                               'self-help': 13,\n",
       "                               'reasons': 15,\n",
       "                               'stressing': 1,\n",
       "                               'approach': 13,\n",
       "                               'kind': 10,\n",
       "                               'There': 34,\n",
       "                               'vitally': 1,\n",
       "                               'since': 23,\n",
       "                               'main': 6,\n",
       "                               'thrust': 1,\n",
       "                               'come': 12,\n",
       "                               'External': 2,\n",
       "                               'only': 69,\n",
       "                               'marginal': 1,\n",
       "                               'although': 4,\n",
       "                               'margin': 2,\n",
       "                               'Marshall': 2,\n",
       "                               'plan': 35,\n",
       "                               'decisive': 1,\n",
       "                               'complement': 2,\n",
       "                               'therefore': 19,\n",
       "                               'increasingly': 5,\n",
       "                               'incentives': 2,\n",
       "                               'take': 36,\n",
       "                               'steps': 10,\n",
       "                               'they': 92,\n",
       "                               'Aid': 4,\n",
       "                               'interference': 31,\n",
       "                               'expect': 6,\n",
       "                               'remake': 1,\n",
       "                               'image': 1,\n",
       "                               'Open': 1,\n",
       "                               'societies': 3,\n",
       "                               'limits': 4,\n",
       "                               'recipients': 2,\n",
       "                               'free': 14,\n",
       "                               'devise': 2,\n",
       "                               'achieve': 6,\n",
       "                               'On': 24,\n",
       "                               'hand': 15,\n",
       "                               'sovereignty': 1,\n",
       "                               'point': 22,\n",
       "                               'defects': 1,\n",
       "                               'exist': 4,\n",
       "                               'calls': 4,\n",
       "                               'factories': 2,\n",
       "                               'run': 12,\n",
       "                               'trained': 10,\n",
       "                               'personnel': 27,\n",
       "                               'Once': 4,\n",
       "                               'clear': 13,\n",
       "                               'genuinely': 1,\n",
       "                               'concerned': 11,\n",
       "                               'blunt': 2,\n",
       "                               'suggesting': 2,\n",
       "                               'met': 7,\n",
       "                               'occur': 1,\n",
       "                               '2': 86,\n",
       "                               'major': 23,\n",
       "                               'following': 16,\n",
       "                               'mobilizing': 1,\n",
       "                               'tax': 86,\n",
       "                               'raise': 7,\n",
       "                               'equitably': 1,\n",
       "                               'fiscal': 96,\n",
       "                               'monetary': 2,\n",
       "                               'prevent': 11,\n",
       "                               'serious': 12,\n",
       "                               'regulatory': 2,\n",
       "                               'aimed': 3,\n",
       "                               'attract': 2,\n",
       "                               'managerial': 1,\n",
       "                               'excessive': 7,\n",
       "                               'luxury': 1,\n",
       "                               'consumption': 4,\n",
       "                               'B': 40,\n",
       "                               'reduction': 7,\n",
       "                               'dependence': 3,\n",
       "                               'foreseeing': 1,\n",
       "                               'balance-of-payments': 1,\n",
       "                               'crises': 3,\n",
       "                               'adequate': 14,\n",
       "                               'reducing': 4,\n",
       "                               'imports': 3,\n",
       "                               'adopting': 3,\n",
       "                               'realistic': 5,\n",
       "                               'infant': 2,\n",
       "                               'spur': 1,\n",
       "                               'exports': 2,\n",
       "                               'training': 19,\n",
       "                               ...}),\n",
       "                     'hobbies': FreqDist({'Too': 6,\n",
       "                               'often': 30,\n",
       "                               'a': 1737,\n",
       "                               'beginning': 15,\n",
       "                               'bodybuilder': 6,\n",
       "                               'has': 231,\n",
       "                               'to': 1797,\n",
       "                               'do': 97,\n",
       "                               'his': 238,\n",
       "                               'training': 25,\n",
       "                               'secretly': 1,\n",
       "                               'either': 32,\n",
       "                               'because': 70,\n",
       "                               'parents': 7,\n",
       "                               \"don't\": 21,\n",
       "                               'want': 27,\n",
       "                               'sonny-boy': 1,\n",
       "                               '``': 227,\n",
       "                               'lift': 3,\n",
       "                               'all': 195,\n",
       "                               'those': 63,\n",
       "                               'old': 34,\n",
       "                               'barbell': 5,\n",
       "                               'things': 23,\n",
       "                               \"''\": 261,\n",
       "                               \"you'll\": 20,\n",
       "                               'stunt': 1,\n",
       "                               'your': 271,\n",
       "                               'growth': 14,\n",
       "                               'or': 457,\n",
       "                               'childish': 1,\n",
       "                               'taunts': 1,\n",
       "                               'from': 278,\n",
       "                               'schoolmates': 2,\n",
       "                               ',': 3849,\n",
       "                               'like': 66,\n",
       "                               'Hey': 1,\n",
       "                               'lookit': 1,\n",
       "                               'Mr.': 21,\n",
       "                               'America': 20,\n",
       "                               ';': 512,\n",
       "                               'whaddya': 1,\n",
       "                               'gonna': 1,\n",
       "                               'with': 595,\n",
       "                               'muscles': 9,\n",
       "                               '(': 285,\n",
       "                               'of': 2390,\n",
       "                               'which': 252,\n",
       "                               'he': 155,\n",
       "                               'none': 1,\n",
       "                               'at': 328,\n",
       "                               'the': 4300,\n",
       "                               'time': 127,\n",
       "                               ')': 280,\n",
       "                               '?': 320,\n",
       "                               'After': 25,\n",
       "                               \"guy's\": 1,\n",
       "                               'gotta': 1,\n",
       "                               'have': 351,\n",
       "                               'little': 46,\n",
       "                               'ego': 1,\n",
       "                               '!': 88,\n",
       "                               'Therefore': 3,\n",
       "                               \"it's\": 26,\n",
       "                               'genuine': 2,\n",
       "                               'pleasure': 10,\n",
       "                               'tell': 7,\n",
       "                               'you': 383,\n",
       "                               'about': 98,\n",
       "                               'an': 226,\n",
       "                               'entirely': 9,\n",
       "                               'happy': 5,\n",
       "                               'who': 103,\n",
       "                               'never': 28,\n",
       "                               'had': 85,\n",
       "                               'train': 4,\n",
       "                               'in': 1427,\n",
       "                               'secret': 2,\n",
       "                               'heard': 4,\n",
       "                               'one': 258,\n",
       "                               'unkind': 1,\n",
       "                               'word': 10,\n",
       "                               'and': 2144,\n",
       "                               'been': 115,\n",
       "                               'taunted': 1,\n",
       "                               'by': 332,\n",
       "                               'This': 136,\n",
       "                               'always': 23,\n",
       "                               'smiling': 1,\n",
       "                               'lad': 1,\n",
       "                               'sunny': 2,\n",
       "                               'disposition': 3,\n",
       "                               'is': 959,\n",
       "                               'our': 77,\n",
       "                               'new': 103,\n",
       "                               'Junior': 33,\n",
       "                               'Canada': 6,\n",
       "                               '--': 295,\n",
       "                               'Henri': 12,\n",
       "                               'De': 4,\n",
       "                               'Courcy': 3,\n",
       "                               '.': 3453,\n",
       "                               'Far': 2,\n",
       "                               'discouraging': 3,\n",
       "                               'urge': 2,\n",
       "                               'him': 49,\n",
       "                               'on': 515,\n",
       "                               'greater': 28,\n",
       "                               'accomplishments': 1,\n",
       "                               'Instead': 8,\n",
       "                               'admonishing': 1,\n",
       "                               'let': 13,\n",
       "                               'weights': 2,\n",
       "                               'alone': 16,\n",
       "                               'they': 177,\n",
       "                               'personally': 2,\n",
       "                               'took': 15,\n",
       "                               'that': 514,\n",
       "                               'master': 5,\n",
       "                               'Montreal': 3,\n",
       "                               'bodybuilding': 1,\n",
       "                               'authority': 6,\n",
       "                               'Professor': 2,\n",
       "                               'Roland': 2,\n",
       "                               'Claude': 6,\n",
       "                               'And': 34,\n",
       "                               \"couldn't\": 2,\n",
       "                               'entrusted': 1,\n",
       "                               'better': 46,\n",
       "                               'hands': 21,\n",
       "                               'le': 1,\n",
       "                               'professeur': 1,\n",
       "                               'knows': 13,\n",
       "                               'sterno-cleido': 1,\n",
       "                               'mastoideus': 1,\n",
       "                               'neck': 6,\n",
       "                               'right': 65,\n",
       "                               'down': 46,\n",
       "                               'tibialis': 1,\n",
       "                               'anticus': 1,\n",
       "                               'leg': 11,\n",
       "                               'still': 45,\n",
       "                               'just': 67,\n",
       "                               'what': 78,\n",
       "                               'exercises': 7,\n",
       "                               'work': 87,\n",
       "                               'best': 51,\n",
       "                               'for': 776,\n",
       "                               'them': 127,\n",
       "                               'Weider': 6,\n",
       "                               'principles': 8,\n",
       "                               'combine': 5,\n",
       "                               'fast': 7,\n",
       "                               'muscle': 10,\n",
       "                               \"That's\": 3,\n",
       "                               'good': 96,\n",
       "                               'professor': 9,\n",
       "                               'teaches': 1,\n",
       "                               'only': 121,\n",
       "                               'methods': 11,\n",
       "                               'famous': 16,\n",
       "                               'Health': 2,\n",
       "                               'Studio': 1,\n",
       "                               'located': 12,\n",
       "                               '1821': 2,\n",
       "                               'Mt.': 1,\n",
       "                               'Royal': 4,\n",
       "                               'East': 6,\n",
       "                               'Undoubtedly': 1,\n",
       "                               'read': 8,\n",
       "                               'case': 9,\n",
       "                               'histories': 1,\n",
       "                               'some': 89,\n",
       "                               'prize-winning': 1,\n",
       "                               'pupils': 2,\n",
       "                               'every': 47,\n",
       "                               'pupil': 1,\n",
       "                               'physique': 1,\n",
       "                               'title': 10,\n",
       "                               'kind': 15,\n",
       "                               'other': 129,\n",
       "                               \"There's\": 6,\n",
       "                               'Gaetan': 1,\n",
       "                               \"D'Amours\": 1,\n",
       "                               'newest': 3,\n",
       "                               'Jean-Paul': 1,\n",
       "                               'Senesac': 1,\n",
       "                               'whose': 14,\n",
       "                               'story': 6,\n",
       "                               'appeared': 7,\n",
       "                               'here': 24,\n",
       "                               'two': 116,\n",
       "                               'issues': 3,\n",
       "                               'ago': 23,\n",
       "                               'Jack': 1,\n",
       "                               'Boissoneault': 1,\n",
       "                               'was': 265,\n",
       "                               'us': 23,\n",
       "                               'last': 22,\n",
       "                               'month': 10,\n",
       "                               'Charles': 1,\n",
       "                               'Harve': 1,\n",
       "                               'recently': 11,\n",
       "                               'won': 9,\n",
       "                               'Most': 17,\n",
       "                               'Muscular': 1,\n",
       "                               'Man': 3,\n",
       "                               'subdivision': 1,\n",
       "                               'award': 3,\n",
       "                               'event': 3,\n",
       "                               'host': 4,\n",
       "                               'others': 22,\n",
       "                               'Yesiree': 1,\n",
       "                               'Now': 14,\n",
       "                               'when': 119,\n",
       "                               '12': 17,\n",
       "                               \"4'\": 1,\n",
       "                               \"10''\": 3,\n",
       "                               'tall': 3,\n",
       "                               'weighed': 2,\n",
       "                               'astounding': 1,\n",
       "                               '72': 3,\n",
       "                               'pounds': 11,\n",
       "                               'greatest': 8,\n",
       "                               'desire': 2,\n",
       "                               'pack': 1,\n",
       "                               'weight': 25,\n",
       "                               'About': 4,\n",
       "                               'began': 5,\n",
       "                               'reading': 7,\n",
       "                               'Muscle': 1,\n",
       "                               'Builder': 2,\n",
       "                               'learned': 11,\n",
       "                               'way': 76,\n",
       "                               'gaining': 2,\n",
       "                               'Seeing': 1,\n",
       "                               'so': 106,\n",
       "                               'many': 110,\n",
       "                               'illustrations': 2,\n",
       "                               'testimonials': 1,\n",
       "                               'value': 9,\n",
       "                               'Quick-Wate': 1,\n",
       "                               'Super-Protein': 1,\n",
       "                               'wonder-working': 1,\n",
       "                               'food': 9,\n",
       "                               'supplements': 3,\n",
       "                               'decided': 3,\n",
       "                               'try': 12,\n",
       "                               'see': 36,\n",
       "                               'could': 58,\n",
       "                               'Well': 2,\n",
       "                               'sir': 1,\n",
       "                               'did': 25,\n",
       "                               'real': 18,\n",
       "                               'great': 42,\n",
       "                               'For': 81,\n",
       "                               'almost': 25,\n",
       "                               'less': 48,\n",
       "                               'than': 159,\n",
       "                               'it': 476,\n",
       "                               'takes': 16,\n",
       "                               \"Henri's\": 2,\n",
       "                               'bodyweight': 1,\n",
       "                               'increasing': 6,\n",
       "                               'rapidly': 1,\n",
       "                               'Of': 22,\n",
       "                               'course': 33,\n",
       "                               'exercising': 2,\n",
       "                               \"He's\": 2,\n",
       "                               'crazy': 2,\n",
       "                               'water': 80,\n",
       "                               'skiing': 2,\n",
       "                               'swimming': 5,\n",
       "                               'this': 305,\n",
       "                               'vigorous': 4,\n",
       "                               'exercise': 20,\n",
       "                               'conjunction': 2,\n",
       "                               'added': 17,\n",
       "                               'packed': 2,\n",
       "                               'solid': 7,\n",
       "                               'skinny': 1,\n",
       "                               'frame': 30,\n",
       "                               'shapely': 1,\n",
       "                               'legs': 11,\n",
       "                               'really': 14,\n",
       "                               \"doesn't\": 8,\n",
       "                               'very': 63,\n",
       "                               'much': 81,\n",
       "                               'But': 51,\n",
       "                               'totally': 2,\n",
       "                               'dissatisfied': 1,\n",
       "                               'upper': 13,\n",
       "                               'body': 28,\n",
       "                               'It': 129,\n",
       "                               'muscular': 4,\n",
       "                               'but': 170,\n",
       "                               \"wasn't\": 2,\n",
       "                               'symmetrical': 1,\n",
       "                               'A': 121,\n",
       "                               \"'\": 25,\n",
       "                               'nothing': 16,\n",
       "                               'torso': 3,\n",
       "                               'says': 9,\n",
       "                               'seemed': 7,\n",
       "                               'widen': 1,\n",
       "                               'got': 6,\n",
       "                               'longer': 16,\n",
       "                               'went': 10,\n",
       "                               'once': 22,\n",
       "                               'saw': 17,\n",
       "                               'trouble': 4,\n",
       "                               'knew': 5,\n",
       "                               'how': 40,\n",
       "                               'correct': 8,\n",
       "                               'In': 116,\n",
       "                               'gym': 1,\n",
       "                               'most': 107,\n",
       "                               'knocked': 3,\n",
       "                               'out': 84,\n",
       "                               'equipment': 33,\n",
       "                               'since': 34,\n",
       "                               'Vic': 1,\n",
       "                               'Tanny': 1,\n",
       "                               'specialist': 4,\n",
       "                               'development': 41,\n",
       "                               'long': 70,\n",
       "                               'favored': 1,\n",
       "                               'now-famous': 1,\n",
       "                               'Push-Pull': 9,\n",
       "                               'Super-Set': 8,\n",
       "                               'technique': 12,\n",
       "                               'pressing': 2,\n",
       "                               'pushing': 2,\n",
       "                               'movement': 7,\n",
       "                               'accents': 2,\n",
       "                               'sector': 4,\n",
       "                               'group': 30,\n",
       "                               'specific': 9,\n",
       "                               'followed': 9,\n",
       "                               'pulling': 2,\n",
       "                               'works': 14,\n",
       "                               'opposing': 3,\n",
       "                               'same': 68,\n",
       "                               'So': 15,\n",
       "                               'away': 20,\n",
       "                               'introduced': 10,\n",
       "                               'moon': 2,\n",
       "                               'bench': 4,\n",
       "                               'proceeded': 2,\n",
       "                               'teach': 7,\n",
       "                               'first': 114,\n",
       "                               'consisting': 2,\n",
       "                               'wide-grip': 1,\n",
       "                               'Straight-Arm': 1,\n",
       "                               'Pullover': 2,\n",
       "                               'pull': 6,\n",
       "                               'part': 28,\n",
       "                               'dramatically': 3,\n",
       "                               'widens': 1,\n",
       "                               'ribcage': 1,\n",
       "                               'strongly': 5,\n",
       "                               'affects': 2,\n",
       "                               'back': 39,\n",
       "                               'chest': 9,\n",
       "                               'collar-to-collar': 1,\n",
       "                               'Bench': 7,\n",
       "                               'Press': 8,\n",
       "                               'specifically': 6,\n",
       "                               'build': 26,\n",
       "                               'wide': 24,\n",
       "                               'Reeves-type': 1,\n",
       "                               'gladiator': 1,\n",
       "                               'pecs': 3,\n",
       "                               'while': 31,\n",
       "                               'stimulating': 1,\n",
       "                               'lats': 2,\n",
       "                               'frontal': 2,\n",
       "                               'deltoids': 2,\n",
       "                               'As': 44,\n",
       "                               'can': 268,\n",
       "                               'Super': 1,\n",
       "                               'Set': 5,\n",
       "                               'entire': 14,\n",
       "                               'chest-back-shoulder': 1,\n",
       "                               'area': 64,\n",
       "                               'vigorously': 1,\n",
       "                               'exercised': 2,\n",
       "                               'alternate': 5,\n",
       "                               'sectors': 1,\n",
       "                               'complete': 29,\n",
       "                               'remains': 8,\n",
       "                               'pumped-up': 2,\n",
       "                               'completed': 9,\n",
       "                               'four': 40,\n",
       "                               'Super-Sets': 3,\n",
       "                               'No.': 25,\n",
       "                               '1': 37,\n",
       "                               'allows': 2,\n",
       "                               'five-minute': 1,\n",
       "                               'rest': 9,\n",
       "                               'period': 14,\n",
       "                               'before': 63,\n",
       "                               'starting': 13,\n",
       "                               '2': 37,\n",
       "                               'made': 69,\n",
       "                               'up': 101,\n",
       "                               'similar': 9,\n",
       "                               'done': 35,\n",
       "                               'dumbbells': 1,\n",
       "                               'using': 22,\n",
       "                               'both': 42,\n",
       "                               'flat': 14,\n",
       "                               'benches': 1,\n",
       "                               'The': 458,\n",
       "                               'push': 5,\n",
       "                               'elbows': 1,\n",
       "                               'well': 76,\n",
       "                               'pulled': 7,\n",
       "                               'downward': 2,\n",
       "                               'stretch': 6,\n",
       "                               'pectorals': 1,\n",
       "                               'not': 215,\n",
       "                               'possible': 44,\n",
       "                               'variation': 7,\n",
       "                               'You': 51,\n",
       "                               'need': 44,\n",
       "                               'width': 7,\n",
       "                               'mass': 4,\n",
       "                               'dumbbell': 2,\n",
       "                               'develops': 1,\n",
       "                               'classically': 1,\n",
       "                               'sculptured': 1,\n",
       "                               'outline': 2,\n",
       "                               'Aj': 16,\n",
       "                               'one-dumbbell': 1,\n",
       "                               'Bent-Arm': 1,\n",
       "                               'Note': 9,\n",
       "                               'serratus': 2,\n",
       "                               'are': 508,\n",
       "                               'worked': 16,\n",
       "                               'fine': 25,\n",
       "                               'pin-point': 1,\n",
       "                               'concentration': 2,\n",
       "                               'force': 23,\n",
       "                               'affords': 2,\n",
       "                               'third': 11,\n",
       "                               'widegrip': 1,\n",
       "                               'Pushup': 2,\n",
       "                               'Between': 2,\n",
       "                               'Bars': 1,\n",
       "                               'Moon': 1,\n",
       "                               'Lateral': 1,\n",
       "                               'Raise': 1,\n",
       "                               'bent': 4,\n",
       "                               'arms': 9,\n",
       "                               'manner': 12,\n",
       "                               'pectoral-ribcage': 1,\n",
       "                               'stretcher': 1,\n",
       "                               'ever': 14,\n",
       "                               'invented': 3,\n",
       "                               'true': 12,\n",
       "                               'if': 106,\n",
       "                               'grip': 3,\n",
       "                               'used': 99,\n",
       "                               'achieved': 7,\n",
       "                               \"You'll\": 10,\n",
       "                               'know': 23,\n",
       "                               \"you've\": 6,\n",
       "                               'shoulder': 5,\n",
       "                               'blades': 4,\n",
       "                               'will': 264,\n",
       "                               'touch': 7,\n",
       "                               'designed': 18,\n",
       "                               'piece': 42,\n",
       "                               'apparatus': 7,\n",
       "                               'forces': 23,\n",
       "                               'use': 90,\n",
       "                               'w-i-d-e': 1,\n",
       "                               'He': 41,\n",
       "                               \"can't\": 7,\n",
       "                               'anything': 4,\n",
       "                               'as': 452,\n",
       "                               'also': 100,\n",
       "                               'painful': 1,\n",
       "                               'looks': 17,\n",
       "                               'though': 16,\n",
       "                               'were': 106,\n",
       "                               'having': 16,\n",
       "                               'life': 36,\n",
       "                               \"Claude's\": 1,\n",
       "                               'prescribed': 1,\n",
       "                               'program': 43,\n",
       "                               'single': 9,\n",
       "                               'individual': 27,\n",
       "                               'sets': 11,\n",
       "                               'bit': 15,\n",
       "                               'pause': 1,\n",
       "                               'between': 41,\n",
       "                               'By': 14,\n",
       "                               'chest-back-lat-shoulder': 1,\n",
       "                               'bursting': 2,\n",
       "                               'point': 24,\n",
       "                               'more': 189,\n",
       "                               'pectoral-front': 1,\n",
       "                               'deltoid': 1,\n",
       "                               'shaping': 3,\n",
       "                               'six': 22,\n",
       "                               'Incline': 2,\n",
       "                               'note': 6,\n",
       "                               'high': 47,\n",
       "                               'incline': 1,\n",
       "                               'gives': 15,\n",
       "                               'flare': 1,\n",
       "                               'causing': 2,\n",
       "                               'flow': 10,\n",
       "                               'upward': 3,\n",
       "                               'into': 108,\n",
       "                               'invariably': 2,\n",
       "                               'wins': 5,\n",
       "                               'contests': 3,\n",
       "                               'steel-edged': 1,\n",
       "                               'carved-out-of-solid': 1,\n",
       "                               'rock': 6,\n",
       "                               'champions': 1,\n",
       "                               '3': 36,\n",
       "                               'terrific': 2,\n",
       "                               'mass-building': 1,\n",
       "                               'muscle-shaping': 1,\n",
       "                               'torso-defining': 1,\n",
       "                               'workout': 2,\n",
       "                               'cannot': 23,\n",
       "                               'be': 508,\n",
       "                               'improved': 10,\n",
       "                               'upon': 15,\n",
       "                               'Physique': 1,\n",
       "                               'rarely': 2,\n",
       "                               'size': 34,\n",
       "                               'Rarer': 1,\n",
       "                               'Universe': 2,\n",
       "                               'Herculean': 1,\n",
       "                               'aspects': 2,\n",
       "                               'physical': 15,\n",
       "                               'catch': 5,\n",
       "                               \"judges'\": 1,\n",
       "                               'eyes': 8,\n",
       "                               'rightfully': 2,\n",
       "                               'influence': 4,\n",
       "                               'their': 152,\n",
       "                               'decisions': 2,\n",
       "                               'symmetry': 1,\n",
       "                               'hallmark': 1,\n",
       "                               'champion': 3,\n",
       "                               'superior': 3,\n",
       "                               'definition': 7,\n",
       "                               'thing': 12,\n",
       "                               'acquire': 5,\n",
       "                               'occasional': 1,\n",
       "                               'high-set': 2,\n",
       "                               'high-rep': 2,\n",
       "                               'light-weight': 2,\n",
       "                               'workouts': 3,\n",
       "                               'contest': 4,\n",
       "                               'dramatic': 2,\n",
       "                               'separation': 1,\n",
       "                               'seems': 12,\n",
       "                               'must': 83,\n",
       "                               'carved': 4,\n",
       "                               \"sculptor's\": 1,\n",
       "                               'chisel': 3,\n",
       "                               'something': 9,\n",
       "                               'quite': 19,\n",
       "                               'different': 34,\n",
       "                               'comes': 19,\n",
       "                               'certain': 16,\n",
       "                               'definition-specialization': 2,\n",
       "                               'selects': 1,\n",
       "                               'himself': 14,\n",
       "                               'knowledge': 5,\n",
       "                               'exactly': 10,\n",
       "                               'Often': 4,\n",
       "                               'these': 101,\n",
       "                               'bodybuilders': 2,\n",
       "                               'spectacularly': 1,\n",
       "                               'Because': 11,\n",
       "                               'minority': 1,\n",
       "                               'limited': 10,\n",
       "                               'appeal': 3,\n",
       "                               'soon': 6,\n",
       "                               'find': 41,\n",
       "                               'themselves': 17,\n",
       "                               'limbo': 1,\n",
       "                               'forgotten': 5,\n",
       "                               'Only': 5,\n",
       "                               'discovers': 1,\n",
       "                               'puts': 1,\n",
       "                               'practice': 9,\n",
       "                               'we': 100,\n",
       "                               'reacquainted': 1,\n",
       "                               'again': 25,\n",
       "                               'effective': 13,\n",
       "                               'I': 154,\n",
       "                               'shall': 5,\n",
       "                               'discuss': 1,\n",
       "                               'series': 5,\n",
       "                               'articles': 2,\n",
       "                               'particular': 18,\n",
       "                               'One': 28,\n",
       "                               'Leg': 4,\n",
       "                               'Lunge': 3,\n",
       "                               'Why': 7,\n",
       "                               'even': 61,\n",
       "                               'moment': 5,\n",
       "                               'say': 9,\n",
       "                               'perfectly': 3,\n",
       "                               'everyone': 3,\n",
       "                               'no': 85,\n",
       "                               'matter': 14,\n",
       "                               'whether': 12,\n",
       "                               'short': 16,\n",
       "                               'thigh-bone': 1,\n",
       "                               'lengths': 7,\n",
       "                               'drastically': 4,\n",
       "                               'influences': 1,\n",
       "                               'thighs': 2,\n",
       "                               'hipline': 1,\n",
       "                               'mark': 9,\n",
       "                               'apart': 4,\n",
       "                               'criterion': 1,\n",
       "                               'drama': 1,\n",
       "                               'unforgettable': 1,\n",
       "                               'judges': 4,\n",
       "                               'audiences': 4,\n",
       "                               'alike': 2,\n",
       "                               'facet': 1,\n",
       "                               'prizes': 3,\n",
       "                               'Definition': 1,\n",
       "                               'uppermost': 1,\n",
       "                               'commonly': 2,\n",
       "                               'seen': 16,\n",
       "                               'championship': 1,\n",
       "                               'Olympic': 3,\n",
       "                               'lifters': 4,\n",
       "                               'easily': 19,\n",
       "                               'understandable': 1,\n",
       "                               'split': 4,\n",
       "                               'regular': 10,\n",
       "                               'purely': 2,\n",
       "                               'purposes': 2,\n",
       "                               'Squatting': 1,\n",
       "                               'Curling': 1,\n",
       "                               'Extensor': 1,\n",
       "                               'programs': 10,\n",
       "                               'heavy': 13,\n",
       "                               'needed': 24,\n",
       "                               'Indeed': 2,\n",
       "                               'lighter': 3,\n",
       "                               'extensive': 2,\n",
       "                               'performed': 6,\n",
       "                               'Used': 1,\n",
       "                               'several': 36,\n",
       "                               'reps': 1,\n",
       "                               'twice': 7,\n",
       "                               'each': 82,\n",
       "                               'week': 13,\n",
       "                               'razor-sharp': 1,\n",
       "                               'look': 21,\n",
       "                               'wire': 5,\n",
       "                               'cables': 1,\n",
       "                               'writhing': 1,\n",
       "                               'twisting': 2,\n",
       "                               'under': 52,\n",
       "                               'skin': 4,\n",
       "                               'Really': 1,\n",
       "                               'there': 96,\n",
       "                               'reason': 17,\n",
       "                               'why': 10,\n",
       "                               'should': 73,\n",
       "                               'its': 150,\n",
       "                               'times': 18,\n",
       "                               'following': 17,\n",
       "                               'suggestions': 2,\n",
       "                               'show': 27,\n",
       "                               ':': 197,\n",
       "                               \"It's\": 14,\n",
       "                               'thigh': 3,\n",
       "                               'contraction-extension': 1,\n",
       "                               'places': 20,\n",
       "                               'tension': 8,\n",
       "                               'start': 22,\n",
       "                               'finish': 10,\n",
       "                               'repetition': 1,\n",
       "                               'improves': 7,\n",
       "                               'over-all': 5,\n",
       "                               'balance': 4,\n",
       "                               'control': 13,\n",
       "                               'helps': 3,\n",
       "                               'make': 78,\n",
       "                               'Squats': 1,\n",
       "                               'correctly': 3,\n",
       "                               '4': 23,\n",
       "                               'increases': 3,\n",
       "                               'flexibility': 7,\n",
       "                               '5': 18,\n",
       "                               'speeds': 4,\n",
       "                               'power': 17,\n",
       "                               'advanced': 6,\n",
       "                               'hip': 1,\n",
       "                               'separately': 2,\n",
       "                               'thus': 14,\n",
       "                               'enabling': 2,\n",
       "                               'massive': 3,\n",
       "                               'concentrated': 2,\n",
       "                               'effort': 12,\n",
       "                               'focused': 1,\n",
       "                               'Power': 5,\n",
       "                               'Stands': 3,\n",
       "                               \"here's\": 1,\n",
       "                               'Place': 18,\n",
       "                               'position': 38,\n",
       "                               'adjust': 2,\n",
       "                               'height': 6,\n",
       "                               'correspond': 2,\n",
       "                               'shoulders': 4,\n",
       "                               'deep': 9,\n",
       "                               'Clean': 4,\n",
       "                               'suitably-loaded': 1,\n",
       "                               'across': 17,\n",
       "                               'grasp': 1,\n",
       "                               'bar': 29,\n",
       "                               'against': 23,\n",
       "                               'extend': 3,\n",
       "                               'feet': 34,\n",
       "                               'forward': 13,\n",
       "                               'backward': 3,\n",
       "                               'until': 37,\n",
       "                               'raise': 3,\n",
       "                               'straightening': 1,\n",
       "                               'front': 16,\n",
       "                               'without': 25,\n",
       "                               'moving': 11,\n",
       "                               'When': 45,\n",
       "                               'knee': 1,\n",
       "                               'straight': 7,\n",
       "                               'locked': 3,\n",
       "                               'allow': 12,\n",
       "                               'bend': 4,\n",
       "                               'feel': 12,\n",
       "                               'come': 29,\n",
       "                               'lightly': 5,\n",
       "                               'contact': 8,\n",
       "                               'sides': 32,\n",
       "                               'taken': 19,\n",
       "                               'breather': 1,\n",
       "                               'reverse': 2,\n",
       "                               'previous': 9,\n",
       "                               'now': 61,\n",
       "                               'rear': 9,\n",
       "                               'perform': 3,\n",
       "                               'One-Leg': 1,\n",
       "                               'nutshell': 1,\n",
       "                               'couple': 5,\n",
       "                               'partners': 1,\n",
       "                               'stand': 13,\n",
       "                               'experiments': 12,\n",
       "                               'safety': 18,\n",
       "                               'begin': 8,\n",
       "                               'light': 32,\n",
       "                               'become': 30,\n",
       "                               'accustomed': 2,\n",
       "                               'balance-wise': 1,\n",
       "                               'Oh': 1,\n",
       "                               'wobble': 1,\n",
       "                               'weave': 3,\n",
       "                               'worry': 3,\n",
       "                               'Before': 5,\n",
       "                               'experiment': 4,\n",
       "                               'ended': 1,\n",
       "                               'big': 21,\n",
       "                               'improvement': 4,\n",
       "                               'raising': 1,\n",
       "                               'lowering': 1,\n",
       "                               'yourself': 12,\n",
       "                               'veteran': 1,\n",
       "                               'Although': 4,\n",
       "                               'suggested': 6,\n",
       "                               'hold': 15,\n",
       "                               \"there's\": 6,\n",
       "                               \"shouldn't\": 1,\n",
       "                               'held': 12,\n",
       "                               'Squat-style': 1,\n",
       "                               'leg-split': 1,\n",
       "                               'would': 78,\n",
       "                               'benefit': 13,\n",
       "                               'enormously': 1,\n",
       "                               'practicing': 1,\n",
       "                               'variations': 3,\n",
       "                               'providing': 10,\n",
       "                               'remember': 5,\n",
       "                               'left': 39,\n",
       "                               'beautiful': 10,\n",
       "                               'bed': 6,\n",
       "                               'pansies': 9,\n",
       "                               \"I've\": 3,\n",
       "                               'South': 6,\n",
       "                               'Dakota': 2,\n",
       "                               'yard': 7,\n",
       "                               'sizzling': 1,\n",
       "                               'day': 50,\n",
       "                               'Pansies': 4,\n",
       "                               'supposed': 2,\n",
       "                               'cool': 15,\n",
       "                               'velvety': 2,\n",
       "                               'flowers': 9,\n",
       "                               'healthy': 5,\n",
       "                               'perky': 1,\n",
       "                               'glaring': 1,\n",
       "                               'sun': 13,\n",
       "                               'sought': 1,\n",
       "                               'gardener': 2,\n",
       "                               'asked': 9,\n",
       "                               'produce': 9,\n",
       "                               'such': 88,\n",
       "                               'beauties': 2,\n",
       "                               'weather': 14,\n",
       "                               'puzzled': 1,\n",
       "                               'my': 39,\n",
       "                               'question': 12,\n",
       "                               'love': 6,\n",
       "                               'said': 11,\n",
       "                               'talked': 2,\n",
       "                               'convinced': 4,\n",
       "                               'became': 12,\n",
       "                               'riotous': 1,\n",
       "                               'blooming': 6,\n",
       "                               'expressed': 3,\n",
       "                               'intelligent': 1,\n",
       "                               'care': 8,\n",
       "                               'planted': 1,\n",
       "                               'pansy': 6,\n",
       "                               'seeds': 8,\n",
       "                               'buying': 7,\n",
       "                               'These': 40,\n",
       "                               'specialists': 2,\n",
       "                               'deal': 9,\n",
       "                               'improve': 10,\n",
       "                               'health': 8,\n",
       "                               'plants': 18,\n",
       "                               'resulting': 6,\n",
       "                               'Their': 5,\n",
       "                               'half': 24,\n",
       "                               'unimproved': 1,\n",
       "                               'strains': 1,\n",
       "                               'own': 36,\n",
       "                               'Occasionally': 1,\n",
       "                               'unusual': 8,\n",
       "                               'flower': 2,\n",
       "                               'wanted': 4,\n",
       "                               'told': 2,\n",
       "                               'me': 16,\n",
       "                               'run': 23,\n",
       "                               'buy': 14,\n",
       "                               'fresh': 9,\n",
       "                               'dealer': 11,\n",
       "                               'working': 24,\n",
       "                               'His': 20,\n",
       "                               'soil': 8,\n",
       "                               'special': 16,\n",
       "                               'prairie': 1,\n",
       "                               'land': 18,\n",
       "                               'harrowed': 1,\n",
       "                               'compost': 3,\n",
       "                               'loose': 7,\n",
       "                               'spongy': 1,\n",
       "                               'brown-black': 1,\n",
       "                               'fingered': 1,\n",
       "                               'feeling': 2,\n",
       "                               'adequacy': 1,\n",
       "                               'texture': 3,\n",
       "                               'tilth': 1,\n",
       "                               \"isn't\": 7,\n",
       "                               'easy': 19,\n",
       "                               'describe': 4,\n",
       "                               'fingers': 4,\n",
       "                               'Nothing': 1,\n",
       "                               'easier': 12,\n",
       "                               'grow': 9,\n",
       "                               'seed': 4,\n",
       "                               'They': 40,\n",
       "                               'germinate': 2,\n",
       "                               'quickly': 6,\n",
       "                               'tiny': 4,\n",
       "                               'appearing': 1,\n",
       "                               'along': 25,\n",
       "                               'lustily': 1,\n",
       "                               'year': 53,\n",
       "                               'sow': 2,\n",
       "                               'temperature': 18,\n",
       "                               'warm': 5,\n",
       "                               '24': 4,\n",
       "                               'hours': 19,\n",
       "                               'seedbed': 2,\n",
       "                               'open': 18,\n",
       "                               'people': 49,\n",
       "                               'successfully': 4,\n",
       "                               'cold': 10,\n",
       "                               'frames': 18,\n",
       "                               'coddled': 2,\n",
       "                               \"they'd\": 1,\n",
       "                               'rather': 29,\n",
       "                               'rugged': 5,\n",
       "                               'moderate': 1,\n",
       "                               'protection': 3,\n",
       "                               'coldest': 2,\n",
       "                               'days': 38,\n",
       "                               'If': 75,\n",
       "                               'sure': 38,\n",
       "                               'ventilation': 2,\n",
       "                               'adequate': 4,\n",
       "                               'garden': 6,\n",
       "                               'sand': 4,\n",
       "                               'encourage': 4,\n",
       "                               'rooting': 2,\n",
       "                               'dig': 1,\n",
       "                               'rake': 1,\n",
       "                               'smooth': 14,\n",
       "                               'wet': 4,\n",
       "                               'fog': 2,\n",
       "                               'spray': 6,\n",
       "                               'Then': 22,\n",
       "                               'cover': 11,\n",
       "                               'sowing': 1,\n",
       "                               'board': 19,\n",
       "                               'keeps': 4,\n",
       "                               'moist': 2,\n",
       "                               'protects': 2,\n",
       "                               'birds': 7,\n",
       "                               'Ants': 1,\n",
       "                               'carry': 8,\n",
       "                               'ant': 1,\n",
       "                               'hills': 5,\n",
       "                               'nearby': 9,\n",
       "                               'sprinkling': 3,\n",
       "                               'green': 19,\n",
       "                               'appears': 4,\n",
       "                               'remove': 7,\n",
       "                               'porous': 2,\n",
       "                               'mulch': 5,\n",
       "                               'applied': 16,\n",
       "                               'roots': 4,\n",
       "                               'soft': 10,\n",
       "                               'during': 31,\n",
       "                               'early': 30,\n",
       "                               'sawdust': 1,\n",
       "                               'hay': 5,\n",
       "                               '6': 19,\n",
       "                               'leaves': 6,\n",
       "                               'thrifty': 1,\n",
       "                               'set': 42,\n",
       "                               'where': 72,\n",
       "                               'remain': 8,\n",
       "                               'Every': 6,\n",
       "                               'transplant': 2,\n",
       "                               'cause': 9,\n",
       "                               'smaller': 15,\n",
       "                               'moral': 1,\n",
       "                               'any': 87,\n",
       "                               'oftener': 1,\n",
       "                               'large': 50,\n",
       "                               'enough': 33,\n",
       "                               'move': 10,\n",
       "                               'put': 28,\n",
       "                               'mine': 2,\n",
       "                               '9': 6,\n",
       "                               'inches': 26,\n",
       "                               'bloom': 6,\n",
       "                               'scoop': 1,\n",
       "                               'pulverized': 1,\n",
       "                               'phosphate': 1,\n",
       "                               'steamed': 1,\n",
       "                               'bone': 4,\n",
       "                               'meal': 6,\n",
       "                               'hole': 17,\n",
       "                               'plant': 28,\n",
       "                               'That': 12,\n",
       "                               'encourages': 2,\n",
       "                               'developed': 15,\n",
       "                               'larger': 23,\n",
       "                               'plentiful': 2,\n",
       "                               'gluttons': 1,\n",
       "                               'doubt': 3,\n",
       "                               'overfeed': 1,\n",
       "                               'spade': 1,\n",
       "                               'lots': 8,\n",
       "                               'lacking': 3,\n",
       "                               'decayed': 1,\n",
       "                               'manure': 3,\n",
       "                               'spread': 7,\n",
       "                               'over': 78,\n",
       "                               'simply': 6,\n",
       "                               'pile': 3,\n",
       "                               ...}),\n",
       "                     'humor': FreqDist({'It': 48,\n",
       "                               'was': 274,\n",
       "                               'among': 7,\n",
       "                               'these': 16,\n",
       "                               'that': 241,\n",
       "                               'Hinkle': 1,\n",
       "                               'identified': 2,\n",
       "                               'a': 505,\n",
       "                               'photograph': 2,\n",
       "                               'of': 515,\n",
       "                               'Barco': 18,\n",
       "                               '!': 82,\n",
       "                               'For': 8,\n",
       "                               'it': 162,\n",
       "                               'seems': 12,\n",
       "                               ',': 1331,\n",
       "                               'fancying': 1,\n",
       "                               'himself': 8,\n",
       "                               \"ladies'\": 2,\n",
       "                               'man': 21,\n",
       "                               '(': 31,\n",
       "                               'and': 512,\n",
       "                               'why': 9,\n",
       "                               'not': 77,\n",
       "                               'after': 19,\n",
       "                               'seven': 4,\n",
       "                               'marriages': 1,\n",
       "                               '?': 152,\n",
       "                               ')': 31,\n",
       "                               'had': 149,\n",
       "                               'listed': 1,\n",
       "                               'for': 150,\n",
       "                               'Mormon': 1,\n",
       "                               'Beard': 1,\n",
       "                               'roles': 3,\n",
       "                               'at': 100,\n",
       "                               'the': 930,\n",
       "                               'instigation': 1,\n",
       "                               'his': 137,\n",
       "                               'fourth': 1,\n",
       "                               'murder': 5,\n",
       "                               'victim': 1,\n",
       "                               'who': 48,\n",
       "                               'said': 87,\n",
       "                               ':': 40,\n",
       "                               '``': 343,\n",
       "                               'With': 4,\n",
       "                               'your': 38,\n",
       "                               'beard': 1,\n",
       "                               'dear': 7,\n",
       "                               'you': 131,\n",
       "                               'ought': 2,\n",
       "                               'to': 463,\n",
       "                               'be': 78,\n",
       "                               'in': 334,\n",
       "                               'movies': 2,\n",
       "                               \"''\": 340,\n",
       "                               'Mills': 5,\n",
       "                               'secured': 1,\n",
       "                               \"Barco's\": 8,\n",
       "                               'from': 59,\n",
       "                               'gentleman': 3,\n",
       "                               'charge': 2,\n",
       "                               'rushed': 2,\n",
       "                               'Hollywood': 5,\n",
       "                               'police': 7,\n",
       "                               'station': 4,\n",
       "                               'report': 1,\n",
       "                               'theft': 2,\n",
       "                               'less': 12,\n",
       "                               'than': 25,\n",
       "                               'five': 9,\n",
       "                               'minutes': 4,\n",
       "                               'later': 5,\n",
       "                               'detectives': 3,\n",
       "                               'with': 129,\n",
       "                               'picture': 7,\n",
       "                               'hand': 8,\n",
       "                               'were': 84,\n",
       "                               'on': 128,\n",
       "                               'trail': 1,\n",
       "                               'Cal': 1,\n",
       "                               '.': 877,\n",
       "                               'On': 2,\n",
       "                               'their': 49,\n",
       "                               'way': 28,\n",
       "                               'they': 70,\n",
       "                               'stopped': 2,\n",
       "                               'every': 13,\n",
       "                               'gas': 1,\n",
       "                               'along': 5,\n",
       "                               'main': 1,\n",
       "                               'boulevards': 1,\n",
       "                               'question': 4,\n",
       "                               'attendants': 1,\n",
       "                               'Finally': 2,\n",
       "                               'Ye': 1,\n",
       "                               'Olde': 1,\n",
       "                               'Gasse': 1,\n",
       "                               'Filling': 1,\n",
       "                               'Station': 1,\n",
       "                               'Avocado': 1,\n",
       "                               'Avenue': 1,\n",
       "                               'learned': 3,\n",
       "                               'having': 8,\n",
       "                               'paused': 1,\n",
       "                               'get': 25,\n",
       "                               'oil': 3,\n",
       "                               'car': 7,\n",
       "                               'asked': 17,\n",
       "                               'about': 36,\n",
       "                               'route': 1,\n",
       "                               'San': 2,\n",
       "                               'Diego': 1,\n",
       "                               'They': 28,\n",
       "                               'headed': 1,\n",
       "                               'direction': 1,\n",
       "                               'Juan': 1,\n",
       "                               'Capistrano': 1,\n",
       "                               'By-the-Sea': 1,\n",
       "                               'came': 12,\n",
       "                               'upon': 8,\n",
       "                               'sitting': 3,\n",
       "                               'quaint': 1,\n",
       "                               'old': 14,\n",
       "                               'Spanish': 1,\n",
       "                               'Mission': 1,\n",
       "                               'Drive-in': 1,\n",
       "                               'eating': 1,\n",
       "                               'hot': 5,\n",
       "                               'tamale': 1,\n",
       "                               'At': 7,\n",
       "                               'moment': 10,\n",
       "                               'back': 16,\n",
       "                               'road': 2,\n",
       "                               'so': 52,\n",
       "                               'he': 146,\n",
       "                               \"didn't\": 18,\n",
       "                               'see': 12,\n",
       "                               'close': 4,\n",
       "                               'convertible': 1,\n",
       "                               'which': 62,\n",
       "                               'quest': 1,\n",
       "                               'stolen': 1,\n",
       "                               'lap': 3,\n",
       "                               'rug': 1,\n",
       "                               'proceeded': 4,\n",
       "                               'search': 4,\n",
       "                               'The': 97,\n",
       "                               'robe': 1,\n",
       "                               'however': 7,\n",
       "                               'missing': 2,\n",
       "                               'by': 69,\n",
       "                               'time': 43,\n",
       "                               'disposed': 2,\n",
       "                               'pawnshop': 1,\n",
       "                               'Glendale': 1,\n",
       "                               'placed': 1,\n",
       "                               'under': 8,\n",
       "                               'arrest': 2,\n",
       "                               'without': 9,\n",
       "                               'informing': 1,\n",
       "                               'him': 48,\n",
       "                               'nature': 3,\n",
       "                               'took': 10,\n",
       "                               'questioning': 1,\n",
       "                               'Thus': 2,\n",
       "                               'apprehended': 1,\n",
       "                               'mere': 2,\n",
       "                               'larceny': 1,\n",
       "                               'now': 14,\n",
       "                               'began': 7,\n",
       "                               'suspect': 1,\n",
       "                               'one': 64,\n",
       "                               'or': 66,\n",
       "                               'another': 11,\n",
       "                               'murders': 1,\n",
       "                               'been': 39,\n",
       "                               'uncovered': 1,\n",
       "                               'During': 3,\n",
       "                               'return': 3,\n",
       "                               'trip': 2,\n",
       "                               'kept': 4,\n",
       "                               'muttering': 2,\n",
       "                               'meaningless': 1,\n",
       "                               'phrases': 1,\n",
       "                               'such': 30,\n",
       "                               'as': 116,\n",
       "                               \"They're\": 5,\n",
       "                               'sand': 3,\n",
       "                               'dunes': 2,\n",
       "                               'better': 5,\n",
       "                               'off': 15,\n",
       "                               'I': 239,\n",
       "                               'tell': 9,\n",
       "                               'saved': 3,\n",
       "                               'souls': 1,\n",
       "                               'detective': 1,\n",
       "                               'commenting': 1,\n",
       "                               'behavior': 1,\n",
       "                               'felt': 7,\n",
       "                               'merely': 3,\n",
       "                               'belonged': 2,\n",
       "                               'myriad': 1,\n",
       "                               'citizens': 1,\n",
       "                               'our': 30,\n",
       "                               'community': 1,\n",
       "                               'are': 44,\n",
       "                               'mentally': 1,\n",
       "                               'unhinged': 1,\n",
       "                               '--': 67,\n",
       "                               'more': 36,\n",
       "                               'harmless': 1,\n",
       "                               'nut': 3,\n",
       "                               'However': 3,\n",
       "                               'while': 13,\n",
       "                               'cell': 3,\n",
       "                               'awaiting': 1,\n",
       "                               'trial': 5,\n",
       "                               'fit': 3,\n",
       "                               'apprehension': 2,\n",
       "                               'made': 23,\n",
       "                               'an': 75,\n",
       "                               'attempt': 6,\n",
       "                               'take': 5,\n",
       "                               'own': 12,\n",
       "                               'life': 12,\n",
       "                               'failed': 1,\n",
       "                               'because': 16,\n",
       "                               'when': 52,\n",
       "                               'endeavoring': 1,\n",
       "                               'cut': 4,\n",
       "                               'wrists': 1,\n",
       "                               'this': 59,\n",
       "                               'murderer': 2,\n",
       "                               'women': 4,\n",
       "                               'fainted': 1,\n",
       "                               'sight': 1,\n",
       "                               'blood': 1,\n",
       "                               'jail': 3,\n",
       "                               'authorities': 1,\n",
       "                               'attaching': 2,\n",
       "                               'no': 25,\n",
       "                               'particular': 3,\n",
       "                               'significance': 1,\n",
       "                               'episode': 1,\n",
       "                               'offered': 1,\n",
       "                               'whisky': 1,\n",
       "                               'revive': 2,\n",
       "                               ';': 98,\n",
       "                               'but': 67,\n",
       "                               'fellow': 3,\n",
       "                               'lifelong': 1,\n",
       "                               'teetotaler': 1,\n",
       "                               'refused': 4,\n",
       "                               'thought': 14,\n",
       "                               'matter': 8,\n",
       "                               'Then': 16,\n",
       "                               'District': 2,\n",
       "                               'Attorney': 2,\n",
       "                               'Welch': 14,\n",
       "                               'entered': 5,\n",
       "                               'case': 12,\n",
       "                               'A': 18,\n",
       "                               'vaulting': 1,\n",
       "                               'ambition': 3,\n",
       "                               'eye': 3,\n",
       "                               'mayorship': 1,\n",
       "                               'Los': 5,\n",
       "                               'Angeles': 4,\n",
       "                               'nothing': 5,\n",
       "                               'ever': 9,\n",
       "                               'escaped': 1,\n",
       "                               'might': 8,\n",
       "                               'possibly': 1,\n",
       "                               'lead': 4,\n",
       "                               'personal': 4,\n",
       "                               'publicity': 3,\n",
       "                               'reported': 3,\n",
       "                               \"Welch's\": 6,\n",
       "                               'office': 4,\n",
       "                               'thief': 1,\n",
       "                               'city': 3,\n",
       "                               'attempted': 1,\n",
       "                               'suicide': 2,\n",
       "                               'wanted': 7,\n",
       "                               'know': 16,\n",
       "                               'No': 11,\n",
       "                               'knew': 9,\n",
       "                               'Now': 14,\n",
       "                               'pet': 2,\n",
       "                               'theory': 3,\n",
       "                               'everyone': 4,\n",
       "                               'is': 117,\n",
       "                               'guilty': 1,\n",
       "                               'breaking': 1,\n",
       "                               'laws': 1,\n",
       "                               'gets': 2,\n",
       "                               'caught': 5,\n",
       "                               'looked': 13,\n",
       "                               'like': 34,\n",
       "                               'opportunity': 1,\n",
       "                               'put': 13,\n",
       "                               'test': 1,\n",
       "                               'So': 4,\n",
       "                               'paid': 2,\n",
       "                               'call': 6,\n",
       "                               'chat': 1,\n",
       "                               'stating': 1,\n",
       "                               'bluntly': 2,\n",
       "                               \"we've\": 1,\n",
       "                               'got': 11,\n",
       "                               'goods': 1,\n",
       "                               \"It'll\": 1,\n",
       "                               'lot': 7,\n",
       "                               'if': 32,\n",
       "                               'come': 6,\n",
       "                               'clean': 2,\n",
       "                               'first': 13,\n",
       "                               'evasive': 2,\n",
       "                               'shifty': 1,\n",
       "                               'But': 34,\n",
       "                               'relentless': 1,\n",
       "                               'pursuit': 1,\n",
       "                               'subject': 2,\n",
       "                               'finally': 5,\n",
       "                               'broke': 2,\n",
       "                               'started': 8,\n",
       "                               'confessing': 1,\n",
       "                               'By': 4,\n",
       "                               'reached': 4,\n",
       "                               'count': 4,\n",
       "                               'three': 6,\n",
       "                               'situation': 2,\n",
       "                               'seemed': 15,\n",
       "                               'almost': 8,\n",
       "                               'too': 19,\n",
       "                               'good': 11,\n",
       "                               'true': 5,\n",
       "                               'dreamed': 1,\n",
       "                               'would': 56,\n",
       "                               'throw': 4,\n",
       "                               'into': 35,\n",
       "                               'headlines': 3,\n",
       "                               'all': 60,\n",
       "                               'over': 27,\n",
       "                               'America': 3,\n",
       "                               'hero': 2,\n",
       "                               'great': 9,\n",
       "                               'summoned': 1,\n",
       "                               'officials': 1,\n",
       "                               'chagrin': 1,\n",
       "                               'captain': 5,\n",
       "                               'pooh-poohed': 1,\n",
       "                               'credulity': 1,\n",
       "                               'confession': 2,\n",
       "                               'clearly': 4,\n",
       "                               'required': 1,\n",
       "                               'strength': 1,\n",
       "                               'bravado': 1,\n",
       "                               'daring': 1,\n",
       "                               'commit': 1,\n",
       "                               'That': 11,\n",
       "                               'worm': 2,\n",
       "                               'Ridiculous': 1,\n",
       "                               'since': 11,\n",
       "                               'glint': 1,\n",
       "                               'spirit': 4,\n",
       "                               'lit': 1,\n",
       "                               'eyes': 10,\n",
       "                               'His': 8,\n",
       "                               'manhood': 2,\n",
       "                               'attacked': 2,\n",
       "                               'He': 49,\n",
       "                               'stiffened': 1,\n",
       "                               'rose': 1,\n",
       "                               'feet': 8,\n",
       "                               \"He'd\": 1,\n",
       "                               'show': 5,\n",
       "                               'them': 49,\n",
       "                               'Is': 4,\n",
       "                               'queried': 1,\n",
       "                               'Well': 5,\n",
       "                               'ten': 5,\n",
       "                               'years': 21,\n",
       "                               \"I've\": 4,\n",
       "                               'murdering': 1,\n",
       "                               'can': 16,\n",
       "                               'bodies': 4,\n",
       "                               'there': 25,\n",
       "                               \"ain't\": 2,\n",
       "                               'four': 8,\n",
       "                               'nor': 5,\n",
       "                               'six': 2,\n",
       "                               \"'em\": 4,\n",
       "                               \"there's\": 1,\n",
       "                               'next': 8,\n",
       "                               'day': 19,\n",
       "                               'derision': 1,\n",
       "                               'organized': 1,\n",
       "                               'what': 36,\n",
       "                               'termed': 1,\n",
       "                               'Wild': 1,\n",
       "                               'Goose': 1,\n",
       "                               'Chase': 1,\n",
       "                               'indeed': 5,\n",
       "                               'incredible': 1,\n",
       "                               'anyone': 6,\n",
       "                               'could': 30,\n",
       "                               'go': 10,\n",
       "                               'committing': 1,\n",
       "                               'even': 38,\n",
       "                               'searching': 2,\n",
       "                               'party': 7,\n",
       "                               'consisted': 1,\n",
       "                               'policemen': 2,\n",
       "                               'shovels': 2,\n",
       "                               'newspaper': 10,\n",
       "                               'reporters': 1,\n",
       "                               'cameramen': 1,\n",
       "                               'state': 5,\n",
       "                               'gone': 5,\n",
       "                               'never': 16,\n",
       "                               'assumed': 3,\n",
       "                               'matter-of-factness': 1,\n",
       "                               'remained': 3,\n",
       "                               'principal': 2,\n",
       "                               'attitude': 1,\n",
       "                               'directed': 1,\n",
       "                               'cortege': 1,\n",
       "                               'autos': 1,\n",
       "                               'near': 2,\n",
       "                               'Santa': 1,\n",
       "                               'Monica': 1,\n",
       "                               'Stopping': 1,\n",
       "                               'cars': 1,\n",
       "                               'fork': 1,\n",
       "                               'out': 44,\n",
       "                               'paced': 2,\n",
       "                               'certain': 8,\n",
       "                               'distance': 2,\n",
       "                               'spot': 1,\n",
       "                               'between': 3,\n",
       "                               'two': 25,\n",
       "                               'shrub-covered': 1,\n",
       "                               'hills': 1,\n",
       "                               'indicated': 1,\n",
       "                               'location': 2,\n",
       "                               'Orders': 1,\n",
       "                               'given': 6,\n",
       "                               'dig': 1,\n",
       "                               'Nothing': 2,\n",
       "                               'found': 12,\n",
       "                               'worried': 3,\n",
       "                               'chortled': 1,\n",
       "                               'boys': 3,\n",
       "                               'cracked': 1,\n",
       "                               'jokes': 2,\n",
       "                               'again': 14,\n",
       "                               'pride': 2,\n",
       "                               'aroused': 2,\n",
       "                               'greater': 2,\n",
       "                               'precision': 2,\n",
       "                               'little': 25,\n",
       "                               'left': 8,\n",
       "                               'quibs': 1,\n",
       "                               'gibes': 1,\n",
       "                               'digging': 1,\n",
       "                               'edge': 1,\n",
       "                               'remarking': 1,\n",
       "                               'nice': 8,\n",
       "                               'picnic': 1,\n",
       "                               'struck': 2,\n",
       "                               'object': 3,\n",
       "                               \"There's\": 3,\n",
       "                               'something': 16,\n",
       "                               'here': 7,\n",
       "                               'Said': 1,\n",
       "                               'digger': 2,\n",
       "                               'Joking': 1,\n",
       "                               'gathered': 1,\n",
       "                               'around': 15,\n",
       "                               'thrusting': 1,\n",
       "                               'shovel': 2,\n",
       "                               'raised': 2,\n",
       "                               'view': 1,\n",
       "                               'package': 1,\n",
       "                               'crudely': 1,\n",
       "                               'wrapped': 3,\n",
       "                               \"murderer's\": 1,\n",
       "                               'sport': 1,\n",
       "                               'shirts': 1,\n",
       "                               'Although': 2,\n",
       "                               'fragment': 1,\n",
       "                               \"victim's\": 1,\n",
       "                               'remains': 2,\n",
       "                               'enough': 11,\n",
       "                               'wild': 1,\n",
       "                               'delight': 2,\n",
       "                               'elation': 1,\n",
       "                               'grew': 2,\n",
       "                               'disclosures': 1,\n",
       "                               'brought': 7,\n",
       "                               'light': 7,\n",
       "                               'reward': 1,\n",
       "                               'did': 23,\n",
       "                               'truly': 3,\n",
       "                               'become': 9,\n",
       "                               'hour': 5,\n",
       "                               'everything': 5,\n",
       "                               'followed': 3,\n",
       "                               'procedure': 1,\n",
       "                               'Justice': 1,\n",
       "                               'new': 14,\n",
       "                               'triumph': 1,\n",
       "                               'went': 15,\n",
       "                               'head': 12,\n",
       "                               'increased': 2,\n",
       "                               'apparent': 2,\n",
       "                               'cahoots': 1,\n",
       "                               'Marshall': 2,\n",
       "                               'use': 10,\n",
       "                               'power': 7,\n",
       "                               'D.A.': 2,\n",
       "                               'drag': 1,\n",
       "                               'possible': 3,\n",
       "                               'sensation': 1,\n",
       "                               'Every': 1,\n",
       "                               'scandal': 1,\n",
       "                               'provide': 3,\n",
       "                               'copy': 1,\n",
       "                               \"Marshall's\": 1,\n",
       "                               'pen': 1,\n",
       "                               'thus': 3,\n",
       "                               'mean': 7,\n",
       "                               'both': 9,\n",
       "                               'cynics': 1,\n",
       "                               'waiting': 3,\n",
       "                               'impatience': 1,\n",
       "                               'dramatic': 1,\n",
       "                               'Viola': 11,\n",
       "                               'called': 15,\n",
       "                               'stand': 2,\n",
       "                               'Once': 2,\n",
       "                               'devilish': 1,\n",
       "                               'cleverness': 1,\n",
       "                               \"Viola's\": 4,\n",
       "                               'Multiple': 1,\n",
       "                               'Romances': 1,\n",
       "                               'Lake': 2,\n",
       "                               'Addict': 1,\n",
       "                               'Downfall': 1,\n",
       "                               'Another': 7,\n",
       "                               'Film': 1,\n",
       "                               'Idol': 1,\n",
       "                               'fine': 2,\n",
       "                               'willing': 1,\n",
       "                               'walk': 2,\n",
       "                               \"mayor's\": 1,\n",
       "                               'throne': 1,\n",
       "                               'broken': 2,\n",
       "                               'reputation': 3,\n",
       "                               'helpless': 2,\n",
       "                               'girl': 11,\n",
       "                               'studied': 1,\n",
       "                               'closely': 3,\n",
       "                               'progressed': 2,\n",
       "                               'any': 18,\n",
       "                               'hint': 2,\n",
       "                               'give': 2,\n",
       "                               'me': 56,\n",
       "                               'how': 18,\n",
       "                               'thwarted': 1,\n",
       "                               \"wasn't\": 8,\n",
       "                               'long': 18,\n",
       "                               'before': 10,\n",
       "                               'sensed': 1,\n",
       "                               'deeper': 2,\n",
       "                               'overvaulting': 1,\n",
       "                               'desire': 1,\n",
       "                               'destruction': 2,\n",
       "                               'bitter': 5,\n",
       "                               'resentful': 2,\n",
       "                               'toward': 4,\n",
       "                               'her': 62,\n",
       "                               'personally': 2,\n",
       "                               'dreadful': 2,\n",
       "                               'fear': 5,\n",
       "                               'my': 68,\n",
       "                               'consciousness': 1,\n",
       "                               'perhaps': 6,\n",
       "                               'entertained': 1,\n",
       "                               'aspirations': 1,\n",
       "                               'favors': 1,\n",
       "                               'serious': 2,\n",
       "                               'attained': 2,\n",
       "                               'share': 2,\n",
       "                               'then': 21,\n",
       "                               'superseded': 2,\n",
       "                               'some': 19,\n",
       "                               'luckier': 1,\n",
       "                               'chap': 1,\n",
       "                               'rest': 6,\n",
       "                               'until': 5,\n",
       "                               'tracked': 1,\n",
       "                               'mystery': 3,\n",
       "                               'down': 23,\n",
       "                               'One': 13,\n",
       "                               'year': 8,\n",
       "                               'cocktail': 1,\n",
       "                               'apartment': 3,\n",
       "                               'downtown': 1,\n",
       "                               'hotel': 2,\n",
       "                               'urged': 1,\n",
       "                               'attend': 1,\n",
       "                               'telephone': 5,\n",
       "                               'knowing': 2,\n",
       "                               'host': 5,\n",
       "                               'character': 4,\n",
       "                               'she': 58,\n",
       "                               'She': 23,\n",
       "                               'arrived': 4,\n",
       "                               'late': 5,\n",
       "                               'noted': 3,\n",
       "                               'gentlemen': 1,\n",
       "                               'majority': 1,\n",
       "                               'air': 4,\n",
       "                               'thick': 2,\n",
       "                               'smoke': 1,\n",
       "                               'empty': 2,\n",
       "                               'bottles': 1,\n",
       "                               'evidence': 2,\n",
       "                               'several': 4,\n",
       "                               'guests': 1,\n",
       "                               'somewhat': 3,\n",
       "                               'worse': 2,\n",
       "                               'liquor': 2,\n",
       "                               'Naturally': 1,\n",
       "                               'wish': 3,\n",
       "                               'remain': 1,\n",
       "                               \"couldn't\": 15,\n",
       "                               'leave': 1,\n",
       "                               'soon': 5,\n",
       "                               'arrival': 1,\n",
       "                               'politeness': 1,\n",
       "                               'And': 17,\n",
       "                               'happened': 3,\n",
       "                               'adjacent': 1,\n",
       "                               'couch': 3,\n",
       "                               'taken': 6,\n",
       "                               'refuge': 1,\n",
       "                               'small': 9,\n",
       "                               'table': 4,\n",
       "                               'vase': 1,\n",
       "                               'red': 4,\n",
       "                               'rosebuds': 3,\n",
       "                               'projecting': 1,\n",
       "                               'beneath': 2,\n",
       "                               'pair': 2,\n",
       "                               'Fate': 1,\n",
       "                               'have': 55,\n",
       "                               'As': 17,\n",
       "                               'sat': 10,\n",
       "                               'playful': 1,\n",
       "                               'impulse': 1,\n",
       "                               'overcame': 1,\n",
       "                               'remove': 2,\n",
       "                               'shoes': 6,\n",
       "                               'socks': 3,\n",
       "                               'unidentified': 1,\n",
       "                               'prank': 1,\n",
       "                               'insert': 1,\n",
       "                               'toes': 2,\n",
       "                               'district': 1,\n",
       "                               'attorney': 1,\n",
       "                               'woke': 2,\n",
       "                               'up': 50,\n",
       "                               'emerged': 1,\n",
       "                               'watch': 2,\n",
       "                               'realized': 2,\n",
       "                               'engagement': 1,\n",
       "                               'very': 24,\n",
       "                               'address': 2,\n",
       "                               'meeting': 7,\n",
       "                               'Culture': 1,\n",
       "                               'Forum': 1,\n",
       "                               'Civic': 2,\n",
       "                               'Spirit': 1,\n",
       "                               'Southland': 1,\n",
       "                               'Byzantine': 2,\n",
       "                               'room': 18,\n",
       "                               'where': 15,\n",
       "                               'wife': 10,\n",
       "                               'president': 1,\n",
       "                               'forum': 1,\n",
       "                               'preside': 1,\n",
       "                               \"host's\": 2,\n",
       "                               'bedroom': 2,\n",
       "                               'carefully': 2,\n",
       "                               'brushed': 1,\n",
       "                               'neatly': 2,\n",
       "                               'arranged': 1,\n",
       "                               'hair': 5,\n",
       "                               'painstakingly': 1,\n",
       "                               'selected': 1,\n",
       "                               'hat': 2,\n",
       "                               'many': 15,\n",
       "                               'bed': 2,\n",
       "                               'noting': 1,\n",
       "                               'neither': 3,\n",
       "                               'absence': 2,\n",
       "                               'footwear': 1,\n",
       "                               'presence': 2,\n",
       "                               'usual': 3,\n",
       "                               'dignity': 1,\n",
       "                               'mounted': 1,\n",
       "                               'rostrum': 1,\n",
       "                               'effect': 5,\n",
       "                               'intellectuals': 1,\n",
       "                               'audience': 2,\n",
       "                               'may': 8,\n",
       "                               'well': 10,\n",
       "                               'imagined': 1,\n",
       "                               'incident': 1,\n",
       "                               'aside': 1,\n",
       "                               'reflecting': 1,\n",
       "                               'political': 4,\n",
       "                               'career': 3,\n",
       "                               'wrecked': 1,\n",
       "                               'home': 17,\n",
       "                               'rested': 1,\n",
       "                               'discovered': 4,\n",
       "                               'culprit': 1,\n",
       "                               'vowed': 1,\n",
       "                               'vengeance': 2,\n",
       "                               'chance': 3,\n",
       "                               'innocent': 3,\n",
       "                               'actions': 1,\n",
       "                               'human': 11,\n",
       "                               'tragedies': 1,\n",
       "                               'sometimes': 6,\n",
       "                               'set': 12,\n",
       "                               'motion': 2,\n",
       "                               'days': 6,\n",
       "                               'much': 19,\n",
       "                               'commiserate': 1,\n",
       "                               'should': 7,\n",
       "                               'liked': 3,\n",
       "                               'In': 26,\n",
       "                               'place': 9,\n",
       "                               'difficult': 1,\n",
       "                               'us': 23,\n",
       "                               'meet': 2,\n",
       "                               'We': 18,\n",
       "                               'seen': 3,\n",
       "                               'together': 4,\n",
       "                               'tongue': 2,\n",
       "                               'Scandal': 2,\n",
       "                               'ready': 3,\n",
       "                               'link': 1,\n",
       "                               'names': 5,\n",
       "                               'finds': 1,\n",
       "                               'thing': 13,\n",
       "                               'say': 18,\n",
       "                               'association': 1,\n",
       "                               'invite': 1,\n",
       "                               'house': 13,\n",
       "                               'Mother': 12,\n",
       "                               'snobbishly': 1,\n",
       "                               'receive': 1,\n",
       "                               'Czarship': 1,\n",
       "                               'affected': 1,\n",
       "                               'sense': 2,\n",
       "                               'social': 4,\n",
       "                               'values': 1,\n",
       "                               'reflected': 1,\n",
       "                               'glory': 1,\n",
       "                               'through': 18,\n",
       "                               'opened': 2,\n",
       "                               'doors': 5,\n",
       "                               'Angeles-Pasadena': 1,\n",
       "                               'Society': 3,\n",
       "                               'There': 17,\n",
       "                               'received': 6,\n",
       "                               'scions': 1,\n",
       "                               'aristocratic': 1,\n",
       "                               'lines': 4,\n",
       "                               'dominated': 1,\n",
       "                               'Budweisers': 1,\n",
       "                               'beer': 1,\n",
       "                               'derivation': 1,\n",
       "                               'Chalmers': 1,\n",
       "                               'underwear': 1,\n",
       "                               'origin': 2,\n",
       "                               'Heinzes': 1,\n",
       "                               'whose': 8,\n",
       "                               'forbears': 1,\n",
       "                               'founded': 1,\n",
       "                               'nationally': 1,\n",
       "                               'famous': 3,\n",
       "                               'trade': 1,\n",
       "                               'pickles': 1,\n",
       "                               'hated': 1,\n",
       "                               'being': 16,\n",
       "                               'dragged': 2,\n",
       "                               'salons': 1,\n",
       "                               'aristocrats': 1,\n",
       "                               'insisted': 3,\n",
       "                               'seldom': 1,\n",
       "                               'remotely': 1,\n",
       "                               'connected': 1,\n",
       "                               'cinema': 1,\n",
       "                               'exclusive': 1,\n",
       "                               'midsts': 1,\n",
       "                               'fact': 4,\n",
       "                               'King': 1,\n",
       "                               'Spain': 1,\n",
       "                               'visited': 3,\n",
       "                               'Pickfair': 1,\n",
       "                               'Mary': 1,\n",
       "                               'Doug': 1,\n",
       "                               'beckoned': 1,\n",
       "                               'cross': 1,\n",
       "                               'sacred': 2,\n",
       "                               'barriers': 1,\n",
       "                               'separate': 1,\n",
       "                               'Pasadena': 2,\n",
       "                               'hoi-polloi': 1,\n",
       "                               'far': 7,\n",
       "                               'trump': 1,\n",
       "                               'matrimonial': 1,\n",
       "                               'opportunities': 1,\n",
       "                               'debs': 1,\n",
       "                               'educated': 1,\n",
       "                               'abroad': 1,\n",
       "                               'those': 10,\n",
       "                               'lenient': 1,\n",
       "                               'area': 4,\n",
       "                               'debutante': 1,\n",
       "                               'high': 6,\n",
       "                               'school': 8,\n",
       "                               'last': 16,\n",
       "                               'away': 7,\n",
       "                               'society': 2,\n",
       "                               'chi-chi': 1,\n",
       "                               'order': 5,\n",
       "                               'spend': 1,\n",
       "                               'cosy': 1,\n",
       "                               'evening': 5,\n",
       "                               'chaperon': 1,\n",
       "                               'hotbed': 1,\n",
       "                               'gossip': 1,\n",
       "                               'grown': 2,\n",
       "                               'during': 6,\n",
       "                               'precaution': 1,\n",
       "                               'keep': 8,\n",
       "                               'visit': 3,\n",
       "                               'whispered': 1,\n",
       "                               'world': 11,\n",
       "                               'alas': 1,\n",
       "                               'mother': 12,\n",
       "                               'When': 10,\n",
       "                               'shown': 2,\n",
       "                               'surprise': 3,\n",
       "                               'kitchen': 10,\n",
       "                               'greeted': 1,\n",
       "                               'checked': 1,\n",
       "                               'apron': 1,\n",
       "                               'ladle': 1,\n",
       "                               'explained': 5,\n",
       "                               \"cook's\": 1,\n",
       "                               'night': 11,\n",
       "                               'herself': 7,\n",
       "                               'preparing': 1,\n",
       "                               'dinner': 5,\n",
       "                               'watched': 4,\n",
       "                               'proceedings': 1,\n",
       "                               'roast': 2,\n",
       "                               'chicken': 3,\n",
       "                               'dressing': 2,\n",
       "                               'giblet': 1,\n",
       "                               'gravy': 1,\n",
       "                               'asparagus': 1,\n",
       "                               'peas': 1,\n",
       "                               'sprig': 1,\n",
       "                               'mint': 1,\n",
       "                               'creamed': 1,\n",
       "                               'onions': 1,\n",
       "                               'mashed': 1,\n",
       "                               'potatoes': 1,\n",
       "                               'chosen': 3,\n",
       "                               'prepared': 1,\n",
       "                               'cooked': 1,\n",
       "                               'Hamlet': 1,\n",
       "                               'faced': 1,\n",
       "                               'entirely': 3,\n",
       "                               'different': 5,\n",
       "                               'problem': 5,\n",
       "                               'agony': 1,\n",
       "                               'most': 16,\n",
       "                               'accomplished': 2,\n",
       "                               'adding': 2,\n",
       "                               'Mrs.': 6,\n",
       "                               \"Beige's\": 1,\n",
       "                               'tray': 1,\n",
       "                               'dish': 1,\n",
       "                               'pile': 3,\n",
       "                               'means': 4,\n",
       "                               'repeated': 2,\n",
       "                               'threats': 2,\n",
       "                               'ascending': 1,\n",
       "                               'scale': 1,\n",
       "                               'seeing': 2,\n",
       "                               'girls': 6,\n",
       "                               'dressed': 1,\n",
       "                               'themselves': 4,\n",
       "                               'fashion': 3,\n",
       "                               'making': 5,\n",
       "                               'decision': 2,\n",
       "                               'phone': 8,\n",
       "                               'rang': 1,\n",
       "                               'instantly': 1,\n",
       "                               \"Here's\": 1,\n",
       "                               'household': 1,\n",
       "                               \"can't\": 7,\n",
       "                               'find': 10,\n",
       "                               'children': 20,\n",
       "                               'tired': 2,\n",
       "                               'calling': 2,\n",
       "                               'pick': 2,\n",
       "                               'visiting': 2,\n",
       "                               'grandmother': 1,\n",
       "                               'field': 1,\n",
       "                               'distant': 3,\n",
       "                               'will': 13,\n",
       "                               'magically': 1,\n",
       "                               'within': 2,\n",
       "                               'seconds': 3,\n",
       "                               'Jennie': 3,\n",
       "                               'Miranda': 1,\n",
       "                               'twined': 1,\n",
       "                               'murmuring': 1,\n",
       "                               'endearments': 1,\n",
       "                               'Louise': 2,\n",
       "                               'climbed': 1,\n",
       "                               'onto': 2,\n",
       "                               'stool': 5,\n",
       "                               'clutched': 1,\n",
       "                               'trying': 5,\n",
       "                               'hold': 3,\n",
       "                               'claiming': 1,\n",
       "                               'immediate': 1,\n",
       "                               'attention': 6,\n",
       "                               'grounds': 1,\n",
       "                               'extreme': 2,\n",
       "                               'emergency': 3,\n",
       "                               'Somehow': 1,\n",
       "                               'managing': 1,\n",
       "                               'cool': 1,\n",
       "                               'poised': 1,\n",
       "                               \"Won't\": 1,\n",
       "                               'second': 6,\n",
       "                               'please': 2,\n",
       "                               'covered': 1,\n",
       "                               'mouthpiece': 1,\n",
       "                               'warmth': 1,\n",
       "                               'poise': 1,\n",
       "                               'gave': 5,\n",
       "                               'quick': 3,\n",
       "                               'lecture': 2,\n",
       "                               'crime': 1,\n",
       "                               'punishment': 3,\n",
       "                               'mostly': 1,\n",
       "                               'latter': 2,\n",
       "                               'including': 3,\n",
       "                               \"Devil's\": 1,\n",
       "                               'Island': 1,\n",
       "                               'remoter': 1,\n",
       "                               'reaches': 1,\n",
       "                               'Siberia': 1,\n",
       "                               'promised': 1,\n",
       "                               'illustrate': 1,\n",
       "                               'breathed': 1,\n",
       "                               'till': 2,\n",
       "                               'completed': 1,\n",
       "                               'Speaking': 2,\n",
       "                               'recognizing': 1,\n",
       "                               'caller': 1,\n",
       "                               'resumed': 1,\n",
       "                               'everyday': 1,\n",
       "                               'voice': 7,\n",
       "                               'Soon': 1,\n",
       "                               'we': 32,\n",
       "                               'deep': 2,\n",
       "                               'conversation': 2,\n",
       "                               'interrupted': 1,\n",
       "                               'times': 7,\n",
       "                               'things': 27,\n",
       "                               \"Jennie's\": 1,\n",
       "                               'holding': 1,\n",
       "                               ...}),\n",
       "                     'learned': FreqDist({'1': 241,\n",
       "                               '.': 6773,\n",
       "                               'Introduction': 7,\n",
       "                               'It': 290,\n",
       "                               'has': 429,\n",
       "                               'recently': 16,\n",
       "                               'become': 59,\n",
       "                               'practical': 24,\n",
       "                               'to': 3882,\n",
       "                               'use': 120,\n",
       "                               'the': 11079,\n",
       "                               'radio': 28,\n",
       "                               'emission': 31,\n",
       "                               'of': 7418,\n",
       "                               'moon': 23,\n",
       "                               'and': 4237,\n",
       "                               'planets': 10,\n",
       "                               'as': 1203,\n",
       "                               'a': 3215,\n",
       "                               'new': 127,\n",
       "                               'source': 22,\n",
       "                               'information': 124,\n",
       "                               'about': 212,\n",
       "                               'these': 314,\n",
       "                               'bodies': 8,\n",
       "                               'their': 359,\n",
       "                               'atmospheres': 2,\n",
       "                               'The': 1458,\n",
       "                               'results': 81,\n",
       "                               'present': 85,\n",
       "                               'observations': 27,\n",
       "                               'thermal': 27,\n",
       "                               'are': 991,\n",
       "                               'consistent': 11,\n",
       "                               'with': 1119,\n",
       "                               'very': 151,\n",
       "                               'low': 66,\n",
       "                               'conductivity': 3,\n",
       "                               'surface': 117,\n",
       "                               'layer': 4,\n",
       "                               'which': 832,\n",
       "                               'was': 1114,\n",
       "                               'derived': 22,\n",
       "                               'from': 768,\n",
       "                               'variation': 19,\n",
       "                               'in': 3644,\n",
       "                               'infrared': 6,\n",
       "                               'during': 89,\n",
       "                               'eclipses': 1,\n",
       "                               '(': 803,\n",
       "                               'e.g.': 14,\n",
       "                               ',': 8242,\n",
       "                               'Garstung': 1,\n",
       "                               '1958': 46,\n",
       "                               ')': 800,\n",
       "                               'When': 85,\n",
       "                               'sufficiently': 17,\n",
       "                               'accurate': 8,\n",
       "                               'complete': 41,\n",
       "                               'measurements': 35,\n",
       "                               'available': 71,\n",
       "                               'it': 856,\n",
       "                               'will': 340,\n",
       "                               'be': 1363,\n",
       "                               'possible': 114,\n",
       "                               'set': 71,\n",
       "                               'limits': 14,\n",
       "                               'on': 896,\n",
       "                               'electrical': 9,\n",
       "                               'characteristics': 29,\n",
       "                               'subsurface': 1,\n",
       "                               'materials': 23,\n",
       "                               'Observations': 3,\n",
       "                               'planet': 6,\n",
       "                               'an': 695,\n",
       "                               'extensive': 16,\n",
       "                               'atmosphere': 20,\n",
       "                               'probe': 2,\n",
       "                               'greater': 53,\n",
       "                               'extent': 42,\n",
       "                               'than': 335,\n",
       "                               'those': 137,\n",
       "                               'using': 43,\n",
       "                               'shorter': 3,\n",
       "                               'wave': 15,\n",
       "                               'lengths': 13,\n",
       "                               'should': 171,\n",
       "                               'some': 276,\n",
       "                               'cases': 61,\n",
       "                               'give': 56,\n",
       "                               'otherwise': 13,\n",
       "                               'unobtainable': 1,\n",
       "                               'solid': 15,\n",
       "                               'Radio': 3,\n",
       "                               'Venus': 5,\n",
       "                               'Jupiter': 7,\n",
       "                               'have': 550,\n",
       "                               'already': 41,\n",
       "                               'supplied': 14,\n",
       "                               'unexpected': 4,\n",
       "                               'experimental': 26,\n",
       "                               'data': 105,\n",
       "                               'physical': 30,\n",
       "                               'conditions': 79,\n",
       "                               'observed': 34,\n",
       "                               'intensity': 27,\n",
       "                               'is': 2403,\n",
       "                               'much': 136,\n",
       "                               'higher': 42,\n",
       "                               'expected': 47,\n",
       "                               'although': 50,\n",
       "                               'spectrum': 9,\n",
       "                               'indicated': 37,\n",
       "                               'by': 1172,\n",
       "                               'at': 691,\n",
       "                               'near': 31,\n",
       "                               '3': 116,\n",
       "                               'cm': 11,\n",
       "                               '10': 38,\n",
       "                               'like': 83,\n",
       "                               'that': 1695,\n",
       "                               'black': 9,\n",
       "                               'body': 27,\n",
       "                               '600-degrees': 1,\n",
       "                               'This': 279,\n",
       "                               'result': 57,\n",
       "                               'suggests': 14,\n",
       "                               'high': 99,\n",
       "                               'temperature': 84,\n",
       "                               'there': 284,\n",
       "                               'possibility': 25,\n",
       "                               'radiation': 56,\n",
       "                               'may': 324,\n",
       "                               'combination': 13,\n",
       "                               'both': 133,\n",
       "                               'non-thermal': 2,\n",
       "                               'components': 27,\n",
       "                               'merely': 25,\n",
       "                               'coincidence': 3,\n",
       "                               'For': 112,\n",
       "                               'case': 88,\n",
       "                               'definitely': 3,\n",
       "                               'not': 773,\n",
       "                               'black-body': 4,\n",
       "                               'radiator': 1,\n",
       "                               'seems': 69,\n",
       "                               'likely': 54,\n",
       "                               'reaching': 4,\n",
       "                               'earth': 13,\n",
       "                               'Of': 34,\n",
       "                               'remaining': 10,\n",
       "                               'only': 321,\n",
       "                               'Mars': 5,\n",
       "                               'Saturn': 3,\n",
       "                               'been': 409,\n",
       "                               'sources': 24,\n",
       "                               'twice': 11,\n",
       "                               '3-cm': 2,\n",
       "                               'length': 51,\n",
       "                               'reasonable': 19,\n",
       "                               'agreement': 14,\n",
       "                               'might': 128,\n",
       "                               'predicted': 8,\n",
       "                               'basis': 62,\n",
       "                               'known': 45,\n",
       "                               'limited': 32,\n",
       "                               'but': 404,\n",
       "                               'again': 44,\n",
       "                               'measured': 40,\n",
       "                               'origin': 17,\n",
       "                               'No': 31,\n",
       "                               'attempts': 17,\n",
       "                               'measure': 15,\n",
       "                               'reported': 25,\n",
       "                               'because': 130,\n",
       "                               'distances': 10,\n",
       "                               'small': 107,\n",
       "                               'diameters': 3,\n",
       "                               'or': 895,\n",
       "                               'temperatures': 10,\n",
       "                               'In': 453,\n",
       "                               'spite': 14,\n",
       "                               'this': 714,\n",
       "                               'large': 88,\n",
       "                               'reflectors': 3,\n",
       "                               'improved': 16,\n",
       "                               'amplifying': 1,\n",
       "                               'techniques': 41,\n",
       "                               'now': 101,\n",
       "                               'becoming': 17,\n",
       "                               'make': 90,\n",
       "                               'observe': 6,\n",
       "                               'most': 185,\n",
       "                               'few': 84,\n",
       "                               'years': 87,\n",
       "                               'study': 90,\n",
       "                               'began': 27,\n",
       "                               'detection': 5,\n",
       "                               '1.25-cm': 2,\n",
       "                               'Dicke': 1,\n",
       "                               'Beringer': 1,\n",
       "                               '1946': 5,\n",
       "                               'followed': 27,\n",
       "                               'comprehensive': 6,\n",
       "                               'series': 26,\n",
       "                               'over': 130,\n",
       "                               'three': 103,\n",
       "                               'lunar': 9,\n",
       "                               'cycles': 2,\n",
       "                               'Piddington': 3,\n",
       "                               'Minnett': 3,\n",
       "                               '1949': 6,\n",
       "                               'They': 69,\n",
       "                               'deduced': 4,\n",
       "                               'whole': 55,\n",
       "                               'disk': 14,\n",
       "                               'varied': 15,\n",
       "                               'lunation': 2,\n",
       "                               'roughly': 5,\n",
       "                               'sinusoidal': 2,\n",
       "                               'fashion': 16,\n",
       "                               ';': 1000,\n",
       "                               'amplitude': 5,\n",
       "                               'considerably': 8,\n",
       "                               'less': 109,\n",
       "                               'Pettit': 2,\n",
       "                               'Nicholson': 1,\n",
       "                               '1930': 3,\n",
       "                               '1935': 1,\n",
       "                               'maximum': 36,\n",
       "                               'came': 26,\n",
       "                               '3-1/2': 1,\n",
       "                               'days': 28,\n",
       "                               'after': 95,\n",
       "                               'Full': 3,\n",
       "                               'Moon': 3,\n",
       "                               'contrast': 34,\n",
       "                               'reaches': 7,\n",
       "                               'its': 287,\n",
       "                               'explained': 11,\n",
       "                               'pointing': 5,\n",
       "                               'out': 159,\n",
       "                               'rocklike': 2,\n",
       "                               'up': 133,\n",
       "                               'would': 319,\n",
       "                               'partially': 9,\n",
       "                               'transparent': 1,\n",
       "                               'waves': 3,\n",
       "                               'opaque': 3,\n",
       "                               'could': 159,\n",
       "                               'then': 150,\n",
       "                               'assumed': 36,\n",
       "                               'originate': 2,\n",
       "                               'while': 69,\n",
       "                               'originates': 1,\n",
       "                               'depth': 21,\n",
       "                               'beneath': 4,\n",
       "                               'where': 118,\n",
       "                               'due': 45,\n",
       "                               'solar': 8,\n",
       "                               'reduced': 33,\n",
       "                               'shifted': 7,\n",
       "                               'phase': 35,\n",
       "                               'Since': 57,\n",
       "                               'absorption': 8,\n",
       "                               'material': 71,\n",
       "                               'varies': 8,\n",
       "                               'sample': 46,\n",
       "                               'different': 103,\n",
       "                               'depths': 3,\n",
       "                               'possibly': 7,\n",
       "                               'detect': 3,\n",
       "                               'changes': 51,\n",
       "                               'structure': 35,\n",
       "                               'composition': 9,\n",
       "                               'first': 227,\n",
       "                               'detected': 11,\n",
       "                               '1955': 16,\n",
       "                               'when': 227,\n",
       "                               'Burke': 2,\n",
       "                               'Franklin': 2,\n",
       "                               'identified': 14,\n",
       "                               'interference-like': 1,\n",
       "                               'noise': 11,\n",
       "                               'records': 26,\n",
       "                               '15': 31,\n",
       "                               'meters': 4,\n",
       "                               'sporadic': 4,\n",
       "                               'type': 91,\n",
       "                               'planetary': 7,\n",
       "                               'discussed': 24,\n",
       "                               'chap.': 3,\n",
       "                               '13': 12,\n",
       "                               'Gallet': 1,\n",
       "                               '14': 15,\n",
       "                               'Steady': 1,\n",
       "                               'presumably': 18,\n",
       "                               '3.15': 4,\n",
       "                               '9.4': 1,\n",
       "                               '1956': 11,\n",
       "                               'Mayer': 3,\n",
       "                               'McCullough': 3,\n",
       "                               'Sloanaker': 5,\n",
       "                               'A': 248,\n",
       "                               'B': 37,\n",
       "                               'C': 74,\n",
       "                               '3.75': 1,\n",
       "                               '1957': 19,\n",
       "                               'Drake': 1,\n",
       "                               'Ewen': 1,\n",
       "                               'relatively': 40,\n",
       "                               'short': 46,\n",
       "                               'time': 209,\n",
       "                               'since': 92,\n",
       "                               'early': 46,\n",
       "                               'additional': 32,\n",
       "                               'range': 58,\n",
       "                               '0.8': 4,\n",
       "                               '10.2': 1,\n",
       "                               'wave-length': 2,\n",
       "                               '3.03': 2,\n",
       "                               '68': 1,\n",
       "                               'Aj': 63,\n",
       "                               'observable': 1,\n",
       "                               'polarization': 3,\n",
       "                               'direction': 45,\n",
       "                               'arrival': 3,\n",
       "                               'angular': 10,\n",
       "                               'diameter': 33,\n",
       "                               'any': 209,\n",
       "                               'minute': 10,\n",
       "                               'arc': 31,\n",
       "                               'smaller': 23,\n",
       "                               'highest': 11,\n",
       "                               'resolution': 27,\n",
       "                               'even': 133,\n",
       "                               'under': 107,\n",
       "                               'construction': 23,\n",
       "                               'consequently': 6,\n",
       "                               'regions': 19,\n",
       "                               'cannot': 56,\n",
       "                               'resolved': 3,\n",
       "                               'however': 88,\n",
       "                               'put': 40,\n",
       "                               'useful': 22,\n",
       "                               'observing': 3,\n",
       "                               'interferometers': 1,\n",
       "                               'Measurements': 4,\n",
       "                               'presently': 7,\n",
       "                               'apparatus': 14,\n",
       "                               'sensitivity': 12,\n",
       "                               'remain': 20,\n",
       "                               'difficult': 36,\n",
       "                               'There': 129,\n",
       "                               'specifically': 9,\n",
       "                               'for': 1455,\n",
       "                               'determination': 10,\n",
       "                               'made': 164,\n",
       "                               'NRL': 1,\n",
       "                               '50-foot': 3,\n",
       "                               'reflector': 4,\n",
       "                               'altitude-azimuth-mounted': 1,\n",
       "                               'shown': 64,\n",
       "                               'systematic': 6,\n",
       "                               'change': 63,\n",
       "                               'local': 69,\n",
       "                               'hour': 10,\n",
       "                               'angle': 36,\n",
       "                               'intensities': 3,\n",
       "                               'if': 205,\n",
       "                               'substantial': 19,\n",
       "                               'part': 76,\n",
       "                               'had': 328,\n",
       "                               'linearly': 4,\n",
       "                               'polarized': 2,\n",
       "                               'Recent': 6,\n",
       "                               'interferometer': 1,\n",
       "                               'Radhakrishnan': 1,\n",
       "                               'Roberts': 1,\n",
       "                               '1960': 31,\n",
       "                               '960-mc': 1,\n",
       "                               'region': 27,\n",
       "                               'larger': 48,\n",
       "                               'visible': 9,\n",
       "                               'Other': 21,\n",
       "                               'significant': 24,\n",
       "                               'restricted': 4,\n",
       "                               'concept': 20,\n",
       "                               'apparent': 18,\n",
       "                               'used': 201,\n",
       "                               'describe': 13,\n",
       "                               'received': 21,\n",
       "                               'compared': 23,\n",
       "                               'hypothetical': 5,\n",
       "                               'subtends': 1,\n",
       "                               'same': 152,\n",
       "                               'must': 202,\n",
       "                               'order': 103,\n",
       "                               'equal': 29,\n",
       "                               'does': 95,\n",
       "                               'specify': 6,\n",
       "                               'really': 18,\n",
       "                               'radiates': 1,\n",
       "                               'correspond': 3,\n",
       "                               'emitting': 1,\n",
       "                               'sun': 11,\n",
       "                               'reflected': 8,\n",
       "                               'negligible': 7,\n",
       "                               'centimeter': 2,\n",
       "                               'except': 26,\n",
       "                               'times': 52,\n",
       "                               'exceptional': 8,\n",
       "                               'outbursts': 4,\n",
       "                               'quiescent': 1,\n",
       "                               'level': 77,\n",
       "                               'increase': 75,\n",
       "                               'average': 39,\n",
       "                               'brightness': 14,\n",
       "                               '1-degree': 1,\n",
       "                               'At': 48,\n",
       "                               'meter': 2,\n",
       "                               '10-degrees': 1,\n",
       "                               'nearer': 4,\n",
       "                               'Therefore': 27,\n",
       "                               'neglecting': 3,\n",
       "                               'extreme': 13,\n",
       "                               'cause': 21,\n",
       "                               'sizable': 3,\n",
       "                               'errors': 14,\n",
       "                               'centimeter-': 1,\n",
       "                               'decimeter-wave-length': 1,\n",
       "                               '2': 197,\n",
       "                               '2.1': 3,\n",
       "                               '4.3': 3,\n",
       "                               'mm': 5,\n",
       "                               '75': 6,\n",
       "                               'summarized': 7,\n",
       "                               'Table': 36,\n",
       "                               'also': 215,\n",
       "                               '1.5': 4,\n",
       "                               'optical': 16,\n",
       "                               'Sinton': 1,\n",
       "                               'see': 75,\n",
       "                               '11': 18,\n",
       "                               'Not': 10,\n",
       "                               'all': 341,\n",
       "                               'observers': 7,\n",
       "                               'procedures': 34,\n",
       "                               'assumptions': 12,\n",
       "                               'distribution': 54,\n",
       "                               'reducing': 7,\n",
       "                               'together': 32,\n",
       "                               'differences': 46,\n",
       "                               'methods': 62,\n",
       "                               'calibrating': 1,\n",
       "                               'antennae': 1,\n",
       "                               'receivers': 1,\n",
       "                               'account': 25,\n",
       "                               'disagreement': 3,\n",
       "                               'Coates': 2,\n",
       "                               '1959': 31,\n",
       "                               'antenna': 10,\n",
       "                               'beam': 12,\n",
       "                               \"6'.7\": 1,\n",
       "                               'enough': 55,\n",
       "                               'allow': 17,\n",
       "                               'features': 21,\n",
       "                               'contour': 4,\n",
       "                               'diagrams': 2,\n",
       "                               'phases': 5,\n",
       "                               'These': 107,\n",
       "                               'indicate': 29,\n",
       "                               'maria': 1,\n",
       "                               'heat': 27,\n",
       "                               'more': 373,\n",
       "                               'rapidly': 19,\n",
       "                               'cool': 1,\n",
       "                               'off': 44,\n",
       "                               'do': 133,\n",
       "                               'mountainous': 1,\n",
       "                               'Mare': 1,\n",
       "                               'Imbrium': 1,\n",
       "                               'exception': 11,\n",
       "                               'remains': 18,\n",
       "                               'cooler': 1,\n",
       "                               'surround': 1,\n",
       "                               'suggest': 15,\n",
       "                               'rather': 87,\n",
       "                               'rapid': 18,\n",
       "                               'falloff': 1,\n",
       "                               'latitude': 2,\n",
       "                               'Very': 3,\n",
       "                               '8-mm': 1,\n",
       "                               '22': 13,\n",
       "                               'resultant': 6,\n",
       "                               'width': 6,\n",
       "                               \"2'\": 1,\n",
       "                               'Amenitskii': 1,\n",
       "                               'Noskova': 1,\n",
       "                               'Salomonovich': 1,\n",
       "                               'constant-temperature': 1,\n",
       "                               'contours': 7,\n",
       "                               'smoother': 2,\n",
       "                               'apparently': 19,\n",
       "                               '8': 26,\n",
       "                               'nearly': 27,\n",
       "                               'so': 217,\n",
       "                               'sensitive': 19,\n",
       "                               'Such': 26,\n",
       "                               'high-resolution': 1,\n",
       "                               'needed': 25,\n",
       "                               'several': 67,\n",
       "                               'can': 365,\n",
       "                               'properly': 10,\n",
       "                               'interpreted': 9,\n",
       "                               '10.3': 1,\n",
       "                               'previously': 26,\n",
       "                               'published': 22,\n",
       "                               'briefly': 8,\n",
       "                               'described': 56,\n",
       "                               'were': 633,\n",
       "                               'obtained': 49,\n",
       "                               'spread': 10,\n",
       "                               'interval': 10,\n",
       "                               'May': 12,\n",
       "                               'June': 9,\n",
       "                               '19': 8,\n",
       "                               'U.': 9,\n",
       "                               'S.': 15,\n",
       "                               'Naval': 3,\n",
       "                               'Research': 8,\n",
       "                               'Laboratory': 3,\n",
       "                               'Washington': 13,\n",
       "                               'half-intensity': 2,\n",
       "                               \"9'\": 1,\n",
       "                               'subtended': 1,\n",
       "                               'included': 22,\n",
       "                               'entire': 37,\n",
       "                               'main': 29,\n",
       "                               'side': 37,\n",
       "                               'lobes': 1,\n",
       "                               'patterns': 18,\n",
       "                               'power': 59,\n",
       "                               'gain': 35,\n",
       "                               'peak': 8,\n",
       "                               'absolute': 6,\n",
       "                               'ratio': 15,\n",
       "                               'drift': 8,\n",
       "                               'scan': 1,\n",
       "                               'across': 20,\n",
       "                               'assuming': 8,\n",
       "                               'sky': 2,\n",
       "                               'found': 117,\n",
       "                               'graphical': 1,\n",
       "                               'integration': 8,\n",
       "                               'directivity': 1,\n",
       "                               'diagram': 2,\n",
       "                               '0.85': 1,\n",
       "                               'good': 44,\n",
       "                               'approximation': 6,\n",
       "                               'center': 34,\n",
       "                               'narrow': 5,\n",
       "                               'central': 28,\n",
       "                               'portion': 23,\n",
       "                               \"moon's\": 1,\n",
       "                               'uniform': 5,\n",
       "                               'Af': 908,\n",
       "                               'Q': 46,\n",
       "                               'degrees': 6,\n",
       "                               'probable': 3,\n",
       "                               'include': 30,\n",
       "                               'well': 122,\n",
       "                               'relative': 22,\n",
       "                               'plotted': 6,\n",
       "                               'along': 43,\n",
       "                               '8.6-mm': 2,\n",
       "                               'Gibson': 1,\n",
       "                               'figure': 38,\n",
       "                               'explanation': 17,\n",
       "                               'discussion': 33,\n",
       "                               'follows': 40,\n",
       "                               'referred': 11,\n",
       "                               'constant': 26,\n",
       "                               'component': 17,\n",
       "                               'superimposed': 4,\n",
       "                               'periodic': 3,\n",
       "                               'called': 36,\n",
       "                               'variable': 28,\n",
       "                               '10.3-cm': 1,\n",
       "                               'observation': 10,\n",
       "                               '20': 22,\n",
       "                               '84-foot': 1,\n",
       "                               'Maryland': 5,\n",
       "                               'Point': 7,\n",
       "                               'Observatory': 1,\n",
       "                               'age': 53,\n",
       "                               'lobe': 3,\n",
       "                               \"18'.5\": 1,\n",
       "                               'Gaussian': 2,\n",
       "                               'shape': 21,\n",
       "                               'uniformly': 1,\n",
       "                               'bright': 10,\n",
       "                               'Abstract': 2,\n",
       "                               'Experiments': 5,\n",
       "                               'electric': 16,\n",
       "                               'applying': 12,\n",
       "                               'porous': 10,\n",
       "                               'graphite': 5,\n",
       "                               'anode': 77,\n",
       "                               'cooled': 6,\n",
       "                               'transpiring': 4,\n",
       "                               'gas': 42,\n",
       "                               'Argon': 3,\n",
       "                               'Thus': 78,\n",
       "                               'energy': 48,\n",
       "                               'transferred': 15,\n",
       "                               'partly': 13,\n",
       "                               'fed': 7,\n",
       "                               'back': 38,\n",
       "                               'into': 222,\n",
       "                               'proper': 18,\n",
       "                               'design': 16,\n",
       "                               'net': 8,\n",
       "                               'loss': 22,\n",
       "                               'approximately': 32,\n",
       "                               '15%': 1,\n",
       "                               'total': 64,\n",
       "                               'detailed': 15,\n",
       "                               'balance': 28,\n",
       "                               'established': 30,\n",
       "                               'ablation': 2,\n",
       "                               'amount': 52,\n",
       "                               'dependence': 7,\n",
       "                               'voltage': 13,\n",
       "                               'upon': 114,\n",
       "                               'mass': 43,\n",
       "                               'flow': 29,\n",
       "                               'velocity': 15,\n",
       "                               'transpirating': 1,\n",
       "                               'investigated': 11,\n",
       "                               'various': 81,\n",
       "                               'currents': 4,\n",
       "                               'between': 191,\n",
       "                               '100': 25,\n",
       "                               'Amp': 2,\n",
       "                               '200': 6,\n",
       "                               'Qualitative': 1,\n",
       "                               'high-speed': 1,\n",
       "                               'motion': 6,\n",
       "                               'pictures': 5,\n",
       "                               'taken': 48,\n",
       "                               'phenomena': 12,\n",
       "                               'velocities': 4,\n",
       "                               'fluxes': 4,\n",
       "                               'existing': 17,\n",
       "                               'electrode': 5,\n",
       "                               'surfaces': 19,\n",
       "                               'arcs': 8,\n",
       "                               'necessitate': 2,\n",
       "                               'cooling': 6,\n",
       "                               'prevent': 20,\n",
       "                               'requirements': 28,\n",
       "                               'particularly': 37,\n",
       "                               'severe': 11,\n",
       "                               'free-burning': 1,\n",
       "                               'instance': 20,\n",
       "                               '90%': 1,\n",
       "                               'giving': 10,\n",
       "                               'rise': 29,\n",
       "                               'excess': 10,\n",
       "                               'authors': 12,\n",
       "                               '--': 335,\n",
       "                               'exact': 5,\n",
       "                               'value': 76,\n",
       "                               'depending': 11,\n",
       "                               'plasma': 12,\n",
       "                               'generators': 9,\n",
       "                               'currently': 5,\n",
       "                               'commercially': 5,\n",
       "                               'industrial': 25,\n",
       "                               'research': 24,\n",
       "                               'tools': 2,\n",
       "                               'often': 64,\n",
       "                               '50%': 3,\n",
       "                               'input': 19,\n",
       "                               'being': 119,\n",
       "                               'medium': 11,\n",
       "                               'transfer': 26,\n",
       "                               'rates': 54,\n",
       "                               'cathode': 10,\n",
       "                               'occurring': 16,\n",
       "                               'free': 58,\n",
       "                               'burning': 8,\n",
       "                               'forced': 6,\n",
       "                               'convection': 2,\n",
       "                               'modify': 3,\n",
       "                               'picture': 28,\n",
       "                               'somewhat': 40,\n",
       "                               'following': 70,\n",
       "                               'effects': 48,\n",
       "                               ':': 274,\n",
       "                               'Heat': 2,\n",
       "                               'condensation': 5,\n",
       "                               'work': 117,\n",
       "                               'function': 81,\n",
       "                               'plus': 14,\n",
       "                               'kinetic': 8,\n",
       "                               'electrons': 4,\n",
       "                               'impinging': 4,\n",
       "                               'depends': 15,\n",
       "                               'current': 25,\n",
       "                               'column': 32,\n",
       "                               'sheath': 3,\n",
       "                               'molecular': 15,\n",
       "                               'conduction': 2,\n",
       "                               'enhanced': 4,\n",
       "                               'hot': 9,\n",
       "                               'jet': 4,\n",
       "                               'flowing': 4,\n",
       "                               'towards': 13,\n",
       "                               'phenomenon': 17,\n",
       "                               'experimentally': 5,\n",
       "                               'detail': 14,\n",
       "                               'Maecker': 1,\n",
       "                               'Ref.': 4,\n",
       "                               'pressure': 68,\n",
       "                               'gradient': 11,\n",
       "                               'producing': 7,\n",
       "                               'nature': 34,\n",
       "                               'magnetic': 10,\n",
       "                               'field': 48,\n",
       "                               'decrease': 8,\n",
       "                               'density': 22,\n",
       "                               'Hence': 16,\n",
       "                               'resemble': 2,\n",
       "                               'stagnation': 1,\n",
       "                               'point': 110,\n",
       "                               'above': 66,\n",
       "                               'evidence': 73,\n",
       "                               'through': 141,\n",
       "                               'generator': 9,\n",
       "                               'still': 79,\n",
       "                               'receiving': 6,\n",
       "                               'largest': 7,\n",
       "                               'flux': 26,\n",
       "                               'An': 45,\n",
       "                               'attempt': 16,\n",
       "                               'improve': 8,\n",
       "                               'life': 69,\n",
       "                               'anodes': 1,\n",
       "                               'efficiency': 21,\n",
       "                               'therefore': 49,\n",
       "                               'aim': 6,\n",
       "                               'reduction': 17,\n",
       "                               'possibilities': 18,\n",
       "                               'exist': 21,\n",
       "                               'achieving': 4,\n",
       "                               'voltages': 4,\n",
       "                               'reduce': 16,\n",
       "                               'electron': 23,\n",
       "                               'given': 103,\n",
       "                               'output': 25,\n",
       "                               'Continuous': 1,\n",
       "                               'contact': 12,\n",
       "                               'area': 101,\n",
       "                               'forces': 33,\n",
       "                               'Feedback': 1,\n",
       "                               'transpiration': 3,\n",
       "                               'third': 34,\n",
       "                               'method': 59,\n",
       "                               'our': 133,\n",
       "                               'knowledge': 26,\n",
       "                               'successfully': 4,\n",
       "                               'applied': 38,\n",
       "                               'C.': 19,\n",
       "                               'Sheer': 1,\n",
       "                               'co-workers': 1,\n",
       "                               'purpose': 29,\n",
       "                               'establish': 12,\n",
       "                               'effect': 67,\n",
       "                               'blowing': 7,\n",
       "                               'Gas': 1,\n",
       "                               'injection': 4,\n",
       "                               'feeds': 1,\n",
       "                               'mentioned': 19,\n",
       "                               'processes': 22,\n",
       "                               'modifies': 1,\n",
       "                               'itself': 73,\n",
       "                               'latter': 43,\n",
       "                               'attempted': 7,\n",
       "                               'paper': 43,\n",
       "                               'exclude': 2,\n",
       "                               'dissociation': 2,\n",
       "                               'chemical': 24,\n",
       "                               'reaction': 82,\n",
       "                               'Sintered': 1,\n",
       "                               'metals': 4,\n",
       "                               'usable': 3,\n",
       "                               'principle': 33,\n",
       "                               'However': 59,\n",
       "                               'technical': 22,\n",
       "                               'difficulties': 15,\n",
       "                               'arise': 9,\n",
       "                               'melting': 11,\n",
       "                               'spots': 3,\n",
       "                               'arrangement': 6,\n",
       "                               'below': 35,\n",
       "                               'based': 42,\n",
       "                               'geometry': 6,\n",
       "                               'direct': 39,\n",
       "                               'comparisons': 3,\n",
       "                               'drawn': 18,\n",
       "                               'studied': 16,\n",
       "                               'past': 44,\n",
       "                               'decades': 11,\n",
       "                               'numerous': 14,\n",
       "                               'investigators': 10,\n",
       "                               'Experimental': 5,\n",
       "                               'Figures': 11,\n",
       "                               'show': 55,\n",
       "                               'photographic': 4,\n",
       "                               'schematic': 3,\n",
       "                               'views': 7,\n",
       "                               'test': 48,\n",
       "                               'stand': 15,\n",
       "                               'two': 238,\n",
       "                               'models': 9,\n",
       "                               'holder': 21,\n",
       "                               'consisted': 6,\n",
       "                               \"1/4''\": 1,\n",
       "                               \"''\": 591,\n",
       "                               'thoriated': 1,\n",
       "                               'tungsten': 4,\n",
       "                               'rod': 1,\n",
       "                               'attached': 11,\n",
       "                               'water': 61,\n",
       "                               'copper': 1,\n",
       "                               'tube': 21,\n",
       "                               'adjusted': 3,\n",
       "                               'axial': 1,\n",
       "                               'drive': 10,\n",
       "                               'required': 67,\n",
       "                               'spacing': 2,\n",
       "                               'mounted': 12,\n",
       "                               'means': 64,\n",
       "                               'steel': 3,\n",
       "                               'plug': 15,\n",
       "                               'ejected': 2,\n",
       "                               'formed': 28,\n",
       "                               'directed': 11,\n",
       "                               'axially': 1,\n",
       "                               'Inflow': 1,\n",
       "                               'air': 27,\n",
       "                               'surrounding': 8,\n",
       "                               'prevented': 7,\n",
       "                               'disks': 1,\n",
       "                               'blown': 1,\n",
       "                               'rate': 114,\n",
       "                               'coaxial': 1,\n",
       "                               'precaution': 1,\n",
       "                               'against': 88,\n",
       "                               'contamination': 2,\n",
       "                               '1/2': 3,\n",
       "                               'inch': 14,\n",
       "                               '1/4': 2,\n",
       "                               'long': 67,\n",
       "                               'National': 18,\n",
       "                               'Carbon': 1,\n",
       "                               'NC': 1,\n",
       "                               '60': 10,\n",
       "                               'porosity': 2,\n",
       "                               'pore': 2,\n",
       "                               'size': 47,\n",
       "                               '30': 30,\n",
       "                               'ensure': 3,\n",
       "                               'uniformity': 3,\n",
       "                               'leaving': 9,\n",
       "                               'Figure': 28,\n",
       "                               'inserted': 3,\n",
       "                               'carbon': 26,\n",
       "                               'shielded': 1,\n",
       "                               'thermocouple': 3,\n",
       "                               'upstream': 2,\n",
       "                               'exposed': 9,\n",
       "                               'holes': 2,\n",
       "                               'cylindrical': 10,\n",
       "                               'walls': 7,\n",
       "                               'divided': 15,\n",
       "                               'chamber': 4,\n",
       "                               'parts': 35,\n",
       "                               'heated': 5,\n",
       "                               'reach': 19,\n",
       "                               'natural': 23,\n",
       "                               'Two': 12,\n",
       "                               'pyrometers': 1,\n",
       "                               'Pyrometer': 1,\n",
       "                               'Instrument': 1,\n",
       "                               'Co.': 3,\n",
       "                               'Model': 1,\n",
       "                               '95': 1,\n",
       "                               'served': 17,\n",
       "                               'simultaneous': 3,\n",
       "                               'measurement': 19,\n",
       "                               'Three': 11,\n",
       "                               'thermocouples': 3,\n",
       "                               'placed': 23,\n",
       "                               'locations': 7,\n",
       "                               'aluminum': 8,\n",
       "                               'determine': 32,\n",
       "                               'Another': 15,\n",
       "                               'experiments': 28,\n",
       "                               'losses': 19,\n",
       "                               'determined': 39,\n",
       "                               'measuring': 14,\n",
       "                               'coolant': 2,\n",
       "                               'To': 67,\n",
       "                               'outside': 23,\n",
       "                               'regime': 1,\n",
       "                               'shield': 4,\n",
       "                               'providing': 11,\n",
       "                               'gap': 3,\n",
       "                               '1/16': 2,\n",
       "                               'plate': 5,\n",
       "                               'addition': 47,\n",
       "                               'inner': 9,\n",
       "                               'covered': 22,\n",
       "                               'foil': 1,\n",
       "                               'Temperatures': 1,\n",
       "                               'water-cooled': 1,\n",
       "                               'originating': 2,\n",
       "                               'argon': 4,\n",
       "                               'commercial': 25,\n",
       "                               'bottles': 1,\n",
       "                               'regulated': 2,\n",
       "                               'regulator': 1,\n",
       "                               'rator': 1,\n",
       "                               'D.': 10,\n",
       "                               'rectifier': 2,\n",
       "                               '360': 1,\n",
       "                               'cycle': 13,\n",
       "                               'ripple': 1,\n",
       "                               '0.5': 5,\n",
       "                               'V': 23,\n",
       "                               'resistive': 1,\n",
       "                               'load': 14,\n",
       "                               'resistor': 2,\n",
       "                               '50': 12,\n",
       "                               'mV': 1,\n",
       "                               'shunt': 1,\n",
       "                               'millivoltmeter': 1,\n",
       "                               'voltmeter': 1,\n",
       "                               'whose': 38,\n",
       "                               'terminals': 2,\n",
       "                               'connected': 6,\n",
       "                               'holders': 1,\n",
       "                               'Because': 13,\n",
       "                               'falling': 6,\n",
       "                               'characteristic': 30,\n",
       "                               'no': 245,\n",
       "                               'ballast': 1,\n",
       "                               'stability': 7,\n",
       "                               'operation': 28,\n",
       "                               'frequency': 10,\n",
       "                               'starter': 1,\n",
       "                               'start': 6,\n",
       "                               'procedure': 46,\n",
       "                               'error': 11,\n",
       "                               'analysis': 68,\n",
       "                               'Transpiration': 1,\n",
       "                               'designed': 21,\n",
       "                               'goals': 7,\n",
       "                               'mind': 24,\n",
       "                               'far': 53,\n",
       "                               'they': 338,\n",
       "                               'such': 290,\n",
       "                               'number': 173,\n",
       "                               'parameters': 8,\n",
       "                               \"0.5''\": 1,\n",
       "                               'systematically': 4,\n",
       "                               'lower': 48,\n",
       "                               'limit': 16,\n",
       "                               'fact': 84,\n",
       "                               'started': 12,\n",
       "                               'strike': 10,\n",
       "                               'instead': 15,\n",
       "                               'became': 44,\n",
       "                               'highly': 26,\n",
       "                               'unstable': 5,\n",
       "                               'upper': 16,\n",
       "                               'difficulty': 25,\n",
       "                               'struck': 1,\n",
       "                               'rest': 14,\n",
       "                               'changed': 13,\n",
       "                               'location': 20,\n",
       "                               'continuously': 10,\n",
       "                               'each': 202,\n",
       "                               'scanned': 1,\n",
       "                               'pyrometer': 2,\n",
       "                               'As': 87,\n",
       "                               'turned': 18,\n",
       "                               ...}),\n",
       "                     'lore': FreqDist({'In': 195,\n",
       "                               'American': 81,\n",
       "                               'romance': 2,\n",
       "                               ',': 5519,\n",
       "                               'almost': 46,\n",
       "                               'nothing': 29,\n",
       "                               'rates': 4,\n",
       "                               'higher': 21,\n",
       "                               'than': 189,\n",
       "                               'what': 130,\n",
       "                               'the': 6328,\n",
       "                               'movie': 8,\n",
       "                               'men': 86,\n",
       "                               'have': 395,\n",
       "                               'called': 62,\n",
       "                               '``': 727,\n",
       "                               'meeting': 13,\n",
       "                               'cute': 2,\n",
       "                               \"''\": 717,\n",
       "                               '--': 395,\n",
       "                               'that': 984,\n",
       "                               'is': 1007,\n",
       "                               'boy-meets-girl': 1,\n",
       "                               'seems': 27,\n",
       "                               'more': 220,\n",
       "                               'adorable': 1,\n",
       "                               'if': 136,\n",
       "                               'it': 566,\n",
       "                               \"doesn't\": 4,\n",
       "                               'take': 56,\n",
       "                               'place': 70,\n",
       "                               'in': 2001,\n",
       "                               'an': 364,\n",
       "                               'atmosphere': 5,\n",
       "                               'of': 3668,\n",
       "                               'correct': 8,\n",
       "                               'and': 2758,\n",
       "                               'acute': 2,\n",
       "                               'boredom': 2,\n",
       "                               '.': 4367,\n",
       "                               'Just': 11,\n",
       "                               'about': 162,\n",
       "                               'most': 139,\n",
       "                               'enthralling': 2,\n",
       "                               'real-life': 2,\n",
       "                               'example': 30,\n",
       "                               'Charles': 12,\n",
       "                               'MacArthur-Helen': 1,\n",
       "                               'Hayes': 2,\n",
       "                               'saga': 1,\n",
       "                               ':': 150,\n",
       "                               'reputedly': 1,\n",
       "                               'all': 223,\n",
       "                               'he': 541,\n",
       "                               'did': 90,\n",
       "                               'was': 961,\n",
       "                               'give': 31,\n",
       "                               'her': 302,\n",
       "                               'a': 2304,\n",
       "                               'handful': 4,\n",
       "                               'peanuts': 4,\n",
       "                               'but': 273,\n",
       "                               'said': 89,\n",
       "                               'simultaneously': 4,\n",
       "                               'I': 265,\n",
       "                               'wish': 8,\n",
       "                               'they': 303,\n",
       "                               'were': 349,\n",
       "                               'emeralds': 5,\n",
       "                               'Aside': 1,\n",
       "                               'from': 471,\n",
       "                               'comico-romantico': 1,\n",
       "                               'content': 5,\n",
       "                               'here': 37,\n",
       "                               'good': 90,\n",
       "                               'linguist-anthropologist': 1,\n",
       "                               'could': 141,\n",
       "                               'readily': 9,\n",
       "                               'pick': 3,\n",
       "                               'up': 166,\n",
       "                               'few': 88,\n",
       "                               'other': 139,\n",
       "                               'facts': 17,\n",
       "                               'especially': 16,\n",
       "                               'had': 461,\n",
       "                               'little': 75,\n",
       "                               'conversation': 7,\n",
       "                               'to': 2530,\n",
       "                               'go': 53,\n",
       "                               'on': 594,\n",
       "                               'The': 647,\n",
       "                               'way': 86,\n",
       "                               'MacArthur': 2,\n",
       "                               'his': 496,\n",
       "                               'line': 11,\n",
       "                               'you': 209,\n",
       "                               'recorded': 5,\n",
       "                               'transcript': 2,\n",
       "                               'professional': 14,\n",
       "                               'linguist': 5,\n",
       "                               'would': 186,\n",
       "                               'probably': 28,\n",
       "                               'gone': 18,\n",
       "                               'like': 86,\n",
       "                               'this': 354,\n",
       "                               'Af': 4,\n",
       "                               'Primary': 1,\n",
       "                               'stresses': 4,\n",
       "                               ';': 482,\n",
       "                               'note': 9,\n",
       "                               'pitch': 3,\n",
       "                               '3': 10,\n",
       "                               '(': 164,\n",
       "                               'pretty': 6,\n",
       "                               'high': 69,\n",
       "                               ')': 169,\n",
       "                               'with': 681,\n",
       "                               'slight': 7,\n",
       "                               'degree': 21,\n",
       "                               'drawl': 1,\n",
       "                               'one': 290,\n",
       "                               'oversoftness': 1,\n",
       "                               'Conclusions': 1,\n",
       "                               'people': 125,\n",
       "                               'involved': 12,\n",
       "                               'subsequent': 5,\n",
       "                               'bear': 13,\n",
       "                               'me': 58,\n",
       "                               'out': 168,\n",
       "                               'knew': 34,\n",
       "                               'clearly': 13,\n",
       "                               'relative': 2,\n",
       "                               'values': 10,\n",
       "                               'both': 69,\n",
       "                               'monetary': 1,\n",
       "                               'sentimental': 4,\n",
       "                               'And': 75,\n",
       "                               'drawling': 1,\n",
       "                               'oversoft': 2,\n",
       "                               'voice': 12,\n",
       "                               'flirtation': 1,\n",
       "                               'though': 42,\n",
       "                               'fairly': 6,\n",
       "                               'overt': 2,\n",
       "                               'still': 85,\n",
       "                               'well': 73,\n",
       "                               'within': 27,\n",
       "                               'prescribed': 2,\n",
       "                               'gambit': 1,\n",
       "                               'their': 300,\n",
       "                               'culture': 13,\n",
       "                               'words': 26,\n",
       "                               'automation': 1,\n",
       "                               'machines': 11,\n",
       "                               'designed': 7,\n",
       "                               'work': 85,\n",
       "                               'tandem': 1,\n",
       "                               'shared': 4,\n",
       "                               'same': 58,\n",
       "                               'programming': 1,\n",
       "                               'mutual': 6,\n",
       "                               'understanding': 12,\n",
       "                               'not': 401,\n",
       "                               'only': 136,\n",
       "                               'English': 18,\n",
       "                               'four': 38,\n",
       "                               'pitches': 4,\n",
       "                               'junctures': 2,\n",
       "                               'can': 170,\n",
       "                               'change': 26,\n",
       "                               'meaning': 9,\n",
       "                               'black': 15,\n",
       "                               'white': 36,\n",
       "                               'At': 42,\n",
       "                               'point': 37,\n",
       "                               'unfortunately': 2,\n",
       "                               'becomes': 15,\n",
       "                               'regrettably': 2,\n",
       "                               'small': 37,\n",
       "                               'part': 42,\n",
       "                               'picture': 14,\n",
       "                               'consider': 14,\n",
       "                               'might': 49,\n",
       "                               'happened': 18,\n",
       "                               'for': 882,\n",
       "                               'some': 152,\n",
       "                               'perverse': 1,\n",
       "                               'undaunted': 1,\n",
       "                               'reason': 18,\n",
       "                               'made': 112,\n",
       "                               'remark': 3,\n",
       "                               'Eskimo': 2,\n",
       "                               'girl': 29,\n",
       "                               'To': 51,\n",
       "                               'been': 235,\n",
       "                               'just': 55,\n",
       "                               'so': 160,\n",
       "                               'much': 76,\n",
       "                               'blubber': 1,\n",
       "                               'quite': 16,\n",
       "                               'simply': 17,\n",
       "                               'communication': 16,\n",
       "                               'no': 173,\n",
       "                               'This': 128,\n",
       "                               'basic': 19,\n",
       "                               'principle': 11,\n",
       "                               'first': 145,\n",
       "                               'richly': 3,\n",
       "                               'knotted': 1,\n",
       "                               'bundle': 3,\n",
       "                               'conveyed': 1,\n",
       "                               'by': 565,\n",
       "                               'Dr.': 44,\n",
       "                               'Henry': 21,\n",
       "                               'Lee': 9,\n",
       "                               'Smith': 12,\n",
       "                               'Jr.': 3,\n",
       "                               'at': 445,\n",
       "                               'University': 14,\n",
       "                               'Buffalo': 3,\n",
       "                               'where': 97,\n",
       "                               'heads': 9,\n",
       "                               \"world's\": 6,\n",
       "                               'department': 5,\n",
       "                               'anthropology': 2,\n",
       "                               'linguistics': 3,\n",
       "                               'A': 122,\n",
       "                               'brisk': 1,\n",
       "                               'amusing': 1,\n",
       "                               'man': 88,\n",
       "                               'apparently': 11,\n",
       "                               'constructed': 2,\n",
       "                               'ingenious': 2,\n",
       "                               'system': 28,\n",
       "                               'spring-joints': 1,\n",
       "                               'attuned': 2,\n",
       "                               'peppery': 1,\n",
       "                               'rhythm': 4,\n",
       "                               'as': 697,\n",
       "                               'mind': 33,\n",
       "                               'began': 32,\n",
       "                               'academic': 14,\n",
       "                               'career': 6,\n",
       "                               'teaching': 5,\n",
       "                               'speech': 9,\n",
       "                               'Barnard': 1,\n",
       "                               'girls': 22,\n",
       "                               'project': 5,\n",
       "                               'considerably': 3,\n",
       "                               'enlivened': 1,\n",
       "                               'devotion': 2,\n",
       "                               'recording': 7,\n",
       "                               'young': 33,\n",
       "                               'rat': 1,\n",
       "                               'named': 16,\n",
       "                               'Arthur': 6,\n",
       "                               'who': 259,\n",
       "                               'never': 62,\n",
       "                               'make': 71,\n",
       "                               'Later': 6,\n",
       "                               'became': 42,\n",
       "                               'central': 11,\n",
       "                               'spirits': 7,\n",
       "                               'Army': 14,\n",
       "                               'Language': 1,\n",
       "                               'Program': 1,\n",
       "                               'language': 13,\n",
       "                               'school': 101,\n",
       "                               \"Washington's\": 1,\n",
       "                               'Foreign': 4,\n",
       "                               'Service': 4,\n",
       "                               'Institute': 4,\n",
       "                               'It': 182,\n",
       "                               'there': 161,\n",
       "                               'course': 64,\n",
       "                               'trying': 9,\n",
       "                               'prepare': 4,\n",
       "                               'new': 95,\n",
       "                               'shock': 5,\n",
       "                               'encounter': 3,\n",
       "                               'remote': 3,\n",
       "                               'overseas': 2,\n",
       "                               'posts': 8,\n",
       "                               'develop': 13,\n",
       "                               'charting': 3,\n",
       "                               'norms': 2,\n",
       "                               'human': 28,\n",
       "                               'trained': 3,\n",
       "                               'ear': 3,\n",
       "                               'talk': 13,\n",
       "                               'has': 226,\n",
       "                               'always': 62,\n",
       "                               'revealed': 9,\n",
       "                               'staggering': 1,\n",
       "                               'quantity': 4,\n",
       "                               'information': 24,\n",
       "                               'talker': 1,\n",
       "                               'such': 106,\n",
       "                               'things': 31,\n",
       "                               'geographical': 2,\n",
       "                               'origin': 4,\n",
       "                               'and/or': 2,\n",
       "                               'history': 34,\n",
       "                               'socio-economic': 2,\n",
       "                               'identity': 26,\n",
       "                               'education': 24,\n",
       "                               'recently': 8,\n",
       "                               'however': 50,\n",
       "                               'linguists': 3,\n",
       "                               'developed': 18,\n",
       "                               'systematic': 2,\n",
       "                               'voices': 3,\n",
       "                               'paper': 14,\n",
       "                               'tells': 4,\n",
       "                               'even': 107,\n",
       "                               'speakers': 2,\n",
       "                               'success': 9,\n",
       "                               'or': 496,\n",
       "                               'failure': 9,\n",
       "                               'between': 67,\n",
       "                               'two': 125,\n",
       "                               'obvious': 6,\n",
       "                               'reasons': 14,\n",
       "                               'makes': 19,\n",
       "                               'techniques': 9,\n",
       "                               'superbly': 3,\n",
       "                               'useful': 6,\n",
       "                               'studying': 7,\n",
       "                               'psychiatric': 4,\n",
       "                               'interview': 14,\n",
       "                               'fact': 68,\n",
       "                               'successfully': 3,\n",
       "                               'used': 95,\n",
       "                               'suggest': 7,\n",
       "                               'ways': 15,\n",
       "                               'speed': 6,\n",
       "                               'diagnosis': 4,\n",
       "                               'evaluate': 1,\n",
       "                               'progress': 8,\n",
       "                               'therapy': 3,\n",
       "                               'early': 47,\n",
       "                               \"1950's\": 2,\n",
       "                               'together': 18,\n",
       "                               'distinguished': 8,\n",
       "                               'colleague': 1,\n",
       "                               'George': 13,\n",
       "                               'Trager': 1,\n",
       "                               'austerely': 1,\n",
       "                               'sometimes': 25,\n",
       "                               'fights': 1,\n",
       "                               'own': 80,\n",
       "                               'evident': 6,\n",
       "                               'charm': 2,\n",
       "                               'third': 18,\n",
       "                               'engaging': 2,\n",
       "                               'name': 39,\n",
       "                               'Birdwhistell': 1,\n",
       "                               'Ray': 1,\n",
       "                               'agreed': 10,\n",
       "                               'premises': 1,\n",
       "                               'three-part': 1,\n",
       "                               'process': 18,\n",
       "                               '1': 20,\n",
       "                               '2': 17,\n",
       "                               'paralanguage': 2,\n",
       "                               'set': 35,\n",
       "                               'phenomena': 3,\n",
       "                               'including': 19,\n",
       "                               'laughing': 1,\n",
       "                               'weeping': 1,\n",
       "                               'breaks': 3,\n",
       "                               'tone': 3,\n",
       "                               'kinesics': 1,\n",
       "                               'technical': 9,\n",
       "                               'gestures': 1,\n",
       "                               'facial': 2,\n",
       "                               'expressions': 1,\n",
       "                               'body': 25,\n",
       "                               'shifts': 4,\n",
       "                               'nodding': 2,\n",
       "                               'shaking': 1,\n",
       "                               'head': 38,\n",
       "                               'talking': 9,\n",
       "                               \"one's\": 14,\n",
       "                               'hands': 13,\n",
       "                               'et': 2,\n",
       "                               'cetera': 2,\n",
       "                               \"Smith's\": 1,\n",
       "                               'workout': 1,\n",
       "                               'based': 9,\n",
       "                               'mother': 19,\n",
       "                               'which': 275,\n",
       "                               'spells': 1,\n",
       "                               'our': 87,\n",
       "                               'deal': 17,\n",
       "                               'bread': 14,\n",
       "                               'alone': 17,\n",
       "                               'For': 59,\n",
       "                               'are': 480,\n",
       "                               'reasonably': 3,\n",
       "                               'well-adjusted': 1,\n",
       "                               'person': 25,\n",
       "                               'certain': 31,\n",
       "                               'reasonable': 4,\n",
       "                               'appropriate': 4,\n",
       "                               'addressing': 2,\n",
       "                               'your': 57,\n",
       "                               'usual': 11,\n",
       "                               'U.S.': 16,\n",
       "                               'norm': 1,\n",
       "                               'be': 570,\n",
       "                               'Middle': 9,\n",
       "                               'pause': 3,\n",
       "                               'juncture': 2,\n",
       "                               'before': 98,\n",
       "                               'rise': 8,\n",
       "                               'end': 48,\n",
       "                               'symbols': 6,\n",
       "                               \"mother's\": 5,\n",
       "                               'status': 10,\n",
       "                               'U.S.A.': 1,\n",
       "                               'Quite': 2,\n",
       "                               'feelings': 4,\n",
       "                               'evidenced': 1,\n",
       "                               'style': 17,\n",
       "                               'Note': 1,\n",
       "                               'drop': 3,\n",
       "                               'lowest': 2,\n",
       "                               'sentence': 7,\n",
       "                               'fade': 2,\n",
       "                               'ending': 1,\n",
       "                               'downtalking': 1,\n",
       "                               'expressing': 4,\n",
       "                               'something': 21,\n",
       "                               'less': 39,\n",
       "                               'conventional': 2,\n",
       "                               'respect': 10,\n",
       "                               'Even': 16,\n",
       "                               'regard': 14,\n",
       "                               'mom': 1,\n",
       "                               \"mom's\": 1,\n",
       "                               'apple': 2,\n",
       "                               'pie': 1,\n",
       "                               'goes': 10,\n",
       "                               'speaker': 2,\n",
       "                               'relates': 1,\n",
       "                               'indicated': 8,\n",
       "                               'while': 52,\n",
       "                               'instance': 8,\n",
       "                               'altered': 3,\n",
       "                               'quality': 6,\n",
       "                               'second': 28,\n",
       "                               'examples': 8,\n",
       "                               'definitely': 2,\n",
       "                               'impaired': 1,\n",
       "                               'An': 32,\n",
       "                               'accompanying': 3,\n",
       "                               'record': 14,\n",
       "                               'factors': 5,\n",
       "                               'also': 93,\n",
       "                               'throaty': 1,\n",
       "                               'rasp': 1,\n",
       "                               'With': 34,\n",
       "                               'seven-word': 1,\n",
       "                               'undoubtedly': 2,\n",
       "                               'thought': 36,\n",
       "                               'dealing': 6,\n",
       "                               'subject': 10,\n",
       "                               'food': 23,\n",
       "                               'telling': 5,\n",
       "                               'himself': 40,\n",
       "                               'last': 37,\n",
       "                               'revealing': 3,\n",
       "                               'departed': 4,\n",
       "                               'customs': 4,\n",
       "                               'joint': 3,\n",
       "                               'investigations': 2,\n",
       "                               'psychiatry': 2,\n",
       "                               'established': 13,\n",
       "                               'matter': 39,\n",
       "                               'impossible': 7,\n",
       "                               'without': 51,\n",
       "                               'over': 116,\n",
       "                               'again': 39,\n",
       "                               'sort': 15,\n",
       "                               'how': 65,\n",
       "                               'relate': 2,\n",
       "                               'rest': 13,\n",
       "                               'world': 77,\n",
       "                               'Since': 16,\n",
       "                               'interviewing': 1,\n",
       "                               'therapeutic': 5,\n",
       "                               'diagnostic': 3,\n",
       "                               'instrument': 5,\n",
       "                               'modern': 16,\n",
       "                               'interviews': 6,\n",
       "                               'playbacks': 1,\n",
       "                               'study': 24,\n",
       "                               'boost': 1,\n",
       "                               'Redstone': 1,\n",
       "                               'proportions': 3,\n",
       "                               'research': 6,\n",
       "                               'training': 14,\n",
       "                               'Some': 31,\n",
       "                               'earliest': 3,\n",
       "                               'recordings': 1,\n",
       "                               \"1940's\": 1,\n",
       "                               'demonstrated': 2,\n",
       "                               'psychiatrists': 4,\n",
       "                               'reacted': 1,\n",
       "                               'immediately': 19,\n",
       "                               'anger': 4,\n",
       "                               'anxiety': 4,\n",
       "                               'sound': 14,\n",
       "                               'track': 3,\n",
       "                               'whereas': 4,\n",
       "                               'written': 14,\n",
       "                               'records': 10,\n",
       "                               'offered': 9,\n",
       "                               'far': 59,\n",
       "                               'fewer': 3,\n",
       "                               'cues': 2,\n",
       "                               'discernible': 1,\n",
       "                               'print': 4,\n",
       "                               'picked': 9,\n",
       "                               'skilled': 3,\n",
       "                               'sensitive': 11,\n",
       "                               'experts': 11,\n",
       "                               'general': 40,\n",
       "                               'able': 28,\n",
       "                               'establish': 5,\n",
       "                               'wide': 14,\n",
       "                               'basis': 18,\n",
       "                               'many': 122,\n",
       "                               'them': 181,\n",
       "                               'felt': 17,\n",
       "                               'psychotherapy': 1,\n",
       "                               'acoustic': 1,\n",
       "                               'stress': 6,\n",
       "                               'nagging': 1,\n",
       "                               'transmitted': 1,\n",
       "                               'necessarily': 5,\n",
       "                               'minimum': 7,\n",
       "                               'usually': 31,\n",
       "                               'tape': 4,\n",
       "                               'now': 84,\n",
       "                               'use': 68,\n",
       "                               'brings': 5,\n",
       "                               'alive': 3,\n",
       "                               'full': 22,\n",
       "                               'range': 19,\n",
       "                               'emotion': 2,\n",
       "                               'explored': 3,\n",
       "                               'repeatedly': 3,\n",
       "                               'therapist': 11,\n",
       "                               'battery': 2,\n",
       "                               'therapists': 2,\n",
       "                               'Newest': 1,\n",
       "                               'high-powered': 1,\n",
       "                               'carried': 16,\n",
       "                               'level': 19,\n",
       "                               'By': 26,\n",
       "                               'adding': 3,\n",
       "                               'analysis': 1,\n",
       "                               'typed': 2,\n",
       "                               'transcripts': 1,\n",
       "                               'supplied': 6,\n",
       "                               'Linguistic': 1,\n",
       "                               'transcribed': 2,\n",
       "                               'flags': 2,\n",
       "                               'points': 8,\n",
       "                               \"patient's\": 5,\n",
       "                               'departs': 1,\n",
       "                               'expected': 17,\n",
       "                               'possible': 28,\n",
       "                               'breakdowns': 1,\n",
       "                               'rehearsed': 3,\n",
       "                               'dialogue': 2,\n",
       "                               'disapproval': 3,\n",
       "                               'ambivalence': 3,\n",
       "                               'ambiguity': 3,\n",
       "                               'annoyance': 2,\n",
       "                               'resentment': 4,\n",
       "                               'disinclination': 2,\n",
       "                               'speak': 8,\n",
       "                               'often': 66,\n",
       "                               'marked': 11,\n",
       "                               'fade-in': 1,\n",
       "                               'beginning': 19,\n",
       "                               'sentences': 1,\n",
       "                               'Interpretation': 2,\n",
       "                               'naturally': 3,\n",
       "                               'remains': 13,\n",
       "                               'role': 14,\n",
       "                               'orientation': 2,\n",
       "                               'vocal': 2,\n",
       "                               'giveaways': 3,\n",
       "                               'background': 3,\n",
       "                               'non-verbal': 1,\n",
       "                               'danger': 6,\n",
       "                               'spots': 2,\n",
       "                               'relationship': 13,\n",
       "                               'beefed': 1,\n",
       "                               'His': 30,\n",
       "                               'esoteric': 1,\n",
       "                               'chartings': 1,\n",
       "                               'alert': 3,\n",
       "                               'areas': 17,\n",
       "                               'deeper': 6,\n",
       "                               'probing': 1,\n",
       "                               'may': 165,\n",
       "                               'bring': 22,\n",
       "                               'light': 21,\n",
       "                               'underlying': 1,\n",
       "                               'psychological': 7,\n",
       "                               'difficulties': 5,\n",
       "                               'making': 31,\n",
       "                               'apparent': 5,\n",
       "                               'eventually': 3,\n",
       "                               'patient': 14,\n",
       "                               'now-historic': 1,\n",
       "                               'reproduced': 1,\n",
       "                               'book': 13,\n",
       "                               'First': 16,\n",
       "                               'Five': 3,\n",
       "                               'Minutes': 2,\n",
       "                               \"therapist's\": 1,\n",
       "                               'bland': 2,\n",
       "                               'neutral': 2,\n",
       "                               'avoided': 3,\n",
       "                               'stressing': 2,\n",
       "                               'imply': 1,\n",
       "                               'surprise': 3,\n",
       "                               'apart': 6,\n",
       "                               'hand': 30,\n",
       "                               'aside': 5,\n",
       "                               'specifically': 4,\n",
       "                               'regional': 5,\n",
       "                               'accent': 1,\n",
       "                               'she': 232,\n",
       "                               'reveals': 4,\n",
       "                               'triad': 1,\n",
       "                               'irritable': 3,\n",
       "                               'tense': 3,\n",
       "                               'depressed': 2,\n",
       "                               'pedantic': 1,\n",
       "                               'itemization': 1,\n",
       "                               'indicates': 3,\n",
       "                               'familiarity': 1,\n",
       "                               'literary': 4,\n",
       "                               'scientific': 10,\n",
       "                               'i.e.': 5,\n",
       "                               'must': 96,\n",
       "                               'least': 35,\n",
       "                               'high-school': 1,\n",
       "                               'story': 18,\n",
       "                               'mentally': 1,\n",
       "                               'time': 174,\n",
       "                               'Then': 37,\n",
       "                               'catapults': 1,\n",
       "                               'into': 162,\n",
       "                               'everything': 17,\n",
       "                               'everybody': 8,\n",
       "                               'putting': 6,\n",
       "                               'particular': 17,\n",
       "                               'violence': 7,\n",
       "                               'indicating': 1,\n",
       "                               'spot': 8,\n",
       "                               'flag': 2,\n",
       "                               'congruent': 1,\n",
       "                               'Consequently': 1,\n",
       "                               'referred': 10,\n",
       "                               'attention': 12,\n",
       "                               'He': 142,\n",
       "                               'then': 88,\n",
       "                               'very': 65,\n",
       "                               'conclude': 2,\n",
       "                               'true': 24,\n",
       "                               'target': 3,\n",
       "                               'Immediately': 3,\n",
       "                               'thereafter': 2,\n",
       "                               'fractures': 1,\n",
       "                               'veering': 1,\n",
       "                               'breathy': 1,\n",
       "                               'sloppily': 1,\n",
       "                               'articulated': 1,\n",
       "                               \"don't\": 26,\n",
       "                               'feel': 15,\n",
       "                               'right': 45,\n",
       "                               'Within': 5,\n",
       "                               'five': 24,\n",
       "                               'minutes': 20,\n",
       "                               'truthfully': 1,\n",
       "                               'refers': 3,\n",
       "                               \"woman's\": 2,\n",
       "                               'husband': 36,\n",
       "                               'She': 78,\n",
       "                               'says': 30,\n",
       "                               'later': 33,\n",
       "                               'opening': 8,\n",
       "                               'keep': 31,\n",
       "                               'thinking': 11,\n",
       "                               'divorce': 2,\n",
       "                               \"that's\": 6,\n",
       "                               'another': 75,\n",
       "                               'emotional': 12,\n",
       "                               'death': 26,\n",
       "                               'linguistic': 1,\n",
       "                               'paralinguistic': 1,\n",
       "                               'signals': 4,\n",
       "                               'misery': 4,\n",
       "                               'present': 21,\n",
       "                               'chart': 2,\n",
       "                               'does': 41,\n",
       "                               'accept': 8,\n",
       "                               'saying': 7,\n",
       "                               'previous': 11,\n",
       "                               'although': 20,\n",
       "                               'described': 13,\n",
       "                               'pursue': 3,\n",
       "                               'questioning': 2,\n",
       "                               'phrase': 4,\n",
       "                               'interesting': 11,\n",
       "                               'non-scientific': 1,\n",
       "                               'rather': 27,\n",
       "                               'touching': 1,\n",
       "                               'suggests': 2,\n",
       "                               'woman': 26,\n",
       "                               'flair': 1,\n",
       "                               'perhaps': 20,\n",
       "                               'temperament': 1,\n",
       "                               'creative': 9,\n",
       "                               'any': 117,\n",
       "                               'depends': 6,\n",
       "                               'significant': 19,\n",
       "                               'skill': 11,\n",
       "                               'long': 71,\n",
       "                               'experience': 30,\n",
       "                               'apparatus': 1,\n",
       "                               'operated': 3,\n",
       "                               'Lillian': 3,\n",
       "                               'Ross': 1,\n",
       "                               'readers': 2,\n",
       "                               'will': 175,\n",
       "                               'instantly': 1,\n",
       "                               'its': 185,\n",
       "                               'total': 13,\n",
       "                               'lack': 10,\n",
       "                               'resemblance': 1,\n",
       "                               'blunted': 1,\n",
       "                               'monumentally': 1,\n",
       "                               'unmeshed': 1,\n",
       "                               'mechanism': 1,\n",
       "                               'Blauberman': 2,\n",
       "                               'Interestingly': 1,\n",
       "                               'enough': 31,\n",
       "                               'none': 7,\n",
       "                               'conceivably': 2,\n",
       "                               'compare': 3,\n",
       "                               'when': 182,\n",
       "                               'groups': 13,\n",
       "                               'playing': 6,\n",
       "                               'back': 60,\n",
       "                               'discovered': 9,\n",
       "                               'number': 36,\n",
       "                               'wanted': 14,\n",
       "                               'polish': 3,\n",
       "                               'everyone': 8,\n",
       "                               'hearing': 3,\n",
       "                               'sessions': 1,\n",
       "                               'expressed': 5,\n",
       "                               'desire': 9,\n",
       "                               'whole': 25,\n",
       "                               'thing': 25,\n",
       "                               'Yet': 15,\n",
       "                               'spite': 5,\n",
       "                               'intensive': 2,\n",
       "                               'taped': 1,\n",
       "                               'teams': 5,\n",
       "                               'psychotherapists': 1,\n",
       "                               'laid': 11,\n",
       "                               'bare': 1,\n",
       "                               'surprising': 3,\n",
       "                               'initial': 7,\n",
       "                               'dozen': 6,\n",
       "                               'times': 31,\n",
       "                               \"what's\": 1,\n",
       "                               'wrong': 11,\n",
       "                               'him': 167,\n",
       "                               'these': 122,\n",
       "                               'know': 50,\n",
       "                               'either': 22,\n",
       "                               'intuitively': 1,\n",
       "                               'scientifically': 2,\n",
       "                               'listen': 1,\n",
       "                               'Naturally': 3,\n",
       "                               'say': 30,\n",
       "                               'hate': 2,\n",
       "                               'my': 47,\n",
       "                               'father': 15,\n",
       "                               'Sibling': 1,\n",
       "                               'rivalry': 1,\n",
       "                               'bugs': 2,\n",
       "                               'What': 32,\n",
       "                               'do': 107,\n",
       "                               'away': 42,\n",
       "                               'communicating': 1,\n",
       "                               'above': 23,\n",
       "                               'classic': 2,\n",
       "                               'indicators': 1,\n",
       "                               'Drs.': 1,\n",
       "                               'Pittenger': 1,\n",
       "                               'Hockett': 1,\n",
       "                               'Danehy': 1,\n",
       "                               'pronouns': 1,\n",
       "                               'Stammering': 1,\n",
       "                               'repetition': 1,\n",
       "                               'signal': 3,\n",
       "                               'uncertainty': 1,\n",
       "                               'On': 42,\n",
       "                               'concealed': 1,\n",
       "                               'mean': 16,\n",
       "                               'mentioned': 3,\n",
       "                               'refer': 4,\n",
       "                               'specific': 6,\n",
       "                               'word': 25,\n",
       "                               'important': 45,\n",
       "                               'alternatives': 2,\n",
       "                               'When': 68,\n",
       "                               'someone': 12,\n",
       "                               'They': 97,\n",
       "                               'took': 32,\n",
       "                               'x-rays': 2,\n",
       "                               'see': 69,\n",
       "                               'pays': 1,\n",
       "                               'statement': 14,\n",
       "                               'normally': 4,\n",
       "                               'actuality': 3,\n",
       "                               'neurasthenic': 1,\n",
       "                               'come': 59,\n",
       "                               'accepting': 3,\n",
       "                               'soma': 1,\n",
       "                               'psyche': 2,\n",
       "                               'cause': 22,\n",
       "                               'difficulty': 12,\n",
       "                               'Amateur': 1,\n",
       "                               'Pursewarden': 1,\n",
       "                               \"Durrell's\": 1,\n",
       "                               'Alexandria': 1,\n",
       "                               'Quartet': 1,\n",
       "                               'stammered': 1,\n",
       "                               'spoke': 12,\n",
       "                               'wife': 47,\n",
       "                               'hardly': 11,\n",
       "                               'view': 28,\n",
       "                               'disastrous': 4,\n",
       "                               'freighter': 2,\n",
       "                               'States': 46,\n",
       "                               'seemed': 31,\n",
       "                               'commonplace': 3,\n",
       "                               'John': 44,\n",
       "                               'Harvey': 8,\n",
       "                               'those': 75,\n",
       "                               'Atlantic': 5,\n",
       "                               'sea-horses': 1,\n",
       "                               'sailed': 7,\n",
       "                               'Bari': 13,\n",
       "                               'beans': 4,\n",
       "                               'bombs': 9,\n",
       "                               'bullets': 5,\n",
       "                               'Fifteenth': 2,\n",
       "                               'Air': 5,\n",
       "                               'Force': 2,\n",
       "                               'Field': 2,\n",
       "                               'Marshal': 2,\n",
       "                               \"Montgomery's\": 1,\n",
       "                               'Eighth': 2,\n",
       "                               'racing': 1,\n",
       "                               'calf': 2,\n",
       "                               'boot': 1,\n",
       "                               'Italy': 5,\n",
       "                               'December': 6,\n",
       "                               '1943': 2,\n",
       "                               'arrived': 11,\n",
       "                               'port': 8,\n",
       "                               'Adriatic': 3,\n",
       "                               'November': 9,\n",
       "                               '28th': 1,\n",
       "                               'Porto': 3,\n",
       "                               'Nuovo': 1,\n",
       "                               'ancient': 12,\n",
       "                               \"city's\": 3,\n",
       "                               'harbor': 7,\n",
       "                               'Hardly': 2,\n",
       "                               'anyone': 13,\n",
       "                               'ashore': 4,\n",
       "                               'anchored': 3,\n",
       "                               'stern-to': 1,\n",
       "                               'off': 57,\n",
       "                               'Berth': 1,\n",
       "                               '29': 1,\n",
       "                               'mole': 1,\n",
       "                               'If': 72,\n",
       "                               'observe': 3,\n",
       "                               'straddled': 1,\n",
       "                               'pair': 4,\n",
       "                               'ships': 7,\n",
       "                               'heavily': 5,\n",
       "                               'laden': 1,\n",
       "                               'explosive': 3,\n",
       "                               'hit': 8,\n",
       "                               'likely': 22,\n",
       "                               'blown': 2,\n",
       "                               'ammo': 1,\n",
       "                               'whatever': 6,\n",
       "                               'else': 17,\n",
       "                               'Which': 2,\n",
       "                               'poison': 4,\n",
       "                               'gas': 13,\n",
       "                               'required': 13,\n",
       "                               'approval': 5,\n",
       "                               'President': 20,\n",
       "                               'Franklin': 6,\n",
       "                               'Delano': 1,\n",
       "                               'Roosevelt': 9,\n",
       "                               'loaded': 3,\n",
       "                               '100': 8,\n",
       "                               'tons': 10,\n",
       "                               'mustard': 6,\n",
       "                               'despatched': 2,\n",
       "                               'Italian': 10,\n",
       "                               'warfront': 1,\n",
       "                               'yet': 21,\n",
       "                               'unacquainted': 1,\n",
       "                               'horrors': 2,\n",
       "                               'mushroom': 1,\n",
       "                               'cloud': 3,\n",
       "                               'regarded': 9,\n",
       "                               'ultimate': 5,\n",
       "                               'hideous': 1,\n",
       "                               'weapons': 7,\n",
       "                               'Throughout': 3,\n",
       "                               'years': 109,\n",
       "                               'World': 13,\n",
       "                               'War': 21,\n",
       "                               'reports': 15,\n",
       "                               'persisted': 2,\n",
       "                               'Axis': 4,\n",
       "                               'powers': 4,\n",
       "                               'Germany': 8,\n",
       "                               'Russia': 3,\n",
       "                               'Japan': 17,\n",
       "                               'China': 4,\n",
       "                               'denied': 5,\n",
       "                               'Influential': 1,\n",
       "                               'America': 25,\n",
       "                               'warning': 16,\n",
       "                               'Pentagon': 1,\n",
       "                               'prepared': 7,\n",
       "                               'against': 58,\n",
       "                               'desperation': 2,\n",
       "                               'attacks': 2,\n",
       "                               'Germans': 2,\n",
       "                               'future': 13,\n",
       "                               'campaigns': 1,\n",
       "                               'extremists': 2,\n",
       "                               'went': 41,\n",
       "                               'urge': 2,\n",
       "                               'using': 16,\n",
       "                               'silence': 4,\n",
       "                               'warn': 3,\n",
       "                               'issued': 3,\n",
       "                               'Allies': 1,\n",
       "                               'August': 8,\n",
       "                               'From': 18,\n",
       "                               'since': 40,\n",
       "                               'war': 23,\n",
       "                               'seriously': 6,\n",
       "                               'contemplating': 1,\n",
       "                               'poisonous': 3,\n",
       "                               'noxious': 1,\n",
       "                               'gases': 1,\n",
       "                               'inhumane': 2,\n",
       "                               'devices': 9,\n",
       "                               'warfare': 8,\n",
       "                               'loath': 1,\n",
       "                               'believe': 19,\n",
       "                               'nation': 14,\n",
       "                               'enemies': 7,\n",
       "                               'willing': 7,\n",
       "                               'loose': 7,\n",
       "                               'upon': 51,\n",
       "                               'mankind': 3,\n",
       "                               'terrible': 2,\n",
       "                               'However': 21,\n",
       "                               'evidence': 20,\n",
       "                               'preparations': 4,\n",
       "                               'indicative': 1,\n",
       "                               'intention': 5,\n",
       "                               'being': 52,\n",
       "                               ...}),\n",
       "                     'mystery': FreqDist({'There': 82,\n",
       "                               'were': 155,\n",
       "                               'thirty-eight': 1,\n",
       "                               'patients': 3,\n",
       "                               'on': 421,\n",
       "                               'the': 2573,\n",
       "                               'bus': 7,\n",
       "                               'morning': 24,\n",
       "                               'I': 583,\n",
       "                               'left': 56,\n",
       "                               'for': 353,\n",
       "                               'Hanover': 8,\n",
       "                               ',': 2805,\n",
       "                               'most': 16,\n",
       "                               'of': 903,\n",
       "                               'them': 120,\n",
       "                               'disturbed': 1,\n",
       "                               'and': 1215,\n",
       "                               'hallucinating': 1,\n",
       "                               '.': 3326,\n",
       "                               'An': 7,\n",
       "                               'interne': 1,\n",
       "                               'a': 1136,\n",
       "                               'nurse': 2,\n",
       "                               'two': 80,\n",
       "                               'attendants': 1,\n",
       "                               'in': 658,\n",
       "                               'charge': 5,\n",
       "                               'us': 33,\n",
       "                               'felt': 40,\n",
       "                               'lonely': 4,\n",
       "                               'depressed': 2,\n",
       "                               'as': 277,\n",
       "                               'stared': 12,\n",
       "                               'out': 212,\n",
       "                               'window': 31,\n",
       "                               'at': 303,\n",
       "                               \"Chicago's\": 2,\n",
       "                               'grim': 1,\n",
       "                               'dirty': 4,\n",
       "                               'West': 3,\n",
       "                               'Side': 2,\n",
       "                               'It': 138,\n",
       "                               'seemed': 33,\n",
       "                               'incredible': 2,\n",
       "                               'listened': 8,\n",
       "                               'to': 1284,\n",
       "                               'monotonous': 1,\n",
       "                               'drone': 1,\n",
       "                               'voices': 2,\n",
       "                               'smelled': 2,\n",
       "                               'fetid': 1,\n",
       "                               'odors': 2,\n",
       "                               'coming': 22,\n",
       "                               'from': 175,\n",
       "                               'that': 494,\n",
       "                               'technically': 1,\n",
       "                               'was': 820,\n",
       "                               'ward': 3,\n",
       "                               'state': 4,\n",
       "                               'Illinois': 2,\n",
       "                               'going': 66,\n",
       "                               'hospital': 6,\n",
       "                               'mentally': 3,\n",
       "                               'ill': 4,\n",
       "                               'suddenly': 19,\n",
       "                               'thought': 54,\n",
       "                               'Mary': 7,\n",
       "                               'Jane': 6,\n",
       "                               'Brennan': 3,\n",
       "                               'way': 61,\n",
       "                               'her': 296,\n",
       "                               'pretty': 8,\n",
       "                               'eyes': 48,\n",
       "                               'could': 141,\n",
       "                               'flash': 2,\n",
       "                               'with': 324,\n",
       "                               'anger': 3,\n",
       "                               'quiet': 8,\n",
       "                               'competence': 1,\n",
       "                               'gentleness': 1,\n",
       "                               'sweetness': 1,\n",
       "                               'lay': 13,\n",
       "                               'just': 87,\n",
       "                               'beneath': 2,\n",
       "                               'surface': 5,\n",
       "                               'defenses': 1,\n",
       "                               'We': 32,\n",
       "                               'had': 517,\n",
       "                               'become': 7,\n",
       "                               'good': 40,\n",
       "                               'friends': 9,\n",
       "                               'during': 8,\n",
       "                               'my': 104,\n",
       "                               'stay': 10,\n",
       "                               'Cook': 1,\n",
       "                               'County': 4,\n",
       "                               'Hospital': 3,\n",
       "                               'told': 52,\n",
       "                               'enough': 37,\n",
       "                               'about': 127,\n",
       "                               'myself': 9,\n",
       "                               'offset': 1,\n",
       "                               'somewhat': 3,\n",
       "                               'damaging': 1,\n",
       "                               'stories': 6,\n",
       "                               'appeared': 7,\n",
       "                               'local': 5,\n",
       "                               'newspapers': 3,\n",
       "                               'after': 36,\n",
       "                               'little': 57,\n",
       "                               'adventure': 1,\n",
       "                               'Marshall': 1,\n",
       "                               'Field': 1,\n",
       "                               '&': 1,\n",
       "                               'Co.': 1,\n",
       "                               'She': 131,\n",
       "                               'knew': 65,\n",
       "                               'lived': 15,\n",
       "                               'address': 6,\n",
       "                               'Gold': 1,\n",
       "                               'Coast': 1,\n",
       "                               'once': 28,\n",
       "                               'been': 152,\n",
       "                               'medical': 6,\n",
       "                               'student': 1,\n",
       "                               'thinking': 14,\n",
       "                               'returning': 4,\n",
       "                               'university': 2,\n",
       "                               'finish': 5,\n",
       "                               'studies': 1,\n",
       "                               'also': 23,\n",
       "                               'unmarried': 1,\n",
       "                               'without': 27,\n",
       "                               'single': 7,\n",
       "                               'known': 18,\n",
       "                               'relative': 1,\n",
       "                               \"wasn't\": 32,\n",
       "                               'quite': 21,\n",
       "                               'sure': 29,\n",
       "                               'remorse': 1,\n",
       "                               'drinking': 6,\n",
       "                               'or': 129,\n",
       "                               'would': 186,\n",
       "                               'not': 191,\n",
       "                               'return': 10,\n",
       "                               'it': 515,\n",
       "                               'own': 26,\n",
       "                               'again': 60,\n",
       "                               'This': 26,\n",
       "                               'worried': 4,\n",
       "                               '``': 740,\n",
       "                               'read': 6,\n",
       "                               'those': 25,\n",
       "                               'newspaper': 7,\n",
       "                               'you': 340,\n",
       "                               \"''\": 738,\n",
       "                               'she': 219,\n",
       "                               'said': 202,\n",
       "                               'You': 76,\n",
       "                               'must': 30,\n",
       "                               'have': 219,\n",
       "                               'loved': 3,\n",
       "                               'girl': 17,\n",
       "                               'very': 36,\n",
       "                               'much': 57,\n",
       "                               'but': 186,\n",
       "                               \"couldn't\": 34,\n",
       "                               'meant': 9,\n",
       "                               'when': 114,\n",
       "                               'wanted': 33,\n",
       "                               'kill': 13,\n",
       "                               'Why': 27,\n",
       "                               'do': 91,\n",
       "                               'say': 46,\n",
       "                               '?': 664,\n",
       "                               'asked': 45,\n",
       "                               'full': 12,\n",
       "                               'booze': 1,\n",
       "                               'well': 33,\n",
       "                               'drunk': 7,\n",
       "                               'is': 116,\n",
       "                               'apt': 1,\n",
       "                               'anything': 37,\n",
       "                               'he': 670,\n",
       "                               'says': 16,\n",
       "                               \"he'll\": 1,\n",
       "                               'Nonsense': 1,\n",
       "                               '!': 104,\n",
       "                               'grew': 3,\n",
       "                               'up': 217,\n",
       "                               'an': 125,\n",
       "                               'Irish': 1,\n",
       "                               'neighborhood': 4,\n",
       "                               \"Don't\": 12,\n",
       "                               'tell': 37,\n",
       "                               'me': 114,\n",
       "                               'drunks': 2,\n",
       "                               \"You're\": 10,\n",
       "                               'kind': 15,\n",
       "                               'go': 80,\n",
       "                               'violent': 2,\n",
       "                               'Were': 2,\n",
       "                               'love': 7,\n",
       "                               'Would': 3,\n",
       "                               'make': 46,\n",
       "                               'any': 64,\n",
       "                               'difference': 4,\n",
       "                               'if': 130,\n",
       "                               'met': 6,\n",
       "                               'angry': 5,\n",
       "                               \"wouldn't\": 32,\n",
       "                               'gone': 29,\n",
       "                               'into': 143,\n",
       "                               'nursing': 2,\n",
       "                               \"didn't\": 74,\n",
       "                               'care': 14,\n",
       "                               'people': 34,\n",
       "                               \"I'm\": 53,\n",
       "                               'interested': 5,\n",
       "                               'every': 14,\n",
       "                               'patient': 3,\n",
       "                               \"I've\": 23,\n",
       "                               'helped': 3,\n",
       "                               'take': 48,\n",
       "                               'When': 40,\n",
       "                               'think': 54,\n",
       "                               'like': 136,\n",
       "                               '--': 270,\n",
       "                               'what': 109,\n",
       "                               'are': 50,\n",
       "                               'young': 14,\n",
       "                               'intelligent': 1,\n",
       "                               'whole': 14,\n",
       "                               'lifetime': 2,\n",
       "                               'before': 68,\n",
       "                               'something': 52,\n",
       "                               'worth': 5,\n",
       "                               'while': 41,\n",
       "                               'yourself': 9,\n",
       "                               'mess': 1,\n",
       "                               'whiskey': 4,\n",
       "                               'indifference': 1,\n",
       "                               'self-destructive': 1,\n",
       "                               'attitudes': 1,\n",
       "                               \"don't\": 71,\n",
       "                               'blame': 5,\n",
       "                               'breaking': 2,\n",
       "                               'engagement': 2,\n",
       "                               'Was': 8,\n",
       "                               'Oh': 19,\n",
       "                               'yes': 13,\n",
       "                               'feeling': 7,\n",
       "                               'annoyed': 2,\n",
       "                               'believe': 13,\n",
       "                               'back': 156,\n",
       "                               'school': 5,\n",
       "                               'should': 29,\n",
       "                               'worked': 6,\n",
       "                               'this': 146,\n",
       "                               'three': 33,\n",
       "                               'months': 5,\n",
       "                               'now': 83,\n",
       "                               'keep': 24,\n",
       "                               'getting': 13,\n",
       "                               'same': 41,\n",
       "                               'ones': 10,\n",
       "                               'They': 59,\n",
       "                               'all': 148,\n",
       "                               'mean': 13,\n",
       "                               'great': 9,\n",
       "                               'promises': 1,\n",
       "                               'they': 106,\n",
       "                               'home': 28,\n",
       "                               'their': 48,\n",
       "                               'sickness': 1,\n",
       "                               \"You've\": 6,\n",
       "                               'maybe': 15,\n",
       "                               'treated': 1,\n",
       "                               'your': 67,\n",
       "                               'here': 74,\n",
       "                               'big': 32,\n",
       "                               'joke': 3,\n",
       "                               \"It's\": 39,\n",
       "                               'be': 233,\n",
       "                               'sent': 7,\n",
       "                               'place': 33,\n",
       "                               'college': 5,\n",
       "                               'too': 72,\n",
       "                               'Chicago': 5,\n",
       "                               'has': 17,\n",
       "                               'some': 74,\n",
       "                               'best': 13,\n",
       "                               'Her': 15,\n",
       "                               'flashed': 6,\n",
       "                               'angrily': 1,\n",
       "                               \"That's\": 20,\n",
       "                               'Anderson': 2,\n",
       "                               'seem': 5,\n",
       "                               'know': 86,\n",
       "                               'reality': 3,\n",
       "                               \"I'll\": 44,\n",
       "                               'why': 25,\n",
       "                               ';': 228,\n",
       "                               'oldest': 1,\n",
       "                               'six': 12,\n",
       "                               'children': 6,\n",
       "                               'My': 13,\n",
       "                               \"father's\": 4,\n",
       "                               'policeman': 6,\n",
       "                               'makes': 3,\n",
       "                               'less': 14,\n",
       "                               'than': 62,\n",
       "                               'seven': 4,\n",
       "                               'thousand': 14,\n",
       "                               'dollars': 7,\n",
       "                               'year': 11,\n",
       "                               'no': 147,\n",
       "                               'money': 32,\n",
       "                               'tuition': 1,\n",
       "                               'clothes': 8,\n",
       "                               'things': 26,\n",
       "                               'apparently': 7,\n",
       "                               'granted': 1,\n",
       "                               \"Nurses'\": 1,\n",
       "                               'training': 1,\n",
       "                               \"doesn't\": 8,\n",
       "                               'cost': 4,\n",
       "                               'even': 53,\n",
       "                               'pay': 6,\n",
       "                               'month': 6,\n",
       "                               \"it's\": 25,\n",
       "                               'deal': 12,\n",
       "                               'got': 77,\n",
       "                               'baby': 3,\n",
       "                               'brothers': 2,\n",
       "                               'work': 33,\n",
       "                               'profession': 1,\n",
       "                               'until': 30,\n",
       "                               'old': 58,\n",
       "                               'maid': 2,\n",
       "                               'give': 23,\n",
       "                               'Do': 11,\n",
       "                               'boy': 18,\n",
       "                               'friend': 14,\n",
       "                               'none': 9,\n",
       "                               'business': 15,\n",
       "                               'then': 101,\n",
       "                               'changed': 3,\n",
       "                               'subject': 2,\n",
       "                               'What': 37,\n",
       "                               'father': 8,\n",
       "                               'mother': 11,\n",
       "                               \"you're\": 20,\n",
       "                               'died': 9,\n",
       "                               'years': 24,\n",
       "                               'aunt': 1,\n",
       "                               'raised': 9,\n",
       "                               'Aunt': 1,\n",
       "                               'doing': 13,\n",
       "                               'military': 1,\n",
       "                               'service': 4,\n",
       "                               'one': 165,\n",
       "                               'worry': 9,\n",
       "                               'Something': 6,\n",
       "                               'voice': 25,\n",
       "                               'touched': 9,\n",
       "                               'deeply': 3,\n",
       "                               'because': 37,\n",
       "                               'passed': 18,\n",
       "                               'quickly': 9,\n",
       "                               'turned': 51,\n",
       "                               'away': 50,\n",
       "                               'seeing': 6,\n",
       "                               'face': 47,\n",
       "                               'sorry': 4,\n",
       "                               \"I'd\": 31,\n",
       "                               'family': 7,\n",
       "                               \"We've\": 5,\n",
       "                               'always': 26,\n",
       "                               'so': 104,\n",
       "                               'close': 17,\n",
       "                               'Tell': 4,\n",
       "                               'more': 78,\n",
       "                               'became': 8,\n",
       "                               'bright': 7,\n",
       "                               'talked': 4,\n",
       "                               'aunts': 1,\n",
       "                               'uncles': 1,\n",
       "                               'cousins': 3,\n",
       "                               'Listening': 1,\n",
       "                               'cheated': 1,\n",
       "                               'only': 49,\n",
       "                               'orphan': 1,\n",
       "                               'can': 42,\n",
       "                               'finished': 16,\n",
       "                               ':': 27,\n",
       "                               'Your': 3,\n",
       "                               'dad': 1,\n",
       "                               'sounds': 4,\n",
       "                               'bet': 5,\n",
       "                               'pleased': 1,\n",
       "                               'rumdum': 2,\n",
       "                               'ask': 17,\n",
       "                               'his': 529,\n",
       "                               'daughter': 1,\n",
       "                               'date': 8,\n",
       "                               'sergeant': 3,\n",
       "                               'detectives': 4,\n",
       "                               'attached': 4,\n",
       "                               'Homicide': 4,\n",
       "                               'five': 22,\n",
       "                               \"He's\": 5,\n",
       "                               'judge': 3,\n",
       "                               'character': 3,\n",
       "                               \"he'd\": 23,\n",
       "                               'mind': 33,\n",
       "                               \"you'd\": 8,\n",
       "                               'decided': 20,\n",
       "                               'future': 6,\n",
       "                               'How': 11,\n",
       "                               'feel': 20,\n",
       "                               'get': 95,\n",
       "                               'through': 57,\n",
       "                               'If': 44,\n",
       "                               'serious': 4,\n",
       "                               'learned': 4,\n",
       "                               'experiences': 1,\n",
       "                               'might': 57,\n",
       "                               'consider': 2,\n",
       "                               'such': 22,\n",
       "                               'offer': 4,\n",
       "                               'important': 8,\n",
       "                               'truth': 9,\n",
       "                               'confused': 2,\n",
       "                               'sick': 4,\n",
       "                               'irresponsible': 1,\n",
       "                               'person': 7,\n",
       "                               'believed': 2,\n",
       "                               \"can't\": 24,\n",
       "                               \"you'll\": 7,\n",
       "                               'dinner': 8,\n",
       "                               'story': 15,\n",
       "                               'dead': 21,\n",
       "                               'As': 25,\n",
       "                               'other': 51,\n",
       "                               \"let's\": 6,\n",
       "                               'never': 36,\n",
       "                               'want': 51,\n",
       "                               'see': 79,\n",
       "                               'will': 20,\n",
       "                               'come': 55,\n",
       "                               'long': 39,\n",
       "                               'weekends': 1,\n",
       "                               \"won't\": 17,\n",
       "                               'Yes': 9,\n",
       "                               'overnight': 4,\n",
       "                               \"We'll\": 6,\n",
       "                               'Edgewater': 1,\n",
       "                               'Beach': 10,\n",
       "                               'Hotel': 7,\n",
       "                               'dance': 4,\n",
       "                               'orchestra': 2,\n",
       "                               'walked': 31,\n",
       "                               \"hadn't\": 27,\n",
       "                               'really': 21,\n",
       "                               'personal': 2,\n",
       "                               'interest': 8,\n",
       "                               'benefit': 2,\n",
       "                               'treatment': 1,\n",
       "                               'there': 150,\n",
       "                               'Now': 31,\n",
       "                               'riding': 3,\n",
       "                               'isolated': 1,\n",
       "                               'utterly': 3,\n",
       "                               'alone': 20,\n",
       "                               'genuine': 1,\n",
       "                               'unique': 1,\n",
       "                               'unlike': 1,\n",
       "                               'thing': 31,\n",
       "                               'life': 21,\n",
       "                               'moment': 38,\n",
       "                               'real': 20,\n",
       "                               'fantastic': 2,\n",
       "                               'Only': 7,\n",
       "                               'entering': 1,\n",
       "                               'State': 3,\n",
       "                               'under': 27,\n",
       "                               'assumed': 3,\n",
       "                               'name': 16,\n",
       "                               'unlikely': 2,\n",
       "                               'sharp': 6,\n",
       "                               'proof': 2,\n",
       "                               'But': 80,\n",
       "                               'documented': 1,\n",
       "                               'legal': 3,\n",
       "                               'agreement': 2,\n",
       "                               'which': 58,\n",
       "                               'show': 13,\n",
       "                               'free': 9,\n",
       "                               'main': 3,\n",
       "                               'highway': 4,\n",
       "                               'headed': 5,\n",
       "                               'toward': 39,\n",
       "                               'settled': 5,\n",
       "                               'seat': 19,\n",
       "                               'closed': 14,\n",
       "                               'over': 108,\n",
       "                               'events': 2,\n",
       "                               'past': 14,\n",
       "                               'weeks': 9,\n",
       "                               'trying': 13,\n",
       "                               'put': 48,\n",
       "                               'pieces': 2,\n",
       "                               'order': 7,\n",
       "                               'wondered': 11,\n",
       "                               'disconnected': 2,\n",
       "                               'jabberings': 1,\n",
       "                               'behind': 33,\n",
       "                               'perhaps': 11,\n",
       "                               'imagined': 2,\n",
       "                               'Perhaps': 5,\n",
       "                               'Dale': 3,\n",
       "                               'Nelson': 6,\n",
       "                               'actor': 4,\n",
       "                               'delusion': 1,\n",
       "                               'figment': 1,\n",
       "                               'Carl': 1,\n",
       "                               \"Anderson's\": 1,\n",
       "                               'imagination': 4,\n",
       "                               'Four': 1,\n",
       "                               'New': 13,\n",
       "                               'York': 8,\n",
       "                               'early': 14,\n",
       "                               'September': 1,\n",
       "                               'dramatic': 1,\n",
       "                               'production': 1,\n",
       "                               'called': 21,\n",
       "                               'Ask': 3,\n",
       "                               'Tony': 6,\n",
       "                               'bad': 13,\n",
       "                               'play': 6,\n",
       "                               'grade-A': 1,\n",
       "                               'turkey': 2,\n",
       "                               'prevalence': 1,\n",
       "                               'angels': 1,\n",
       "                               'grandiose': 1,\n",
       "                               'dreams': 1,\n",
       "                               'capital': 1,\n",
       "                               'gain': 1,\n",
       "                               'tax': 2,\n",
       "                               'burn': 1,\n",
       "                               'rehearsal': 1,\n",
       "                               'No': 40,\n",
       "                               'producer': 2,\n",
       "                               'hope': 14,\n",
       "                               'Broadway': 2,\n",
       "                               'suspense': 2,\n",
       "                               'gangster': 1,\n",
       "                               'Capone': 1,\n",
       "                               'era': 1,\n",
       "                               'many': 15,\n",
       "                               'catch': 3,\n",
       "                               'run': 18,\n",
       "                               'continue': 2,\n",
       "                               'road': 41,\n",
       "                               'company': 5,\n",
       "                               'eventually': 2,\n",
       "                               'movie': 1,\n",
       "                               'Such': 1,\n",
       "                               'optimism': 1,\n",
       "                               'completely': 7,\n",
       "                               'unjustified': 1,\n",
       "                               'The': 244,\n",
       "                               'critics': 1,\n",
       "                               'literally': 3,\n",
       "                               'screamed': 3,\n",
       "                               'indignation': 1,\n",
       "                               'doomed': 1,\n",
       "                               'Kupcinet': 1,\n",
       "                               'leveled': 1,\n",
       "                               'Sun-Times': 1,\n",
       "                               'column': 1,\n",
       "                               'opened': 20,\n",
       "                               'Friday': 2,\n",
       "                               'following': 3,\n",
       "                               'Monday': 5,\n",
       "                               'Out': 2,\n",
       "                               'entire': 4,\n",
       "                               'cast': 2,\n",
       "                               'received': 3,\n",
       "                               'notices': 1,\n",
       "                               'portrayal': 1,\n",
       "                               'psychopathic': 2,\n",
       "                               'killer': 8,\n",
       "                               'let': 22,\n",
       "                               'lot': 16,\n",
       "                               'kidding': 5,\n",
       "                               'rest': 8,\n",
       "                               'members': 3,\n",
       "                               'native': 1,\n",
       "                               'Chicagoans': 1,\n",
       "                               'paid': 5,\n",
       "                               'off': 79,\n",
       "                               'Tuesday': 2,\n",
       "                               'given': 8,\n",
       "                               'tickets': 2,\n",
       "                               'packed': 3,\n",
       "                               'bags': 1,\n",
       "                               'Croydon': 1,\n",
       "                               'destined': 1,\n",
       "                               'brilliant': 2,\n",
       "                               'failure': 1,\n",
       "                               'another': 41,\n",
       "                               'among': 9,\n",
       "                               'top': 15,\n",
       "                               'third': 9,\n",
       "                               'class': 1,\n",
       "                               'N.Y.U.': 1,\n",
       "                               'desperately': 1,\n",
       "                               'energy': 2,\n",
       "                               'time': 82,\n",
       "                               'Then': 35,\n",
       "                               'later': 32,\n",
       "                               'quit': 1,\n",
       "                               'safe': 8,\n",
       "                               'secure': 2,\n",
       "                               'five-a-week': 1,\n",
       "                               'spot': 7,\n",
       "                               'network': 1,\n",
       "                               'soap': 1,\n",
       "                               'opera': 1,\n",
       "                               'part': 9,\n",
       "                               'unlucky': 2,\n",
       "                               'stupid': 3,\n",
       "                               'soon': 16,\n",
       "                               'working': 12,\n",
       "                               'orderly': 2,\n",
       "                               'counterman': 1,\n",
       "                               'Union': 2,\n",
       "                               'News': 1,\n",
       "                               'Schraffts': 1,\n",
       "                               'waiting': 23,\n",
       "                               'acting': 7,\n",
       "                               'job': 15,\n",
       "                               'open': 34,\n",
       "                               'occurred': 4,\n",
       "                               'did': 47,\n",
       "                               'particularly': 6,\n",
       "                               'sort': 12,\n",
       "                               'crossroads': 1,\n",
       "                               'decide': 3,\n",
       "                               'last': 32,\n",
       "                               'bag': 7,\n",
       "                               'stood': 41,\n",
       "                               'door': 80,\n",
       "                               'bellboy': 4,\n",
       "                               'pick': 9,\n",
       "                               'went': 77,\n",
       "                               'bathroom': 3,\n",
       "                               'drink': 16,\n",
       "                               'water': 22,\n",
       "                               'telephone': 13,\n",
       "                               'rang': 7,\n",
       "                               'answered': 6,\n",
       "                               'dignified': 2,\n",
       "                               'British': 2,\n",
       "                               'Is': 4,\n",
       "                               'Mr.': 63,\n",
       "                               'All': 17,\n",
       "                               'right': 65,\n",
       "                               'bastards': 2,\n",
       "                               'beg': 2,\n",
       "                               'pardon': 1,\n",
       "                               'sir': 8,\n",
       "                               'Good': 5,\n",
       "                               'calling': 4,\n",
       "                               'request': 1,\n",
       "                               'Phillip': 1,\n",
       "                               'Wycoff': 1,\n",
       "                               'Could': 4,\n",
       "                               'possibly': 6,\n",
       "                               'lunch': 7,\n",
       "                               'him': 330,\n",
       "                               'today': 5,\n",
       "                               'His': 36,\n",
       "                               'car': 69,\n",
       "                               'hotel': 17,\n",
       "                               'twelve': 3,\n",
       "                               'smiled': 10,\n",
       "                               \"You'll\": 4,\n",
       "                               'send': 10,\n",
       "                               'Rolls-Royce': 2,\n",
       "                               'course': 26,\n",
       "                               'started': 22,\n",
       "                               'else': 19,\n",
       "                               'appropriate': 1,\n",
       "                               'man': 106,\n",
       "                               'hung': 12,\n",
       "                               'finally': 13,\n",
       "                               'downstairs': 3,\n",
       "                               'bar': 9,\n",
       "                               'lobby': 12,\n",
       "                               'where': 59,\n",
       "                               'drowning': 1,\n",
       "                               'sorrows': 1,\n",
       "                               'untimely': 1,\n",
       "                               'passing': 5,\n",
       "                               'bowed': 1,\n",
       "                               'low': 7,\n",
       "                               'approached': 5,\n",
       "                               'buy': 4,\n",
       "                               'laid': 5,\n",
       "                               'tenspot': 1,\n",
       "                               'motioned': 1,\n",
       "                               'bartender': 4,\n",
       "                               'serve': 1,\n",
       "                               'round': 5,\n",
       "                               'He': 406,\n",
       "                               'returned': 13,\n",
       "                               'change': 11,\n",
       "                               'doorman': 2,\n",
       "                               'came': 50,\n",
       "                               'street': 36,\n",
       "                               'page': 4,\n",
       "                               \"Wycoff's\": 1,\n",
       "                               'east': 7,\n",
       "                               'entrance': 8,\n",
       "                               'followed': 12,\n",
       "                               'ancient': 3,\n",
       "                               'shiningly': 1,\n",
       "                               'impressive': 1,\n",
       "                               'day': 40,\n",
       "                               'ship': 2,\n",
       "                               'parked': 19,\n",
       "                               'curb': 8,\n",
       "                               'elderly': 1,\n",
       "                               'chauffeur': 1,\n",
       "                               'immaculate': 1,\n",
       "                               'dark': 23,\n",
       "                               'uniform': 2,\n",
       "                               'stiffly': 2,\n",
       "                               'attention': 11,\n",
       "                               'holding': 7,\n",
       "                               'town': 8,\n",
       "                               'giving': 7,\n",
       "                               'cars': 17,\n",
       "                               'once-over': 1,\n",
       "                               'Oldsmobile': 1,\n",
       "                               'license': 9,\n",
       "                               'number': 20,\n",
       "                               'JYJ': 1,\n",
       "                               '114': 2,\n",
       "                               'stall': 1,\n",
       "                               'Okay': 4,\n",
       "                               'attendant': 4,\n",
       "                               'office': 50,\n",
       "                               'building': 21,\n",
       "                               'gave': 22,\n",
       "                               'ticket': 3,\n",
       "                               'agency': 5,\n",
       "                               'ten': 19,\n",
       "                               'minutes': 26,\n",
       "                               'Forgot': 1,\n",
       "                               'showing': 4,\n",
       "                               'grinned': 6,\n",
       "                               'talking': 10,\n",
       "                               'monthly': 2,\n",
       "                               'rental': 1,\n",
       "                               'consulted': 2,\n",
       "                               'parking': 13,\n",
       "                               'looked': 52,\n",
       "                               'notation': 1,\n",
       "                               'row': 3,\n",
       "                               'rear': 4,\n",
       "                               'Can': 3,\n",
       "                               'find': 29,\n",
       "                               'Sure': 12,\n",
       "                               'electric': 5,\n",
       "                               'bug': 3,\n",
       "                               'newest': 2,\n",
       "                               'devices': 1,\n",
       "                               'electronic': 4,\n",
       "                               'shadowing': 3,\n",
       "                               'set': 21,\n",
       "                               'new': 16,\n",
       "                               'batteries': 3,\n",
       "                               'certain': 9,\n",
       "                               'plenty': 3,\n",
       "                               'power': 2,\n",
       "                               'regular': 3,\n",
       "                               'stalls': 1,\n",
       "                               'looking': 24,\n",
       "                               'thoughtfully': 2,\n",
       "                               'waited': 16,\n",
       "                               'busy': 9,\n",
       "                               'customer': 6,\n",
       "                               'slipped': 5,\n",
       "                               'around': 76,\n",
       "                               'JYM': 1,\n",
       "                               'bumper': 1,\n",
       "                               'waved': 5,\n",
       "                               'One': 7,\n",
       "                               'hardest': 1,\n",
       "                               'chores': 1,\n",
       "                               'detective': 3,\n",
       "                               'hanging': 4,\n",
       "                               'city': 5,\n",
       "                               'himself': 52,\n",
       "                               'inconspicuous': 1,\n",
       "                               'keeping': 5,\n",
       "                               'eye': 11,\n",
       "                               'For': 25,\n",
       "                               'first': 37,\n",
       "                               'fifteen': 4,\n",
       "                               'twenty': 5,\n",
       "                               'possible': 14,\n",
       "                               'displays': 1,\n",
       "                               'by': 104,\n",
       "                               'After': 20,\n",
       "                               'however': 4,\n",
       "                               \"person's\": 1,\n",
       "                               'gets': 6,\n",
       "                               'fed': 1,\n",
       "                               'magnifies': 1,\n",
       "                               'disagreeable': 1,\n",
       "                               'physical': 1,\n",
       "                               'symptoms': 2,\n",
       "                               'assignment': 2,\n",
       "                               'sit': 7,\n",
       "                               'down': 83,\n",
       "                               'leg': 5,\n",
       "                               'muscles': 3,\n",
       "                               'weary': 1,\n",
       "                               'conscious': 2,\n",
       "                               'fact': 14,\n",
       "                               'feet': 20,\n",
       "                               'hurt': 4,\n",
       "                               'pavements': 1,\n",
       "                               'hard': 15,\n",
       "                               'solid': 7,\n",
       "                               'hours': 10,\n",
       "                               'far': 19,\n",
       "                               'entered': 9,\n",
       "                               'hurried': 4,\n",
       "                               'recognized': 7,\n",
       "                               \"haven't\": 5,\n",
       "                               'made': 60,\n",
       "                               'yet': 18,\n",
       "                               'sublease': 1,\n",
       "                               'couple': 25,\n",
       "                               'figuring': 2,\n",
       "                               \"that's\": 12,\n",
       "                               'ways': 2,\n",
       "                               \"there's\": 9,\n",
       "                               'usually': 5,\n",
       "                               'That': 32,\n",
       "                               'undependable': 1,\n",
       "                               'annoying': 2,\n",
       "                               'rains': 1,\n",
       "                               'kept': 14,\n",
       "                               'rush': 2,\n",
       "                               'Want': 2,\n",
       "                               'drive': 10,\n",
       "                               'boys': 10,\n",
       "                               'rules': 2,\n",
       "                               'transients': 1,\n",
       "                               'Regulars': 1,\n",
       "                               'Make': 4,\n",
       "                               'snappy': 1,\n",
       "                               'lease': 1,\n",
       "                               'sticks': 3,\n",
       "                               \"isn't\": 12,\n",
       "                               'handed': 7,\n",
       "                               'By': 13,\n",
       "                               'figured': 5,\n",
       "                               'cigar': 2,\n",
       "                               'heap': 3,\n",
       "                               'jumped': 6,\n",
       "                               'motor': 3,\n",
       "                               'shadow': 8,\n",
       "                               'turn': 12,\n",
       "                               'held': 12,\n",
       "                               'bit': 14,\n",
       "                               'Traffic': 1,\n",
       "                               'heavy': 9,\n",
       "                               'signal': 11,\n",
       "                               'loud': 4,\n",
       "                               'clear': 13,\n",
       "                               'picked': 11,\n",
       "                               'within': 3,\n",
       "                               'blocks': 1,\n",
       "                               'stayed': 9,\n",
       "                               'half': 16,\n",
       "                               'block': 15,\n",
       "                               'letting': 3,\n",
       "                               'lots': 4,\n",
       "                               'between': 26,\n",
       "                               'listening': 7,\n",
       "                               'steady': 11,\n",
       "                               'beep': 4,\n",
       "                               'traffic': 5,\n",
       "                               'driving': 4,\n",
       "                               'bugging': 3,\n",
       "                               'device': 7,\n",
       "                               'beeps': 3,\n",
       "                               'straight': 7,\n",
       "                               'ahead': 12,\n",
       "                               'short': 13,\n",
       "                               'drawn-out': 1,\n",
       "                               'ever': 14,\n",
       "                               'buzz': 3,\n",
       "                               'still': 66,\n",
       "                               'someplace': 1,\n",
       "                               'circle': 4,\n",
       "                               'located': 2,\n",
       "                               'front': 35,\n",
       "                               'apartment': 17,\n",
       "                               'house': 41,\n",
       "                               'found': 42,\n",
       "                               'sat': 17,\n",
       "                               'quarry': 2,\n",
       "                               'beach': 4,\n",
       "                               'drop': 5,\n",
       "                               'lights': 5,\n",
       "                               'giveaway': 1,\n",
       "                               'tried': 16,\n",
       "                               'conventional': 1,\n",
       "                               'manner': 5,\n",
       "                               'Moreover': 1,\n",
       "                               'lost': 15,\n",
       "                               'sudden': 13,\n",
       "                               'circled': 1,\n",
       "                               'high-class': 1,\n",
       "                               'restaurant': 6,\n",
       "                               'watch': 13,\n",
       "                               'exit': 3,\n",
       "                               'realized': 9,\n",
       "                               'hungry': 4,\n",
       "                               'faint': 4,\n",
       "                               'odor': 3,\n",
       "                               'charcoal-broiled': 1,\n",
       "                               'steaks': 1,\n",
       "                               'tantalizing': 1,\n",
       "                               'nostrils': 2,\n",
       "                               'occasionally': 3,\n",
       "                               'catching': 3,\n",
       "                               'aroma': 1,\n",
       "                               'coffee': 16,\n",
       "                               'hour': 19,\n",
       "                               'drove': 14,\n",
       "                               'mile': 4,\n",
       "                               'Swim': 1,\n",
       "                               'Tan': 1,\n",
       "                               'Motel': 1,\n",
       "                               'fairly': 2,\n",
       "                               'modern': 6,\n",
       "                               'motel': 7,\n",
       "                               'electrical': 1,\n",
       "                               'display': 3,\n",
       "                               'remembered': 15,\n",
       "                               'Peeping': 1,\n",
       "                               'Tom': 1,\n",
       "                               'key': 11,\n",
       "                               'cabin': 3,\n",
       "                               'register': 4,\n",
       "                               'card': 4,\n",
       "                               'filled': 5,\n",
       "                               'counter': 9,\n",
       "                               'noticed': 14,\n",
       "                               'Unit': 2,\n",
       "                               '12': 3,\n",
       "                               'registered': 1,\n",
       "                               'Oscar': 1,\n",
       "                               'L.': 1,\n",
       "                               'Palmer': 1,\n",
       "                               'wife': 17,\n",
       "                               'San': 5,\n",
       "                               'Francisco': 1,\n",
       "                               'written': 5,\n",
       "                               'transposed': 1,\n",
       "                               'figures': 4,\n",
       "                               'dodge': 1,\n",
       "                               'Ninety-nine': 1,\n",
       "                               'times': 5,\n",
       "                               'hundred': 10,\n",
       "                               'manager': 4,\n",
       "                               'check': 10,\n",
       "                               'plates': 2,\n",
       "                               'against': 31,\n",
       "                               'tenant': 1,\n",
       "                               'writes': 1,\n",
       "                               'does': 9,\n",
       "                               'better': 29,\n",
       "                               'chance': 13,\n",
       "                               'notice': 9,\n",
       "                               'transposition': 1,\n",
       "                               'numbers': 8,\n",
       "                               'honest': 4,\n",
       "                               'mistake': 3,\n",
       "                               ...}),\n",
       "                     'news': FreqDist({'The': 806,\n",
       "                               'Fulton': 14,\n",
       "                               'County': 35,\n",
       "                               'Grand': 6,\n",
       "                               'Jury': 2,\n",
       "                               'said': 402,\n",
       "                               'Friday': 41,\n",
       "                               'an': 300,\n",
       "                               'investigation': 9,\n",
       "                               'of': 2849,\n",
       "                               \"Atlanta's\": 4,\n",
       "                               'recent': 20,\n",
       "                               'primary': 17,\n",
       "                               'election': 38,\n",
       "                               'produced': 6,\n",
       "                               '``': 732,\n",
       "                               'no': 109,\n",
       "                               'evidence': 17,\n",
       "                               \"''\": 702,\n",
       "                               'that': 802,\n",
       "                               'any': 90,\n",
       "                               'irregularities': 3,\n",
       "                               'took': 47,\n",
       "                               'place': 25,\n",
       "                               '.': 4030,\n",
       "                               'jury': 44,\n",
       "                               'further': 16,\n",
       "                               'in': 1893,\n",
       "                               'term-end': 1,\n",
       "                               'presentments': 1,\n",
       "                               'the': 5580,\n",
       "                               'City': 44,\n",
       "                               'Executive': 6,\n",
       "                               'Committee': 37,\n",
       "                               ',': 5188,\n",
       "                               'which': 244,\n",
       "                               'had': 279,\n",
       "                               'over-all': 2,\n",
       "                               'charge': 17,\n",
       "                               'deserves': 3,\n",
       "                               'praise': 2,\n",
       "                               'and': 2146,\n",
       "                               'thanks': 6,\n",
       "                               'Atlanta': 14,\n",
       "                               'for': 943,\n",
       "                               'manner': 7,\n",
       "                               'was': 717,\n",
       "                               'conducted': 8,\n",
       "                               'September-October': 1,\n",
       "                               'term': 13,\n",
       "                               'been': 212,\n",
       "                               'charged': 12,\n",
       "                               'by': 497,\n",
       "                               'Superior': 5,\n",
       "                               'Court': 26,\n",
       "                               'Judge': 28,\n",
       "                               'Durwood': 1,\n",
       "                               'Pye': 1,\n",
       "                               'to': 2116,\n",
       "                               'investigate': 3,\n",
       "                               'reports': 12,\n",
       "                               'possible': 28,\n",
       "                               'hard-fought': 1,\n",
       "                               'won': 24,\n",
       "                               'Mayor-nominate': 1,\n",
       "                               'Ivan': 2,\n",
       "                               'Allen': 7,\n",
       "                               'Jr.': 46,\n",
       "                               'Only': 8,\n",
       "                               'a': 1993,\n",
       "                               'relative': 3,\n",
       "                               'handful': 1,\n",
       "                               'such': 70,\n",
       "                               'received': 33,\n",
       "                               'considering': 2,\n",
       "                               'widespread': 4,\n",
       "                               'interest': 32,\n",
       "                               'number': 32,\n",
       "                               'voters': 12,\n",
       "                               'size': 8,\n",
       "                               'this': 250,\n",
       "                               'city': 49,\n",
       "                               'it': 363,\n",
       "                               'did': 63,\n",
       "                               'find': 16,\n",
       "                               'many': 60,\n",
       "                               \"Georgia's\": 7,\n",
       "                               'registration': 2,\n",
       "                               'laws': 30,\n",
       "                               'are': 328,\n",
       "                               'outmoded': 1,\n",
       "                               'or': 173,\n",
       "                               'inadequate': 4,\n",
       "                               'often': 14,\n",
       "                               'ambiguous': 1,\n",
       "                               'It': 115,\n",
       "                               'recommended': 9,\n",
       "                               'legislators': 8,\n",
       "                               'act': 20,\n",
       "                               'have': 265,\n",
       "                               'these': 59,\n",
       "                               'studied': 7,\n",
       "                               'revised': 2,\n",
       "                               'end': 29,\n",
       "                               'modernizing': 1,\n",
       "                               'improving': 4,\n",
       "                               'them': 96,\n",
       "                               'grand': 13,\n",
       "                               'commented': 7,\n",
       "                               'on': 657,\n",
       "                               'other': 149,\n",
       "                               'topics': 2,\n",
       "                               'among': 24,\n",
       "                               'purchasing': 3,\n",
       "                               'departments': 2,\n",
       "                               'well': 43,\n",
       "                               'operated': 4,\n",
       "                               'follow': 12,\n",
       "                               'generally': 14,\n",
       "                               'accepted': 4,\n",
       "                               'practices': 7,\n",
       "                               'inure': 1,\n",
       "                               'best': 29,\n",
       "                               'both': 56,\n",
       "                               'governments': 5,\n",
       "                               'Merger': 1,\n",
       "                               'proposed': 18,\n",
       "                               'However': 12,\n",
       "                               'believes': 8,\n",
       "                               'two': 157,\n",
       "                               'offices': 4,\n",
       "                               'should': 59,\n",
       "                               'be': 526,\n",
       "                               'combined': 9,\n",
       "                               'achieve': 6,\n",
       "                               'greater': 10,\n",
       "                               'efficiency': 2,\n",
       "                               'reduce': 8,\n",
       "                               'cost': 15,\n",
       "                               'administration': 52,\n",
       "                               'Purchasing': 1,\n",
       "                               'Department': 20,\n",
       "                               'is': 732,\n",
       "                               'lacking': 3,\n",
       "                               'experienced': 4,\n",
       "                               'clerical': 4,\n",
       "                               'personnel': 11,\n",
       "                               'as': 481,\n",
       "                               'result': 30,\n",
       "                               'policies': 8,\n",
       "                               'urged': 11,\n",
       "                               'take': 48,\n",
       "                               'steps': 8,\n",
       "                               'remedy': 1,\n",
       "                               'problem': 39,\n",
       "                               'Implementation': 1,\n",
       "                               'automobile': 4,\n",
       "                               'title': 3,\n",
       "                               'law': 38,\n",
       "                               'also': 120,\n",
       "                               'outgoing': 3,\n",
       "                               'next': 40,\n",
       "                               'Legislature': 19,\n",
       "                               'provide': 24,\n",
       "                               'enabling': 5,\n",
       "                               'funds': 28,\n",
       "                               're-set': 1,\n",
       "                               'effective': 15,\n",
       "                               'date': 16,\n",
       "                               'so': 67,\n",
       "                               'orderly': 3,\n",
       "                               'implementation': 1,\n",
       "                               'may': 66,\n",
       "                               'effected': 1,\n",
       "                               'swipe': 1,\n",
       "                               'at': 598,\n",
       "                               'State': 63,\n",
       "                               'Welfare': 3,\n",
       "                               \"Department's\": 2,\n",
       "                               'handling': 3,\n",
       "                               'federal': 35,\n",
       "                               'granted': 5,\n",
       "                               'child': 9,\n",
       "                               'welfare': 13,\n",
       "                               'services': 18,\n",
       "                               'foster': 1,\n",
       "                               'homes': 9,\n",
       "                               'This': 70,\n",
       "                               'one': 184,\n",
       "                               'major': 28,\n",
       "                               'items': 4,\n",
       "                               'general': 29,\n",
       "                               'assistance': 8,\n",
       "                               'program': 66,\n",
       "                               'but': 174,\n",
       "                               'has': 300,\n",
       "                               'seen': 7,\n",
       "                               'fit': 3,\n",
       "                               'distribute': 2,\n",
       "                               'through': 54,\n",
       "                               'all': 163,\n",
       "                               'counties': 13,\n",
       "                               'state': 90,\n",
       "                               'with': 545,\n",
       "                               'exception': 4,\n",
       "                               'receives': 1,\n",
       "                               'none': 7,\n",
       "                               'money': 29,\n",
       "                               'jurors': 4,\n",
       "                               'they': 205,\n",
       "                               'realize': 4,\n",
       "                               'proportionate': 1,\n",
       "                               'distribution': 7,\n",
       "                               'might': 38,\n",
       "                               'disable': 1,\n",
       "                               'our': 55,\n",
       "                               'less': 10,\n",
       "                               'populous': 3,\n",
       "                               'Nevertheless': 1,\n",
       "                               'we': 77,\n",
       "                               'feel': 19,\n",
       "                               'future': 25,\n",
       "                               'receive': 15,\n",
       "                               'some': 95,\n",
       "                               'portion': 2,\n",
       "                               'available': 10,\n",
       "                               'Failure': 2,\n",
       "                               'do': 63,\n",
       "                               'will': 389,\n",
       "                               'continue': 11,\n",
       "                               'disproportionate': 1,\n",
       "                               'burden': 2,\n",
       "                               'taxpayers': 5,\n",
       "                               \"ordinary's\": 1,\n",
       "                               'court': 29,\n",
       "                               'under': 83,\n",
       "                               'fire': 21,\n",
       "                               'its': 174,\n",
       "                               'appointment': 8,\n",
       "                               'appraisers': 1,\n",
       "                               'guardians': 2,\n",
       "                               'administrators': 1,\n",
       "                               'awarding': 1,\n",
       "                               'fees': 13,\n",
       "                               'compensation': 4,\n",
       "                               'Wards': 1,\n",
       "                               'protected': 1,\n",
       "                               'found': 30,\n",
       "                               'incorporated': 1,\n",
       "                               'into': 114,\n",
       "                               'operating': 4,\n",
       "                               'procedures': 5,\n",
       "                               'recommendations': 6,\n",
       "                               'previous': 11,\n",
       "                               'juries': 1,\n",
       "                               'Bar': 2,\n",
       "                               'Association': 18,\n",
       "                               'interim': 2,\n",
       "                               'citizens': 6,\n",
       "                               'committee': 38,\n",
       "                               'These': 11,\n",
       "                               'actions': 6,\n",
       "                               'serve': 7,\n",
       "                               'protect': 2,\n",
       "                               'fact': 25,\n",
       "                               'effect': 17,\n",
       "                               \"court's\": 1,\n",
       "                               'wards': 1,\n",
       "                               'from': 344,\n",
       "                               'undue': 2,\n",
       "                               'costs': 18,\n",
       "                               'appointed': 6,\n",
       "                               'elected': 11,\n",
       "                               'servants': 5,\n",
       "                               'unmeritorious': 1,\n",
       "                               'criticisms': 2,\n",
       "                               'Regarding': 1,\n",
       "                               'new': 148,\n",
       "                               'multi-million-dollar': 1,\n",
       "                               'airport': 3,\n",
       "                               'when': 128,\n",
       "                               'management': 6,\n",
       "                               'takes': 7,\n",
       "                               'Jan.': 15,\n",
       "                               '1': 47,\n",
       "                               'eliminate': 5,\n",
       "                               'political': 27,\n",
       "                               'influences': 1,\n",
       "                               'not': 254,\n",
       "                               'elaborate': 3,\n",
       "                               'added': 33,\n",
       "                               'there': 131,\n",
       "                               'periodic': 1,\n",
       "                               'surveillance': 1,\n",
       "                               'pricing': 3,\n",
       "                               'concessionaires': 1,\n",
       "                               'purpose': 9,\n",
       "                               'keeping': 4,\n",
       "                               'prices': 19,\n",
       "                               'reasonable': 2,\n",
       "                               'Ask': 1,\n",
       "                               'jail': 6,\n",
       "                               'deputies': 3,\n",
       "                               'On': 34,\n",
       "                               'matters': 3,\n",
       "                               ':': 149,\n",
       "                               '(': 168,\n",
       "                               ')': 171,\n",
       "                               'Four': 9,\n",
       "                               'additional': 14,\n",
       "                               'employed': 5,\n",
       "                               'Jail': 2,\n",
       "                               'doctor': 3,\n",
       "                               'medical': 18,\n",
       "                               'intern': 1,\n",
       "                               'extern': 1,\n",
       "                               'night': 64,\n",
       "                               'weekend': 12,\n",
       "                               'duty': 2,\n",
       "                               '2': 33,\n",
       "                               'work': 66,\n",
       "                               'officials': 12,\n",
       "                               'pass': 15,\n",
       "                               'legislation': 14,\n",
       "                               'permit': 6,\n",
       "                               'establishment': 7,\n",
       "                               'fair': 10,\n",
       "                               'equitable': 1,\n",
       "                               'pension': 5,\n",
       "                               'plan': 45,\n",
       "                               'employes': 9,\n",
       "                               'praised': 3,\n",
       "                               'operation': 15,\n",
       "                               'Police': 9,\n",
       "                               'Tax': 5,\n",
       "                               \"Commissioner's\": 1,\n",
       "                               'Office': 4,\n",
       "                               'Bellwood': 1,\n",
       "                               'Alpharetta': 1,\n",
       "                               'prison': 7,\n",
       "                               'farms': 3,\n",
       "                               'Grady': 5,\n",
       "                               'Hospital': 21,\n",
       "                               'Health': 5,\n",
       "                               'Mayor': 17,\n",
       "                               'William': 36,\n",
       "                               'B.': 31,\n",
       "                               'Hartsfield': 5,\n",
       "                               'filed': 7,\n",
       "                               'suit': 6,\n",
       "                               'divorce': 3,\n",
       "                               'his': 399,\n",
       "                               'wife': 35,\n",
       "                               'Pearl': 1,\n",
       "                               'Williams': 14,\n",
       "                               'His': 29,\n",
       "                               'petition': 6,\n",
       "                               'mental': 1,\n",
       "                               'cruelty': 1,\n",
       "                               'couple': 13,\n",
       "                               'married': 8,\n",
       "                               'Aug.': 8,\n",
       "                               '1913': 2,\n",
       "                               'They': 62,\n",
       "                               'son': 22,\n",
       "                               'Berry': 5,\n",
       "                               'daughter': 26,\n",
       "                               'Mrs.': 253,\n",
       "                               'J.': 42,\n",
       "                               'M.': 22,\n",
       "                               'Cheshire': 1,\n",
       "                               'Griffin': 2,\n",
       "                               'Attorneys': 2,\n",
       "                               'mayor': 2,\n",
       "                               'amicable': 1,\n",
       "                               'property': 16,\n",
       "                               'settlement': 3,\n",
       "                               'agreed': 15,\n",
       "                               'upon': 23,\n",
       "                               'listed': 10,\n",
       "                               \"mayor's\": 4,\n",
       "                               'occupation': 4,\n",
       "                               'attorney': 17,\n",
       "                               'age': 11,\n",
       "                               '71': 4,\n",
       "                               \"wife's\": 1,\n",
       "                               '74': 3,\n",
       "                               'birth': 5,\n",
       "                               'Opelika': 1,\n",
       "                               'Ala.': 7,\n",
       "                               'lived': 3,\n",
       "                               'together': 27,\n",
       "                               'man': 72,\n",
       "                               'more': 171,\n",
       "                               'than': 138,\n",
       "                               'year': 138,\n",
       "                               'home': 127,\n",
       "                               '637': 1,\n",
       "                               'E.': 34,\n",
       "                               'Pelham': 5,\n",
       "                               'Rd.': 3,\n",
       "                               'Aj': 14,\n",
       "                               'Henry': 18,\n",
       "                               'L.': 25,\n",
       "                               'Bowden': 2,\n",
       "                               'brief': 2,\n",
       "                               'interlude': 1,\n",
       "                               'since': 61,\n",
       "                               '1937': 2,\n",
       "                               'career': 10,\n",
       "                               'goes': 5,\n",
       "                               'back': 69,\n",
       "                               'council': 19,\n",
       "                               '1923': 2,\n",
       "                               'present': 30,\n",
       "                               'office': 24,\n",
       "                               'expires': 1,\n",
       "                               'He': 191,\n",
       "                               'succeeded': 3,\n",
       "                               'who': 268,\n",
       "                               'became': 20,\n",
       "                               'candidate': 17,\n",
       "                               'Sept.': 6,\n",
       "                               '13': 16,\n",
       "                               'after': 127,\n",
       "                               'announced': 37,\n",
       "                               'he': 451,\n",
       "                               'would': 244,\n",
       "                               'run': 35,\n",
       "                               'reelection': 1,\n",
       "                               'Georgia': 18,\n",
       "                               'Republicans': 15,\n",
       "                               'getting': 17,\n",
       "                               'strong': 13,\n",
       "                               'encouragement': 5,\n",
       "                               'enter': 5,\n",
       "                               '1962': 5,\n",
       "                               \"governor's\": 4,\n",
       "                               'race': 20,\n",
       "                               'top': 34,\n",
       "                               'official': 16,\n",
       "                               'Wednesday': 22,\n",
       "                               'Robert': 28,\n",
       "                               'Snodgrass': 1,\n",
       "                               'GOP': 5,\n",
       "                               'chairman': 35,\n",
       "                               'meeting': 62,\n",
       "                               'held': 41,\n",
       "                               'Tuesday': 43,\n",
       "                               'Blue': 11,\n",
       "                               'Ridge': 3,\n",
       "                               'brought': 21,\n",
       "                               'enthusiastic': 3,\n",
       "                               'responses': 1,\n",
       "                               'audience': 12,\n",
       "                               'Party': 9,\n",
       "                               'Chairman': 8,\n",
       "                               'James': 37,\n",
       "                               'W.': 38,\n",
       "                               'Dorsey': 1,\n",
       "                               'enthusiasm': 3,\n",
       "                               'picking': 1,\n",
       "                               'up': 168,\n",
       "                               'rally': 3,\n",
       "                               '8': 22,\n",
       "                               'Savannah': 1,\n",
       "                               'newly': 6,\n",
       "                               'Texas': 48,\n",
       "                               'Sen.': 18,\n",
       "                               'John': 65,\n",
       "                               'Tower': 1,\n",
       "                               'featured': 3,\n",
       "                               'speaker': 4,\n",
       "                               'In': 127,\n",
       "                               'warned': 2,\n",
       "                               'entering': 5,\n",
       "                               'governor': 13,\n",
       "                               'force': 7,\n",
       "                               'petitions': 6,\n",
       "                               'out': 161,\n",
       "                               'voting': 7,\n",
       "                               'precincts': 4,\n",
       "                               'obtain': 8,\n",
       "                               'signatures': 5,\n",
       "                               'registered': 2,\n",
       "                               'Despite': 5,\n",
       "                               'warning': 4,\n",
       "                               'unanimous': 2,\n",
       "                               'vote': 28,\n",
       "                               'according': 23,\n",
       "                               'attended': 10,\n",
       "                               'When': 41,\n",
       "                               'crowd': 8,\n",
       "                               'asked': 34,\n",
       "                               'whether': 18,\n",
       "                               'wanted': 20,\n",
       "                               'wait': 4,\n",
       "                               'make': 43,\n",
       "                               'voted': 9,\n",
       "                               '--': 300,\n",
       "                               'were': 252,\n",
       "                               'dissents': 1,\n",
       "                               'largest': 10,\n",
       "                               'hurdle': 1,\n",
       "                               'face': 19,\n",
       "                               'says': 28,\n",
       "                               'before': 86,\n",
       "                               'making': 25,\n",
       "                               'first': 143,\n",
       "                               'alternative': 4,\n",
       "                               'courses': 5,\n",
       "                               'must': 50,\n",
       "                               'taken': 30,\n",
       "                               'Five': 4,\n",
       "                               'per': 61,\n",
       "                               'cent': 51,\n",
       "                               'each': 61,\n",
       "                               'county': 26,\n",
       "                               'sign': 9,\n",
       "                               'requesting': 1,\n",
       "                               'allowed': 8,\n",
       "                               'names': 6,\n",
       "                               'candidates': 10,\n",
       "                               'ballot': 8,\n",
       "                               'hold': 10,\n",
       "                               'unit': 10,\n",
       "                               'system': 47,\n",
       "                               'party': 34,\n",
       "                               'opposes': 2,\n",
       "                               'platform': 2,\n",
       "                               'Sam': 13,\n",
       "                               'Caldwell': 2,\n",
       "                               'Highway': 6,\n",
       "                               'public': 51,\n",
       "                               'relations': 16,\n",
       "                               'director': 30,\n",
       "                               'resigned': 5,\n",
       "                               'Lt.': 1,\n",
       "                               'Gov.': 10,\n",
       "                               'Garland': 3,\n",
       "                               \"Byrd's\": 1,\n",
       "                               'campaign': 17,\n",
       "                               \"Caldwell's\": 1,\n",
       "                               'resignation': 4,\n",
       "                               'expected': 40,\n",
       "                               'time': 97,\n",
       "                               'Rob': 1,\n",
       "                               'Ledford': 1,\n",
       "                               'Gainesville': 1,\n",
       "                               'assistant': 10,\n",
       "                               'three': 97,\n",
       "                               'years': 102,\n",
       "                               'gubernatorial': 6,\n",
       "                               'starts': 9,\n",
       "                               'become': 23,\n",
       "                               'coordinator': 5,\n",
       "                               'Byrd': 1,\n",
       "                               'wind': 4,\n",
       "                               '1961': 42,\n",
       "                               'session': 37,\n",
       "                               'Monday': 54,\n",
       "                               'head': 24,\n",
       "                               'where': 58,\n",
       "                               'highway': 7,\n",
       "                               'bond': 11,\n",
       "                               'approved': 8,\n",
       "                               'shortly': 5,\n",
       "                               'Before': 7,\n",
       "                               'adjournment': 2,\n",
       "                               'afternoon': 19,\n",
       "                               'Senate': 32,\n",
       "                               'approve': 2,\n",
       "                               'study': 13,\n",
       "                               'allotted': 2,\n",
       "                               'rural': 9,\n",
       "                               'urban': 4,\n",
       "                               'areas': 12,\n",
       "                               'determine': 3,\n",
       "                               'what': 76,\n",
       "                               'adjustments': 2,\n",
       "                               'made': 107,\n",
       "                               'Vandiver': 4,\n",
       "                               'traditional': 8,\n",
       "                               'visit': 6,\n",
       "                               'chambers': 2,\n",
       "                               'toward': 23,\n",
       "                               'likely': 7,\n",
       "                               'mention': 6,\n",
       "                               '$100': 7,\n",
       "                               'million': 45,\n",
       "                               'issue': 30,\n",
       "                               'earlier': 24,\n",
       "                               'priority': 4,\n",
       "                               'item': 1,\n",
       "                               'Construction': 2,\n",
       "                               'bonds': 29,\n",
       "                               'Meanwhile': 4,\n",
       "                               'learned': 7,\n",
       "                               'very': 33,\n",
       "                               'near': 16,\n",
       "                               'being': 56,\n",
       "                               'ready': 12,\n",
       "                               '$30': 1,\n",
       "                               'worth': 15,\n",
       "                               'reconstruction': 1,\n",
       "                               'go': 41,\n",
       "                               'courts': 6,\n",
       "                               'friendly': 3,\n",
       "                               'test': 15,\n",
       "                               'validity': 1,\n",
       "                               'then': 56,\n",
       "                               'sales': 51,\n",
       "                               'begin': 10,\n",
       "                               'contracts': 4,\n",
       "                               'let': 10,\n",
       "                               'repair': 2,\n",
       "                               'most': 74,\n",
       "                               'heavily': 5,\n",
       "                               'traveled': 2,\n",
       "                               'highways': 3,\n",
       "                               'A': 137,\n",
       "                               'source': 7,\n",
       "                               '$3': 1,\n",
       "                               '$4': 1,\n",
       "                               'Rural': 2,\n",
       "                               'Roads': 2,\n",
       "                               'Authority': 4,\n",
       "                               'road': 12,\n",
       "                               'construction': 14,\n",
       "                               'revolving': 3,\n",
       "                               'fund': 12,\n",
       "                               'department': 12,\n",
       "                               'apparently': 12,\n",
       "                               'intends': 1,\n",
       "                               'issued': 8,\n",
       "                               'every': 25,\n",
       "                               'old': 23,\n",
       "                               'ones': 8,\n",
       "                               'paid': 25,\n",
       "                               'off': 73,\n",
       "                               'tax': 53,\n",
       "                               'authorities': 7,\n",
       "                               'opened': 9,\n",
       "                               '1958': 19,\n",
       "                               'battle': 15,\n",
       "                               'against': 78,\n",
       "                               'issuance': 2,\n",
       "                               '$50': 2,\n",
       "                               'roads': 10,\n",
       "                               'Marvin': 2,\n",
       "                               'told': 53,\n",
       "                               'Constitution': 4,\n",
       "                               'however': 37,\n",
       "                               'consulted': 4,\n",
       "                               'yet': 10,\n",
       "                               'about': 136,\n",
       "                               'plans': 22,\n",
       "                               'Schley': 1,\n",
       "                               'Rep.': 10,\n",
       "                               'D.': 24,\n",
       "                               'offer': 9,\n",
       "                               'resolution': 21,\n",
       "                               'House': 71,\n",
       "                               'rescind': 2,\n",
       "                               \"body's\": 1,\n",
       "                               'action': 20,\n",
       "                               'itself': 10,\n",
       "                               '$10': 3,\n",
       "                               'day': 61,\n",
       "                               'increase': 24,\n",
       "                               'expense': 7,\n",
       "                               'allowances': 3,\n",
       "                               'Sunday': 51,\n",
       "                               'research': 15,\n",
       "                               'done': 24,\n",
       "                               'quickie': 1,\n",
       "                               'can': 93,\n",
       "                               'repealed': 1,\n",
       "                               'outright': 3,\n",
       "                               'notice': 5,\n",
       "                               'given': 37,\n",
       "                               'reconsideration': 2,\n",
       "                               'sought': 6,\n",
       "                               'While': 12,\n",
       "                               'emphasizing': 1,\n",
       "                               'technical': 7,\n",
       "                               'details': 3,\n",
       "                               'fully': 6,\n",
       "                               'worked': 12,\n",
       "                               'seek': 12,\n",
       "                               'set': 51,\n",
       "                               'aside': 5,\n",
       "                               'privilege': 3,\n",
       "                               '87-31': 1,\n",
       "                               'similar': 17,\n",
       "                               'passed': 18,\n",
       "                               '29-5': 1,\n",
       "                               'As': 36,\n",
       "                               'word': 14,\n",
       "                               'offered': 11,\n",
       "                               'pointed': 9,\n",
       "                               'last': 161,\n",
       "                               'November': 10,\n",
       "                               'rejected': 8,\n",
       "                               'constitutional': 8,\n",
       "                               'amendment': 5,\n",
       "                               'allow': 5,\n",
       "                               'pay': 33,\n",
       "                               'raises': 3,\n",
       "                               'sessions': 6,\n",
       "                               'veteran': 11,\n",
       "                               'Jackson': 5,\n",
       "                               'legislator': 2,\n",
       "                               'ask': 7,\n",
       "                               'aid': 25,\n",
       "                               'education': 31,\n",
       "                               'something': 14,\n",
       "                               'consistently': 1,\n",
       "                               'opposed': 9,\n",
       "                               'past': 35,\n",
       "                               'Mac': 1,\n",
       "                               'Barber': 5,\n",
       "                               'Commerce': 7,\n",
       "                               'asking': 5,\n",
       "                               'endorse': 3,\n",
       "                               'increased': 10,\n",
       "                               'support': 24,\n",
       "                               'provided': 8,\n",
       "                               'expended': 1,\n",
       "                               '13th': 5,\n",
       "                               'members': 69,\n",
       "                               'congressional': 6,\n",
       "                               'delegation': 3,\n",
       "                               'Washington': 48,\n",
       "                               'like': 46,\n",
       "                               'see': 38,\n",
       "                               'But': 109,\n",
       "                               'congressmen': 3,\n",
       "                               'specifically': 1,\n",
       "                               'him': 93,\n",
       "                               'tossed': 1,\n",
       "                               'hopper': 1,\n",
       "                               'formally': 7,\n",
       "                               'read': 13,\n",
       "                               'event': 15,\n",
       "                               'Congress': 21,\n",
       "                               'does': 26,\n",
       "                               'Board': 17,\n",
       "                               'Education': 15,\n",
       "                               'directed': 8,\n",
       "                               'give': 32,\n",
       "                               'teacher': 9,\n",
       "                               'Colquitt': 2,\n",
       "                               'After': 24,\n",
       "                               'long': 39,\n",
       "                               'hot': 9,\n",
       "                               'controversy': 5,\n",
       "                               'Miller': 3,\n",
       "                               'school': 65,\n",
       "                               'superintendent': 9,\n",
       "                               'policeman': 2,\n",
       "                               'put': 27,\n",
       "                               'coolest': 2,\n",
       "                               'I': 179,\n",
       "                               'ever': 32,\n",
       "                               'saw': 17,\n",
       "                               'Harry': 10,\n",
       "                               'Davis': 13,\n",
       "                               'agriculture': 2,\n",
       "                               'defeated': 5,\n",
       "                               'Felix': 2,\n",
       "                               'Bush': 3,\n",
       "                               'principal': 9,\n",
       "                               'Democratic': 37,\n",
       "                               '1,119': 1,\n",
       "                               'votes': 7,\n",
       "                               \"Saturday's\": 2,\n",
       "                               'got': 45,\n",
       "                               '402': 1,\n",
       "                               'Ordinary': 2,\n",
       "                               'Carey': 5,\n",
       "                               'armed': 7,\n",
       "                               'pistol': 3,\n",
       "                               'stood': 4,\n",
       "                               'polls': 3,\n",
       "                               'insure': 2,\n",
       "                               'order': 19,\n",
       "                               'calmest': 1,\n",
       "                               'Policeman': 1,\n",
       "                               'Tom': 6,\n",
       "                               'Being': 1,\n",
       "                               'just': 42,\n",
       "                               'church': 16,\n",
       "                               \"didn't\": 15,\n",
       "                               'smell': 2,\n",
       "                               'drop': 6,\n",
       "                               'liquor': 4,\n",
       "                               'bit': 7,\n",
       "                               'trouble': 8,\n",
       "                               'leading': 11,\n",
       "                               'quiet': 5,\n",
       "                               'marked': 4,\n",
       "                               'anonymous': 4,\n",
       "                               'midnight': 4,\n",
       "                               'phone': 5,\n",
       "                               'calls': 13,\n",
       "                               'veiled': 3,\n",
       "                               'threats': 1,\n",
       "                               'violence': 3,\n",
       "                               'former': 27,\n",
       "                               'George': 23,\n",
       "                               'P.': 18,\n",
       "                               'Callan': 1,\n",
       "                               'shot': 14,\n",
       "                               'himself': 21,\n",
       "                               'death': 10,\n",
       "                               'March': 36,\n",
       "                               '18': 20,\n",
       "                               'four': 73,\n",
       "                               'days': 38,\n",
       "                               'post': 10,\n",
       "                               'dispute': 2,\n",
       "                               'board': 47,\n",
       "                               'During': 5,\n",
       "                               'reportedly': 4,\n",
       "                               'telephone': 8,\n",
       "                               'too': 37,\n",
       "                               'subjected': 2,\n",
       "                               'soon': 15,\n",
       "                               'scheduled': 14,\n",
       "                               'Many': 12,\n",
       "                               'local': 39,\n",
       "                               'feared': 1,\n",
       "                               'carry': 11,\n",
       "                               'gun': 2,\n",
       "                               'promised': 4,\n",
       "                               'Sheriff': 2,\n",
       "                               'Tabb': 1,\n",
       "                               'ordinary': 7,\n",
       "                               'good': 50,\n",
       "                               'promise': 3,\n",
       "                               'Everything': 1,\n",
       "                               'went': 37,\n",
       "                               'real': 24,\n",
       "                               'smooth': 1,\n",
       "                               'sheriff': 3,\n",
       "                               'There': 58,\n",
       "                               \"wasn't\": 3,\n",
       "                               'Austin': 15,\n",
       "                               'approval': 8,\n",
       "                               'Price': 3,\n",
       "                               \"Daniel's\": 1,\n",
       "                               'abandoned': 3,\n",
       "                               'seemed': 12,\n",
       "                               'certain': 18,\n",
       "                               'Thursday': 20,\n",
       "                               'despite': 11,\n",
       "                               'adamant': 2,\n",
       "                               'protests': 1,\n",
       "                               'bankers': 8,\n",
       "                               'Daniel': 5,\n",
       "                               'personally': 3,\n",
       "                               'led': 17,\n",
       "                               'fight': 14,\n",
       "                               'measure': 13,\n",
       "                               'watered': 1,\n",
       "                               'down': 50,\n",
       "                               'considerably': 5,\n",
       "                               'rejection': 3,\n",
       "                               'Legislatures': 1,\n",
       "                               'hearing': 14,\n",
       "                               'Revenue': 5,\n",
       "                               'Taxation': 1,\n",
       "                               'Under': 8,\n",
       "                               'rules': 11,\n",
       "                               'automatically': 3,\n",
       "                               'subcommittee': 1,\n",
       "                               'week': 86,\n",
       "                               'questions': 8,\n",
       "                               'taunted': 1,\n",
       "                               'appearing': 1,\n",
       "                               'witnesses': 7,\n",
       "                               'left': 39,\n",
       "                               'little': 35,\n",
       "                               'doubt': 6,\n",
       "                               'recommend': 4,\n",
       "                               'passage': 3,\n",
       "                               'termed': 4,\n",
       "                               'extremely': 2,\n",
       "                               'conservative': 5,\n",
       "                               'estimate': 3,\n",
       "                               'produce': 7,\n",
       "                               '17': 14,\n",
       "                               'dollars': 15,\n",
       "                               'help': 30,\n",
       "                               'erase': 1,\n",
       "                               'anticipated': 4,\n",
       "                               'deficit': 1,\n",
       "                               '63': 1,\n",
       "                               'current': 13,\n",
       "                               'fiscal': 5,\n",
       "                               '31': 6,\n",
       "                               'merely': 15,\n",
       "                               'means': 18,\n",
       "                               'enforcing': 1,\n",
       "                               'escheat': 2,\n",
       "                               'books': 12,\n",
       "                               'republic': 1,\n",
       "                               'permits': 4,\n",
       "                               'over': 115,\n",
       "                               'bank': 11,\n",
       "                               'accounts': 2,\n",
       "                               'stocks': 10,\n",
       "                               'personal': 12,\n",
       "                               'persons': 24,\n",
       "                               'missing': 3,\n",
       "                               'seven': 16,\n",
       "                               'bill': 45,\n",
       "                               'drafted': 1,\n",
       "                               'banks': 4,\n",
       "                               'insurance': 4,\n",
       "                               'firms': 15,\n",
       "                               'pipeline': 2,\n",
       "                               'companies': 18,\n",
       "                               'corporations': 2,\n",
       "                               'report': 25,\n",
       "                               'treasurer': 6,\n",
       "                               'cannot': 15,\n",
       "                               'enforced': 3,\n",
       "                               'now': 76,\n",
       "                               'because': 51,\n",
       "                               'almost': 24,\n",
       "                               'impossible': 4,\n",
       "                               'locate': 1,\n",
       "                               'declared': 15,\n",
       "                               'Dewey': 1,\n",
       "                               'Lawrence': 12,\n",
       "                               'Tyler': 2,\n",
       "                               'lawyer': 9,\n",
       "                               'representing': 8,\n",
       "                               'Bankers': 3,\n",
       "                               'sounded': 1,\n",
       "                               'opposition': 8,\n",
       "                               'keynote': 3,\n",
       "                               'violate': 2,\n",
       "                               'their': 219,\n",
       "                               'contractual': 1,\n",
       "                               'obligations': 4,\n",
       "                               'depositors': 1,\n",
       "                               'undermine': 1,\n",
       "                               'confidence': 6,\n",
       "                               'customers': 7,\n",
       "                               'If': 29,\n",
       "                               'you': 55,\n",
       "                               'destroy': 5,\n",
       "                               'economy': 9,\n",
       "                               'You': 11,\n",
       "                               'circulation': 2,\n",
       "                               'millions': 9,\n",
       "                               'Charles': 22,\n",
       "                               'Hughes': 22,\n",
       "                               'Sherman': 9,\n",
       "                               'sponsor': 4,\n",
       "                               'failure': 5,\n",
       "                               'enact': 1,\n",
       "                               'amount': 18,\n",
       "                               'gift': 5,\n",
       "                               \"taxpayers'\": 2,\n",
       "                               'pockets': 2,\n",
       "                               'contention': 2,\n",
       "                               'denied': 5,\n",
       "                               'several': 34,\n",
       "                               'including': 25,\n",
       "                               'Scott': 3,\n",
       "                               'Hudson': 2,\n",
       "                               'Gaynor': 1,\n",
       "                               'Jones': 22,\n",
       "                               'Houston': 15,\n",
       "                               'Brady': 1,\n",
       "                               'Harlingen': 1,\n",
       "                               'Howard': 13,\n",
       "                               'Cox': 4,\n",
       "                               'argued': 7,\n",
       "                               'probably': 19,\n",
       "                               'unconstitutional': 1,\n",
       "                               'impair': 1,\n",
       "                               'complained': 4,\n",
       "                               'enough': 27,\n",
       "                               'introduced': 10,\n",
       "                               'only': 103,\n",
       "                               'Senators': 4,\n",
       "                               'unanimously': 2,\n",
       "                               'Parkhouse': 5,\n",
       "                               'Dallas': 49,\n",
       "                               'authorizing': 2,\n",
       "                               'schools': 37,\n",
       "                               'deaf': 5,\n",
       "                               'designed': 16,\n",
       "                               'special': 41,\n",
       "                               'schooling': 2,\n",
       "                               ...}),\n",
       "                     'religion': FreqDist({'As': 24,\n",
       "                               'a': 655,\n",
       "                               'result': 13,\n",
       "                               ',': 1913,\n",
       "                               'although': 7,\n",
       "                               'we': 176,\n",
       "                               'still': 35,\n",
       "                               'make': 22,\n",
       "                               'use': 16,\n",
       "                               'of': 1494,\n",
       "                               'this': 217,\n",
       "                               'distinction': 4,\n",
       "                               'there': 78,\n",
       "                               'is': 533,\n",
       "                               'much': 28,\n",
       "                               'confusion': 2,\n",
       "                               'as': 290,\n",
       "                               'to': 882,\n",
       "                               'the': 2295,\n",
       "                               'meaning': 9,\n",
       "                               'basic': 6,\n",
       "                               'terms': 14,\n",
       "                               'employed': 4,\n",
       "                               '.': 1382,\n",
       "                               'Just': 2,\n",
       "                               'what': 64,\n",
       "                               'meant': 5,\n",
       "                               'by': 186,\n",
       "                               '``': 270,\n",
       "                               'spirit': 46,\n",
       "                               \"''\": 266,\n",
       "                               'and': 921,\n",
       "                               'matter': 7,\n",
       "                               '?': 148,\n",
       "                               'The': 185,\n",
       "                               'are': 193,\n",
       "                               'generally': 5,\n",
       "                               'taken': 13,\n",
       "                               'for': 283,\n",
       "                               'granted': 6,\n",
       "                               'though': 19,\n",
       "                               'they': 115,\n",
       "                               'referred': 2,\n",
       "                               'direct': 6,\n",
       "                               'axiomatic': 1,\n",
       "                               'elements': 8,\n",
       "                               'in': 724,\n",
       "                               'common': 9,\n",
       "                               'experience': 27,\n",
       "                               'all': 114,\n",
       "                               'Yet': 14,\n",
       "                               'contemporary': 4,\n",
       "                               'context': 5,\n",
       "                               'precisely': 4,\n",
       "                               'one': 87,\n",
       "                               'must': 54,\n",
       "                               'not': 232,\n",
       "                               'do': 52,\n",
       "                               'For': 32,\n",
       "                               'modern': 18,\n",
       "                               'world': 90,\n",
       "                               'neither': 7,\n",
       "                               'nor': 15,\n",
       "                               'refer': 2,\n",
       "                               'any': 60,\n",
       "                               'agreed-upon': 1,\n",
       "                               'We': 42,\n",
       "                               'transitional': 1,\n",
       "                               'stage': 1,\n",
       "                               'which': 202,\n",
       "                               'many': 46,\n",
       "                               'connotations': 1,\n",
       "                               'former': 5,\n",
       "                               'usage': 2,\n",
       "                               'have': 190,\n",
       "                               'had': 83,\n",
       "                               'be': 243,\n",
       "                               'revised': 1,\n",
       "                               'or': 166,\n",
       "                               'rejected': 2,\n",
       "                               'When': 15,\n",
       "                               'words': 15,\n",
       "                               'used': 11,\n",
       "                               'never': 22,\n",
       "                               'sure': 8,\n",
       "                               'traditional': 13,\n",
       "                               'meanings': 4,\n",
       "                               'user': 1,\n",
       "                               'may': 78,\n",
       "                               'mind': 13,\n",
       "                               'extent': 12,\n",
       "                               'his': 132,\n",
       "                               'revisions': 1,\n",
       "                               'rejections': 1,\n",
       "                               'understandings': 1,\n",
       "                               'correspond': 1,\n",
       "                               'ours': 2,\n",
       "                               'One': 17,\n",
       "                               'most': 49,\n",
       "                               'widespread': 3,\n",
       "                               'features': 3,\n",
       "                               'thought': 12,\n",
       "                               'almost': 18,\n",
       "                               'universal': 7,\n",
       "                               'disbelief': 2,\n",
       "                               'reality': 16,\n",
       "                               'few': 15,\n",
       "                               'centuries': 7,\n",
       "                               'ago': 17,\n",
       "                               'spirits': 12,\n",
       "                               'was': 214,\n",
       "                               'populous': 1,\n",
       "                               'real': 25,\n",
       "                               'material': 9,\n",
       "                               'entities': 4,\n",
       "                               'Not': 4,\n",
       "                               'only': 93,\n",
       "                               'popular': 9,\n",
       "                               'but': 132,\n",
       "                               'that': 475,\n",
       "                               'highly': 3,\n",
       "                               'educated': 2,\n",
       "                               'well': 22,\n",
       "                               'true': 12,\n",
       "                               'Demons': 1,\n",
       "                               'fairies': 1,\n",
       "                               'angels': 1,\n",
       "                               'host': 3,\n",
       "                               'other': 60,\n",
       "                               'spiritual': 25,\n",
       "                               'beings': 9,\n",
       "                               'were': 92,\n",
       "                               'part': 23,\n",
       "                               'experiential': 1,\n",
       "                               'western': 2,\n",
       "                               'man': 64,\n",
       "                               'rocks': 1,\n",
       "                               'trees': 1,\n",
       "                               'stars': 3,\n",
       "                               'In': 50,\n",
       "                               'such': 64,\n",
       "                               'both': 19,\n",
       "                               'directly': 9,\n",
       "                               'known': 7,\n",
       "                               'realities': 3,\n",
       "                               'it': 264,\n",
       "                               'important': 17,\n",
       "                               'Christianity': 21,\n",
       "                               'Biblical': 2,\n",
       "                               'view': 13,\n",
       "                               'general': 9,\n",
       "                               'now': 33,\n",
       "                               'cause': 9,\n",
       "                               'us': 59,\n",
       "                               'difficulty': 3,\n",
       "                               'could': 59,\n",
       "                               'responded': 3,\n",
       "                               'quite': 13,\n",
       "                               'naturally': 6,\n",
       "                               'spontaneously': 2,\n",
       "                               'progress': 3,\n",
       "                               'science': 8,\n",
       "                               'over': 31,\n",
       "                               'these': 66,\n",
       "                               'last': 14,\n",
       "                               'gradual': 1,\n",
       "                               'replacement': 1,\n",
       "                               'scientific': 8,\n",
       "                               'categories': 3,\n",
       "                               'large': 10,\n",
       "                               'emptied': 2,\n",
       "                               'previously': 1,\n",
       "                               'populated': 3,\n",
       "                               'carrying': 3,\n",
       "                               'out': 54,\n",
       "                               'program': 9,\n",
       "                               'has': 111,\n",
       "                               'undoubtedly': 2,\n",
       "                               'performed': 1,\n",
       "                               'very': 33,\n",
       "                               'considerable': 9,\n",
       "                               'service': 12,\n",
       "                               'can': 82,\n",
       "                               'claim': 14,\n",
       "                               'due': 4,\n",
       "                               'credit': 2,\n",
       "                               'objectification': 1,\n",
       "                               'superstition': 1,\n",
       "                               'certainly': 6,\n",
       "                               'gone': 6,\n",
       "                               'far': 16,\n",
       "                               'beyond': 13,\n",
       "                               'justify': 3,\n",
       "                               'support': 11,\n",
       "                               'Science': 4,\n",
       "                               'fully': 6,\n",
       "                               'competent': 1,\n",
       "                               'deal': 4,\n",
       "                               'with': 215,\n",
       "                               'element': 1,\n",
       "                               'arises': 1,\n",
       "                               'from': 138,\n",
       "                               'an': 119,\n",
       "                               'object': 4,\n",
       "                               'space': 15,\n",
       "                               'time': 34,\n",
       "                               'therefore': 9,\n",
       "                               'turned': 3,\n",
       "                               'its': 86,\n",
       "                               'attention': 6,\n",
       "                               'concrete': 4,\n",
       "                               'imagination': 5,\n",
       "                               'peopled': 1,\n",
       "                               'soon': 6,\n",
       "                               'lost': 7,\n",
       "                               'whatever': 8,\n",
       "                               'status': 2,\n",
       "                               'enjoyed': 2,\n",
       "                               'actual': 2,\n",
       "                               'external': 2,\n",
       "                               'doing': 9,\n",
       "                               'so': 87,\n",
       "                               'unquestionably': 1,\n",
       "                               'cleared': 1,\n",
       "                               'up': 37,\n",
       "                               'misconceptions': 1,\n",
       "                               'removed': 5,\n",
       "                               'extraneous': 1,\n",
       "                               'illusory': 1,\n",
       "                               'sources': 6,\n",
       "                               'fear': 24,\n",
       "                               'dispelled': 1,\n",
       "                               'undesirable': 1,\n",
       "                               'superstitions': 1,\n",
       "                               'There': 24,\n",
       "                               'been': 76,\n",
       "                               'indeed': 11,\n",
       "                               'valuable': 1,\n",
       "                               'gains': 1,\n",
       "                               'development': 7,\n",
       "                               'our': 77,\n",
       "                               'present': 25,\n",
       "                               'rightly': 2,\n",
       "                               'grateful': 1,\n",
       "                               'All': 9,\n",
       "                               'however': 13,\n",
       "                               'unmixed': 1,\n",
       "                               'blessing': 2,\n",
       "                               'debunking': 1,\n",
       "                               'way': 31,\n",
       "                               'too': 28,\n",
       "                               'successful': 2,\n",
       "                               'thorough': 1,\n",
       "                               'house': 3,\n",
       "                               'swept': 2,\n",
       "                               'clean': 1,\n",
       "                               'left': 12,\n",
       "                               'no': 81,\n",
       "                               'means': 25,\n",
       "                               'at': 114,\n",
       "                               'best': 12,\n",
       "                               'wholly': 2,\n",
       "                               'inadequate': 1,\n",
       "                               'dealing': 2,\n",
       "                               'Although': 9,\n",
       "                               'particular': 8,\n",
       "                               'form': 11,\n",
       "                               'conceptualization': 1,\n",
       "                               'made': 28,\n",
       "                               'response': 3,\n",
       "                               'defective': 1,\n",
       "                               'raw': 1,\n",
       "                               'itself': 20,\n",
       "                               'led': 7,\n",
       "                               'excesses': 1,\n",
       "                               'remains': 6,\n",
       "                               'vividly': 2,\n",
       "                               'ever': 11,\n",
       "                               'simply': 13,\n",
       "                               'find': 20,\n",
       "                               'ourselves': 14,\n",
       "                               'position': 16,\n",
       "                               'having': 10,\n",
       "                               'inquiring': 1,\n",
       "                               'into': 82,\n",
       "                               'structure': 9,\n",
       "                               'range': 2,\n",
       "                               'framework': 1,\n",
       "                               'respect': 3,\n",
       "                               'organize': 1,\n",
       "                               'know': 30,\n",
       "                               'apprehend': 1,\n",
       "                               'helpless': 2,\n",
       "                               'powerless': 1,\n",
       "                               'sector': 2,\n",
       "                               'lives': 7,\n",
       "                               'situation': 13,\n",
       "                               'brought': 9,\n",
       "                               'dramatic': 4,\n",
       "                               'force': 9,\n",
       "                               'Arthur': 3,\n",
       "                               \"Miller's\": 1,\n",
       "                               'play': 13,\n",
       "                               'Crucible': 1,\n",
       "                               'deals': 1,\n",
       "                               'Salem': 4,\n",
       "                               'witch': 1,\n",
       "                               'trials': 1,\n",
       "                               'opens': 1,\n",
       "                               'audience': 6,\n",
       "                               'introduced': 3,\n",
       "                               'community': 25,\n",
       "                               'Puritan': 2,\n",
       "                               'America': 13,\n",
       "                               'end': 14,\n",
       "                               'eighteenth': 1,\n",
       "                               'century': 22,\n",
       "                               'Aside': 1,\n",
       "                               'quaint': 1,\n",
       "                               'concern': 2,\n",
       "                               'witches': 3,\n",
       "                               'devils': 2,\n",
       "                               'provides': 3,\n",
       "                               'immediate': 8,\n",
       "                               'problem': 12,\n",
       "                               'opening': 3,\n",
       "                               'scene': 1,\n",
       "                               'normal': 4,\n",
       "                               'conversation': 4,\n",
       "                               'characters': 2,\n",
       "                               'creates': 2,\n",
       "                               'atmosphere': 5,\n",
       "                               'suggesting': 1,\n",
       "                               'usual': 3,\n",
       "                               'mixture': 2,\n",
       "                               'pleasures': 1,\n",
       "                               'foibles': 1,\n",
       "                               'irritations': 1,\n",
       "                               'concerns': 2,\n",
       "                               'would': 68,\n",
       "                               'characterize': 2,\n",
       "                               'life': 55,\n",
       "                               'village': 2,\n",
       "                               'age': 8,\n",
       "                               'occasion': 2,\n",
       "                               'feel': 6,\n",
       "                               'uneasy': 2,\n",
       "                               'disturbed': 4,\n",
       "                               'about': 64,\n",
       "                               'people': 34,\n",
       "                               'Instead': 2,\n",
       "                               'sit': 5,\n",
       "                               'back': 14,\n",
       "                               'ease': 2,\n",
       "                               'perspective': 2,\n",
       "                               'enlightened': 2,\n",
       "                               'longer': 14,\n",
       "                               'believes': 5,\n",
       "                               'things': 23,\n",
       "                               'enjoy': 2,\n",
       "                               'dead': 9,\n",
       "                               'seriousness': 1,\n",
       "                               'take': 15,\n",
       "                               'under': 19,\n",
       "                               'discussion': 7,\n",
       "                               'A': 39,\n",
       "                               'teenage': 1,\n",
       "                               'girl': 1,\n",
       "                               'Abigail': 2,\n",
       "                               'Williams': 1,\n",
       "                               'being': 30,\n",
       "                               'sharply': 2,\n",
       "                               'questioned': 1,\n",
       "                               'her': 8,\n",
       "                               'minister': 9,\n",
       "                               'uncle': 1,\n",
       "                               'Reverend': 1,\n",
       "                               'Samuel': 3,\n",
       "                               'Parris': 2,\n",
       "                               'wild': 1,\n",
       "                               'night': 12,\n",
       "                               'affair': 1,\n",
       "                               'woods': 3,\n",
       "                               'she': 10,\n",
       "                               'some': 50,\n",
       "                               'girls': 1,\n",
       "                               'seemed': 8,\n",
       "                               'contact': 1,\n",
       "                               'evil': 26,\n",
       "                               'involved': 6,\n",
       "                               'devil': 7,\n",
       "                               'entity': 1,\n",
       "                               'who': 100,\n",
       "                               'really': 8,\n",
       "                               'confronted': 2,\n",
       "                               'on': 160,\n",
       "                               'dark': 3,\n",
       "                               'demon': 1,\n",
       "                               'creatures': 3,\n",
       "                               'actually': 8,\n",
       "                               'seen': 13,\n",
       "                               'flying': 3,\n",
       "                               'through': 48,\n",
       "                               'air': 4,\n",
       "                               'unfolds': 2,\n",
       "                               'subtly': 2,\n",
       "                               'grip': 4,\n",
       "                               'awful': 1,\n",
       "                               'grows': 5,\n",
       "                               'ominously': 1,\n",
       "                               'gathering': 1,\n",
       "                               'power': 49,\n",
       "                               'engulfs': 1,\n",
       "                               'Everyone': 3,\n",
       "                               'saint': 2,\n",
       "                               'sinner': 2,\n",
       "                               'alike': 2,\n",
       "                               'It': 73,\n",
       "                               'like': 18,\n",
       "                               'mysterious': 3,\n",
       "                               'epidemic': 1,\n",
       "                               'starting': 1,\n",
       "                               'first': 25,\n",
       "                               'spreads': 1,\n",
       "                               'inexorably': 1,\n",
       "                               'dreadfully': 1,\n",
       "                               'growing': 11,\n",
       "                               'virulence': 1,\n",
       "                               'whole': 16,\n",
       "                               'town': 2,\n",
       "                               'until': 10,\n",
       "                               'infected': 1,\n",
       "                               'terribly': 1,\n",
       "                               'unavoidably': 2,\n",
       "                               'leaves': 3,\n",
       "                               'wake': 1,\n",
       "                               'trail': 1,\n",
       "                               'misery': 2,\n",
       "                               'moral': 21,\n",
       "                               'disintegration': 1,\n",
       "                               'destruction': 5,\n",
       "                               'spell': 4,\n",
       "                               'kind': 8,\n",
       "                               'exposure': 1,\n",
       "                               'living': 17,\n",
       "                               'active': 5,\n",
       "                               'manifestation': 1,\n",
       "                               'always': 10,\n",
       "                               'evokes': 1,\n",
       "                               'If': 35,\n",
       "                               'asks': 2,\n",
       "                               'comes': 9,\n",
       "                               'upon': 21,\n",
       "                               'works': 9,\n",
       "                               'within': 18,\n",
       "                               'terrible': 8,\n",
       "                               'better': 9,\n",
       "                               'answer': 4,\n",
       "                               'give': 17,\n",
       "                               'than': 69,\n",
       "                               'This': 40,\n",
       "                               'attempt': 5,\n",
       "                               'say': 39,\n",
       "                               'employ': 1,\n",
       "                               'commonly': 2,\n",
       "                               'word': 18,\n",
       "                               'designate': 1,\n",
       "                               'identify': 5,\n",
       "                               'good': 37,\n",
       "                               'John': 30,\n",
       "                               'Proctor': 1,\n",
       "                               'expresses': 2,\n",
       "                               'already': 14,\n",
       "                               'come': 16,\n",
       "                               'when': 53,\n",
       "                               'he': 137,\n",
       "                               'says': 9,\n",
       "                               'fire': 5,\n",
       "                               'burning': 4,\n",
       "                               '!': 50,\n",
       "                               'I': 155,\n",
       "                               'hear': 5,\n",
       "                               'boot': 1,\n",
       "                               'Lucifer': 1,\n",
       "                               'see': 35,\n",
       "                               'filthy': 1,\n",
       "                               'face': 7,\n",
       "                               'tragic': 2,\n",
       "                               'irony': 1,\n",
       "                               'belief': 7,\n",
       "                               'met': 5,\n",
       "                               'combatted': 1,\n",
       "                               'formulae': 1,\n",
       "                               'set': 9,\n",
       "                               'books': 7,\n",
       "                               'thing': 17,\n",
       "                               'prevented': 1,\n",
       "                               'them': 74,\n",
       "                               'detecting': 1,\n",
       "                               'came': 22,\n",
       "                               'among': 24,\n",
       "                               'marvel': 2,\n",
       "                               'their': 113,\n",
       "                               'blindness': 1,\n",
       "                               'seeing': 3,\n",
       "                               'mid-twentieth': 1,\n",
       "                               'believe': 12,\n",
       "                               'just': 22,\n",
       "                               'bad': 3,\n",
       "                               'off': 2,\n",
       "                               '--': 110,\n",
       "                               'different': 8,\n",
       "                               'think': 17,\n",
       "                               'even': 39,\n",
       "                               'unable': 1,\n",
       "                               'name': 12,\n",
       "                               'elemental': 2,\n",
       "                               'cope': 1,\n",
       "                               'because': 39,\n",
       "                               'dare': 3,\n",
       "                               'speak': 9,\n",
       "                               'anything': 10,\n",
       "                               'imply': 3,\n",
       "                               'commitment': 4,\n",
       "                               'discredited': 1,\n",
       "                               'proved': 3,\n",
       "                               'false': 2,\n",
       "                               'Even': 10,\n",
       "                               'Mr.': 6,\n",
       "                               'Miller': 1,\n",
       "                               'himself': 22,\n",
       "                               'seems': 14,\n",
       "                               'uncertain': 2,\n",
       "                               'score': 1,\n",
       "                               'long': 13,\n",
       "                               'commentary': 2,\n",
       "                               'inserted': 1,\n",
       "                               'published': 2,\n",
       "                               'text': 1,\n",
       "                               'act': 5,\n",
       "                               'point': 16,\n",
       "                               ':': 123,\n",
       "                               'However': 6,\n",
       "                               'raised': 4,\n",
       "                               'doubt': 6,\n",
       "                               'underworld': 1,\n",
       "                               'existence': 13,\n",
       "                               \"Lucifer's\": 1,\n",
       "                               'many-faced': 1,\n",
       "                               'lieutenants': 1,\n",
       "                               'And': 41,\n",
       "                               'discredit': 1,\n",
       "                               'Better': 1,\n",
       "                               'minds': 9,\n",
       "                               \"Hale's\": 1,\n",
       "                               'convinced': 3,\n",
       "                               'society': 10,\n",
       "                               'ken': 1,\n",
       "                               '(': 101,\n",
       "                               'page': 3,\n",
       "                               '33': 1,\n",
       "                               ')': 127,\n",
       "                               'On': 10,\n",
       "                               'hand': 10,\n",
       "                               'little': 19,\n",
       "                               'later': 9,\n",
       "                               'Since': 6,\n",
       "                               '1692': 1,\n",
       "                               'great': 26,\n",
       "                               'superficial': 1,\n",
       "                               'change': 4,\n",
       "                               'wiped': 1,\n",
       "                               \"God's\": 9,\n",
       "                               'beard': 1,\n",
       "                               \"Devil's\": 1,\n",
       "                               'horns': 1,\n",
       "                               'gripped': 1,\n",
       "                               'between': 31,\n",
       "                               'two': 27,\n",
       "                               'diametrically': 1,\n",
       "                               'opposed': 6,\n",
       "                               'absolutes': 1,\n",
       "                               'concept': 4,\n",
       "                               'unity': 21,\n",
       "                               'positive': 9,\n",
       "                               'negative': 3,\n",
       "                               'attributes': 1,\n",
       "                               'same': 28,\n",
       "                               'relative': 2,\n",
       "                               'ever-changing': 1,\n",
       "                               'joined': 2,\n",
       "                               'phenomenon': 2,\n",
       "                               'reserved': 2,\n",
       "                               'physical': 4,\n",
       "                               'sciences': 1,\n",
       "                               'grasped': 1,\n",
       "                               'history': 26,\n",
       "                               'ideas': 9,\n",
       "                               'steady': 1,\n",
       "                               'methodical': 1,\n",
       "                               'inculcation': 1,\n",
       "                               'humanity': 6,\n",
       "                               'idea': 15,\n",
       "                               \"man's\": 11,\n",
       "                               'worthlessness': 1,\n",
       "                               'redeemed': 1,\n",
       "                               'necessity': 3,\n",
       "                               'Devil': 1,\n",
       "                               'become': 24,\n",
       "                               'evident': 6,\n",
       "                               'weapon': 4,\n",
       "                               'designed': 2,\n",
       "                               'again': 19,\n",
       "                               'every': 16,\n",
       "                               'whip': 1,\n",
       "                               'men': 39,\n",
       "                               'surrender': 5,\n",
       "                               'church': 51,\n",
       "                               'church-state': 1,\n",
       "                               '34': 3,\n",
       "                               'Apparently': 1,\n",
       "                               'does': 34,\n",
       "                               'intend': 1,\n",
       "                               'those': 42,\n",
       "                               'read': 7,\n",
       "                               'should': 45,\n",
       "                               'writing': 2,\n",
       "                               'nevertheless': 4,\n",
       "                               'potency': 1,\n",
       "                               'casts': 2,\n",
       "                               'leave': 8,\n",
       "                               'feeling': 4,\n",
       "                               'presence': 4,\n",
       "                               'enough': 7,\n",
       "                               'accounting': 1,\n",
       "                               'analyze': 2,\n",
       "                               'wickedness': 1,\n",
       "                               'individual': 11,\n",
       "                               'added': 4,\n",
       "                               'together': 6,\n",
       "                               'produce': 1,\n",
       "                               'cumulative': 1,\n",
       "                               'effect': 13,\n",
       "                               'account': 6,\n",
       "                               'integral': 1,\n",
       "                               'abounding': 1,\n",
       "                               'vigor': 1,\n",
       "                               'explain': 3,\n",
       "                               'strange': 2,\n",
       "                               'numinous': 1,\n",
       "                               'sense': 20,\n",
       "                               'presentness': 1,\n",
       "                               'watch': 2,\n",
       "                               'emerges': 2,\n",
       "                               'spite': 5,\n",
       "                               \"author's\": 1,\n",
       "                               'convictions': 4,\n",
       "                               'contrary': 4,\n",
       "                               'Spirit': 13,\n",
       "                               'nothing': 8,\n",
       "                               'human': 43,\n",
       "                               'more': 65,\n",
       "                               'widely': 6,\n",
       "                               'universally': 1,\n",
       "                               'felt': 6,\n",
       "                               'Apart': 1,\n",
       "                               'draws': 1,\n",
       "                               'gives': 8,\n",
       "                               'cohesiveness': 1,\n",
       "                               'permanence': 1,\n",
       "                               'Think': 1,\n",
       "                               'example': 10,\n",
       "                               'Marine': 2,\n",
       "                               'Corps': 3,\n",
       "                               'Surely': 1,\n",
       "                               'acknowledge': 2,\n",
       "                               'cannot': 22,\n",
       "                               'course': 14,\n",
       "                               'assign': 1,\n",
       "                               'substance': 3,\n",
       "                               'occupying': 2,\n",
       "                               'exists': 2,\n",
       "                               'objective': 2,\n",
       "                               'experienced': 2,\n",
       "                               'So': 12,\n",
       "                               'Nazism': 1,\n",
       "                               'Communism': 2,\n",
       "                               'school': 5,\n",
       "                               'street': 1,\n",
       "                               'corner': 1,\n",
       "                               'gang': 2,\n",
       "                               'football': 3,\n",
       "                               'team': 1,\n",
       "                               'Rotary': 1,\n",
       "                               'Ku': 1,\n",
       "                               'Klux': 1,\n",
       "                               'Klan': 1,\n",
       "                               'Every': 3,\n",
       "                               'if': 61,\n",
       "                               'alive': 2,\n",
       "                               'center': 8,\n",
       "                               'identity': 2,\n",
       "                               'searching': 1,\n",
       "                               'clues': 1,\n",
       "                               'might': 12,\n",
       "                               'lead': 3,\n",
       "                               'fresh': 3,\n",
       "                               'apprehension': 2,\n",
       "                               'close': 4,\n",
       "                               'connection': 5,\n",
       "                               'likely': 3,\n",
       "                               'prove': 2,\n",
       "                               'fruitful': 1,\n",
       "                               'primarily': 3,\n",
       "                               'causes': 5,\n",
       "                               'cohere': 1,\n",
       "                               'source': 5,\n",
       "                               \"community's\": 1,\n",
       "                               'drawing': 2,\n",
       "                               'others': 13,\n",
       "                               'drawn': 3,\n",
       "                               'outside': 5,\n",
       "                               'prospers': 1,\n",
       "                               'identical': 1,\n",
       "                               'distinct': 1,\n",
       "                               'separable': 1,\n",
       "                               'characteristic': 2,\n",
       "                               'givenness': 1,\n",
       "                               'members': 49,\n",
       "                               'create': 2,\n",
       "                               'rather': 16,\n",
       "                               'waiting': 1,\n",
       "                               'given': 15,\n",
       "                               'alone': 8,\n",
       "                               'possess': 3,\n",
       "                               'operative': 1,\n",
       "                               'before': 26,\n",
       "                               'keep': 9,\n",
       "                               'preserve': 4,\n",
       "                               'will': 71,\n",
       "                               'continue': 8,\n",
       "                               'future': 13,\n",
       "                               'recruits': 1,\n",
       "                               'content': 1,\n",
       "                               'faith': 40,\n",
       "                               'presented': 2,\n",
       "                               'today': 18,\n",
       "                               'understanded': 1,\n",
       "                               'forgotten': 3,\n",
       "                               'goals': 1,\n",
       "                               'perennial': 2,\n",
       "                               'theological': 11,\n",
       "                               'task': 1,\n",
       "                               'choice': 12,\n",
       "                               'abandon': 2,\n",
       "                               'completely': 10,\n",
       "                               'mythological': 6,\n",
       "                               'manner': 6,\n",
       "                               'representation': 2,\n",
       "                               'mean': 17,\n",
       "                               'language': 5,\n",
       "                               'theology': 13,\n",
       "                               'preaching': 3,\n",
       "                               'absurd': 2,\n",
       "                               'notion': 2,\n",
       "                               'demythologization': 6,\n",
       "                               'entails': 2,\n",
       "                               'expurgation': 1,\n",
       "                               'concepts': 5,\n",
       "                               'misrepresents': 1,\n",
       "                               \"Bultmann's\": 7,\n",
       "                               'intention': 4,\n",
       "                               'His': 45,\n",
       "                               'mythology': 1,\n",
       "                               'regarded': 3,\n",
       "                               'appropriate': 2,\n",
       "                               'conceptuality': 2,\n",
       "                               'expressing': 3,\n",
       "                               'Christian': 50,\n",
       "                               'kerygma': 3,\n",
       "                               'mode': 1,\n",
       "                               'abandoned': 2,\n",
       "                               'sole': 1,\n",
       "                               'proper': 4,\n",
       "                               'presenting': 1,\n",
       "                               'understanding': 7,\n",
       "                               'Mythological': 1,\n",
       "                               'responsibly': 1,\n",
       "                               'symbols': 2,\n",
       "                               'ciphers': 2,\n",
       "                               'also': 56,\n",
       "                               'constantly': 2,\n",
       "                               'interpreted': 2,\n",
       "                               'nonmythological': 1,\n",
       "                               'existential': 2,\n",
       "                               'statement': 7,\n",
       "                               'often': 15,\n",
       "                               'Bultmann': 4,\n",
       "                               'argues': 1,\n",
       "                               'overestimates': 1,\n",
       "                               'intellectual': 4,\n",
       "                               'stumbling-block': 1,\n",
       "                               'myth': 5,\n",
       "                               'supposed': 8,\n",
       "                               'put': 16,\n",
       "                               'accepting': 2,\n",
       "                               'But': 43,\n",
       "                               'unconvincing': 1,\n",
       "                               'own': 23,\n",
       "                               'definition': 2,\n",
       "                               'strictly': 1,\n",
       "                               'adhered': 2,\n",
       "                               'interesting': 2,\n",
       "                               'done': 13,\n",
       "                               'pronouncements': 1,\n",
       "                               'evidence': 9,\n",
       "                               'overwhelming': 1,\n",
       "                               'exaggerate': 1,\n",
       "                               'incredible': 3,\n",
       "                               'irrelevant': 3,\n",
       "                               'Nor': 3,\n",
       "                               'necessary': 8,\n",
       "                               'look': 12,\n",
       "                               'urban': 2,\n",
       "                               'centers': 2,\n",
       "                               'culture': 4,\n",
       "                               'admittedly': 1,\n",
       "                               'entirely': 6,\n",
       "                               'secularized': 2,\n",
       "                               'profoundly': 2,\n",
       "                               'estranged': 1,\n",
       "                               'conventional': 1,\n",
       "                               'forms': 10,\n",
       "                               'gospel': 7,\n",
       "                               'communicated': 1,\n",
       "                               'heart': 15,\n",
       "                               'Bible': 19,\n",
       "                               'belt': 1,\n",
       "                               'attested': 1,\n",
       "                               'called': 11,\n",
       "                               'work': 23,\n",
       "                               'industrial': 1,\n",
       "                               'technological': 1,\n",
       "                               'revolutions': 1,\n",
       "                               'corresponding': 2,\n",
       "                               'changes': 4,\n",
       "                               'picture': 15,\n",
       "                               'fact': 26,\n",
       "                               'profundity': 1,\n",
       "                               'argument': 4,\n",
       "                               'disclosed': 1,\n",
       "                               'past': 9,\n",
       "                               'exist': 3,\n",
       "                               'striking': 1,\n",
       "                               'rapidity': 1,\n",
       "                               'reduced': 2,\n",
       "                               'marginal': 1,\n",
       "                               'especially': 8,\n",
       "                               'generation': 6,\n",
       "                               'suburban': 1,\n",
       "                               'middle': 9,\n",
       "                               'class': 7,\n",
       "                               'Time': 1,\n",
       "                               'counseling': 1,\n",
       "                               'teaching': 3,\n",
       "                               'encounters': 1,\n",
       "                               'group': 17,\n",
       "                               'whose': 9,\n",
       "                               'attempts': 2,\n",
       "                               'bring': 11,\n",
       "                               'insubstantial': 1,\n",
       "                               'mythologies': 1,\n",
       "                               'fundamentalist': 2,\n",
       "                               'heritage': 3,\n",
       "                               'stubborn': 2,\n",
       "                               'painfully': 1,\n",
       "                               'obvious': 3,\n",
       "                               'evidenced': 2,\n",
       "                               'extreme': 5,\n",
       "                               'culture-Protestantism': 1,\n",
       "                               'observed': 2,\n",
       "                               'American': 17,\n",
       "                               'churches': 29,\n",
       "                               'absence': 2,\n",
       "                               'truly': 4,\n",
       "                               'adequate': 2,\n",
       "                               'expressed': 8,\n",
       "                               'unavoidable': 3,\n",
       "                               'need': 24,\n",
       "                               'demythologize': 2,\n",
       "                               'makes': 11,\n",
       "                               'resources': 2,\n",
       "                               'usually': 4,\n",
       "                               'another': 17,\n",
       "                               'various': 9,\n",
       "                               'folk': 2,\n",
       "                               'religion': 10,\n",
       "                               'current': 2,\n",
       "                               'explanation': 2,\n",
       "                               'infatuation': 2,\n",
       "                               'Norman': 2,\n",
       "                               'Vincent': 2,\n",
       "                               \"Peale's\": 1,\n",
       "                               'cult': 3,\n",
       "                               'reassurance': 1,\n",
       "                               'types': 1,\n",
       "                               'purely': 3,\n",
       "                               'cultural': 3,\n",
       "                               'ever-present': 1,\n",
       "                               'demythologized': 2,\n",
       "                               'pundits': 1,\n",
       "                               'seem': 8,\n",
       "                               'suspected': 1,\n",
       "                               'latent': 1,\n",
       "                               'demand': 11,\n",
       "                               'nearly': 5,\n",
       "                               'claiming': 3,\n",
       "                               'least': 20,\n",
       "                               'cultured': 3,\n",
       "                               'population': 10,\n",
       "                               'tends': 1,\n",
       "                               'complete': 6,\n",
       "                               'indifference': 2,\n",
       "                               'message': 5,\n",
       "                               'sin': 30,\n",
       "                               'grace': 7,\n",
       "                               'To': 22,\n",
       "                               'pointed': 2,\n",
       "                               'certain': 17,\n",
       "                               'churchmen': 1,\n",
       "                               'fulminate': 1,\n",
       "                               'flock': 2,\n",
       "                               'crowd': 1,\n",
       "                               'solace': 2,\n",
       "                               \"Paul's\": 1,\n",
       "                               'castigation': 1,\n",
       "                               'wisdom': 8,\n",
       "                               'wise': 1,\n",
       "                               'chapter': 2,\n",
       "                               'First': 4,\n",
       "                               'Corinthians': 3,\n",
       "                               'afford': 2,\n",
       "                               'luxury': 1,\n",
       "                               'smug': 2,\n",
       "                               'indigation': 1,\n",
       "                               'Can': 2,\n",
       "                               'risk': 11,\n",
       "                               'assuming': 1,\n",
       "                               'folly': 2,\n",
       "                               'dear': 2,\n",
       "                               'God': 131,\n",
       "                               'implied': 3,\n",
       "                               'foolishness': 2,\n",
       "                               'ways': 11,\n",
       "                               'talking': 6,\n",
       "                               'alienate': 1,\n",
       "                               'gifts': 2,\n",
       "                               'desperately': 1,\n",
       "                               'apart': 4,\n",
       "                               'co-operation': 1,\n",
       "                               'mission': 2,\n",
       "                               'increasingly': 2,\n",
       "                               'precarious': 1,\n",
       "                               'ancient': 2,\n",
       "                               'venerable': 1,\n",
       "                               'tradition': 8,\n",
       "                               'derives': 1,\n",
       "                               'Greeks': 1,\n",
       "                               'independent': 2,\n",
       "                               'creation': 10,\n",
       "                               'accomplishing': 1,\n",
       "                               'By': 6,\n",
       "                               'analogy': 1,\n",
       "                               'requiring': 1,\n",
       "                               'order': 19,\n",
       "                               'Scripture': 2,\n",
       "                               'everywhere': 7,\n",
       "                               'reminds': 3,\n",
       "                               'fortiori': 1,\n",
       "                               'ill': 1,\n",
       "                               'without': 24,\n",
       "                               'talents': 2,\n",
       "                               'providence': 1,\n",
       "                               'presents': 3,\n",
       "                               'yet': 20,\n",
       "                               'exactly': 5,\n",
       "                               'run': 8,\n",
       "                               'assume': 1,\n",
       "                               'preach': 2,\n",
       "                               'Until': 1,\n",
       "                               'translate': 2,\n",
       "                               'understand': 5,\n",
       "                               'depriving': 1,\n",
       "                               'continued': 5,\n",
       "                               'success': 1,\n",
       "                               'witness': 3,\n",
       "                               'depends': 2,\n",
       "                               'arguing': 1,\n",
       "                               'obviously': 4,\n",
       "                               'taking': 4,\n",
       "                               ...}),\n",
       "                     'reviews': FreqDist({'It': 63,\n",
       "                               'is': 513,\n",
       "                               'not': 143,\n",
       "                               'news': 5,\n",
       "                               'that': 336,\n",
       "                               'Nathan': 1,\n",
       "                               'Milstein': 4,\n",
       "                               'a': 874,\n",
       "                               'wizard': 1,\n",
       "                               'of': 1299,\n",
       "                               'the': 2048,\n",
       "                               'violin': 4,\n",
       "                               '.': 1549,\n",
       "                               'Certainly': 3,\n",
       "                               'in': 656,\n",
       "                               'Orchestra': 4,\n",
       "                               'Hall': 14,\n",
       "                               'where': 25,\n",
       "                               'he': 161,\n",
       "                               'has': 192,\n",
       "                               'played': 18,\n",
       "                               'countless': 1,\n",
       "                               'recitals': 1,\n",
       "                               ',': 2318,\n",
       "                               'and': 1103,\n",
       "                               'Thursday': 2,\n",
       "                               'night': 34,\n",
       "                               'celebrated': 2,\n",
       "                               'his': 208,\n",
       "                               '20th': 3,\n",
       "                               'season': 24,\n",
       "                               'with': 272,\n",
       "                               'Chicago': 11,\n",
       "                               'Symphony': 7,\n",
       "                               'playing': 21,\n",
       "                               'Brahms': 5,\n",
       "                               'Concerto': 3,\n",
       "                               'own': 34,\n",
       "                               'slashing': 1,\n",
       "                               'demon-ridden': 1,\n",
       "                               'cadenza': 2,\n",
       "                               'melting': 1,\n",
       "                               'into': 42,\n",
       "                               'high': 17,\n",
       "                               'pale': 5,\n",
       "                               'pure': 1,\n",
       "                               'lovely': 10,\n",
       "                               'song': 16,\n",
       "                               'which': 123,\n",
       "                               'violinist': 3,\n",
       "                               'unlocks': 1,\n",
       "                               'heart': 15,\n",
       "                               'music': 68,\n",
       "                               'or': 97,\n",
       "                               'forever': 3,\n",
       "                               'finds': 5,\n",
       "                               'it': 206,\n",
       "                               'closed': 4,\n",
       "                               'There': 31,\n",
       "                               'was': 227,\n",
       "                               'about': 71,\n",
       "                               'something': 16,\n",
       "                               'incandescent': 1,\n",
       "                               'for': 268,\n",
       "                               'this': 143,\n",
       "                               'at': 184,\n",
       "                               'white': 8,\n",
       "                               'heat': 2,\n",
       "                               'Not': 13,\n",
       "                               'noblest': 1,\n",
       "                               'performance': 26,\n",
       "                               'we': 40,\n",
       "                               'have': 124,\n",
       "                               'heard': 13,\n",
       "                               'him': 40,\n",
       "                               'play': 15,\n",
       "                               'most': 51,\n",
       "                               'spacious': 2,\n",
       "                               'even': 31,\n",
       "                               'eloquent': 4,\n",
       "                               'Those': 2,\n",
       "                               'would': 47,\n",
       "                               'be': 153,\n",
       "                               'reserved': 4,\n",
       "                               \"orchestra's\": 2,\n",
       "                               'great': 40,\n",
       "                               'nights': 3,\n",
       "                               'when': 54,\n",
       "                               'soloist': 6,\n",
       "                               'can': 45,\n",
       "                               'surpass': 1,\n",
       "                               'himself': 30,\n",
       "                               'This': 41,\n",
       "                               'time': 41,\n",
       "                               'orchestra': 16,\n",
       "                               'gave': 17,\n",
       "                               'some': 52,\n",
       "                               'superb': 8,\n",
       "                               'support': 5,\n",
       "                               'fired': 1,\n",
       "                               'by': 203,\n",
       "                               'response': 2,\n",
       "                               'to': 706,\n",
       "                               'mood': 8,\n",
       "                               'But': 71,\n",
       "                               'had': 69,\n",
       "                               'Walter': 2,\n",
       "                               'Hendl': 3,\n",
       "                               'willing': 5,\n",
       "                               'conductor': 6,\n",
       "                               'able': 10,\n",
       "                               'only': 64,\n",
       "                               'up': 54,\n",
       "                               'point': 14,\n",
       "                               'That': 12,\n",
       "                               'Mr.': 105,\n",
       "                               'thrust': 1,\n",
       "                               'straight': 4,\n",
       "                               'core': 1,\n",
       "                               'sparks': 2,\n",
       "                               'flying': 3,\n",
       "                               'bow': 1,\n",
       "                               'shredding': 1,\n",
       "                               'singing': 20,\n",
       "                               'glittering': 1,\n",
       "                               'sometimes': 13,\n",
       "                               'spitting': 1,\n",
       "                               'could': 40,\n",
       "                               'go': 10,\n",
       "                               'along': 13,\n",
       "                               'does': 32,\n",
       "                               'any': 29,\n",
       "                               'He': 78,\n",
       "                               'flounders': 1,\n",
       "                               'lets': 1,\n",
       "                               'sprawl': 1,\n",
       "                               'none': 7,\n",
       "                               'mysterious': 2,\n",
       "                               'marvelous': 2,\n",
       "                               'alchemy': 1,\n",
       "                               'bring': 4,\n",
       "                               'ultimate': 2,\n",
       "                               'fusion': 1,\n",
       "                               'So': 17,\n",
       "                               'dazzling': 1,\n",
       "                               'memorable': 2,\n",
       "                               'but': 99,\n",
       "                               'The': 322,\n",
       "                               'concert': 9,\n",
       "                               'opened': 11,\n",
       "                               'another': 14,\n",
       "                               'big': 23,\n",
       "                               'romantic': 4,\n",
       "                               'score': 9,\n",
       "                               \"Schumann's\": 1,\n",
       "                               'Overture': 4,\n",
       "                               '``': 390,\n",
       "                               'Manfred': 1,\n",
       "                               \"''\": 389,\n",
       "                               'suffered': 4,\n",
       "                               'fate': 2,\n",
       "                               'orchestral': 2,\n",
       "                               'thrusts': 1,\n",
       "                               'Byronic': 1,\n",
       "                               'keep': 8,\n",
       "                               'afloat': 2,\n",
       "                               \"Hindemith's\": 1,\n",
       "                               'joust': 1,\n",
       "                               'Weber': 1,\n",
       "                               'tunes': 2,\n",
       "                               'considerably': 4,\n",
       "                               'more': 103,\n",
       "                               'serious': 9,\n",
       "                               'misfortune': 2,\n",
       "                               'demands': 3,\n",
       "                               'transluscent': 1,\n",
       "                               'textures': 1,\n",
       "                               'buoyant': 1,\n",
       "                               'rhythms': 2,\n",
       "                               'astringent': 1,\n",
       "                               'wit': 7,\n",
       "                               'got': 9,\n",
       "                               'kind': 13,\n",
       "                               'scrambled': 1,\n",
       "                               'coarsened': 1,\n",
       "                               'happen': 3,\n",
       "                               'best': 20,\n",
       "                               'orchestras': 1,\n",
       "                               'man': 49,\n",
       "                               'baton': 2,\n",
       "                               'lacks': 1,\n",
       "                               'technique': 6,\n",
       "                               'style': 23,\n",
       "                               'Bayreuth': 2,\n",
       "                               'next': 10,\n",
       "                               'summer': 4,\n",
       "                               'Festival': 9,\n",
       "                               'opens': 2,\n",
       "                               'July': 6,\n",
       "                               '23': 11,\n",
       "                               'new': 42,\n",
       "                               'production': 14,\n",
       "                               'Tannhaeuser': 2,\n",
       "                               'staged': 5,\n",
       "                               'Wieland': 1,\n",
       "                               'Wagner': 1,\n",
       "                               'who': 128,\n",
       "                               'doing': 6,\n",
       "                               'all': 122,\n",
       "                               'operas': 2,\n",
       "                               'conducted': 3,\n",
       "                               'Wolfgang': 1,\n",
       "                               'Sawallisch': 1,\n",
       "                               'Sawalisch': 1,\n",
       "                               'also': 31,\n",
       "                               'conducts': 3,\n",
       "                               'Flying': 2,\n",
       "                               'Dutch': 1,\n",
       "                               'opening': 10,\n",
       "                               '24': 7,\n",
       "                               'Parsifal': 1,\n",
       "                               'follows': 2,\n",
       "                               '25': 5,\n",
       "                               'Hans': 2,\n",
       "                               'Knappertsbusch': 1,\n",
       "                               'conducting': 1,\n",
       "                               'Die': 1,\n",
       "                               'Meistersinger': 1,\n",
       "                               'presented': 9,\n",
       "                               'Aug.': 2,\n",
       "                               '8': 7,\n",
       "                               '12': 6,\n",
       "                               'Ring': 4,\n",
       "                               'cycles': 1,\n",
       "                               'are': 190,\n",
       "                               '26': 2,\n",
       "                               '27': 2,\n",
       "                               '28': 5,\n",
       "                               '30': 5,\n",
       "                               '21': 2,\n",
       "                               '22': 2,\n",
       "                               'Rudolf': 1,\n",
       "                               'Kempe': 1,\n",
       "                               'No': 7,\n",
       "                               'casts': 1,\n",
       "                               'listed': 2,\n",
       "                               'Lotte': 1,\n",
       "                               'Lehmann': 1,\n",
       "                               'sent': 2,\n",
       "                               'word': 16,\n",
       "                               'Negro': 27,\n",
       "                               'soprano': 4,\n",
       "                               'Grace': 2,\n",
       "                               'Bumbry': 1,\n",
       "                               'will': 58,\n",
       "                               'sing': 8,\n",
       "                               'Venus': 1,\n",
       "                               'Remember': 2,\n",
       "                               'how': 26,\n",
       "                               'series': 10,\n",
       "                               'booking': 6,\n",
       "                               'absurdities': 1,\n",
       "                               'missed': 6,\n",
       "                               'seeing': 1,\n",
       "                               'Bolshoi': 1,\n",
       "                               'Ballet': 6,\n",
       "                               '?': 64,\n",
       "                               'lack': 4,\n",
       "                               'two': 34,\n",
       "                               'theaters': 2,\n",
       "                               'first': 65,\n",
       "                               'visit': 3,\n",
       "                               'Royal': 3,\n",
       "                               'Danish': 1,\n",
       "                               'Well': 6,\n",
       "                               'now': 20,\n",
       "                               'barring': 2,\n",
       "                               'miracle': 2,\n",
       "                               \"don't\": 5,\n",
       "                               'hold': 9,\n",
       "                               'your': 10,\n",
       "                               'breath': 2,\n",
       "                               'see': 14,\n",
       "                               'Leningrad-Kirov': 1,\n",
       "                               'stems': 1,\n",
       "                               'from': 138,\n",
       "                               'ballet': 9,\n",
       "                               'cradle': 1,\n",
       "                               'Maryinsky': 1,\n",
       "                               'one': 106,\n",
       "                               'companies': 1,\n",
       "                               'world': 26,\n",
       "                               'Before': 3,\n",
       "                               'you': 29,\n",
       "                               'let': 9,\n",
       "                               'loose': 3,\n",
       "                               'howl': 1,\n",
       "                               'saying': 3,\n",
       "                               'announced': 5,\n",
       "                               'its': 94,\n",
       "                               'coming': 2,\n",
       "                               'once': 13,\n",
       "                               'several': 9,\n",
       "                               'times': 12,\n",
       "                               'indeed': 5,\n",
       "                               'did': 22,\n",
       "                               'engagement': 5,\n",
       "                               'supposed': 3,\n",
       "                               'set': 16,\n",
       "                               'theater': 7,\n",
       "                               'McCormick': 4,\n",
       "                               'Place': 4,\n",
       "                               'Sol': 1,\n",
       "                               'Hurok': 3,\n",
       "                               'booker': 1,\n",
       "                               'extraordinary': 5,\n",
       "                               'considers': 1,\n",
       "                               'finest': 5,\n",
       "                               'house': 6,\n",
       "                               'country': 12,\n",
       "                               '--': 142,\n",
       "                               'course': 24,\n",
       "                               \"doesn't\": 7,\n",
       "                               'weep': 3,\n",
       "                               'capacity': 2,\n",
       "                               'either': 11,\n",
       "                               'Allied': 10,\n",
       "                               'Arts': 10,\n",
       "                               'Corporation': 2,\n",
       "                               'dates': 3,\n",
       "                               'as': 259,\n",
       "                               'Dec.': 7,\n",
       "                               '4': 9,\n",
       "                               'thru': 8,\n",
       "                               '10': 6,\n",
       "                               'Later': 2,\n",
       "                               'office': 2,\n",
       "                               'made': 35,\n",
       "                               '17': 2,\n",
       "                               'nice': 7,\n",
       "                               'long': 22,\n",
       "                               'full': 12,\n",
       "                               'repertory': 2,\n",
       "                               'if': 30,\n",
       "                               'calendar': 2,\n",
       "                               'events': 8,\n",
       "                               'do': 35,\n",
       "                               'noticed': 1,\n",
       "                               'conflict': 3,\n",
       "                               'booked': 3,\n",
       "                               'Marlene': 1,\n",
       "                               'Dietrich': 3,\n",
       "                               '9': 3,\n",
       "                               'Something': 1,\n",
       "                               'give': 14,\n",
       "                               'La': 11,\n",
       "                               'then': 24,\n",
       "                               'notified': 1,\n",
       "                               'us': 21,\n",
       "                               'Kirov': 6,\n",
       "                               'cut': 6,\n",
       "                               'short': 10,\n",
       "                               'Los': 6,\n",
       "                               'Angeles': 5,\n",
       "                               'fly': 2,\n",
       "                               'here': 20,\n",
       "                               'open': 11,\n",
       "                               'Nov.': 9,\n",
       "                               'close': 12,\n",
       "                               '2': 9,\n",
       "                               'Shorter': 1,\n",
       "                               'still': 19,\n",
       "                               'We': 5,\n",
       "                               'printed': 1,\n",
       "                               'A': 56,\n",
       "                               'couple': 7,\n",
       "                               'days': 10,\n",
       "                               'later': 9,\n",
       "                               'balletomane': 1,\n",
       "                               'told': 7,\n",
       "                               'me': 9,\n",
       "                               'telephoned': 1,\n",
       "                               'ticket': 2,\n",
       "                               'information': 2,\n",
       "                               'newspapers': 2,\n",
       "                               'mistake': 3,\n",
       "                               'I': 49,\n",
       "                               'started': 3,\n",
       "                               'making': 5,\n",
       "                               'calls': 6,\n",
       "                               'my': 9,\n",
       "                               'These': 6,\n",
       "                               'results': 5,\n",
       "                               'firmly': 2,\n",
       "                               'Shrine': 1,\n",
       "                               'Auditorium': 3,\n",
       "                               'chance': 7,\n",
       "                               'Then': 8,\n",
       "                               'why': 9,\n",
       "                               'juicy': 3,\n",
       "                               'held': 7,\n",
       "                               \"won't\": 3,\n",
       "                               'budge': 1,\n",
       "                               'Civic': 2,\n",
       "                               'Opera': 7,\n",
       "                               'House': 3,\n",
       "                               'Lena': 1,\n",
       "                               'Horne': 1,\n",
       "                               'there': 64,\n",
       "                               'week': 6,\n",
       "                               'starting': 3,\n",
       "                               'Queried': 1,\n",
       "                               'impasse': 1,\n",
       "                               'said': 11,\n",
       "                               ':': 65,\n",
       "                               'Better': 1,\n",
       "                               'cancel': 1,\n",
       "                               'being': 30,\n",
       "                               \"It's\": 7,\n",
       "                               'air': 6,\n",
       "                               'again': 17,\n",
       "                               'back': 19,\n",
       "                               'Russia': 8,\n",
       "                               'minus': 1,\n",
       "                               'loss': 2,\n",
       "                               'dance': 17,\n",
       "                               'fans': 4,\n",
       "                               'frustrated': 1,\n",
       "                               'bookers': 1,\n",
       "                               'cancellation': 1,\n",
       "                               'richest': 1,\n",
       "                               'bookings': 1,\n",
       "                               'Will': 3,\n",
       "                               'somebody': 1,\n",
       "                               'please': 2,\n",
       "                               'reopen': 1,\n",
       "                               'Paintings': 1,\n",
       "                               'drawings': 7,\n",
       "                               'Marie': 2,\n",
       "                               'Moore': 2,\n",
       "                               'St.': 9,\n",
       "                               'Thomas': 3,\n",
       "                               'Virgin': 1,\n",
       "                               'Islands': 1,\n",
       "                               'shown': 1,\n",
       "                               '5': 5,\n",
       "                               'Meadows': 1,\n",
       "                               'Gallery': 2,\n",
       "                               '3211': 1,\n",
       "                               'Ellis': 1,\n",
       "                               'Av.': 1,\n",
       "                               '3': 4,\n",
       "                               'p.m.': 5,\n",
       "                               'Sundays': 1,\n",
       "                               '6': 2,\n",
       "                               'Mondays': 1,\n",
       "                               'An': 8,\n",
       "                               'exhibition': 5,\n",
       "                               'Evelyn': 1,\n",
       "                               \"Cibula's\": 1,\n",
       "                               'paintings': 8,\n",
       "                               'reception': 3,\n",
       "                               'Evanston': 1,\n",
       "                               'Community': 1,\n",
       "                               'center': 4,\n",
       "                               '828': 1,\n",
       "                               'Davis': 1,\n",
       "                               'continue': 5,\n",
       "                               'month': 4,\n",
       "                               'Abstractions': 1,\n",
       "                               'semi-abstractions': 1,\n",
       "                               'Everett': 1,\n",
       "                               'McNear': 1,\n",
       "                               'exhibited': 1,\n",
       "                               'University': 6,\n",
       "                               'Notre': 1,\n",
       "                               'Dame': 1,\n",
       "                               'until': 9,\n",
       "                               'In': 72,\n",
       "                               'line': 3,\n",
       "                               'operatic': 3,\n",
       "                               'trades': 1,\n",
       "                               'cushion': 1,\n",
       "                               'budget': 1,\n",
       "                               'Dallas': 2,\n",
       "                               'use': 8,\n",
       "                               'San': 6,\n",
       "                               \"Francisco's\": 1,\n",
       "                               'Leni': 1,\n",
       "                               'Bauer-Ecsy': 1,\n",
       "                               'Lucia': 7,\n",
       "                               'Di': 3,\n",
       "                               'Lammermoor': 2,\n",
       "                               'returning': 1,\n",
       "                               'favor': 4,\n",
       "                               'Francisco': 4,\n",
       "                               'uses': 4,\n",
       "                               'Don': 7,\n",
       "                               'Giovanni': 1,\n",
       "                               'designed': 8,\n",
       "                               'Franco': 2,\n",
       "                               'Zeffirelli': 1,\n",
       "                               'H': 1,\n",
       "                               'E.': 3,\n",
       "                               'Bates': 2,\n",
       "                               'scribbled': 1,\n",
       "                               'farce': 2,\n",
       "                               'called': 20,\n",
       "                               'Hark': 3,\n",
       "                               'Lark': 1,\n",
       "                               '!': 14,\n",
       "                               'entertaining': 4,\n",
       "                               'irresponsible': 1,\n",
       "                               'novels': 2,\n",
       "                               'If': 18,\n",
       "                               'moral': 3,\n",
       "                               'lurking': 1,\n",
       "                               'among': 13,\n",
       "                               'shenanigans': 2,\n",
       "                               'hard': 6,\n",
       "                               'find': 6,\n",
       "                               'Perhaps': 5,\n",
       "                               'lesson': 3,\n",
       "                               'should': 18,\n",
       "                               'take': 12,\n",
       "                               'these': 29,\n",
       "                               'pages': 4,\n",
       "                               'welfare': 2,\n",
       "                               'state': 6,\n",
       "                               'England': 11,\n",
       "                               'allows': 1,\n",
       "                               'wild': 6,\n",
       "                               'scope': 2,\n",
       "                               'kinds': 1,\n",
       "                               'rugged': 1,\n",
       "                               'eccentrics': 1,\n",
       "                               'Anyway': 1,\n",
       "                               'number': 17,\n",
       "                               'them': 45,\n",
       "                               'meet': 4,\n",
       "                               'devastating': 1,\n",
       "                               'collisions': 1,\n",
       "                               'One': 19,\n",
       "                               'an': 163,\n",
       "                               'imperial': 1,\n",
       "                               'London': 19,\n",
       "                               'stockbroker': 1,\n",
       "                               'Jerebohm': 2,\n",
       "                               'Another': 2,\n",
       "                               'wily': 2,\n",
       "                               'countryman': 1,\n",
       "                               'Larkin': 10,\n",
       "                               'whose': 17,\n",
       "                               'blandly': 1,\n",
       "                               'boisterous': 1,\n",
       "                               'progress': 5,\n",
       "                               'been': 69,\n",
       "                               'chronicled': 1,\n",
       "                               'believe': 3,\n",
       "                               'earlier': 10,\n",
       "                               'volumes': 4,\n",
       "                               \"Bates'\": 1,\n",
       "                               'comedie': 1,\n",
       "                               'humaine': 1,\n",
       "                               \"What's\": 2,\n",
       "                               'wife': 11,\n",
       "                               'Pinkie': 1,\n",
       "                               'reached': 4,\n",
       "                               'stage': 23,\n",
       "                               'affluence': 2,\n",
       "                               'stirs': 2,\n",
       "                               'longing': 1,\n",
       "                               'atrociously': 1,\n",
       "                               'expensive': 1,\n",
       "                               'rustic': 2,\n",
       "                               'simplicities': 2,\n",
       "                               'They': 24,\n",
       "                               'want': 5,\n",
       "                               'junior-grade': 1,\n",
       "                               'castle': 1,\n",
       "                               'manor': 1,\n",
       "                               'modest': 4,\n",
       "                               'little': 32,\n",
       "                               'place': 19,\n",
       "                               'Shakespeare': 5,\n",
       "                               'might': 26,\n",
       "                               'pageant': 1,\n",
       "                               'Great': 3,\n",
       "                               'Elizabeth': 2,\n",
       "                               'her': 85,\n",
       "                               'bearded': 3,\n",
       "                               'courtiers': 1,\n",
       "                               'settle': 1,\n",
       "                               'however': 16,\n",
       "                               'anything': 4,\n",
       "                               'offers': 2,\n",
       "                               'pheasants': 2,\n",
       "                               'shoot': 3,\n",
       "                               'peasants': 3,\n",
       "                               'work': 35,\n",
       "                               'And': 58,\n",
       "                               'just': 34,\n",
       "                               'thing': 9,\n",
       "                               'they': 74,\n",
       "                               'Splendor': 1,\n",
       "                               'sorcery': 1,\n",
       "                               'horror': 1,\n",
       "                               'name': 7,\n",
       "                               'Gore': 3,\n",
       "                               'Court': 3,\n",
       "                               'surrounded': 1,\n",
       "                               'wasteland': 1,\n",
       "                               'impress': 2,\n",
       "                               'T.': 1,\n",
       "                               'S.': 3,\n",
       "                               'Eliot': 1,\n",
       "                               \"That's\": 1,\n",
       "                               'precisely': 1,\n",
       "                               'way': 35,\n",
       "                               'urges': 1,\n",
       "                               'look': 9,\n",
       "                               'though': 18,\n",
       "                               'conjures': 1,\n",
       "                               'herds': 1,\n",
       "                               'deer': 1,\n",
       "                               'birds': 6,\n",
       "                               'crowding': 1,\n",
       "                               'suggests': 4,\n",
       "                               'embodies': 1,\n",
       "                               'glories': 1,\n",
       "                               'Tudor': 2,\n",
       "                               'splendor': 2,\n",
       "                               'stained-glass': 1,\n",
       "                               'windows': 1,\n",
       "                               'may': 45,\n",
       "                               'developed': 4,\n",
       "                               'unpremeditated': 1,\n",
       "                               'patinas': 1,\n",
       "                               'paneling': 1,\n",
       "                               'no': 57,\n",
       "                               'durable': 1,\n",
       "                               'than': 80,\n",
       "                               'planks': 1,\n",
       "                               'political': 8,\n",
       "                               'platform': 2,\n",
       "                               'vast': 4,\n",
       "                               'dungeon': 1,\n",
       "                               'kitchens': 1,\n",
       "                               'seem': 15,\n",
       "                               'hardly': 8,\n",
       "                               'worth': 4,\n",
       "                               'using': 3,\n",
       "                               'except': 7,\n",
       "                               'on': 184,\n",
       "                               'occasions': 1,\n",
       "                               'faced': 2,\n",
       "                               'thousand': 2,\n",
       "                               'unexpected': 2,\n",
       "                               'guests': 1,\n",
       "                               'lunch': 1,\n",
       "                               'answer': 1,\n",
       "                               'spaciousness': 1,\n",
       "                               'cooking': 2,\n",
       "                               'areas': 4,\n",
       "                               'example': 9,\n",
       "                               'provide': 3,\n",
       "                               'needed': 2,\n",
       "                               'space': 6,\n",
       "                               'extra': 5,\n",
       "                               'television': 6,\n",
       "                               'sets': 5,\n",
       "                               'required': 3,\n",
       "                               'modern': 6,\n",
       "                               'butlers': 1,\n",
       "                               'cooks': 1,\n",
       "                               'maids': 1,\n",
       "                               'Also': 4,\n",
       "                               'perhaps': 14,\n",
       "                               'table-tennis': 1,\n",
       "                               'other': 54,\n",
       "                               'indoor': 1,\n",
       "                               'sports': 2,\n",
       "                               'fit': 1,\n",
       "                               'contented': 2,\n",
       "                               'wonder': 6,\n",
       "                               'really': 19,\n",
       "                               'much': 33,\n",
       "                               'mendacious': 1,\n",
       "                               'trouble': 3,\n",
       "                               'puts': 2,\n",
       "                               'sell': 3,\n",
       "                               'Jerebohms': 3,\n",
       "                               'preposterous': 1,\n",
       "                               'manse': 1,\n",
       "                               'need': 11,\n",
       "                               'immense': 2,\n",
       "                               'sum': 1,\n",
       "                               'money': 2,\n",
       "                               '(': 101,\n",
       "                               'probably': 8,\n",
       "                               'converted': 1,\n",
       "                               'American': 44,\n",
       "                               'gold': 4,\n",
       "                               'Exchange': 1,\n",
       "                               ')': 101,\n",
       "                               'makes': 13,\n",
       "                               'pay': 4,\n",
       "                               'For': 32,\n",
       "                               'already': 12,\n",
       "                               'wonderfully': 3,\n",
       "                               'lot': 4,\n",
       "                               'glorious': 3,\n",
       "                               'many': 40,\n",
       "                               'children': 5,\n",
       "                               'When': 6,\n",
       "                               'needs': 6,\n",
       "                               'buy': 4,\n",
       "                               'like': 36,\n",
       "                               'say': 17,\n",
       "                               'Rolls-Royce': 1,\n",
       "                               'keeps': 1,\n",
       "                               'near': 7,\n",
       "                               'vegetable': 4,\n",
       "                               'patch': 2,\n",
       "                               'takes': 9,\n",
       "                               'flyer': 1,\n",
       "                               'sale': 1,\n",
       "                               'surplus': 2,\n",
       "                               'army': 6,\n",
       "                               'supplies': 2,\n",
       "                               'those': 24,\n",
       "                               'capital-gains': 1,\n",
       "                               'ventures': 1,\n",
       "                               'fact': 15,\n",
       "                               'saddled': 1,\n",
       "                               'get': 18,\n",
       "                               'off': 18,\n",
       "                               'hands': 4,\n",
       "                               'plan': 2,\n",
       "                               'become': 14,\n",
       "                               'county': 1,\n",
       "                               'people': 25,\n",
       "                               'know': 14,\n",
       "                               'proper': 2,\n",
       "                               'terminate': 2,\n",
       "                               \"fox's\": 1,\n",
       "                               'life': 33,\n",
       "                               'earth': 3,\n",
       "                               'First': 4,\n",
       "                               \"Larkin's\": 1,\n",
       "                               'eyes': 7,\n",
       "                               'nothing': 9,\n",
       "                               'Piccadilly': 1,\n",
       "                               'farmers': 1,\n",
       "                               'learn': 4,\n",
       "                               'ways': 5,\n",
       "                               'truly': 4,\n",
       "                               'rural': 2,\n",
       "                               'living': 8,\n",
       "                               'shows': 9,\n",
       "                               'mutual': 2,\n",
       "                               'education': 1,\n",
       "                               'spreads': 1,\n",
       "                               'inevitable': 2,\n",
       "                               'havoc': 1,\n",
       "                               'Oneupmanship': 1,\n",
       "                               'practiced': 1,\n",
       "                               'both': 25,\n",
       "                               'sides': 3,\n",
       "                               'total': 8,\n",
       "                               'war': 17,\n",
       "                               'Larkins': 1,\n",
       "                               'ahead': 2,\n",
       "                               'After': 7,\n",
       "                               'persuaded': 1,\n",
       "                               'restock': 1,\n",
       "                               'tangled': 1,\n",
       "                               'acres': 2,\n",
       "                               'poaches': 1,\n",
       "                               'what': 44,\n",
       "                               'nourishment': 1,\n",
       "                               'family': 8,\n",
       "                               'local': 6,\n",
       "                               'callers': 2,\n",
       "                               'retired': 1,\n",
       "                               'brigadier': 2,\n",
       "                               'apparently': 9,\n",
       "                               'left': 14,\n",
       "                               'over': 21,\n",
       "                               \"Kipling's\": 1,\n",
       "                               'tales': 1,\n",
       "                               'India': 2,\n",
       "                               'approve': 1,\n",
       "                               'gets': 6,\n",
       "                               'think': 10,\n",
       "                               'potting': 1,\n",
       "                               'deck': 2,\n",
       "                               'chair': 3,\n",
       "                               'south': 5,\n",
       "                               'side': 3,\n",
       "                               'quart': 1,\n",
       "                               'glass': 2,\n",
       "                               'beer': 2,\n",
       "                               'sustenance': 2,\n",
       "                               'entirely': 1,\n",
       "                               'sporting': 1,\n",
       "                               'dines': 1,\n",
       "                               'relish': 3,\n",
       "                               'odd': 4,\n",
       "                               'ironic': 2,\n",
       "                               'handsome': 3,\n",
       "                               'impressive': 10,\n",
       "                               'film': 13,\n",
       "                               'yet': 8,\n",
       "                               'Miguel': 1,\n",
       "                               'De': 12,\n",
       "                               \"Cervantes'\": 1,\n",
       "                               'Quixote': 4,\n",
       "                               'brilliant': 7,\n",
       "                               'Russian': 14,\n",
       "                               'spectacle': 4,\n",
       "                               'done': 10,\n",
       "                               'wide': 6,\n",
       "                               'screen': 2,\n",
       "                               'color': 16,\n",
       "                               'yesterday': 5,\n",
       "                               'Fifty-fifth': 2,\n",
       "                               'Street': 7,\n",
       "                               'Sixty-eighth': 1,\n",
       "                               'Playhouses': 1,\n",
       "                               'More': 4,\n",
       "                               'beautiful': 11,\n",
       "                               'visualization': 1,\n",
       "                               'illustrious': 1,\n",
       "                               'adventures': 2,\n",
       "                               'escapades': 1,\n",
       "                               'tragi-comic': 1,\n",
       "                               'knight-errant': 2,\n",
       "                               'squire': 2,\n",
       "                               'Sancho': 3,\n",
       "                               'Panza': 3,\n",
       "                               'seventeenth-century': 1,\n",
       "                               'Spain': 1,\n",
       "                               'inevitably': 4,\n",
       "                               'abbreviated': 1,\n",
       "                               'rendering': 1,\n",
       "                               'classic': 10,\n",
       "                               'satire': 2,\n",
       "                               'chivalry': 1,\n",
       "                               'affectingly': 1,\n",
       "                               'warm': 6,\n",
       "                               'human': 16,\n",
       "                               'exposition': 1,\n",
       "                               'character': 15,\n",
       "                               'Nikolai': 2,\n",
       "                               'Cherkasov': 3,\n",
       "                               'actor': 8,\n",
       "                               'such': 32,\n",
       "                               'heroic': 4,\n",
       "                               'roles': 5,\n",
       "                               'Alexander': 1,\n",
       "                               'Nevsky': 1,\n",
       "                               'Ivan': 2,\n",
       "                               'Terrible': 1,\n",
       "                               'performs': 3,\n",
       "                               'lanky': 1,\n",
       "                               'so': 59,\n",
       "                               'simple': 6,\n",
       "                               'dignity': 3,\n",
       "                               'bridges': 1,\n",
       "                               'inner': 4,\n",
       "                               'nobility': 1,\n",
       "                               'surface': 7,\n",
       "                               'absurdity': 2,\n",
       "                               'poignant': 1,\n",
       "                               'His': 23,\n",
       "                               'addle-brained': 1,\n",
       "                               'self-appointed': 1,\n",
       "                               'ridiculous': 1,\n",
       "                               'position': 4,\n",
       "                               'age': 7,\n",
       "                               'armor': 1,\n",
       "                               'relegated': 1,\n",
       "                               'museums': 1,\n",
       "                               'chivalrous': 1,\n",
       "                               'code': 1,\n",
       "                               'knight-errantry': 1,\n",
       "                               'joke': 3,\n",
       "                               'Cervantes': 1,\n",
       "                               'doubt': 6,\n",
       "                               'intended': 4,\n",
       "                               'gaunt': 1,\n",
       "                               'gracious': 2,\n",
       "                               'symbol': 4,\n",
       "                               'good': 42,\n",
       "                               'moving': 11,\n",
       "                               'soberly': 1,\n",
       "                               'sincerely': 1,\n",
       "                               'cynics': 1,\n",
       "                               'hypocrites': 1,\n",
       "                               'rogues': 1,\n",
       "                               'caricature': 1,\n",
       "                               'actors': 3,\n",
       "                               'inclined': 1,\n",
       "                               'treats': 1,\n",
       "                               'deep-eyed': 1,\n",
       "                               'bony': 1,\n",
       "                               'crackpot': 1,\n",
       "                               'tangible': 1,\n",
       "                               'affection': 3,\n",
       "                               'respect': 6,\n",
       "                               'Directed': 2,\n",
       "                               'Grigory': 1,\n",
       "                               'Kozintsev': 1,\n",
       "                               'tempo': 1,\n",
       "                               'studiously': 1,\n",
       "                               'slow': 7,\n",
       "                               'develops': 1,\n",
       "                               'sense': 22,\n",
       "                               'tradition': 11,\n",
       "                               'shining': 1,\n",
       "                               'brightly': 2,\n",
       "                               'passing': 3,\n",
       "                               'gravely': 1,\n",
       "                               'through': 26,\n",
       "                               'impious': 1,\n",
       "                               'complexities': 2,\n",
       "                               'communication': 5,\n",
       "                               'abetted': 1,\n",
       "                               'case': 9,\n",
       "                               'appropriately': 1,\n",
       "                               'stilted': 1,\n",
       "                               'English': 13,\n",
       "                               'language': 7,\n",
       "                               'excellently': 2,\n",
       "                               'dubbed': 1,\n",
       "                               'dialogue': 3,\n",
       "                               'voices': 5,\n",
       "                               'characters': 6,\n",
       "                               'including': 9,\n",
       "                               'richness': 1,\n",
       "                               'roughness': 1,\n",
       "                               'conform': 1,\n",
       "                               'personalities': 3,\n",
       "                               'subtleties': 3,\n",
       "                               'helpfully': 1,\n",
       "                               'conveyed': 1,\n",
       "                               'Since': 7,\n",
       "                               'spoken': 2,\n",
       "                               'instead': 5,\n",
       "                               'Spanish': 4,\n",
       "                               'violation': 1,\n",
       "                               'artistry': 2,\n",
       "                               'logic': 1,\n",
       "                               'Splendid': 1,\n",
       "                               'too': 41,\n",
       "                               'Yuri': 4,\n",
       "                               'Tolubeyev': 1,\n",
       "                               \"Russia's\": 2,\n",
       "                               'leading': 5,\n",
       "                               'comedians': 1,\n",
       "                               'fat': 11,\n",
       "                               'grotesque': 1,\n",
       "                               'Though': 3,\n",
       "                               'broader': 1,\n",
       "                               'comically': 2,\n",
       "                               'rounded': 1,\n",
       "                               'don': 1,\n",
       "                               'gives': 4,\n",
       "                               'firmness': 1,\n",
       "                               'toughness': 1,\n",
       "                               'sort': 6,\n",
       "                               'peasant': 1,\n",
       "                               'Russians': 4,\n",
       "                               'seen': 10,\n",
       "                               'oftentimes': 1,\n",
       "                               'underlying': 2,\n",
       "                               'vitality': 4,\n",
       "                               'courage': 3,\n",
       "                               'buffoons': 1,\n",
       "                               'episode': 1,\n",
       "                               'concludes': 1,\n",
       "                               'facetiously': 1,\n",
       "                               'put': 12,\n",
       "                               'command': 4,\n",
       "                               'island': 1,\n",
       "                               'True': 1,\n",
       "                               'pattern': 1,\n",
       "                               'flow': 5,\n",
       "                               'drama': 10,\n",
       "                               'strong': 17,\n",
       "                               'literary': 6,\n",
       "                               'qualities': 6,\n",
       "                               'bit': 8,\n",
       "                               'wearisome': 1,\n",
       "                               'half': 17,\n",
       "                               'before': 23,\n",
       "                               'goes': 3,\n",
       "                               \"duke's\": 1,\n",
       "                               'court': 4,\n",
       "                               ...}),\n",
       "                     'romance': FreqDist({'They': 69,\n",
       "                               'neither': 7,\n",
       "                               'liked': 12,\n",
       "                               'nor': 5,\n",
       "                               'disliked': 4,\n",
       "                               'the': 2758,\n",
       "                               'Old': 17,\n",
       "                               'Man': 13,\n",
       "                               '.': 3736,\n",
       "                               'To': 15,\n",
       "                               'them': 142,\n",
       "                               'he': 702,\n",
       "                               'could': 193,\n",
       "                               'have': 258,\n",
       "                               'been': 179,\n",
       "                               'broken': 8,\n",
       "                               'bell': 4,\n",
       "                               'in': 875,\n",
       "                               'church': 29,\n",
       "                               'tower': 1,\n",
       "                               'which': 104,\n",
       "                               'rang': 6,\n",
       "                               'before': 88,\n",
       "                               'and': 1776,\n",
       "                               'after': 58,\n",
       "                               'Mass': 1,\n",
       "                               ',': 3899,\n",
       "                               'at': 402,\n",
       "                               'noon': 4,\n",
       "                               'six': 11,\n",
       "                               'each': 24,\n",
       "                               'evening': 14,\n",
       "                               '--': 291,\n",
       "                               'its': 69,\n",
       "                               'tone': 9,\n",
       "                               'repetitive': 1,\n",
       "                               'monotonous': 1,\n",
       "                               'never': 84,\n",
       "                               'breaking': 4,\n",
       "                               'boredom': 3,\n",
       "                               'of': 1186,\n",
       "                               'streets': 5,\n",
       "                               'The': 230,\n",
       "                               'was': 993,\n",
       "                               'unimportant': 1,\n",
       "                               'Yet': 9,\n",
       "                               'if': 142,\n",
       "                               'were': 214,\n",
       "                               'not': 250,\n",
       "                               'there': 169,\n",
       "                               'they': 168,\n",
       "                               'would': 244,\n",
       "                               'missed': 5,\n",
       "                               'him': 339,\n",
       "                               'as': 282,\n",
       "                               'sounds': 12,\n",
       "                               'bees': 1,\n",
       "                               'buzzing': 4,\n",
       "                               'against': 42,\n",
       "                               'screen': 4,\n",
       "                               'door': 43,\n",
       "                               'early': 21,\n",
       "                               'June': 4,\n",
       "                               ';': 264,\n",
       "                               'or': 150,\n",
       "                               'smell': 3,\n",
       "                               'thick': 9,\n",
       "                               'tomato': 1,\n",
       "                               'paste': 1,\n",
       "                               'ripe': 3,\n",
       "                               'that': 583,\n",
       "                               'both': 28,\n",
       "                               'sweet': 8,\n",
       "                               'sour': 1,\n",
       "                               'rising': 8,\n",
       "                               'up': 211,\n",
       "                               'from': 202,\n",
       "                               'aluminum': 1,\n",
       "                               'trays': 1,\n",
       "                               'wrapped': 3,\n",
       "                               'fly-dotted': 1,\n",
       "                               'cheesecloth': 1,\n",
       "                               'Or': 15,\n",
       "                               'surging': 1,\n",
       "                               'whirling': 2,\n",
       "                               'bats': 2,\n",
       "                               'night': 54,\n",
       "                               'when': 126,\n",
       "                               'their': 114,\n",
       "                               'black': 32,\n",
       "                               'bodies': 1,\n",
       "                               'dived': 1,\n",
       "                               'into': 136,\n",
       "                               'blackness': 1,\n",
       "                               'above': 17,\n",
       "                               'below': 4,\n",
       "                               'amber': 1,\n",
       "                               'street': 14,\n",
       "                               'lights': 2,\n",
       "                               'bay': 1,\n",
       "                               'female': 4,\n",
       "                               'dogs': 3,\n",
       "                               'heat': 4,\n",
       "                               'called': 31,\n",
       "                               'by': 107,\n",
       "                               'name': 13,\n",
       "                               'although': 4,\n",
       "                               'had': 692,\n",
       "                               'one': 166,\n",
       "                               'Filippo': 1,\n",
       "                               'Rossi': 1,\n",
       "                               \"that's\": 21,\n",
       "                               'what': 121,\n",
       "                               'old': 73,\n",
       "                               'country': 10,\n",
       "                               'but': 252,\n",
       "                               'here': 65,\n",
       "                               'just': 100,\n",
       "                               'Signore': 1,\n",
       "                               'But': 135,\n",
       "                               'this': 149,\n",
       "                               'unusual': 5,\n",
       "                               'because': 85,\n",
       "                               'youth': 5,\n",
       "                               'these': 30,\n",
       "                               'quarters': 4,\n",
       "                               'always': 49,\n",
       "                               'pushed': 7,\n",
       "                               'a': 1335,\n",
       "                               'distance': 7,\n",
       "                               'elders': 1,\n",
       "                               'Youth': 1,\n",
       "                               'obeyed': 2,\n",
       "                               'commanded': 2,\n",
       "                               'It': 144,\n",
       "                               'went': 82,\n",
       "                               'to': 1502,\n",
       "                               'on': 362,\n",
       "                               'Sunday': 5,\n",
       "                               'Saturday': 4,\n",
       "                               'month': 6,\n",
       "                               'confession': 2,\n",
       "                               'asked': 45,\n",
       "                               'nothing': 47,\n",
       "                               'parents': 6,\n",
       "                               'touch': 7,\n",
       "                               'hand': 35,\n",
       "                               'kiss': 3,\n",
       "                               'given': 18,\n",
       "                               'passing': 5,\n",
       "                               'only': 106,\n",
       "                               'thing': 52,\n",
       "                               'about': 164,\n",
       "                               'long': 65,\n",
       "                               'since': 19,\n",
       "                               'happened': 19,\n",
       "                               'past': 15,\n",
       "                               'dead': 15,\n",
       "                               'present': 9,\n",
       "                               'Once': 9,\n",
       "                               'wife': 21,\n",
       "                               'And': 129,\n",
       "                               'once': 38,\n",
       "                               'she': 496,\n",
       "                               'too': 92,\n",
       "                               'ignored': 2,\n",
       "                               'With': 13,\n",
       "                               'tiny': 12,\n",
       "                               'fur-piece': 1,\n",
       "                               'around': 68,\n",
       "                               'her': 651,\n",
       "                               'shoulders': 7,\n",
       "                               'wiggled': 1,\n",
       "                               'satin-covered': 1,\n",
       "                               'buttocks': 1,\n",
       "                               'down': 127,\n",
       "                               \"didn't\": 101,\n",
       "                               'stop': 16,\n",
       "                               'In': 55,\n",
       "                               'clutched': 1,\n",
       "                               'hundred': 4,\n",
       "                               'dollar': 3,\n",
       "                               'bill': 3,\n",
       "                               'other': 70,\n",
       "                               'straw': 1,\n",
       "                               'suitcase': 4,\n",
       "                               'way': 83,\n",
       "                               'strutted': 1,\n",
       "                               'blind': 2,\n",
       "                               'noticed': 3,\n",
       "                               'Without': 2,\n",
       "                               'looking': 36,\n",
       "                               'without': 30,\n",
       "                               'anything': 42,\n",
       "                               'except': 10,\n",
       "                               'Drexel': 3,\n",
       "                               'Street': 5,\n",
       "                               'directly': 2,\n",
       "                               'front': 17,\n",
       "                               'climbed': 7,\n",
       "                               'those': 53,\n",
       "                               'orange': 6,\n",
       "                               'streetcars': 1,\n",
       "                               'rode': 4,\n",
       "                               'away': 64,\n",
       "                               'it': 573,\n",
       "                               'came': 75,\n",
       "                               'back': 126,\n",
       "                               '``': 1045,\n",
       "                               \"shouldn't\": 10,\n",
       "                               'come': 73,\n",
       "                               'first': 52,\n",
       "                               'place': 45,\n",
       "                               \"''\": 1044,\n",
       "                               'women': 22,\n",
       "                               'said': 330,\n",
       "                               'No': 40,\n",
       "                               'no': 123,\n",
       "                               'Not': 23,\n",
       "                               'She': 232,\n",
       "                               'thought': 105,\n",
       "                               'bigger': 1,\n",
       "                               'than': 65,\n",
       "                               'we': 78,\n",
       "                               'are': 72,\n",
       "                               'Torino': 2,\n",
       "                               'Eh': 2,\n",
       "                               '!': 316,\n",
       "                               'gave': 32,\n",
       "                               'herself': 40,\n",
       "                               'fancy': 1,\n",
       "                               'airs': 1,\n",
       "                               'Just': 28,\n",
       "                               'part': 18,\n",
       "                               'stage': 2,\n",
       "                               'carry': 9,\n",
       "                               'head': 46,\n",
       "                               'higher': 3,\n",
       "                               'ours': 1,\n",
       "                               'slapped': 2,\n",
       "                               'thighs': 2,\n",
       "                               \"It's\": 28,\n",
       "                               'for': 410,\n",
       "                               'making': 17,\n",
       "                               'pretty': 19,\n",
       "                               'speeches': 1,\n",
       "                               'Dante': 1,\n",
       "                               'actresses': 1,\n",
       "                               'get': 92,\n",
       "                               'paid': 9,\n",
       "                               'so': 174,\n",
       "                               'good': 65,\n",
       "                               'Henh': 1,\n",
       "                               'Calloused': 1,\n",
       "                               'fingers': 13,\n",
       "                               'caressed': 2,\n",
       "                               'smoothness': 2,\n",
       "                               'polished': 1,\n",
       "                               'rosaries': 2,\n",
       "                               'swayed': 4,\n",
       "                               'excitedly': 1,\n",
       "                               'beneath': 6,\n",
       "                               'puckered': 1,\n",
       "                               'chins': 1,\n",
       "                               'where': 54,\n",
       "                               'hairs': 1,\n",
       "                               'sprouted': 1,\n",
       "                               'be': 289,\n",
       "                               'tweezed': 1,\n",
       "                               'Mauve-colored': 1,\n",
       "                               'mouths': 1,\n",
       "                               'known': 10,\n",
       "                               'sweeter': 2,\n",
       "                               'taste': 9,\n",
       "                               'new': 31,\n",
       "                               'wine': 5,\n",
       "                               'passion': 5,\n",
       "                               \"man's\": 9,\n",
       "                               'tongue': 11,\n",
       "                               'smiled': 23,\n",
       "                               'condemned': 2,\n",
       "                               'again': 53,\n",
       "                               'Puttana': 1,\n",
       "                               'even': 73,\n",
       "                               'his': 559,\n",
       "                               'now': 83,\n",
       "                               'nobody': 11,\n",
       "                               'cared': 5,\n",
       "                               'fig': 2,\n",
       "                               'enough': 40,\n",
       "                               'people': 48,\n",
       "                               'know': 88,\n",
       "                               'time': 93,\n",
       "                               'looked': 72,\n",
       "                               'fleshy': 1,\n",
       "                               'suppleness': 1,\n",
       "                               'woman': 34,\n",
       "                               'consumed': 2,\n",
       "                               'watching': 20,\n",
       "                               'become': 6,\n",
       "                               'thinner': 3,\n",
       "                               'thin': 11,\n",
       "                               'seams': 1,\n",
       "                               'stockings': 3,\n",
       "                               'still': 62,\n",
       "                               'His': 44,\n",
       "                               'voice': 33,\n",
       "                               'questioned': 2,\n",
       "                               'why': 34,\n",
       "                               'seen': 20,\n",
       "                               'wave': 2,\n",
       "                               'an': 152,\n",
       "                               'exhausted': 2,\n",
       "                               'farewell': 2,\n",
       "                               'might': 51,\n",
       "                               'shooing': 1,\n",
       "                               'fleas': 1,\n",
       "                               'hopped': 1,\n",
       "                               'yellow': 13,\n",
       "                               'dog': 8,\n",
       "                               'onto': 6,\n",
       "                               '(': 21,\n",
       "                               'He': 366,\n",
       "                               ')': 21,\n",
       "                               'eyes': 76,\n",
       "                               'miniature': 3,\n",
       "                               'sundials': 1,\n",
       "                               'variegated': 1,\n",
       "                               'altered': 2,\n",
       "                               'expression': 1,\n",
       "                               'direction': 6,\n",
       "                               \"Man's\": 2,\n",
       "                               'very': 50,\n",
       "                               'soul': 6,\n",
       "                               'left': 49,\n",
       "                               'flown': 1,\n",
       "                               \"wouldn't\": 33,\n",
       "                               'anyone': 11,\n",
       "                               'Perhaps': 9,\n",
       "                               'then': 101,\n",
       "                               'taking': 19,\n",
       "                               'withered': 1,\n",
       "                               'wrinkled': 3,\n",
       "                               'sister': 7,\n",
       "                               'Rose': 4,\n",
       "                               'care': 19,\n",
       "                               'children': 20,\n",
       "                               'guessed': 6,\n",
       "                               'all': 209,\n",
       "                               'remember': 14,\n",
       "                               'memory': 6,\n",
       "                               'climbing': 2,\n",
       "                               'streetcar': 1,\n",
       "                               '?': 690,\n",
       "                               'There': 66,\n",
       "                               'seemed': 51,\n",
       "                               'contemptuous': 1,\n",
       "                               'purpose': 1,\n",
       "                               'sat': 32,\n",
       "                               'with': 460,\n",
       "                               'glued': 2,\n",
       "                               'opposition': 1,\n",
       "                               'behind': 15,\n",
       "                               'For': 31,\n",
       "                               'saw': 47,\n",
       "                               'see': 74,\n",
       "                               'town': 15,\n",
       "                               'Italy': 7,\n",
       "                               'outskirts': 1,\n",
       "                               'Philadelphia': 1,\n",
       "                               'Bari': 1,\n",
       "                               'Chieti': 1,\n",
       "                               'smelled': 8,\n",
       "                               'What': 50,\n",
       "                               'did': 115,\n",
       "                               'matter': 18,\n",
       "                               'park': 5,\n",
       "                               'foot': 7,\n",
       "                               'Ash': 1,\n",
       "                               'Road': 1,\n",
       "                               'stretched': 2,\n",
       "                               'elevated': 1,\n",
       "                               'trains': 1,\n",
       "                               'roared': 2,\n",
       "                               'stucco': 2,\n",
       "                               'station': 3,\n",
       "                               \"city's\": 1,\n",
       "                               'center': 7,\n",
       "                               'half-hour': 1,\n",
       "                               'intervals': 3,\n",
       "                               'creek': 1,\n",
       "                               'spun': 4,\n",
       "                               'silent': 11,\n",
       "                               'course': 36,\n",
       "                               'toward': 22,\n",
       "                               'Schuylkill': 1,\n",
       "                               'This': 38,\n",
       "                               'hatred': 4,\n",
       "                               'companion': 3,\n",
       "                               'aloneness': 1,\n",
       "                               'same': 30,\n",
       "                               'Sameness': 2,\n",
       "                               'framed': 1,\n",
       "                               'wall': 8,\n",
       "                               'ginkgo': 1,\n",
       "                               'trees': 7,\n",
       "                               'divided': 3,\n",
       "                               'city': 10,\n",
       "                               'lined': 1,\n",
       "                               'two-story': 1,\n",
       "                               'houses': 6,\n",
       "                               'color': 13,\n",
       "                               'ash': 3,\n",
       "                               'slashed': 1,\n",
       "                               'sloping': 2,\n",
       "                               'manure-scented': 1,\n",
       "                               'lawns': 1,\n",
       "                               'concrete': 3,\n",
       "                               'steps': 11,\n",
       "                               'upward': 2,\n",
       "                               'white': 30,\n",
       "                               'wooden': 3,\n",
       "                               'porches': 2,\n",
       "                               'wicker': 1,\n",
       "                               'swings': 1,\n",
       "                               'screeched': 2,\n",
       "                               'rusted': 1,\n",
       "                               'hinges': 1,\n",
       "                               'doors': 3,\n",
       "                               'Even': 13,\n",
       "                               'stable-garage': 1,\n",
       "                               'housed': 2,\n",
       "                               'scent': 2,\n",
       "                               'rot': 1,\n",
       "                               'lawn': 2,\n",
       "                               'coffee': 19,\n",
       "                               'shop': 8,\n",
       "                               'men': 29,\n",
       "                               'spent': 9,\n",
       "                               'evenings': 1,\n",
       "                               'Sundays': 1,\n",
       "                               'playing': 5,\n",
       "                               'cards': 5,\n",
       "                               'rose': 9,\n",
       "                               'hedge': 2,\n",
       "                               'window': 9,\n",
       "                               'reeked': 1,\n",
       "                               'dregs': 1,\n",
       "                               'thrown': 3,\n",
       "                               'Only': 8,\n",
       "                               'house': 36,\n",
       "                               'squatted': 1,\n",
       "                               'low': 10,\n",
       "                               'square': 4,\n",
       "                               'upon': 16,\n",
       "                               'sidewalk': 1,\n",
       "                               'heavy': 13,\n",
       "                               'iron': 3,\n",
       "                               'grating': 1,\n",
       "                               'supporting': 2,\n",
       "                               'glass': 7,\n",
       "                               'facade': 2,\n",
       "                               'That': 29,\n",
       "                               \"Bartoli's\": 1,\n",
       "                               'Above': 3,\n",
       "                               'second-story': 1,\n",
       "                               'showroom': 1,\n",
       "                               'angels': 1,\n",
       "                               'surveyed': 1,\n",
       "                               'neighborhood': 5,\n",
       "                               'Did': 12,\n",
       "                               'everywhere': 2,\n",
       "                               'else': 29,\n",
       "                               'sameness': 1,\n",
       "                               'wood': 5,\n",
       "                               'blocks': 2,\n",
       "                               'like': 185,\n",
       "                               'fortresses': 2,\n",
       "                               'perched': 1,\n",
       "                               'slant': 1,\n",
       "                               'hill': 4,\n",
       "                               'top': 8,\n",
       "                               'beyond': 9,\n",
       "                               'cemetery': 6,\n",
       "                               'paved': 1,\n",
       "                               'alleyways': 1,\n",
       "                               'tunneled': 1,\n",
       "                               'through': 56,\n",
       "                               'walls': 10,\n",
       "                               'mysterious': 3,\n",
       "                               'core': 1,\n",
       "                               'intimacy': 1,\n",
       "                               'backyards': 1,\n",
       "                               'owned': 5,\n",
       "                               'fences': 1,\n",
       "                               'property': 2,\n",
       "                               'blended': 1,\n",
       "                               'next': 43,\n",
       "                               'form': 3,\n",
       "                               'courtyards': 1,\n",
       "                               'knew': 69,\n",
       "                               'privacy': 2,\n",
       "                               'Love': 4,\n",
       "                               'fear': 4,\n",
       "                               'shaded': 2,\n",
       "                               'grape': 2,\n",
       "                               'vines': 1,\n",
       "                               'forked': 3,\n",
       "                               'gossip': 3,\n",
       "                               'licked': 2,\n",
       "                               'sinister': 2,\n",
       "                               'porch': 7,\n",
       "                               'silently': 3,\n",
       "                               'fed': 3,\n",
       "                               'kept': 26,\n",
       "                               'alive': 10,\n",
       "                               'waiting': 15,\n",
       "                               'Waiting': 1,\n",
       "                               'whom': 5,\n",
       "                               'tell': 37,\n",
       "                               'though': 29,\n",
       "                               'made': 62,\n",
       "                               'pact': 1,\n",
       "                               'devil': 3,\n",
       "                               'himself': 53,\n",
       "                               'yet': 21,\n",
       "                               'pay': 8,\n",
       "                               'price': 5,\n",
       "                               'holding': 7,\n",
       "                               'out': 217,\n",
       "                               'something': 59,\n",
       "                               'determined': 3,\n",
       "                               'hold': 12,\n",
       "                               'son': 33,\n",
       "                               'threw': 9,\n",
       "                               'belly': 3,\n",
       "                               'step': 5,\n",
       "                               'coolness': 4,\n",
       "                               'dreaming': 3,\n",
       "                               'day': 63,\n",
       "                               'rich': 6,\n",
       "                               'At': 29,\n",
       "                               'fifteen': 8,\n",
       "                               'mother': 44,\n",
       "                               \"couldn't\": 46,\n",
       "                               'face': 44,\n",
       "                               'Aunt': 2,\n",
       "                               'provided': 2,\n",
       "                               'named': 7,\n",
       "                               'Pompeii': 5,\n",
       "                               'tribute': 2,\n",
       "                               'heritage': 1,\n",
       "                               'less': 12,\n",
       "                               'either': 9,\n",
       "                               'life': 51,\n",
       "                               'restless': 2,\n",
       "                               'began': 23,\n",
       "                               'sun': 23,\n",
       "                               'ended': 1,\n",
       "                               'sleep': 10,\n",
       "                               'When': 37,\n",
       "                               'man': 87,\n",
       "                               'Americans': 2,\n",
       "                               'who': 89,\n",
       "                               'lived': 19,\n",
       "                               'white-columned': 1,\n",
       "                               'side': 17,\n",
       "                               'ride': 5,\n",
       "                               'eight-thirty': 1,\n",
       "                               'local': 1,\n",
       "                               'morning': 40,\n",
       "                               'brief': 4,\n",
       "                               'case': 10,\n",
       "                               'Nor': 3,\n",
       "                               'work': 32,\n",
       "                               'cane': 4,\n",
       "                               'sit': 6,\n",
       "                               'inside': 11,\n",
       "                               'pound': 1,\n",
       "                               'gloved': 1,\n",
       "                               'fist': 3,\n",
       "                               'table': 19,\n",
       "                               'girl': 26,\n",
       "                               'hear': 16,\n",
       "                               'running': 11,\n",
       "                               'bowing': 3,\n",
       "                               'calling': 5,\n",
       "                               'your': 106,\n",
       "                               'service': 6,\n",
       "                               'order': 8,\n",
       "                               'bring': 9,\n",
       "                               'take': 62,\n",
       "                               'vest': 1,\n",
       "                               'pocket': 6,\n",
       "                               'pipe': 6,\n",
       "                               'stuff': 5,\n",
       "                               'remove': 4,\n",
       "                               'gloves': 1,\n",
       "                               'light': 24,\n",
       "                               'smoke': 7,\n",
       "                               'do': 109,\n",
       "                               'Hey': 4,\n",
       "                               'Laura': 5,\n",
       "                               'ten': 11,\n",
       "                               'months': 11,\n",
       "                               'older': 7,\n",
       "                               'you': 456,\n",
       "                               'say': 60,\n",
       "                               'I': 951,\n",
       "                               'smoked': 3,\n",
       "                               'answer': 11,\n",
       "                               'leaned': 10,\n",
       "                               'unconcerned': 1,\n",
       "                               'fence': 3,\n",
       "                               'brushing': 2,\n",
       "                               'drying': 2,\n",
       "                               'wet': 10,\n",
       "                               'gilded': 1,\n",
       "                               'hair': 30,\n",
       "                               'One': 16,\n",
       "                               'lithe': 1,\n",
       "                               'leg': 7,\n",
       "                               'straddled': 1,\n",
       "                               'railing': 1,\n",
       "                               'swung': 4,\n",
       "                               'loosely': 1,\n",
       "                               'creaking': 1,\n",
       "                               'torn': 3,\n",
       "                               'pales': 1,\n",
       "                               'Her': 29,\n",
       "                               'tanned': 2,\n",
       "                               'whose': 9,\n",
       "                               'arch': 2,\n",
       "                               'swept': 2,\n",
       "                               'high': 20,\n",
       "                               'pointed': 7,\n",
       "                               'artfully': 1,\n",
       "                               'tapering': 1,\n",
       "                               'toes': 5,\n",
       "                               'tips': 1,\n",
       "                               'glowed': 1,\n",
       "                               'All': 33,\n",
       "                               'while': 48,\n",
       "                               'sinewy': 1,\n",
       "                               'arms': 13,\n",
       "                               'swirled': 1,\n",
       "                               'chest': 6,\n",
       "                               'showed': 7,\n",
       "                               'sign': 6,\n",
       "                               'having': 24,\n",
       "                               'heard': 31,\n",
       "                               'lost': 13,\n",
       "                               'childlike': 1,\n",
       "                               'softness': 1,\n",
       "                               'beginning': 9,\n",
       "                               'fold': 3,\n",
       "                               'within': 11,\n",
       "                               'fragile': 1,\n",
       "                               'features': 2,\n",
       "                               'harshness': 1,\n",
       "                               'belied': 1,\n",
       "                               'lyric': 1,\n",
       "                               'lines': 7,\n",
       "                               'contours': 1,\n",
       "                               'blue': 19,\n",
       "                               'somewhat': 7,\n",
       "                               'downcast': 1,\n",
       "                               'possessed': 1,\n",
       "                               'sullen': 3,\n",
       "                               'quality': 3,\n",
       "                               'boy': 38,\n",
       "                               'clouded': 1,\n",
       "                               'sure': 30,\n",
       "                               'fully': 3,\n",
       "                               'took': 48,\n",
       "                               'reached': 6,\n",
       "                               'screeching': 1,\n",
       "                               'rail': 1,\n",
       "                               'moving': 6,\n",
       "                               \"She's\": 10,\n",
       "                               'mood': 5,\n",
       "                               \"There's\": 8,\n",
       "                               \"doesn't\": 12,\n",
       "                               'Well': 34,\n",
       "                               'shining': 7,\n",
       "                               'dreams': 2,\n",
       "                               'dream': 8,\n",
       "                               'wanted': 44,\n",
       "                               'Suddenly': 6,\n",
       "                               'interrupted': 4,\n",
       "                               'daydreaming': 1,\n",
       "                               'warm': 10,\n",
       "                               'wetness': 1,\n",
       "                               'lapping': 2,\n",
       "                               'chin': 3,\n",
       "                               'opened': 13,\n",
       "                               'wide': 10,\n",
       "                               'sight': 6,\n",
       "                               \"goat's\": 2,\n",
       "                               'claret': 1,\n",
       "                               'feasting': 1,\n",
       "                               'salt': 1,\n",
       "                               'aged': 3,\n",
       "                               'eye': 11,\n",
       "                               'sallow': 1,\n",
       "                               'time-cast': 1,\n",
       "                               'encrusted': 1,\n",
       "                               'sphere': 2,\n",
       "                               'marbleized': 1,\n",
       "                               'pink': 17,\n",
       "                               'skin': 6,\n",
       "                               'stared': 14,\n",
       "                               'unfalteringly': 1,\n",
       "                               'Christ': 2,\n",
       "                               'sake': 6,\n",
       "                               'goat': 3,\n",
       "                               'git': 1,\n",
       "                               \"You're\": 16,\n",
       "                               'boiling': 3,\n",
       "                               'milk': 5,\n",
       "                               \"ain't\": 4,\n",
       "                               'Soothing': 1,\n",
       "                               'knowing': 11,\n",
       "                               'whiskered': 1,\n",
       "                               'jowls': 2,\n",
       "                               'swollen': 2,\n",
       "                               'teats': 2,\n",
       "                               'expectantly': 1,\n",
       "                               'rolled': 6,\n",
       "                               'over': 88,\n",
       "                               'undulated': 1,\n",
       "                               'gradually': 1,\n",
       "                               'covering': 1,\n",
       "                               'space': 7,\n",
       "                               'straining': 2,\n",
       "                               'taut': 3,\n",
       "                               'warmth': 3,\n",
       "                               'mouth': 11,\n",
       "                               'squirted': 1,\n",
       "                               'roof': 3,\n",
       "                               'savored': 1,\n",
       "                               'earthy': 1,\n",
       "                               \"boy's\": 4,\n",
       "                               'operated': 1,\n",
       "                               'skilled': 1,\n",
       "                               'unity': 1,\n",
       "                               'bagpipe': 1,\n",
       "                               'player': 3,\n",
       "                               'pressing': 1,\n",
       "                               'pulling': 1,\n",
       "                               'delighting': 1,\n",
       "                               'slid': 6,\n",
       "                               'evasive': 1,\n",
       "                               'shadow': 3,\n",
       "                               'storm': 2,\n",
       "                               'cloud': 1,\n",
       "                               'Its': 1,\n",
       "                               'figure': 7,\n",
       "                               'fluttering': 1,\n",
       "                               'soutane': 1,\n",
       "                               'near': 9,\n",
       "                               'corner': 9,\n",
       "                               'let': 39,\n",
       "                               'pass': 3,\n",
       "                               'sensing': 1,\n",
       "                               'portentous': 1,\n",
       "                               'also': 15,\n",
       "                               'raise': 3,\n",
       "                               'finger': 2,\n",
       "                               'smooth': 5,\n",
       "                               \"dog's\": 1,\n",
       "                               'perhaps': 15,\n",
       "                               'reassured': 2,\n",
       "                               'due': 4,\n",
       "                               'Time': 1,\n",
       "                               'give': 28,\n",
       "                               'meantime': 1,\n",
       "                               'sandals': 3,\n",
       "                               'stained': 1,\n",
       "                               'ocher': 1,\n",
       "                               \"Pompeii's\": 1,\n",
       "                               'shaved': 4,\n",
       "                               'edged': 1,\n",
       "                               'close': 16,\n",
       "                               'clapping': 1,\n",
       "                               'ecstatic': 1,\n",
       "                               'pleasure': 7,\n",
       "                               'quickly': 8,\n",
       "                               'released': 1,\n",
       "                               'pretended': 2,\n",
       "                               'examining': 3,\n",
       "                               'haunches': 1,\n",
       "                               'ticks': 1,\n",
       "                               'glance': 6,\n",
       "                               'biggest': 1,\n",
       "                               'belonged': 3,\n",
       "                               'Niobe': 1,\n",
       "                               'neatest': 1,\n",
       "                               'ones': 10,\n",
       "                               'Concetta': 1,\n",
       "                               'laced': 1,\n",
       "                               'Romeo': 1,\n",
       "                               \"Concetta's\": 2,\n",
       "                               'idiot': 1,\n",
       "                               'brother': 5,\n",
       "                               'expected': 6,\n",
       "                               \"Romeo's\": 1,\n",
       "                               'small': 31,\n",
       "                               'body': 19,\n",
       "                               'sink': 3,\n",
       "                               'closer': 6,\n",
       "                               'ground': 8,\n",
       "                               'reach': 5,\n",
       "                               'grasp': 1,\n",
       "                               'shrill': 3,\n",
       "                               'impetuous': 1,\n",
       "                               'sound': 23,\n",
       "                               'rotundity': 1,\n",
       "                               'disfigured': 2,\n",
       "                               'flesh': 7,\n",
       "                               'hearing': 9,\n",
       "                               'People': 2,\n",
       "                               'baby': 25,\n",
       "                               'room': 45,\n",
       "                               'filled': 5,\n",
       "                               \"Maggie's\": 3,\n",
       "                               'throbbed': 1,\n",
       "                               'excitement': 5,\n",
       "                               'fatigue': 1,\n",
       "                               'Stuart': 6,\n",
       "                               'such': 21,\n",
       "                               'happy': 8,\n",
       "                               'earnest': 1,\n",
       "                               'look': 54,\n",
       "                               'proud': 5,\n",
       "                               'possession': 2,\n",
       "                               'Maggie': 22,\n",
       "                               'bear': 4,\n",
       "                               'quench': 1,\n",
       "                               'Little': 5,\n",
       "                               'Anne': 23,\n",
       "                               'rapidly': 2,\n",
       "                               'outdistanced': 1,\n",
       "                               'recovery': 1,\n",
       "                               'two': 48,\n",
       "                               'became': 7,\n",
       "                               'fat': 5,\n",
       "                               'highly': 1,\n",
       "                               'social': 6,\n",
       "                               'fuzz': 1,\n",
       "                               'flaxen': 1,\n",
       "                               'stopped': 25,\n",
       "                               'flying': 4,\n",
       "                               'rages': 1,\n",
       "                               'started': 22,\n",
       "                               'digesting': 1,\n",
       "                               'food': 9,\n",
       "                               'developed': 5,\n",
       "                               'peaches': 1,\n",
       "                               'cream': 1,\n",
       "                               'complexion': 3,\n",
       "                               'sunny': 3,\n",
       "                               'disposition': 1,\n",
       "                               'more': 85,\n",
       "                               'dry': 4,\n",
       "                               'comfortable': 7,\n",
       "                               'huge': 2,\n",
       "                               'amounts': 1,\n",
       "                               'stated': 1,\n",
       "                               'carried': 7,\n",
       "                               'watch': 11,\n",
       "                               'activity': 3,\n",
       "                               'going': 60,\n",
       "                               'shook': 8,\n",
       "                               'lifting': 1,\n",
       "                               'seem': 10,\n",
       "                               'strength': 8,\n",
       "                               'catch': 3,\n",
       "                               ':': 56,\n",
       "                               'big': 36,\n",
       "                               'basket': 2,\n",
       "                               'clothes': 26,\n",
       "                               'coaxed': 1,\n",
       "                               'rackety': 1,\n",
       "                               'washer': 1,\n",
       "                               'lugged': 3,\n",
       "                               'daily': 1,\n",
       "                               'round': 7,\n",
       "                               'household': 2,\n",
       "                               'chores': 1,\n",
       "                               'insisted': 6,\n",
       "                               'participating': 1,\n",
       "                               'Worry': 1,\n",
       "                               'great': 30,\n",
       "                               'deal': 4,\n",
       "                               'laid': 5,\n",
       "                               'off': 56,\n",
       "                               'produce': 1,\n",
       "                               'company': 13,\n",
       "                               'go': 76,\n",
       "                               'sitting': 19,\n",
       "                               \"father's\": 5,\n",
       "                               'office': 13,\n",
       "                               'salary': 1,\n",
       "                               'father': 23,\n",
       "                               'Mr.': 33,\n",
       "                               'Clifton': 1,\n",
       "                               'preferred': 1,\n",
       "                               'death': 12,\n",
       "                               'bankruptcy': 1,\n",
       "                               'stay': 22,\n",
       "                               \"wife's\": 2,\n",
       "                               'contributing': 2,\n",
       "                               \"family's\": 1,\n",
       "                               'upkeep': 2,\n",
       "                               'besides': 3,\n",
       "                               'things': 30,\n",
       "                               'bought': 5,\n",
       "                               'juice': 4,\n",
       "                               'vitamins': 1,\n",
       "                               'soap': 2,\n",
       "                               'plain': 5,\n",
       "                               'pored': 1,\n",
       "                               'figures': 7,\n",
       "                               'every': 23,\n",
       "                               'trying': 23,\n",
       "                               'find': 34,\n",
       "                               'how': 60,\n",
       "                               'squeeze': 1,\n",
       "                               'few': 37,\n",
       "                               'pennies': 1,\n",
       "                               'desperation': 2,\n",
       "                               'consulted': 1,\n",
       "                               'Eugenia': 15,\n",
       "                               'afternoon': 12,\n",
       "                               'Do': 12,\n",
       "                               'think': 56,\n",
       "                               'me': 193,\n",
       "                               'home': 46,\n",
       "                               'make': 49,\n",
       "                               'some': 69,\n",
       "                               'money': 24,\n",
       "                               'rest': 17,\n",
       "                               'seems': 2,\n",
       "                               'is': 150,\n",
       "                               'washing': 4,\n",
       "                               'machine': 3,\n",
       "                               'stove': 5,\n",
       "                               'plenty': 8,\n",
       "                               'odd': 4,\n",
       "                               'moments': 9,\n",
       "                               'doing': 20,\n",
       "                               'feel': 36,\n",
       "                               'lot': 17,\n",
       "                               'better': 32,\n",
       "                               \"Woman's\": 1,\n",
       "                               'Exchange': 1,\n",
       "                               \"isn't\": 20,\n",
       "                               'baked': 2,\n",
       "                               'goods': 1,\n",
       "                               'any': 67,\n",
       "                               \"can't\": 24,\n",
       "                               'leave': 24,\n",
       "                               'Grandma': 10,\n",
       "                               'strong': 9,\n",
       "                               \"baby's\": 4,\n",
       "                               'young': 49,\n",
       "                               'put': 49,\n",
       "                               'nursery': 2,\n",
       "                               'should': 32,\n",
       "                               'can': 74,\n",
       "                               'keeping': 6,\n",
       "                               'child': 17,\n",
       "                               'starched': 1,\n",
       "                               'dresses': 3,\n",
       "                               'changed': 9,\n",
       "                               'nineteen': 1,\n",
       "                               'times': 14,\n",
       "                               'beautiful': 25,\n",
       "                               'keep': 26,\n",
       "                               'nice': 18,\n",
       "                               'picked': 16,\n",
       "                               'nuzzled': 1,\n",
       "                               'little': 99,\n",
       "                               'neck': 12,\n",
       "                               \"She'll\": 4,\n",
       "                               'ironed': 1,\n",
       "                               'Evadna': 3,\n",
       "                               'Mae': 3,\n",
       "                               'Evans': 8,\n",
       "                               'flannel': 2,\n",
       "                               'wrapper': 1,\n",
       "                               'until': 34,\n",
       "                               'nine': 4,\n",
       "                               'got': 89,\n",
       "                               \"Best's\": 1,\n",
       "                               'Liliputian': 1,\n",
       "                               'Bazaar': 1,\n",
       "                               'New': 15,\n",
       "                               'York': 13,\n",
       "                               ...}),\n",
       "                     'science_fiction': FreqDist({'Now': 8,\n",
       "                               'that': 126,\n",
       "                               'he': 139,\n",
       "                               'knew': 11,\n",
       "                               'himself': 17,\n",
       "                               'to': 305,\n",
       "                               'be': 80,\n",
       "                               'self': 3,\n",
       "                               'was': 198,\n",
       "                               'free': 3,\n",
       "                               'grok': 5,\n",
       "                               'ever': 10,\n",
       "                               'closer': 6,\n",
       "                               'his': 93,\n",
       "                               'brothers': 4,\n",
       "                               ',': 791,\n",
       "                               'merge': 2,\n",
       "                               'without': 13,\n",
       "                               'let': 4,\n",
       "                               '.': 786,\n",
       "                               \"Self's\": 1,\n",
       "                               'integrity': 1,\n",
       "                               'and': 278,\n",
       "                               'is': 47,\n",
       "                               'had': 141,\n",
       "                               'been': 40,\n",
       "                               'Mike': 20,\n",
       "                               'stopped': 3,\n",
       "                               'cherish': 2,\n",
       "                               'all': 59,\n",
       "                               'brother': 6,\n",
       "                               'selves': 1,\n",
       "                               'the': 652,\n",
       "                               'many': 10,\n",
       "                               'threes-fulfilled': 1,\n",
       "                               'on': 85,\n",
       "                               'Mars': 9,\n",
       "                               'corporate': 1,\n",
       "                               'discorporate': 2,\n",
       "                               'precious': 1,\n",
       "                               'few': 12,\n",
       "                               'Earth': 15,\n",
       "                               '--': 52,\n",
       "                               'unknown': 1,\n",
       "                               'powers': 2,\n",
       "                               'of': 321,\n",
       "                               'three': 6,\n",
       "                               'would': 79,\n",
       "                               'with': 69,\n",
       "                               'now': 19,\n",
       "                               'at': 51,\n",
       "                               'last': 9,\n",
       "                               'long': 25,\n",
       "                               'waiting': 2,\n",
       "                               'grokked': 4,\n",
       "                               'cherished': 3,\n",
       "                               'remained': 2,\n",
       "                               'in': 152,\n",
       "                               'trance': 2,\n",
       "                               ';': 88,\n",
       "                               'there': 29,\n",
       "                               'much': 14,\n",
       "                               'loose': 1,\n",
       "                               'ends': 1,\n",
       "                               'puzzle': 1,\n",
       "                               'over': 15,\n",
       "                               'fit': 1,\n",
       "                               'into': 22,\n",
       "                               'growing': 6,\n",
       "                               'seen': 4,\n",
       "                               'heard': 4,\n",
       "                               'Archangel': 3,\n",
       "                               'Foster': 4,\n",
       "                               'Tabernacle': 1,\n",
       "                               '(': 8,\n",
       "                               'not': 94,\n",
       "                               'just': 13,\n",
       "                               'cusp': 2,\n",
       "                               'when': 21,\n",
       "                               'Digby': 7,\n",
       "                               'come': 6,\n",
       "                               'face': 8,\n",
       "                               'alone': 3,\n",
       "                               ')': 8,\n",
       "                               'why': 4,\n",
       "                               'Bishop': 4,\n",
       "                               'Senator': 1,\n",
       "                               'Boone': 2,\n",
       "                               'made': 15,\n",
       "                               'him': 58,\n",
       "                               'warily': 1,\n",
       "                               'uneasy': 1,\n",
       "                               'how': 12,\n",
       "                               'Miss': 1,\n",
       "                               'Dawn': 1,\n",
       "                               'Ardent': 1,\n",
       "                               'tasted': 1,\n",
       "                               'like': 25,\n",
       "                               'a': 222,\n",
       "                               'water': 7,\n",
       "                               'she': 36,\n",
       "                               'smell': 1,\n",
       "                               'goodness': 3,\n",
       "                               'incompletely': 1,\n",
       "                               'jumping': 2,\n",
       "                               'up': 33,\n",
       "                               'down': 11,\n",
       "                               'wailing': 1,\n",
       "                               \"Jubal's\": 3,\n",
       "                               'conversations': 1,\n",
       "                               'coming': 1,\n",
       "                               'going': 13,\n",
       "                               'words': 8,\n",
       "                               'troubled': 1,\n",
       "                               'most': 10,\n",
       "                               'studied': 1,\n",
       "                               'them': 47,\n",
       "                               'compared': 2,\n",
       "                               'what': 27,\n",
       "                               'taught': 5,\n",
       "                               'as': 64,\n",
       "                               'nestling': 1,\n",
       "                               'struggling': 1,\n",
       "                               'bridge': 1,\n",
       "                               'between': 10,\n",
       "                               'languages': 2,\n",
       "                               'one': 36,\n",
       "                               'thought': 11,\n",
       "                               'learning': 2,\n",
       "                               'think': 8,\n",
       "                               'The': 71,\n",
       "                               'word': 6,\n",
       "                               '``': 235,\n",
       "                               'church': 3,\n",
       "                               \"''\": 235,\n",
       "                               'which': 32,\n",
       "                               'turned': 11,\n",
       "                               'again': 11,\n",
       "                               'among': 11,\n",
       "                               'gave': 3,\n",
       "                               'knotty': 1,\n",
       "                               'difficulty': 1,\n",
       "                               'no': 44,\n",
       "                               'Martian': 4,\n",
       "                               'concept': 6,\n",
       "                               'match': 2,\n",
       "                               'it': 129,\n",
       "                               'unless': 1,\n",
       "                               'took': 7,\n",
       "                               'worship': 1,\n",
       "                               'God': 5,\n",
       "                               'congregation': 1,\n",
       "                               'other': 22,\n",
       "                               'equated': 1,\n",
       "                               'totality': 1,\n",
       "                               'only': 19,\n",
       "                               'world': 5,\n",
       "                               'known': 6,\n",
       "                               'during': 5,\n",
       "                               'growing-waiting': 1,\n",
       "                               'then': 10,\n",
       "                               'forced': 5,\n",
       "                               'back': 19,\n",
       "                               'English': 4,\n",
       "                               'phrase': 2,\n",
       "                               'rejected': 1,\n",
       "                               'by': 36,\n",
       "                               'each': 12,\n",
       "                               'differently': 1,\n",
       "                               'Jubal': 9,\n",
       "                               'Mahmoud': 2,\n",
       "                               'Thou': 3,\n",
       "                               'art': 4,\n",
       "                               'He': 52,\n",
       "                               'understanding': 1,\n",
       "                               'although': 3,\n",
       "                               'could': 49,\n",
       "                               'never': 15,\n",
       "                               'have': 61,\n",
       "                               'inevitability': 1,\n",
       "                               'stood': 5,\n",
       "                               'for': 92,\n",
       "                               'In': 12,\n",
       "                               'mind': 15,\n",
       "                               'spoke': 9,\n",
       "                               'simultaneously': 2,\n",
       "                               'sentence': 1,\n",
       "                               'felt': 13,\n",
       "                               'grokking': 4,\n",
       "                               'Repeating': 1,\n",
       "                               'student': 1,\n",
       "                               'telling': 2,\n",
       "                               'jewel': 1,\n",
       "                               'lotus': 1,\n",
       "                               'sank': 1,\n",
       "                               'nirvana': 1,\n",
       "                               'Before': 1,\n",
       "                               'midnight': 3,\n",
       "                               'speeded': 1,\n",
       "                               'heart': 2,\n",
       "                               'resumed': 1,\n",
       "                               'normal': 5,\n",
       "                               'breathing': 3,\n",
       "                               'ran': 2,\n",
       "                               'check': 3,\n",
       "                               'list': 2,\n",
       "                               'uncurled': 1,\n",
       "                               'sat': 3,\n",
       "                               'weary': 1,\n",
       "                               'light': 13,\n",
       "                               'gay': 1,\n",
       "                               'clear-headed': 1,\n",
       "                               'ready': 4,\n",
       "                               'actions': 1,\n",
       "                               'saw': 8,\n",
       "                               'spreading': 1,\n",
       "                               'out': 35,\n",
       "                               'before': 12,\n",
       "                               'puppyish': 1,\n",
       "                               'need': 6,\n",
       "                               'company': 3,\n",
       "                               'strong': 4,\n",
       "                               'earlier': 1,\n",
       "                               'necessity': 2,\n",
       "                               'quiet': 2,\n",
       "                               'stepped': 2,\n",
       "                               'hall': 1,\n",
       "                               'delighted': 1,\n",
       "                               'encounter': 1,\n",
       "                               'Hi': 1,\n",
       "                               '!': 46,\n",
       "                               'Oh': 8,\n",
       "                               'Hello': 2,\n",
       "                               'My': 2,\n",
       "                               'you': 81,\n",
       "                               'look': 7,\n",
       "                               'chipper': 1,\n",
       "                               'I': 98,\n",
       "                               'feel': 4,\n",
       "                               'fine': 2,\n",
       "                               'Where': 5,\n",
       "                               'everybody': 2,\n",
       "                               '?': 158,\n",
       "                               'Asleep': 1,\n",
       "                               'Ben': 1,\n",
       "                               'Stinky': 1,\n",
       "                               'went': 10,\n",
       "                               'home': 3,\n",
       "                               'an': 33,\n",
       "                               'hour': 1,\n",
       "                               'ago': 6,\n",
       "                               'people': 20,\n",
       "                               'started': 3,\n",
       "                               'bed': 1,\n",
       "                               'disappointed': 1,\n",
       "                               'left': 5,\n",
       "                               'wanted': 3,\n",
       "                               'explain': 1,\n",
       "                               'new': 9,\n",
       "                               'ought': 1,\n",
       "                               'asleep': 2,\n",
       "                               'too': 14,\n",
       "                               'but': 55,\n",
       "                               'snack': 1,\n",
       "                               'Are': 3,\n",
       "                               'hungry': 2,\n",
       "                               'Sure': 1,\n",
       "                               \"I'm\": 12,\n",
       "                               'Come': 1,\n",
       "                               \"there's\": 6,\n",
       "                               'some': 16,\n",
       "                               'cold': 2,\n",
       "                               'chicken': 1,\n",
       "                               \"we'll\": 1,\n",
       "                               'see': 15,\n",
       "                               'else': 2,\n",
       "                               'They': 14,\n",
       "                               'downstairs': 1,\n",
       "                               'loaded': 1,\n",
       "                               'tray': 3,\n",
       "                               'lavishly': 1,\n",
       "                               \"Let's\": 1,\n",
       "                               'take': 11,\n",
       "                               'outside': 8,\n",
       "                               \"It's\": 3,\n",
       "                               'plenty': 2,\n",
       "                               'warm': 4,\n",
       "                               'A': 14,\n",
       "                               'idea': 2,\n",
       "                               'agreed': 5,\n",
       "                               'Warm': 1,\n",
       "                               'enough': 9,\n",
       "                               'swim': 1,\n",
       "                               'real': 5,\n",
       "                               'Indian': 1,\n",
       "                               'summer': 2,\n",
       "                               \"I'll\": 5,\n",
       "                               'switch': 4,\n",
       "                               'floods': 1,\n",
       "                               \"Don't\": 2,\n",
       "                               'bother': 2,\n",
       "                               'answered': 4,\n",
       "                               'carry': 3,\n",
       "                               'almost': 10,\n",
       "                               'total': 3,\n",
       "                               'darkness': 1,\n",
       "                               'said': 41,\n",
       "                               'night-sight': 1,\n",
       "                               'probably': 2,\n",
       "                               'came': 8,\n",
       "                               'from': 45,\n",
       "                               'conditions': 2,\n",
       "                               'grown': 3,\n",
       "                               'this': 49,\n",
       "                               'true': 2,\n",
       "                               'more': 21,\n",
       "                               'foster': 1,\n",
       "                               'parents': 1,\n",
       "                               'As': 8,\n",
       "                               'night': 10,\n",
       "                               'being': 11,\n",
       "                               'comfortable': 2,\n",
       "                               'naked': 3,\n",
       "                               'Mount': 1,\n",
       "                               'Everest': 1,\n",
       "                               'little': 13,\n",
       "                               'tolerance': 1,\n",
       "                               'changes': 1,\n",
       "                               'temperature': 1,\n",
       "                               'pressure': 3,\n",
       "                               'considerate': 1,\n",
       "                               'their': 40,\n",
       "                               'weakness': 1,\n",
       "                               'once': 5,\n",
       "                               'learned': 3,\n",
       "                               'But': 34,\n",
       "                               'looking': 1,\n",
       "                               'forward': 1,\n",
       "                               'snow': 2,\n",
       "                               'seeing': 2,\n",
       "                               'tiny': 3,\n",
       "                               'crystal': 1,\n",
       "                               'life': 5,\n",
       "                               'unique': 2,\n",
       "                               'individual': 1,\n",
       "                               'read': 6,\n",
       "                               'walking': 1,\n",
       "                               'barefoot': 1,\n",
       "                               'rolling': 1,\n",
       "                               'meantime': 2,\n",
       "                               'pleased': 3,\n",
       "                               'still': 11,\n",
       "                               'pleasing': 1,\n",
       "                               'Okay': 4,\n",
       "                               'underwater': 1,\n",
       "                               'lights': 1,\n",
       "                               \"That'll\": 1,\n",
       "                               'eat': 3,\n",
       "                               'Fine': 2,\n",
       "                               'liked': 1,\n",
       "                               'having': 3,\n",
       "                               'through': 15,\n",
       "                               'ripples': 1,\n",
       "                               'beauty': 1,\n",
       "                               'picnicked': 1,\n",
       "                               'pool': 1,\n",
       "                               'lay': 9,\n",
       "                               'grass': 2,\n",
       "                               'looked': 7,\n",
       "                               'stars': 4,\n",
       "                               'It': 29,\n",
       "                               \"isn't\": 6,\n",
       "                               'Or': 4,\n",
       "                               'Antares': 1,\n",
       "                               'What': 14,\n",
       "                               'are': 23,\n",
       "                               'they': 53,\n",
       "                               'doing': 4,\n",
       "                               'hesitated': 3,\n",
       "                               'question': 4,\n",
       "                               'wide': 2,\n",
       "                               'sparse': 1,\n",
       "                               'language': 3,\n",
       "                               'On': 5,\n",
       "                               'side': 6,\n",
       "                               'toward': 6,\n",
       "                               'horizon': 2,\n",
       "                               'southern': 3,\n",
       "                               'hemisphere': 4,\n",
       "                               'spring': 1,\n",
       "                               'plants': 4,\n",
       "                               'grow': 5,\n",
       "                               \"'\": 11,\n",
       "                               'Taught': 1,\n",
       "                               'Larry': 1,\n",
       "                               'teaches': 1,\n",
       "                               'helped': 2,\n",
       "                               'my': 30,\n",
       "                               'Martians': 3,\n",
       "                               'mean': 6,\n",
       "                               'teach': 2,\n",
       "                               'another': 5,\n",
       "                               'way': 13,\n",
       "                               'colder': 1,\n",
       "                               'nymphs': 1,\n",
       "                               'those': 7,\n",
       "                               'who': 13,\n",
       "                               'stayed': 4,\n",
       "                               'alive': 4,\n",
       "                               'brought': 2,\n",
       "                               'nests': 1,\n",
       "                               'quickening': 1,\n",
       "                               'Of': 8,\n",
       "                               'humans': 2,\n",
       "                               'we': 30,\n",
       "                               'equator': 1,\n",
       "                               'has': 9,\n",
       "                               'discorporated': 1,\n",
       "                               'others': 4,\n",
       "                               'sad': 3,\n",
       "                               'Yes': 7,\n",
       "                               'news': 2,\n",
       "                               'until': 7,\n",
       "                               'asked': 9,\n",
       "                               'should': 3,\n",
       "                               'Mr.': 1,\n",
       "                               'Booker': 1,\n",
       "                               'T.': 1,\n",
       "                               'W.': 1,\n",
       "                               'Jones': 1,\n",
       "                               'Food': 1,\n",
       "                               'Technician': 1,\n",
       "                               'First': 2,\n",
       "                               'Class': 1,\n",
       "                               'Old': 2,\n",
       "                               'Ones': 2,\n",
       "                               'You': 15,\n",
       "                               'own': 17,\n",
       "                               'dark': 2,\n",
       "                               'beautiful': 6,\n",
       "                               'homesick': 3,\n",
       "                               'dear': 3,\n",
       "                               'do': 23,\n",
       "                               'get': 12,\n",
       "                               'For': 8,\n",
       "                               'At': 4,\n",
       "                               'first': 15,\n",
       "                               'lonely': 6,\n",
       "                               'always': 3,\n",
       "                               'rolled': 2,\n",
       "                               'her': 71,\n",
       "                               'arms': 2,\n",
       "                               'am': 7,\n",
       "                               'shall': 3,\n",
       "                               'darling': 1,\n",
       "                               'kissed': 1,\n",
       "                               'kissing': 1,\n",
       "                               'Presently': 1,\n",
       "                               'breathlessly': 1,\n",
       "                               'That': 5,\n",
       "                               'worse': 1,\n",
       "                               'than': 13,\n",
       "                               'time': 30,\n",
       "                               'right': 6,\n",
       "                               'indeed': 1,\n",
       "                               'Kiss': 1,\n",
       "                               'me': 20,\n",
       "                               'later': 6,\n",
       "                               'cosmic': 2,\n",
       "                               'clock': 1,\n",
       "                               'Is': 3,\n",
       "                               'Do': 3,\n",
       "                               'know': 25,\n",
       "                               'Well': 4,\n",
       "                               \"I've\": 5,\n",
       "                               'turn': 5,\n",
       "                               'help': 8,\n",
       "                               'merged': 1,\n",
       "                               'together': 1,\n",
       "                               'softly': 1,\n",
       "                               'triumphantly': 1,\n",
       "                               ':': 10,\n",
       "                               'Her': 11,\n",
       "                               'answer': 3,\n",
       "                               'Then': 8,\n",
       "                               'voice': 9,\n",
       "                               'called': 7,\n",
       "                               'We': 15,\n",
       "                               '25': 1,\n",
       "                               'were': 59,\n",
       "                               'building': 1,\n",
       "                               'domes': 1,\n",
       "                               'male': 1,\n",
       "                               'female': 3,\n",
       "                               'party': 4,\n",
       "                               'arrive': 1,\n",
       "                               'next': 3,\n",
       "                               'ship': 20,\n",
       "                               'This': 12,\n",
       "                               'faster': 2,\n",
       "                               'scheduled': 1,\n",
       "                               'helpful': 1,\n",
       "                               'Part': 1,\n",
       "                               'saved': 1,\n",
       "                               'spent': 2,\n",
       "                               'preliminary': 1,\n",
       "                               'estimate': 1,\n",
       "                               'long-distance': 1,\n",
       "                               'plan': 2,\n",
       "                               'bound': 2,\n",
       "                               'oxygen': 3,\n",
       "                               'sands': 1,\n",
       "                               'make': 16,\n",
       "                               'planet': 10,\n",
       "                               'friendly': 1,\n",
       "                               'future': 3,\n",
       "                               'human': 5,\n",
       "                               'generations': 3,\n",
       "                               'neither': 3,\n",
       "                               'nor': 1,\n",
       "                               'hindered': 1,\n",
       "                               'yet': 7,\n",
       "                               'Their': 1,\n",
       "                               'meditations': 1,\n",
       "                               'approaching': 1,\n",
       "                               'violent': 2,\n",
       "                               'shape': 1,\n",
       "                               'millennia': 1,\n",
       "                               'elections': 1,\n",
       "                               'continued': 2,\n",
       "                               'very': 11,\n",
       "                               'advanced': 1,\n",
       "                               'poet': 1,\n",
       "                               'published': 2,\n",
       "                               'limited': 2,\n",
       "                               'edition': 1,\n",
       "                               'verse': 1,\n",
       "                               'consisting': 1,\n",
       "                               'entirely': 3,\n",
       "                               'punctuation': 1,\n",
       "                               'marks': 1,\n",
       "                               'spaces': 1,\n",
       "                               'Time': 4,\n",
       "                               'magazine': 1,\n",
       "                               'reviewed': 1,\n",
       "                               'suggested': 3,\n",
       "                               'Federation': 2,\n",
       "                               'Assembly': 1,\n",
       "                               'Daily': 1,\n",
       "                               'Record': 1,\n",
       "                               'translated': 2,\n",
       "                               'medium': 2,\n",
       "                               'colossal': 1,\n",
       "                               'campaign': 1,\n",
       "                               'opened': 2,\n",
       "                               'sell': 1,\n",
       "                               'sexual': 1,\n",
       "                               'organs': 3,\n",
       "                               'Mrs.': 1,\n",
       "                               'Joseph': 1,\n",
       "                               'Shadow': 1,\n",
       "                               'Greatness': 1,\n",
       "                               'Douglas': 1,\n",
       "                               'quoted': 1,\n",
       "                               'saying': 2,\n",
       "                               'sit': 2,\n",
       "                               'flowers': 2,\n",
       "                               'table': 1,\n",
       "                               'serviettes': 1,\n",
       "                               'Tibetan': 1,\n",
       "                               'swami': 1,\n",
       "                               'Palermo': 1,\n",
       "                               'Sicily': 1,\n",
       "                               'announced': 3,\n",
       "                               'Beverly': 1,\n",
       "                               'Hills': 1,\n",
       "                               'newly': 1,\n",
       "                               'discovered': 5,\n",
       "                               'ancient': 2,\n",
       "                               'yoga': 1,\n",
       "                               'discipline': 1,\n",
       "                               'ripple': 1,\n",
       "                               'increased': 1,\n",
       "                               'both': 2,\n",
       "                               'pranha': 1,\n",
       "                               'attraction': 1,\n",
       "                               'sexes': 1,\n",
       "                               'His': 9,\n",
       "                               'chelas': 1,\n",
       "                               'required': 3,\n",
       "                               'assume': 1,\n",
       "                               'matsyendra': 1,\n",
       "                               'posture': 1,\n",
       "                               'dressed': 1,\n",
       "                               'hand-woven': 1,\n",
       "                               'diapers': 1,\n",
       "                               'while': 8,\n",
       "                               'aloud': 1,\n",
       "                               'Rig-Veda': 1,\n",
       "                               'assistant': 1,\n",
       "                               'guru': 1,\n",
       "                               'examined': 1,\n",
       "                               'purses': 1,\n",
       "                               'room': 2,\n",
       "                               'nothing': 8,\n",
       "                               'stolen': 1,\n",
       "                               'purpose': 1,\n",
       "                               'less': 9,\n",
       "                               'immediate': 1,\n",
       "                               'President': 1,\n",
       "                               'United': 3,\n",
       "                               'States': 2,\n",
       "                               'proclaimed': 1,\n",
       "                               'Sunday': 1,\n",
       "                               'November': 1,\n",
       "                               'National': 1,\n",
       "                               \"Grandmothers'\": 1,\n",
       "                               'Day': 2,\n",
       "                               'urged': 1,\n",
       "                               'America': 5,\n",
       "                               'say': 3,\n",
       "                               'funeral': 1,\n",
       "                               'parlor': 1,\n",
       "                               'chain': 2,\n",
       "                               'indicted': 1,\n",
       "                               'price-cutting': 1,\n",
       "                               'Fosterite': 1,\n",
       "                               'bishops': 2,\n",
       "                               'after': 11,\n",
       "                               'secret': 5,\n",
       "                               'conclave': 1,\n",
       "                               \"Church's\": 1,\n",
       "                               'second': 3,\n",
       "                               'Major': 1,\n",
       "                               'Miracle': 1,\n",
       "                               'Supreme': 3,\n",
       "                               'bodily': 1,\n",
       "                               'Heaven': 2,\n",
       "                               'spot-promoted': 1,\n",
       "                               'ranking': 1,\n",
       "                               'with-but-after': 1,\n",
       "                               'glorious': 3,\n",
       "                               'held': 3,\n",
       "                               'pending': 1,\n",
       "                               'Heavenly': 1,\n",
       "                               'confirmation': 1,\n",
       "                               'elevation': 2,\n",
       "                               'Huey': 1,\n",
       "                               'Short': 3,\n",
       "                               'candidate': 2,\n",
       "                               'accepted': 2,\n",
       "                               'faction': 1,\n",
       "                               'lots': 2,\n",
       "                               'cast': 2,\n",
       "                               'repeatedly': 1,\n",
       "                               \"L'Unita\": 1,\n",
       "                               'Hoy': 1,\n",
       "                               'identical': 1,\n",
       "                               'denunciations': 1,\n",
       "                               \"Short's\": 1,\n",
       "                               \"l'Osservatore\": 1,\n",
       "                               'Romano': 1,\n",
       "                               'Christian': 1,\n",
       "                               'Science': 1,\n",
       "                               'Monitor': 1,\n",
       "                               'ignored': 2,\n",
       "                               'Times': 1,\n",
       "                               'India': 4,\n",
       "                               'snickered': 1,\n",
       "                               'Manchester': 1,\n",
       "                               'Guardian': 1,\n",
       "                               'simply': 5,\n",
       "                               'reported': 3,\n",
       "                               'Fosterites': 1,\n",
       "                               'England': 1,\n",
       "                               'extremely': 1,\n",
       "                               'militant': 1,\n",
       "                               'promotion': 1,\n",
       "                               'Man': 1,\n",
       "                               'interrupted': 1,\n",
       "                               'work': 9,\n",
       "                               'half': 10,\n",
       "                               'finished': 1,\n",
       "                               'stupid': 3,\n",
       "                               'jackass': 2,\n",
       "                               'certain': 2,\n",
       "                               'louse': 1,\n",
       "                               'listened': 2,\n",
       "                               'angelic': 2,\n",
       "                               'patience': 1,\n",
       "                               'Listen': 2,\n",
       "                               'junior': 2,\n",
       "                               \"you're\": 2,\n",
       "                               'angel': 3,\n",
       "                               'so': 23,\n",
       "                               'forget': 2,\n",
       "                               'Eternity': 1,\n",
       "                               'recriminations': 1,\n",
       "                               'poisoned': 1,\n",
       "                               'Afterwards': 1,\n",
       "                               'did': 35,\n",
       "                               'well': 11,\n",
       "                               \"he'll\": 1,\n",
       "                               \"can't\": 7,\n",
       "                               'Same': 1,\n",
       "                               'Popes': 1,\n",
       "                               'Some': 4,\n",
       "                               'warts': 1,\n",
       "                               'got': 11,\n",
       "                               'promoted': 2,\n",
       "                               'Check': 1,\n",
       "                               'go': 5,\n",
       "                               'ahead': 1,\n",
       "                               'professional': 2,\n",
       "                               'jealousy': 1,\n",
       "                               'here': 8,\n",
       "                               'calmed': 1,\n",
       "                               'request': 1,\n",
       "                               'shook': 2,\n",
       "                               'halo': 2,\n",
       "                               'touch': 3,\n",
       "                               \"shouldn't\": 1,\n",
       "                               'tried': 6,\n",
       "                               'can': 16,\n",
       "                               'submit': 1,\n",
       "                               'requisition': 1,\n",
       "                               'miracle': 1,\n",
       "                               'if': 16,\n",
       "                               'want': 6,\n",
       "                               'fool': 2,\n",
       "                               'yourself': 1,\n",
       "                               \"it'll\": 1,\n",
       "                               \"don't\": 11,\n",
       "                               'understand': 4,\n",
       "                               'System': 2,\n",
       "                               'setup': 2,\n",
       "                               'different': 4,\n",
       "                               'ours': 1,\n",
       "                               'run': 4,\n",
       "                               'show': 4,\n",
       "                               'Universe': 2,\n",
       "                               'variety': 1,\n",
       "                               'something': 8,\n",
       "                               'fact': 5,\n",
       "                               'field': 5,\n",
       "                               'workers': 1,\n",
       "                               'often': 3,\n",
       "                               'miss': 1,\n",
       "                               'punk': 1,\n",
       "                               'brush': 1,\n",
       "                               'aside': 1,\n",
       "                               'hold': 3,\n",
       "                               'same': 6,\n",
       "                               'thing': 9,\n",
       "                               \"didn't\": 5,\n",
       "                               'helping': 1,\n",
       "                               'done': 3,\n",
       "                               'Boss': 1,\n",
       "                               'wants': 1,\n",
       "                               'performance': 2,\n",
       "                               'gripes': 1,\n",
       "                               'If': 13,\n",
       "                               'off': 10,\n",
       "                               'calm': 2,\n",
       "                               'duck': 1,\n",
       "                               'Muslim': 1,\n",
       "                               'Paradise': 1,\n",
       "                               'Otherwise': 1,\n",
       "                               'straighten': 1,\n",
       "                               'your': 17,\n",
       "                               'square': 2,\n",
       "                               'wings': 1,\n",
       "                               'dig': 1,\n",
       "                               'sooner': 1,\n",
       "                               'act': 1,\n",
       "                               'quicker': 1,\n",
       "                               \"you'll\": 1,\n",
       "                               'Get': 1,\n",
       "                               'Happy': 2,\n",
       "                               'heaved': 1,\n",
       "                               'deep': 2,\n",
       "                               'ethereal': 1,\n",
       "                               'sigh': 2,\n",
       "                               'start': 3,\n",
       "                               'hear': 2,\n",
       "                               \"Digby's\": 1,\n",
       "                               'disappearance': 3,\n",
       "                               'fleeting': 1,\n",
       "                               'suspicion': 4,\n",
       "                               'dismissed': 1,\n",
       "                               'finger': 1,\n",
       "                               'gotten': 2,\n",
       "                               'away': 7,\n",
       "                               'happened': 4,\n",
       "                               'supreme': 1,\n",
       "                               'worried': 2,\n",
       "                               \"wasn't\": 4,\n",
       "                               'bothered': 1,\n",
       "                               'household': 1,\n",
       "                               'gone': 5,\n",
       "                               'upset': 1,\n",
       "                               'deduced': 1,\n",
       "                               'whom': 2,\n",
       "                               'inquire': 1,\n",
       "                               'legal': 1,\n",
       "                               'age': 2,\n",
       "                               'presumed': 1,\n",
       "                               'able': 3,\n",
       "                               'defend': 1,\n",
       "                               'clinches': 1,\n",
       "                               'Anyhow': 1,\n",
       "                               'high': 3,\n",
       "                               'boy': 2,\n",
       "                               'salted': 1,\n",
       "                               \"couldn't\": 8,\n",
       "                               'reconstruct': 1,\n",
       "                               'crime': 1,\n",
       "                               'girls': 2,\n",
       "                               'behaved': 1,\n",
       "                               'because': 10,\n",
       "                               'patterns': 2,\n",
       "                               'kept': 4,\n",
       "                               'shifting': 1,\n",
       "                               'ABC': 1,\n",
       "                               'vs': 4,\n",
       "                               'D': 1,\n",
       "                               'BCD': 1,\n",
       "                               'or': 27,\n",
       "                               'AB': 1,\n",
       "                               'CD': 1,\n",
       "                               'AD': 1,\n",
       "                               'CB': 1,\n",
       "                               'ways': 1,\n",
       "                               'four': 1,\n",
       "                               'women': 3,\n",
       "                               'gang': 1,\n",
       "                               'week': 1,\n",
       "                               'following': 2,\n",
       "                               'ill-starred': 1,\n",
       "                               'trip': 3,\n",
       "                               'period': 4,\n",
       "                               'usually': 1,\n",
       "                               'pronounced': 1,\n",
       "                               'dead': 7,\n",
       "                               'minded': 1,\n",
       "                               'service': 1,\n",
       "                               'pieces': 1,\n",
       "                               'seemed': 4,\n",
       "                               'spend': 1,\n",
       "                               'tiptoeing': 1,\n",
       "                               'preoccupied': 1,\n",
       "                               'cook': 1,\n",
       "                               'secretaries': 1,\n",
       "                               'Even': 2,\n",
       "                               'rock-steady': 1,\n",
       "                               'Anne': 3,\n",
       "                               'Hell': 1,\n",
       "                               'worst': 1,\n",
       "                               'Absent-minded': 1,\n",
       "                               'subject': 3,\n",
       "                               'unexplained': 1,\n",
       "                               'tears': 2,\n",
       "                               'bet': 1,\n",
       "                               'witness': 1,\n",
       "                               'Second': 1,\n",
       "                               'Coming': 1,\n",
       "                               'memorize': 1,\n",
       "                               'date': 1,\n",
       "                               'personae': 1,\n",
       "                               'events': 3,\n",
       "                               'barometric': 1,\n",
       "                               'batting': 1,\n",
       "                               'blue': 2,\n",
       "                               'eyes': 9,\n",
       "                               'expense': 1,\n",
       "                               'involved': 2,\n",
       "                               'astronomical': 1,\n",
       "                               'However': 2,\n",
       "                               'sent': 1,\n",
       "                               'third': 2,\n",
       "                               'vessel': 4,\n",
       "                               'smaller': 2,\n",
       "                               'two': 10,\n",
       "                               'about': 18,\n",
       "                               'interstellar': 1,\n",
       "                               'drives': 1,\n",
       "                               'since': 5,\n",
       "                               'hundred': 3,\n",
       "                               'years': 16,\n",
       "                               'tell': 8,\n",
       "                               'several': 6,\n",
       "                               'found': 9,\n",
       "                               'beings': 2,\n",
       "                               'live': 7,\n",
       "                               'already': 6,\n",
       "                               'inhabited': 2,\n",
       "                               'sentient': 2,\n",
       "                               'Said': 4,\n",
       "                               'Hal': 23,\n",
       "                               'forgetting': 1,\n",
       "                               'enthusiasm': 1,\n",
       "                               'speak': 4,\n",
       "                               'Macneff': 7,\n",
       "                               'pacing': 1,\n",
       "                               'stare': 1,\n",
       "                               'pale': 1,\n",
       "                               'How': 4,\n",
       "                               'sharply': 1,\n",
       "                               'Forgive': 1,\n",
       "                               'Sandalphon': 3,\n",
       "                               'inevitable': 2,\n",
       "                               'Did': 3,\n",
       "                               'Forerunner': 4,\n",
       "                               'predict': 1,\n",
       "                               'World': 1,\n",
       "                               'Line': 1,\n",
       "                               'such': 12,\n",
       "                               'believe': 6,\n",
       "                               'page': 1,\n",
       "                               '573': 1,\n",
       "                               'smiled': 7,\n",
       "                               'glad': 1,\n",
       "                               'scriptural': 1,\n",
       "                               'lessons': 4,\n",
       "                               'impression': 1,\n",
       "                               'Thought': 1,\n",
       "                               'Besides': 2,\n",
       "                               'impressions': 1,\n",
       "                               'bear': 1,\n",
       "                               'scars': 1,\n",
       "                               'where': 10,\n",
       "                               'Pornsen': 3,\n",
       "                               'gapt': 7,\n",
       "                               'whipped': 1,\n",
       "                               'good': 13,\n",
       "                               'impresser': 1,\n",
       "                               'Was': 2,\n",
       "                               'grew': 1,\n",
       "                               'older': 2,\n",
       "                               'creche': 1,\n",
       "                               'dormitory': 1,\n",
       "                               'college': 1,\n",
       "                               'getting': 4,\n",
       "                               'block': 1,\n",
       "                               'responsible': 3,\n",
       "                               'low': 4,\n",
       "                               'M.': 2,\n",
       "                               \"R.'s\": 1,\n",
       "                               'Swiftly': 1,\n",
       "                               'revulsion': 1,\n",
       "                               'protest': 1,\n",
       "                               'No': 18,\n",
       "                               'whatever': 3,\n",
       "                               'happens': 1,\n",
       "                               'R.': 1,\n",
       "                               'does': 3,\n",
       "                               'die': 6,\n",
       "                               'willed': 1,\n",
       "                               'So': 3,\n",
       "                               'forgive': 1,\n",
       "                               'Sigmen': 4,\n",
       "                               'contrary-to-reality': 1,\n",
       "                               'thoughts': 3,\n",
       "                               'Please': 1,\n",
       "                               'pardon': 1,\n",
       "                               'expedition': 6,\n",
       "                               'find': 4,\n",
       "                               'any': 17,\n",
       "                               'records': 3,\n",
       "                               'Perhaps': 3,\n",
       "                               'even': 10,\n",
       "                               'though': 10,\n",
       "                               'wish': 1,\n",
       "                               'Though': 3,\n",
       "                               'may': 4,\n",
       "                               'under': 5,\n",
       "                               'orders': 1,\n",
       "                               'swift': 1,\n",
       "                               'survey': 1,\n",
       "                               'return': 3,\n",
       "                               'distance': 2,\n",
       "                               'lightyears': 1,\n",
       "                               'star': 4,\n",
       "                               'eye': 1,\n",
       "                               'volunteer': 2,\n",
       "                               'will': 16,\n",
       "                               'told': 3,\n",
       "                               'leaves': 2,\n",
       "                               'And': 16,\n",
       "                               'soon': 2,\n",
       "                               'linguist': 3,\n",
       "                               'huge': 2,\n",
       "                               'number': 3,\n",
       "                               'military': 1,\n",
       "                               'men': 5,\n",
       "                               'specialists': 1,\n",
       "                               'taking': 1,\n",
       "                               'limits': 1,\n",
       "                               'linguists': 1,\n",
       "                               'considered': 1,\n",
       "                               ...})})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (genre, word)\n",
    "           for genre in brown.categories()\n",
    "           for word in brown.words(categories=genre))\n",
    "\n",
    "print(type(brown))\n",
    "print(brown.categories())\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news', 'The'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'County'),\n",
       " ('news', 'Grand'),\n",
       " ('news', 'Jury'),\n",
       " ('news', 'said'),\n",
       " ('news', 'Friday'),\n",
       " ('news', 'an'),\n",
       " ('news', 'investigation'),\n",
       " ('news', 'of'),\n",
       " ('news', \"Atlanta's\"),\n",
       " ('news', 'recent'),\n",
       " ('news', 'primary'),\n",
       " ('news', 'election'),\n",
       " ('news', 'produced'),\n",
       " ('news', '``'),\n",
       " ('news', 'no'),\n",
       " ('news', 'evidence'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'that'),\n",
       " ('news', 'any'),\n",
       " ('news', 'irregularities'),\n",
       " ('news', 'took'),\n",
       " ('news', 'place'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'further'),\n",
       " ('news', 'said'),\n",
       " ('news', 'in'),\n",
       " ('news', 'term-end'),\n",
       " ('news', 'presentments'),\n",
       " ('news', 'that'),\n",
       " ('news', 'the'),\n",
       " ('news', 'City'),\n",
       " ('news', 'Executive'),\n",
       " ('news', 'Committee'),\n",
       " ('news', ','),\n",
       " ('news', 'which'),\n",
       " ('news', 'had'),\n",
       " ('news', 'over-all'),\n",
       " ('news', 'charge'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'election'),\n",
       " ('news', ','),\n",
       " ('news', '``'),\n",
       " ('news', 'deserves'),\n",
       " ('news', 'the'),\n",
       " ('news', 'praise'),\n",
       " ('news', 'and'),\n",
       " ('news', 'thanks'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'City'),\n",
       " ('news', 'of'),\n",
       " ('news', 'Atlanta'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'for'),\n",
       " ('news', 'the'),\n",
       " ('news', 'manner'),\n",
       " ('news', 'in'),\n",
       " ('news', 'which'),\n",
       " ('news', 'the'),\n",
       " ('news', 'election'),\n",
       " ('news', 'was'),\n",
       " ('news', 'conducted'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'September-October'),\n",
       " ('news', 'term'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'had'),\n",
       " ('news', 'been'),\n",
       " ('news', 'charged'),\n",
       " ('news', 'by'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'Superior'),\n",
       " ('news', 'Court'),\n",
       " ('news', 'Judge'),\n",
       " ('news', 'Durwood'),\n",
       " ('news', 'Pye'),\n",
       " ('news', 'to'),\n",
       " ('news', 'investigate'),\n",
       " ('news', 'reports'),\n",
       " ('news', 'of'),\n",
       " ('news', 'possible'),\n",
       " ('news', '``'),\n",
       " ('news', 'irregularities'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'hard-fought'),\n",
       " ('news', 'primary'),\n",
       " ('news', 'which'),\n",
       " ('news', 'was'),\n",
       " ('news', 'won'),\n",
       " ('news', 'by'),\n",
       " ('news', 'Mayor-nominate'),\n",
       " ('news', 'Ivan'),\n",
       " ('news', 'Allen'),\n",
       " ('news', 'Jr.'),\n",
       " ('news', '.'),\n",
       " ('news', '``'),\n",
       " ('news', 'Only'),\n",
       " ('news', 'a'),\n",
       " ('news', 'relative'),\n",
       " ('news', 'handful'),\n",
       " ('news', 'of'),\n",
       " ('news', 'such'),\n",
       " ('news', 'reports'),\n",
       " ('news', 'was'),\n",
       " ('news', 'received'),\n",
       " ('news', \"''\"),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', ','),\n",
       " ('news', '``'),\n",
       " ('news', 'considering'),\n",
       " ('news', 'the'),\n",
       " ('news', 'widespread'),\n",
       " ('news', 'interest'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'election'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'number'),\n",
       " ('news', 'of'),\n",
       " ('news', 'voters'),\n",
       " ('news', 'and'),\n",
       " ('news', 'the'),\n",
       " ('news', 'size'),\n",
       " ('news', 'of'),\n",
       " ('news', 'this'),\n",
       " ('news', 'city'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', 'it'),\n",
       " ('news', 'did'),\n",
       " ('news', 'find'),\n",
       " ('news', 'that'),\n",
       " ('news', 'many'),\n",
       " ('news', 'of'),\n",
       " ('news', \"Georgia's\"),\n",
       " ('news', 'registration'),\n",
       " ('news', 'and'),\n",
       " ('news', 'election'),\n",
       " ('news', 'laws'),\n",
       " ('news', '``'),\n",
       " ('news', 'are'),\n",
       " ('news', 'outmoded'),\n",
       " ('news', 'or'),\n",
       " ('news', 'inadequate'),\n",
       " ('news', 'and'),\n",
       " ('news', 'often'),\n",
       " ('news', 'ambiguous'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'It'),\n",
       " ('news', 'recommended'),\n",
       " ('news', 'that'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'legislators'),\n",
       " ('news', 'act'),\n",
       " ('news', '``'),\n",
       " ('news', 'to'),\n",
       " ('news', 'have'),\n",
       " ('news', 'these'),\n",
       " ('news', 'laws'),\n",
       " ('news', 'studied'),\n",
       " ('news', 'and'),\n",
       " ('news', 'revised'),\n",
       " ('news', 'to'),\n",
       " ('news', 'the'),\n",
       " ('news', 'end'),\n",
       " ('news', 'of'),\n",
       " ('news', 'modernizing'),\n",
       " ('news', 'and'),\n",
       " ('news', 'improving'),\n",
       " ('news', 'them'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'grand'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'commented'),\n",
       " ('news', 'on'),\n",
       " ('news', 'a'),\n",
       " ('news', 'number'),\n",
       " ('news', 'of'),\n",
       " ('news', 'other'),\n",
       " ('news', 'topics'),\n",
       " ('news', ','),\n",
       " ('news', 'among'),\n",
       " ('news', 'them'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Atlanta'),\n",
       " ('news', 'and'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'County'),\n",
       " ('news', 'purchasing'),\n",
       " ('news', 'departments'),\n",
       " ('news', 'which'),\n",
       " ('news', 'it'),\n",
       " ('news', 'said'),\n",
       " ('news', '``'),\n",
       " ('news', 'are'),\n",
       " ('news', 'well'),\n",
       " ('news', 'operated'),\n",
       " ('news', 'and'),\n",
       " ('news', 'follow'),\n",
       " ('news', 'generally'),\n",
       " ('news', 'accepted'),\n",
       " ('news', 'practices'),\n",
       " ('news', 'which'),\n",
       " ('news', 'inure'),\n",
       " ('news', 'to'),\n",
       " ('news', 'the'),\n",
       " ('news', 'best'),\n",
       " ('news', 'interest'),\n",
       " ('news', 'of'),\n",
       " ('news', 'both'),\n",
       " ('news', 'governments'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'Merger'),\n",
       " ('news', 'proposed'),\n",
       " ('news', 'However'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', 'it'),\n",
       " ('news', 'believes'),\n",
       " ('news', '``'),\n",
       " ('news', 'these'),\n",
       " ('news', 'two'),\n",
       " ('news', 'offices'),\n",
       " ('news', 'should'),\n",
       " ('news', 'be'),\n",
       " ('news', 'combined'),\n",
       " ('news', 'to'),\n",
       " ('news', 'achieve'),\n",
       " ('news', 'greater'),\n",
       " ('news', 'efficiency'),\n",
       " ('news', 'and'),\n",
       " ('news', 'reduce'),\n",
       " ('news', 'the'),\n",
       " ('news', 'cost'),\n",
       " ('news', 'of'),\n",
       " ('news', 'administration'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'City'),\n",
       " ('news', 'Purchasing'),\n",
       " ('news', 'Department'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', ','),\n",
       " ('news', '``'),\n",
       " ('news', 'is'),\n",
       " ('news', 'lacking'),\n",
       " ('news', 'in'),\n",
       " ('news', 'experienced'),\n",
       " ('news', 'clerical'),\n",
       " ('news', 'personnel'),\n",
       " ('news', 'as'),\n",
       " ('news', 'a'),\n",
       " ('news', 'result'),\n",
       " ('news', 'of'),\n",
       " ('news', 'city'),\n",
       " ('news', 'personnel'),\n",
       " ('news', 'policies'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'It'),\n",
       " ('news', 'urged'),\n",
       " ('news', 'that'),\n",
       " ('news', 'the'),\n",
       " ('news', 'city'),\n",
       " ('news', '``'),\n",
       " ('news', 'take'),\n",
       " ('news', 'steps'),\n",
       " ('news', 'to'),\n",
       " ('news', 'remedy'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'this'),\n",
       " ('news', 'problem'),\n",
       " ('news', '.'),\n",
       " ('news', 'Implementation'),\n",
       " ('news', 'of'),\n",
       " ('news', \"Georgia's\"),\n",
       " ('news', 'automobile'),\n",
       " ('news', 'title'),\n",
       " ('news', 'law'),\n",
       " ('news', 'was'),\n",
       " ('news', 'also'),\n",
       " ('news', 'recommended'),\n",
       " ('news', 'by'),\n",
       " ('news', 'the'),\n",
       " ('news', 'outgoing'),\n",
       " ('news', 'jury'),\n",
       " ('news', '.'),\n",
       " ('news', 'It'),\n",
       " ('news', 'urged'),\n",
       " ('news', 'that'),\n",
       " ('news', 'the'),\n",
       " ('news', 'next'),\n",
       " ('news', 'Legislature'),\n",
       " ('news', '``'),\n",
       " ('news', 'provide'),\n",
       " ('news', 'enabling'),\n",
       " ('news', 'funds'),\n",
       " ('news', 'and'),\n",
       " ('news', 're-set'),\n",
       " ('news', 'the'),\n",
       " ('news', 'effective'),\n",
       " ('news', 'date'),\n",
       " ('news', 'so'),\n",
       " ('news', 'that'),\n",
       " ('news', 'an'),\n",
       " ('news', 'orderly'),\n",
       " ('news', 'implementation'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'law'),\n",
       " ('news', 'may'),\n",
       " ('news', 'be'),\n",
       " ('news', 'effected'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'grand'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'took'),\n",
       " ('news', 'a'),\n",
       " ('news', 'swipe'),\n",
       " ('news', 'at'),\n",
       " ('news', 'the'),\n",
       " ('news', 'State'),\n",
       " ('news', 'Welfare'),\n",
       " ('news', \"Department's\"),\n",
       " ('news', 'handling'),\n",
       " ('news', 'of'),\n",
       " ('news', 'federal'),\n",
       " ('news', 'funds'),\n",
       " ('news', 'granted'),\n",
       " ('news', 'for'),\n",
       " ('news', 'child'),\n",
       " ('news', 'welfare'),\n",
       " ('news', 'services'),\n",
       " ('news', 'in'),\n",
       " ('news', 'foster'),\n",
       " ('news', 'homes'),\n",
       " ('news', '.'),\n",
       " ('news', '``'),\n",
       " ('news', 'This'),\n",
       " ('news', 'is'),\n",
       " ('news', 'one'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'major'),\n",
       " ('news', 'items'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'County'),\n",
       " ('news', 'general'),\n",
       " ('news', 'assistance'),\n",
       " ('news', 'program'),\n",
       " ('news', \"''\"),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', ','),\n",
       " ('news', 'but'),\n",
       " ('news', 'the'),\n",
       " ('news', 'State'),\n",
       " ('news', 'Welfare'),\n",
       " ('news', 'Department'),\n",
       " ('news', '``'),\n",
       " ('news', 'has'),\n",
       " ('news', 'seen'),\n",
       " ('news', 'fit'),\n",
       " ('news', 'to'),\n",
       " ('news', 'distribute'),\n",
       " ('news', 'these'),\n",
       " ('news', 'funds'),\n",
       " ('news', 'through'),\n",
       " ('news', 'the'),\n",
       " ('news', 'welfare'),\n",
       " ('news', 'departments'),\n",
       " ('news', 'of'),\n",
       " ('news', 'all'),\n",
       " ('news', 'the'),\n",
       " ('news', 'counties'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'state'),\n",
       " ('news', 'with'),\n",
       " ('news', 'the'),\n",
       " ('news', 'exception'),\n",
       " ('news', 'of'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'County'),\n",
       " ('news', ','),\n",
       " ('news', 'which'),\n",
       " ('news', 'receives'),\n",
       " ('news', 'none'),\n",
       " ('news', 'of'),\n",
       " ('news', 'this'),\n",
       " ('news', 'money'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jurors'),\n",
       " ('news', 'said'),\n",
       " ('news', 'they'),\n",
       " ('news', 'realize'),\n",
       " ('news', '``'),\n",
       " ('news', 'a'),\n",
       " ('news', 'proportionate'),\n",
       " ('news', 'distribution'),\n",
       " ('news', 'of'),\n",
       " ('news', 'these'),\n",
       " ('news', 'funds'),\n",
       " ('news', 'might'),\n",
       " ('news', 'disable'),\n",
       " ('news', 'this'),\n",
       " ('news', 'program'),\n",
       " ('news', 'in'),\n",
       " ('news', 'our'),\n",
       " ('news', 'less'),\n",
       " ('news', 'populous'),\n",
       " ('news', 'counties'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'Nevertheless'),\n",
       " ('news', ','),\n",
       " ('news', '``'),\n",
       " ('news', 'we'),\n",
       " ('news', 'feel'),\n",
       " ('news', 'that'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'future'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'County'),\n",
       " ('news', 'should'),\n",
       " ('news', 'receive'),\n",
       " ('news', 'some'),\n",
       " ('news', 'portion'),\n",
       " ('news', 'of'),\n",
       " ('news', 'these'),\n",
       " ('news', 'available'),\n",
       " ('news', 'funds'),\n",
       " ('news', \"''\"),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jurors'),\n",
       " ('news', 'said'),\n",
       " ('news', '.'),\n",
       " ('news', '``'),\n",
       " ('news', 'Failure'),\n",
       " ('news', 'to'),\n",
       " ('news', 'do'),\n",
       " ('news', 'this'),\n",
       " ('news', 'will'),\n",
       " ('news', 'continue'),\n",
       " ('news', 'to'),\n",
       " ('news', 'place'),\n",
       " ('news', 'a'),\n",
       " ('news', 'disproportionate'),\n",
       " ('news', 'burden'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'on'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'taxpayers'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'also'),\n",
       " ('news', 'commented'),\n",
       " ('news', 'on'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', \"ordinary's\"),\n",
       " ('news', 'court'),\n",
       " ('news', 'which'),\n",
       " ('news', 'has'),\n",
       " ('news', 'been'),\n",
       " ('news', 'under'),\n",
       " ('news', 'fire'),\n",
       " ('news', 'for'),\n",
       " ('news', 'its'),\n",
       " ('news', 'practices'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'appointment'),\n",
       " ('news', 'of'),\n",
       " ('news', 'appraisers'),\n",
       " ('news', ','),\n",
       " ('news', 'guardians'),\n",
       " ('news', 'and'),\n",
       " ('news', 'administrators'),\n",
       " ('news', 'and'),\n",
       " ('news', 'the'),\n",
       " ('news', 'awarding'),\n",
       " ('news', 'of'),\n",
       " ('news', 'fees'),\n",
       " ('news', 'and'),\n",
       " ('news', 'compensation'),\n",
       " ('news', '.'),\n",
       " ('news', 'Wards'),\n",
       " ('news', 'protected'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', 'it'),\n",
       " ('news', 'found'),\n",
       " ('news', 'the'),\n",
       " ('news', 'court'),\n",
       " ('news', '``'),\n",
       " ('news', 'has'),\n",
       " ('news', 'incorporated'),\n",
       " ('news', 'into'),\n",
       " ('news', 'its'),\n",
       " ('news', 'operating'),\n",
       " ('news', 'procedures'),\n",
       " ('news', 'the'),\n",
       " ('news', 'recommendations'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'of'),\n",
       " ('news', 'two'),\n",
       " ('news', 'previous'),\n",
       " ('news', 'grand'),\n",
       " ('news', 'juries'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'Atlanta'),\n",
       " ('news', 'Bar'),\n",
       " ('news', 'Association'),\n",
       " ('news', 'and'),\n",
       " ('news', 'an'),\n",
       " ('news', 'interim'),\n",
       " ('news', 'citizens'),\n",
       " ('news', 'committee'),\n",
       " ('news', '.'),\n",
       " ('news', '``'),\n",
       " ('news', 'These'),\n",
       " ('news', 'actions'),\n",
       " ('news', 'should'),\n",
       " ('news', 'serve'),\n",
       " ('news', 'to'),\n",
       " ('news', 'protect'),\n",
       " ('news', 'in'),\n",
       " ('news', 'fact'),\n",
       " ('news', 'and'),\n",
       " ('news', 'in'),\n",
       " ('news', 'effect'),\n",
       " ('news', 'the'),\n",
       " ('news', \"court's\"),\n",
       " ('news', 'wards'),\n",
       " ('news', 'from'),\n",
       " ('news', 'undue'),\n",
       " ('news', 'costs'),\n",
       " ('news', 'and'),\n",
       " ('news', 'its'),\n",
       " ('news', 'appointed'),\n",
       " ('news', 'and'),\n",
       " ('news', 'elected'),\n",
       " ('news', 'servants'),\n",
       " ('news', 'from'),\n",
       " ('news', 'unmeritorious'),\n",
       " ('news', 'criticisms'),\n",
       " ('news', \"''\"),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'said'),\n",
       " ('news', '.'),\n",
       " ('news', 'Regarding'),\n",
       " ('news', \"Atlanta's\"),\n",
       " ('news', 'new'),\n",
       " ('news', 'multi-million-dollar'),\n",
       " ('news', 'airport'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'recommended'),\n",
       " ('news', '``'),\n",
       " ('news', 'that'),\n",
       " ('news', 'when'),\n",
       " ('news', 'the'),\n",
       " ('news', 'new'),\n",
       " ('news', 'management'),\n",
       " ('news', 'takes'),\n",
       " ('news', 'charge'),\n",
       " ('news', 'Jan.'),\n",
       " ('news', '1'),\n",
       " ('news', 'the'),\n",
       " ('news', 'airport'),\n",
       " ('news', 'be'),\n",
       " ('news', 'operated'),\n",
       " ('news', 'in'),\n",
       " ('news', 'a'),\n",
       " ('news', 'manner'),\n",
       " ('news', 'that'),\n",
       " ('news', 'will'),\n",
       " ('news', 'eliminate'),\n",
       " ('news', 'political'),\n",
       " ('news', 'influences'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'did'),\n",
       " ('news', 'not'),\n",
       " ('news', 'elaborate'),\n",
       " ('news', ','),\n",
       " ('news', 'but'),\n",
       " ('news', 'it'),\n",
       " ('news', 'added'),\n",
       " ('news', 'that'),\n",
       " ('news', '``'),\n",
       " ('news', 'there'),\n",
       " ('news', 'should'),\n",
       " ('news', 'be'),\n",
       " ('news', 'periodic'),\n",
       " ('news', 'surveillance'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'pricing'),\n",
       " ('news', 'practices'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'concessionaires'),\n",
       " ('news', 'for'),\n",
       " ('news', 'the'),\n",
       " ('news', 'purpose'),\n",
       " ('news', 'of'),\n",
       " ('news', 'keeping'),\n",
       " ('news', 'the'),\n",
       " ('news', 'prices'),\n",
       " ('news', 'reasonable'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', 'Ask'),\n",
       " ('news', 'jail'),\n",
       " ('news', 'deputies'),\n",
       " ('news', 'On'),\n",
       " ('news', 'other'),\n",
       " ('news', 'matters'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'recommended'),\n",
       " ('news', 'that'),\n",
       " ('news', ':'),\n",
       " ('news', '('),\n",
       " ('news', '1'),\n",
       " ('news', ')'),\n",
       " ('news', 'Four'),\n",
       " ('news', 'additional'),\n",
       " ('news', 'deputies'),\n",
       " ('news', 'be'),\n",
       " ('news', 'employed'),\n",
       " ('news', 'at'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'County'),\n",
       " ('news', 'Jail'),\n",
       " ('news', 'and'),\n",
       " ('news', '``'),\n",
       " ('news', 'a'),\n",
       " ('news', 'doctor'),\n",
       " ('news', ','),\n",
       " ('news', 'medical'),\n",
       " ('news', 'intern'),\n",
       " ('news', 'or'),\n",
       " ('news', 'extern'),\n",
       " ('news', 'be'),\n",
       " ('news', 'employed'),\n",
       " ('news', 'for'),\n",
       " ('news', 'night'),\n",
       " ('news', 'and'),\n",
       " ('news', 'weekend'),\n",
       " ('news', 'duty'),\n",
       " ('news', 'at'),\n",
       " ('news', 'the'),\n",
       " ('news', 'jail'),\n",
       " ('news', \"''\"),\n",
       " ('news', '.'),\n",
       " ('news', '('),\n",
       " ('news', '2'),\n",
       " ('news', ')'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'legislators'),\n",
       " ('news', '``'),\n",
       " ('news', 'work'),\n",
       " ('news', 'with'),\n",
       " ('news', 'city'),\n",
       " ('news', 'officials'),\n",
       " ('news', 'to'),\n",
       " ('news', 'pass'),\n",
       " ('news', 'enabling'),\n",
       " ('news', 'legislation'),\n",
       " ('news', 'that'),\n",
       " ('news', 'will'),\n",
       " ('news', 'permit'),\n",
       " ('news', 'the'),\n",
       " ('news', 'establishment'),\n",
       " ('news', 'of'),\n",
       " ('news', 'a'),\n",
       " ('news', 'fair'),\n",
       " ('news', 'and'),\n",
       " ('news', 'equitable'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'pension'),\n",
       " ('news', 'plan'),\n",
       " ('news', 'for'),\n",
       " ('news', 'city'),\n",
       " ('news', 'employes'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'jury'),\n",
       " ('news', 'praised'),\n",
       " ('news', 'the'),\n",
       " ('news', 'administration'),\n",
       " ('news', 'and'),\n",
       " ('news', 'operation'),\n",
       " ('news', 'of'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Atlanta'),\n",
       " ('news', 'Police'),\n",
       " ('news', 'Department'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'Tax'),\n",
       " ('news', \"Commissioner's\"),\n",
       " ('news', 'Office'),\n",
       " ('news', ','),\n",
       " ('news', 'the'),\n",
       " ('news', 'Bellwood'),\n",
       " ('news', 'and'),\n",
       " ('news', 'Alpharetta'),\n",
       " ('news', 'prison'),\n",
       " ('news', 'farms'),\n",
       " ('news', ','),\n",
       " ('news', 'Grady'),\n",
       " ('news', 'Hospital'),\n",
       " ('news', 'and'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'Health'),\n",
       " ('news', 'Department'),\n",
       " ('news', '.'),\n",
       " ('news', 'Mayor'),\n",
       " ('news', 'William'),\n",
       " ('news', 'B.'),\n",
       " ('news', 'Hartsfield'),\n",
       " ('news', 'filed'),\n",
       " ('news', 'suit'),\n",
       " ('news', 'for'),\n",
       " ('news', 'divorce'),\n",
       " ('news', 'from'),\n",
       " ('news', 'his'),\n",
       " ('news', 'wife'),\n",
       " ('news', ','),\n",
       " ('news', 'Pearl'),\n",
       " ('news', 'Williams'),\n",
       " ('news', 'Hartsfield'),\n",
       " ('news', ','),\n",
       " ('news', 'in'),\n",
       " ('news', 'Fulton'),\n",
       " ('news', 'Superior'),\n",
       " ('news', 'Court'),\n",
       " ('news', 'Friday'),\n",
       " ('news', '.'),\n",
       " ('news', 'His'),\n",
       " ('news', 'petition'),\n",
       " ('news', 'charged'),\n",
       " ('news', 'mental'),\n",
       " ('news', 'cruelty'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'couple'),\n",
       " ('news', 'was'),\n",
       " ('news', 'married'),\n",
       " ('news', 'Aug.'),\n",
       " ('news', '2'),\n",
       " ('news', ','),\n",
       " ('news', '1913'),\n",
       " ('news', '.'),\n",
       " ('news', 'They'),\n",
       " ('news', 'have'),\n",
       " ('news', 'a'),\n",
       " ('news', 'son'),\n",
       " ('news', ','),\n",
       " ('news', 'William'),\n",
       " ('news', 'Berry'),\n",
       " ('news', 'Jr.'),\n",
       " ('news', ','),\n",
       " ('news', 'and'),\n",
       " ('news', 'a'),\n",
       " ('news', 'daughter'),\n",
       " ('news', ','),\n",
       " ('news', 'Mrs.'),\n",
       " ('news', 'J.'),\n",
       " ('news', 'M.'),\n",
       " ('news', 'Cheshire'),\n",
       " ('news', 'of'),\n",
       " ('news', 'Griffin'),\n",
       " ('news', '.'),\n",
       " ('news', 'Attorneys'),\n",
       " ('news', 'for'),\n",
       " ('news', 'the'),\n",
       " ('news', 'mayor'),\n",
       " ('news', 'said'),\n",
       " ('news', 'that'),\n",
       " ('news', 'an'),\n",
       " ('news', 'amicable'),\n",
       " ('news', 'property'),\n",
       " ('news', 'settlement'),\n",
       " ('news', 'has'),\n",
       " ('news', 'been'),\n",
       " ('news', 'agreed'),\n",
       " ('news', 'upon'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'petition'),\n",
       " ('news', 'listed'),\n",
       " ('news', 'the'),\n",
       " ('news', \"mayor's\"),\n",
       " ('news', 'occupation'),\n",
       " ('news', 'as'),\n",
       " ('news', '``'),\n",
       " ('news', 'attorney'),\n",
       " ('news', \"''\"),\n",
       " ('news', 'and'),\n",
       " ('news', 'his'),\n",
       " ('news', 'age'),\n",
       " ('news', 'as'),\n",
       " ('news', '71'),\n",
       " ('news', '.'),\n",
       " ('news', 'It'),\n",
       " ('news', 'listed'),\n",
       " ('news', 'his'),\n",
       " ('news', \"wife's\"),\n",
       " ('news', 'age'),\n",
       " ('news', 'as'),\n",
       " ('news', '74'),\n",
       " ('news', 'and'),\n",
       " ('news', 'place'),\n",
       " ('news', 'of'),\n",
       " ('news', 'birth'),\n",
       " ('news', 'as'),\n",
       " ('news', 'Opelika'),\n",
       " ('news', ','),\n",
       " ('news', 'Ala.'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'petition'),\n",
       " ('news', 'said'),\n",
       " ('news', 'that'),\n",
       " ('news', 'the'),\n",
       " ('news', 'couple'),\n",
       " ('news', 'has'),\n",
       " ('news', 'not'),\n",
       " ('news', 'lived'),\n",
       " ('news', 'together'),\n",
       " ('news', 'as'),\n",
       " ('news', 'man'),\n",
       " ('news', 'and'),\n",
       " ('news', 'wife'),\n",
       " ('news', 'for'),\n",
       " ('news', 'more'),\n",
       " ('news', 'than'),\n",
       " ('news', 'a'),\n",
       " ('news', 'year'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', 'Hartsfield'),\n",
       " ('news', 'home'),\n",
       " ('news', 'is'),\n",
       " ('news', 'at'),\n",
       " ('news', '637'),\n",
       " ('news', 'E.'),\n",
       " ('news', 'Pelham'),\n",
       " ('news', 'Rd.'),\n",
       " ('news', 'Aj'),\n",
       " ('news', '.'),\n",
       " ('news', 'Henry'),\n",
       " ('news', 'L.'),\n",
       " ('news', 'Bowden'),\n",
       " ('news', 'was'),\n",
       " ('news', 'listed'),\n",
       " ('news', 'on'),\n",
       " ('news', 'the'),\n",
       " ('news', 'petition'),\n",
       " ('news', 'as'),\n",
       " ('news', 'the'),\n",
       " ('news', \"mayor's\"),\n",
       " ('news', 'attorney'),\n",
       " ('news', '.'),\n",
       " ('news', 'Hartsfield'),\n",
       " ('news', 'has'),\n",
       " ('news', 'been'),\n",
       " ('news', 'mayor'),\n",
       " ('news', 'of'),\n",
       " ('news', 'Atlanta'),\n",
       " ('news', ','),\n",
       " ('news', 'with'),\n",
       " ('news', 'exception'),\n",
       " ('news', 'of'),\n",
       " ('news', 'one'),\n",
       " ('news', 'brief'),\n",
       " ('news', 'interlude'),\n",
       " ('news', ','),\n",
       " ('news', 'since'),\n",
       " ('news', '1937'),\n",
       " ('news', '.'),\n",
       " ('news', 'His'),\n",
       " ('news', 'political'),\n",
       " ('news', 'career'),\n",
       " ('news', 'goes'),\n",
       " ('news', 'back'),\n",
       " ('news', 'to'),\n",
       " ('news', 'his'),\n",
       " ('news', 'election'),\n",
       " ('news', 'to'),\n",
       " ('news', 'city'),\n",
       " ('news', 'council'),\n",
       " ('news', 'in'),\n",
       " ('news', '1923'),\n",
       " ('news', '.'),\n",
       " ('news', 'The'),\n",
       " ('news', \"mayor's\"),\n",
       " ('news', 'present'),\n",
       " ('news', 'term'),\n",
       " ('news', 'of'),\n",
       " ('news', 'office'),\n",
       " ('news', 'expires'),\n",
       " ('news', 'Jan.'),\n",
       " ('news', '1'),\n",
       " ('news', '.'),\n",
       " ('news', 'He'),\n",
       " ('news', 'will'),\n",
       " ('news', 'be'),\n",
       " ('news', 'succeeded'),\n",
       " ('news', 'by'),\n",
       " ('news', 'Ivan'),\n",
       " ('news', 'Allen'),\n",
       " ('news', 'Jr.'),\n",
       " ('news', ','),\n",
       " ('news', 'who'),\n",
       " ('news', 'became'),\n",
       " ('news', 'a'),\n",
       " ('news', 'candidate'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', 'Sept.'),\n",
       " ('news', '13'),\n",
       " ('news', 'primary'),\n",
       " ('news', 'after'),\n",
       " ('news', 'Mayor'),\n",
       " ('news', 'Hartsfield'),\n",
       " ('news', 'announced'),\n",
       " ('news', 'that'),\n",
       " ('news', 'he'),\n",
       " ('news', 'would'),\n",
       " ('news', 'not'),\n",
       " ('news', 'run'),\n",
       " ('news', 'for'),\n",
       " ('news', 'reelection'),\n",
       " ('news', '.'),\n",
       " ('news', 'Georgia'),\n",
       " ('news', 'Republicans'),\n",
       " ('news', 'are'),\n",
       " ('news', 'getting'),\n",
       " ('news', 'strong'),\n",
       " ('news', 'encouragement'),\n",
       " ('news', 'to'),\n",
       " ('news', 'enter'),\n",
       " ('news', 'a'),\n",
       " ('news', 'candidate'),\n",
       " ('news', 'in'),\n",
       " ('news', 'the'),\n",
       " ('news', '1962'),\n",
       " ('news', \"governor's\"),\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_word = [(genre, word)\n",
    "               for genre in ['news', 'romance']\n",
    "               for word in brown.words(categories=genre)]\n",
    "\n",
    "genre_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConditionalFreqDist(nltk.probability.FreqDist,\n",
       "                    {'news': FreqDist({'The': 806,\n",
       "                               'Fulton': 14,\n",
       "                               'County': 35,\n",
       "                               'Grand': 6,\n",
       "                               'Jury': 2,\n",
       "                               'said': 402,\n",
       "                               'Friday': 41,\n",
       "                               'an': 300,\n",
       "                               'investigation': 9,\n",
       "                               'of': 2849,\n",
       "                               \"Atlanta's\": 4,\n",
       "                               'recent': 20,\n",
       "                               'primary': 17,\n",
       "                               'election': 38,\n",
       "                               'produced': 6,\n",
       "                               '``': 732,\n",
       "                               'no': 109,\n",
       "                               'evidence': 17,\n",
       "                               \"''\": 702,\n",
       "                               'that': 802,\n",
       "                               'any': 90,\n",
       "                               'irregularities': 3,\n",
       "                               'took': 47,\n",
       "                               'place': 25,\n",
       "                               '.': 4030,\n",
       "                               'jury': 44,\n",
       "                               'further': 16,\n",
       "                               'in': 1893,\n",
       "                               'term-end': 1,\n",
       "                               'presentments': 1,\n",
       "                               'the': 5580,\n",
       "                               'City': 44,\n",
       "                               'Executive': 6,\n",
       "                               'Committee': 37,\n",
       "                               ',': 5188,\n",
       "                               'which': 244,\n",
       "                               'had': 279,\n",
       "                               'over-all': 2,\n",
       "                               'charge': 17,\n",
       "                               'deserves': 3,\n",
       "                               'praise': 2,\n",
       "                               'and': 2146,\n",
       "                               'thanks': 6,\n",
       "                               'Atlanta': 14,\n",
       "                               'for': 943,\n",
       "                               'manner': 7,\n",
       "                               'was': 717,\n",
       "                               'conducted': 8,\n",
       "                               'September-October': 1,\n",
       "                               'term': 13,\n",
       "                               'been': 212,\n",
       "                               'charged': 12,\n",
       "                               'by': 497,\n",
       "                               'Superior': 5,\n",
       "                               'Court': 26,\n",
       "                               'Judge': 28,\n",
       "                               'Durwood': 1,\n",
       "                               'Pye': 1,\n",
       "                               'to': 2116,\n",
       "                               'investigate': 3,\n",
       "                               'reports': 12,\n",
       "                               'possible': 28,\n",
       "                               'hard-fought': 1,\n",
       "                               'won': 24,\n",
       "                               'Mayor-nominate': 1,\n",
       "                               'Ivan': 2,\n",
       "                               'Allen': 7,\n",
       "                               'Jr.': 46,\n",
       "                               'Only': 8,\n",
       "                               'a': 1993,\n",
       "                               'relative': 3,\n",
       "                               'handful': 1,\n",
       "                               'such': 70,\n",
       "                               'received': 33,\n",
       "                               'considering': 2,\n",
       "                               'widespread': 4,\n",
       "                               'interest': 32,\n",
       "                               'number': 32,\n",
       "                               'voters': 12,\n",
       "                               'size': 8,\n",
       "                               'this': 250,\n",
       "                               'city': 49,\n",
       "                               'it': 363,\n",
       "                               'did': 63,\n",
       "                               'find': 16,\n",
       "                               'many': 60,\n",
       "                               \"Georgia's\": 7,\n",
       "                               'registration': 2,\n",
       "                               'laws': 30,\n",
       "                               'are': 328,\n",
       "                               'outmoded': 1,\n",
       "                               'or': 173,\n",
       "                               'inadequate': 4,\n",
       "                               'often': 14,\n",
       "                               'ambiguous': 1,\n",
       "                               'It': 115,\n",
       "                               'recommended': 9,\n",
       "                               'legislators': 8,\n",
       "                               'act': 20,\n",
       "                               'have': 265,\n",
       "                               'these': 59,\n",
       "                               'studied': 7,\n",
       "                               'revised': 2,\n",
       "                               'end': 29,\n",
       "                               'modernizing': 1,\n",
       "                               'improving': 4,\n",
       "                               'them': 96,\n",
       "                               'grand': 13,\n",
       "                               'commented': 7,\n",
       "                               'on': 657,\n",
       "                               'other': 149,\n",
       "                               'topics': 2,\n",
       "                               'among': 24,\n",
       "                               'purchasing': 3,\n",
       "                               'departments': 2,\n",
       "                               'well': 43,\n",
       "                               'operated': 4,\n",
       "                               'follow': 12,\n",
       "                               'generally': 14,\n",
       "                               'accepted': 4,\n",
       "                               'practices': 7,\n",
       "                               'inure': 1,\n",
       "                               'best': 29,\n",
       "                               'both': 56,\n",
       "                               'governments': 5,\n",
       "                               'Merger': 1,\n",
       "                               'proposed': 18,\n",
       "                               'However': 12,\n",
       "                               'believes': 8,\n",
       "                               'two': 157,\n",
       "                               'offices': 4,\n",
       "                               'should': 59,\n",
       "                               'be': 526,\n",
       "                               'combined': 9,\n",
       "                               'achieve': 6,\n",
       "                               'greater': 10,\n",
       "                               'efficiency': 2,\n",
       "                               'reduce': 8,\n",
       "                               'cost': 15,\n",
       "                               'administration': 52,\n",
       "                               'Purchasing': 1,\n",
       "                               'Department': 20,\n",
       "                               'is': 732,\n",
       "                               'lacking': 3,\n",
       "                               'experienced': 4,\n",
       "                               'clerical': 4,\n",
       "                               'personnel': 11,\n",
       "                               'as': 481,\n",
       "                               'result': 30,\n",
       "                               'policies': 8,\n",
       "                               'urged': 11,\n",
       "                               'take': 48,\n",
       "                               'steps': 8,\n",
       "                               'remedy': 1,\n",
       "                               'problem': 39,\n",
       "                               'Implementation': 1,\n",
       "                               'automobile': 4,\n",
       "                               'title': 3,\n",
       "                               'law': 38,\n",
       "                               'also': 120,\n",
       "                               'outgoing': 3,\n",
       "                               'next': 40,\n",
       "                               'Legislature': 19,\n",
       "                               'provide': 24,\n",
       "                               'enabling': 5,\n",
       "                               'funds': 28,\n",
       "                               're-set': 1,\n",
       "                               'effective': 15,\n",
       "                               'date': 16,\n",
       "                               'so': 67,\n",
       "                               'orderly': 3,\n",
       "                               'implementation': 1,\n",
       "                               'may': 66,\n",
       "                               'effected': 1,\n",
       "                               'swipe': 1,\n",
       "                               'at': 598,\n",
       "                               'State': 63,\n",
       "                               'Welfare': 3,\n",
       "                               \"Department's\": 2,\n",
       "                               'handling': 3,\n",
       "                               'federal': 35,\n",
       "                               'granted': 5,\n",
       "                               'child': 9,\n",
       "                               'welfare': 13,\n",
       "                               'services': 18,\n",
       "                               'foster': 1,\n",
       "                               'homes': 9,\n",
       "                               'This': 70,\n",
       "                               'one': 184,\n",
       "                               'major': 28,\n",
       "                               'items': 4,\n",
       "                               'general': 29,\n",
       "                               'assistance': 8,\n",
       "                               'program': 66,\n",
       "                               'but': 174,\n",
       "                               'has': 300,\n",
       "                               'seen': 7,\n",
       "                               'fit': 3,\n",
       "                               'distribute': 2,\n",
       "                               'through': 54,\n",
       "                               'all': 163,\n",
       "                               'counties': 13,\n",
       "                               'state': 90,\n",
       "                               'with': 545,\n",
       "                               'exception': 4,\n",
       "                               'receives': 1,\n",
       "                               'none': 7,\n",
       "                               'money': 29,\n",
       "                               'jurors': 4,\n",
       "                               'they': 205,\n",
       "                               'realize': 4,\n",
       "                               'proportionate': 1,\n",
       "                               'distribution': 7,\n",
       "                               'might': 38,\n",
       "                               'disable': 1,\n",
       "                               'our': 55,\n",
       "                               'less': 10,\n",
       "                               'populous': 3,\n",
       "                               'Nevertheless': 1,\n",
       "                               'we': 77,\n",
       "                               'feel': 19,\n",
       "                               'future': 25,\n",
       "                               'receive': 15,\n",
       "                               'some': 95,\n",
       "                               'portion': 2,\n",
       "                               'available': 10,\n",
       "                               'Failure': 2,\n",
       "                               'do': 63,\n",
       "                               'will': 389,\n",
       "                               'continue': 11,\n",
       "                               'disproportionate': 1,\n",
       "                               'burden': 2,\n",
       "                               'taxpayers': 5,\n",
       "                               \"ordinary's\": 1,\n",
       "                               'court': 29,\n",
       "                               'under': 83,\n",
       "                               'fire': 21,\n",
       "                               'its': 174,\n",
       "                               'appointment': 8,\n",
       "                               'appraisers': 1,\n",
       "                               'guardians': 2,\n",
       "                               'administrators': 1,\n",
       "                               'awarding': 1,\n",
       "                               'fees': 13,\n",
       "                               'compensation': 4,\n",
       "                               'Wards': 1,\n",
       "                               'protected': 1,\n",
       "                               'found': 30,\n",
       "                               'incorporated': 1,\n",
       "                               'into': 114,\n",
       "                               'operating': 4,\n",
       "                               'procedures': 5,\n",
       "                               'recommendations': 6,\n",
       "                               'previous': 11,\n",
       "                               'juries': 1,\n",
       "                               'Bar': 2,\n",
       "                               'Association': 18,\n",
       "                               'interim': 2,\n",
       "                               'citizens': 6,\n",
       "                               'committee': 38,\n",
       "                               'These': 11,\n",
       "                               'actions': 6,\n",
       "                               'serve': 7,\n",
       "                               'protect': 2,\n",
       "                               'fact': 25,\n",
       "                               'effect': 17,\n",
       "                               \"court's\": 1,\n",
       "                               'wards': 1,\n",
       "                               'from': 344,\n",
       "                               'undue': 2,\n",
       "                               'costs': 18,\n",
       "                               'appointed': 6,\n",
       "                               'elected': 11,\n",
       "                               'servants': 5,\n",
       "                               'unmeritorious': 1,\n",
       "                               'criticisms': 2,\n",
       "                               'Regarding': 1,\n",
       "                               'new': 148,\n",
       "                               'multi-million-dollar': 1,\n",
       "                               'airport': 3,\n",
       "                               'when': 128,\n",
       "                               'management': 6,\n",
       "                               'takes': 7,\n",
       "                               'Jan.': 15,\n",
       "                               '1': 47,\n",
       "                               'eliminate': 5,\n",
       "                               'political': 27,\n",
       "                               'influences': 1,\n",
       "                               'not': 254,\n",
       "                               'elaborate': 3,\n",
       "                               'added': 33,\n",
       "                               'there': 131,\n",
       "                               'periodic': 1,\n",
       "                               'surveillance': 1,\n",
       "                               'pricing': 3,\n",
       "                               'concessionaires': 1,\n",
       "                               'purpose': 9,\n",
       "                               'keeping': 4,\n",
       "                               'prices': 19,\n",
       "                               'reasonable': 2,\n",
       "                               'Ask': 1,\n",
       "                               'jail': 6,\n",
       "                               'deputies': 3,\n",
       "                               'On': 34,\n",
       "                               'matters': 3,\n",
       "                               ':': 149,\n",
       "                               '(': 168,\n",
       "                               ')': 171,\n",
       "                               'Four': 9,\n",
       "                               'additional': 14,\n",
       "                               'employed': 5,\n",
       "                               'Jail': 2,\n",
       "                               'doctor': 3,\n",
       "                               'medical': 18,\n",
       "                               'intern': 1,\n",
       "                               'extern': 1,\n",
       "                               'night': 64,\n",
       "                               'weekend': 12,\n",
       "                               'duty': 2,\n",
       "                               '2': 33,\n",
       "                               'work': 66,\n",
       "                               'officials': 12,\n",
       "                               'pass': 15,\n",
       "                               'legislation': 14,\n",
       "                               'permit': 6,\n",
       "                               'establishment': 7,\n",
       "                               'fair': 10,\n",
       "                               'equitable': 1,\n",
       "                               'pension': 5,\n",
       "                               'plan': 45,\n",
       "                               'employes': 9,\n",
       "                               'praised': 3,\n",
       "                               'operation': 15,\n",
       "                               'Police': 9,\n",
       "                               'Tax': 5,\n",
       "                               \"Commissioner's\": 1,\n",
       "                               'Office': 4,\n",
       "                               'Bellwood': 1,\n",
       "                               'Alpharetta': 1,\n",
       "                               'prison': 7,\n",
       "                               'farms': 3,\n",
       "                               'Grady': 5,\n",
       "                               'Hospital': 21,\n",
       "                               'Health': 5,\n",
       "                               'Mayor': 17,\n",
       "                               'William': 36,\n",
       "                               'B.': 31,\n",
       "                               'Hartsfield': 5,\n",
       "                               'filed': 7,\n",
       "                               'suit': 6,\n",
       "                               'divorce': 3,\n",
       "                               'his': 399,\n",
       "                               'wife': 35,\n",
       "                               'Pearl': 1,\n",
       "                               'Williams': 14,\n",
       "                               'His': 29,\n",
       "                               'petition': 6,\n",
       "                               'mental': 1,\n",
       "                               'cruelty': 1,\n",
       "                               'couple': 13,\n",
       "                               'married': 8,\n",
       "                               'Aug.': 8,\n",
       "                               '1913': 2,\n",
       "                               'They': 62,\n",
       "                               'son': 22,\n",
       "                               'Berry': 5,\n",
       "                               'daughter': 26,\n",
       "                               'Mrs.': 253,\n",
       "                               'J.': 42,\n",
       "                               'M.': 22,\n",
       "                               'Cheshire': 1,\n",
       "                               'Griffin': 2,\n",
       "                               'Attorneys': 2,\n",
       "                               'mayor': 2,\n",
       "                               'amicable': 1,\n",
       "                               'property': 16,\n",
       "                               'settlement': 3,\n",
       "                               'agreed': 15,\n",
       "                               'upon': 23,\n",
       "                               'listed': 10,\n",
       "                               \"mayor's\": 4,\n",
       "                               'occupation': 4,\n",
       "                               'attorney': 17,\n",
       "                               'age': 11,\n",
       "                               '71': 4,\n",
       "                               \"wife's\": 1,\n",
       "                               '74': 3,\n",
       "                               'birth': 5,\n",
       "                               'Opelika': 1,\n",
       "                               'Ala.': 7,\n",
       "                               'lived': 3,\n",
       "                               'together': 27,\n",
       "                               'man': 72,\n",
       "                               'more': 171,\n",
       "                               'than': 138,\n",
       "                               'year': 138,\n",
       "                               'home': 127,\n",
       "                               '637': 1,\n",
       "                               'E.': 34,\n",
       "                               'Pelham': 5,\n",
       "                               'Rd.': 3,\n",
       "                               'Aj': 14,\n",
       "                               'Henry': 18,\n",
       "                               'L.': 25,\n",
       "                               'Bowden': 2,\n",
       "                               'brief': 2,\n",
       "                               'interlude': 1,\n",
       "                               'since': 61,\n",
       "                               '1937': 2,\n",
       "                               'career': 10,\n",
       "                               'goes': 5,\n",
       "                               'back': 69,\n",
       "                               'council': 19,\n",
       "                               '1923': 2,\n",
       "                               'present': 30,\n",
       "                               'office': 24,\n",
       "                               'expires': 1,\n",
       "                               'He': 191,\n",
       "                               'succeeded': 3,\n",
       "                               'who': 268,\n",
       "                               'became': 20,\n",
       "                               'candidate': 17,\n",
       "                               'Sept.': 6,\n",
       "                               '13': 16,\n",
       "                               'after': 127,\n",
       "                               'announced': 37,\n",
       "                               'he': 451,\n",
       "                               'would': 244,\n",
       "                               'run': 35,\n",
       "                               'reelection': 1,\n",
       "                               'Georgia': 18,\n",
       "                               'Republicans': 15,\n",
       "                               'getting': 17,\n",
       "                               'strong': 13,\n",
       "                               'encouragement': 5,\n",
       "                               'enter': 5,\n",
       "                               '1962': 5,\n",
       "                               \"governor's\": 4,\n",
       "                               'race': 20,\n",
       "                               'top': 34,\n",
       "                               'official': 16,\n",
       "                               'Wednesday': 22,\n",
       "                               'Robert': 28,\n",
       "                               'Snodgrass': 1,\n",
       "                               'GOP': 5,\n",
       "                               'chairman': 35,\n",
       "                               'meeting': 62,\n",
       "                               'held': 41,\n",
       "                               'Tuesday': 43,\n",
       "                               'Blue': 11,\n",
       "                               'Ridge': 3,\n",
       "                               'brought': 21,\n",
       "                               'enthusiastic': 3,\n",
       "                               'responses': 1,\n",
       "                               'audience': 12,\n",
       "                               'Party': 9,\n",
       "                               'Chairman': 8,\n",
       "                               'James': 37,\n",
       "                               'W.': 38,\n",
       "                               'Dorsey': 1,\n",
       "                               'enthusiasm': 3,\n",
       "                               'picking': 1,\n",
       "                               'up': 168,\n",
       "                               'rally': 3,\n",
       "                               '8': 22,\n",
       "                               'Savannah': 1,\n",
       "                               'newly': 6,\n",
       "                               'Texas': 48,\n",
       "                               'Sen.': 18,\n",
       "                               'John': 65,\n",
       "                               'Tower': 1,\n",
       "                               'featured': 3,\n",
       "                               'speaker': 4,\n",
       "                               'In': 127,\n",
       "                               'warned': 2,\n",
       "                               'entering': 5,\n",
       "                               'governor': 13,\n",
       "                               'force': 7,\n",
       "                               'petitions': 6,\n",
       "                               'out': 161,\n",
       "                               'voting': 7,\n",
       "                               'precincts': 4,\n",
       "                               'obtain': 8,\n",
       "                               'signatures': 5,\n",
       "                               'registered': 2,\n",
       "                               'Despite': 5,\n",
       "                               'warning': 4,\n",
       "                               'unanimous': 2,\n",
       "                               'vote': 28,\n",
       "                               'according': 23,\n",
       "                               'attended': 10,\n",
       "                               'When': 41,\n",
       "                               'crowd': 8,\n",
       "                               'asked': 34,\n",
       "                               'whether': 18,\n",
       "                               'wanted': 20,\n",
       "                               'wait': 4,\n",
       "                               'make': 43,\n",
       "                               'voted': 9,\n",
       "                               '--': 300,\n",
       "                               'were': 252,\n",
       "                               'dissents': 1,\n",
       "                               'largest': 10,\n",
       "                               'hurdle': 1,\n",
       "                               'face': 19,\n",
       "                               'says': 28,\n",
       "                               'before': 86,\n",
       "                               'making': 25,\n",
       "                               'first': 143,\n",
       "                               'alternative': 4,\n",
       "                               'courses': 5,\n",
       "                               'must': 50,\n",
       "                               'taken': 30,\n",
       "                               'Five': 4,\n",
       "                               'per': 61,\n",
       "                               'cent': 51,\n",
       "                               'each': 61,\n",
       "                               'county': 26,\n",
       "                               'sign': 9,\n",
       "                               'requesting': 1,\n",
       "                               'allowed': 8,\n",
       "                               'names': 6,\n",
       "                               'candidates': 10,\n",
       "                               'ballot': 8,\n",
       "                               'hold': 10,\n",
       "                               'unit': 10,\n",
       "                               'system': 47,\n",
       "                               'party': 34,\n",
       "                               'opposes': 2,\n",
       "                               'platform': 2,\n",
       "                               'Sam': 13,\n",
       "                               'Caldwell': 2,\n",
       "                               'Highway': 6,\n",
       "                               'public': 51,\n",
       "                               'relations': 16,\n",
       "                               'director': 30,\n",
       "                               'resigned': 5,\n",
       "                               'Lt.': 1,\n",
       "                               'Gov.': 10,\n",
       "                               'Garland': 3,\n",
       "                               \"Byrd's\": 1,\n",
       "                               'campaign': 17,\n",
       "                               \"Caldwell's\": 1,\n",
       "                               'resignation': 4,\n",
       "                               'expected': 40,\n",
       "                               'time': 97,\n",
       "                               'Rob': 1,\n",
       "                               'Ledford': 1,\n",
       "                               'Gainesville': 1,\n",
       "                               'assistant': 10,\n",
       "                               'three': 97,\n",
       "                               'years': 102,\n",
       "                               'gubernatorial': 6,\n",
       "                               'starts': 9,\n",
       "                               'become': 23,\n",
       "                               'coordinator': 5,\n",
       "                               'Byrd': 1,\n",
       "                               'wind': 4,\n",
       "                               '1961': 42,\n",
       "                               'session': 37,\n",
       "                               'Monday': 54,\n",
       "                               'head': 24,\n",
       "                               'where': 58,\n",
       "                               'highway': 7,\n",
       "                               'bond': 11,\n",
       "                               'approved': 8,\n",
       "                               'shortly': 5,\n",
       "                               'Before': 7,\n",
       "                               'adjournment': 2,\n",
       "                               'afternoon': 19,\n",
       "                               'Senate': 32,\n",
       "                               'approve': 2,\n",
       "                               'study': 13,\n",
       "                               'allotted': 2,\n",
       "                               'rural': 9,\n",
       "                               'urban': 4,\n",
       "                               'areas': 12,\n",
       "                               'determine': 3,\n",
       "                               'what': 76,\n",
       "                               'adjustments': 2,\n",
       "                               'made': 107,\n",
       "                               'Vandiver': 4,\n",
       "                               'traditional': 8,\n",
       "                               'visit': 6,\n",
       "                               'chambers': 2,\n",
       "                               'toward': 23,\n",
       "                               'likely': 7,\n",
       "                               'mention': 6,\n",
       "                               '$100': 7,\n",
       "                               'million': 45,\n",
       "                               'issue': 30,\n",
       "                               'earlier': 24,\n",
       "                               'priority': 4,\n",
       "                               'item': 1,\n",
       "                               'Construction': 2,\n",
       "                               'bonds': 29,\n",
       "                               'Meanwhile': 4,\n",
       "                               'learned': 7,\n",
       "                               'very': 33,\n",
       "                               'near': 16,\n",
       "                               'being': 56,\n",
       "                               'ready': 12,\n",
       "                               '$30': 1,\n",
       "                               'worth': 15,\n",
       "                               'reconstruction': 1,\n",
       "                               'go': 41,\n",
       "                               'courts': 6,\n",
       "                               'friendly': 3,\n",
       "                               'test': 15,\n",
       "                               'validity': 1,\n",
       "                               'then': 56,\n",
       "                               'sales': 51,\n",
       "                               'begin': 10,\n",
       "                               'contracts': 4,\n",
       "                               'let': 10,\n",
       "                               'repair': 2,\n",
       "                               'most': 74,\n",
       "                               'heavily': 5,\n",
       "                               'traveled': 2,\n",
       "                               'highways': 3,\n",
       "                               'A': 137,\n",
       "                               'source': 7,\n",
       "                               '$3': 1,\n",
       "                               '$4': 1,\n",
       "                               'Rural': 2,\n",
       "                               'Roads': 2,\n",
       "                               'Authority': 4,\n",
       "                               'road': 12,\n",
       "                               'construction': 14,\n",
       "                               'revolving': 3,\n",
       "                               'fund': 12,\n",
       "                               'department': 12,\n",
       "                               'apparently': 12,\n",
       "                               'intends': 1,\n",
       "                               'issued': 8,\n",
       "                               'every': 25,\n",
       "                               'old': 23,\n",
       "                               'ones': 8,\n",
       "                               'paid': 25,\n",
       "                               'off': 73,\n",
       "                               'tax': 53,\n",
       "                               'authorities': 7,\n",
       "                               'opened': 9,\n",
       "                               '1958': 19,\n",
       "                               'battle': 15,\n",
       "                               'against': 78,\n",
       "                               'issuance': 2,\n",
       "                               '$50': 2,\n",
       "                               'roads': 10,\n",
       "                               'Marvin': 2,\n",
       "                               'told': 53,\n",
       "                               'Constitution': 4,\n",
       "                               'however': 37,\n",
       "                               'consulted': 4,\n",
       "                               'yet': 10,\n",
       "                               'about': 136,\n",
       "                               'plans': 22,\n",
       "                               'Schley': 1,\n",
       "                               'Rep.': 10,\n",
       "                               'D.': 24,\n",
       "                               'offer': 9,\n",
       "                               'resolution': 21,\n",
       "                               'House': 71,\n",
       "                               'rescind': 2,\n",
       "                               \"body's\": 1,\n",
       "                               'action': 20,\n",
       "                               'itself': 10,\n",
       "                               '$10': 3,\n",
       "                               'day': 61,\n",
       "                               'increase': 24,\n",
       "                               'expense': 7,\n",
       "                               'allowances': 3,\n",
       "                               'Sunday': 51,\n",
       "                               'research': 15,\n",
       "                               'done': 24,\n",
       "                               'quickie': 1,\n",
       "                               'can': 93,\n",
       "                               'repealed': 1,\n",
       "                               'outright': 3,\n",
       "                               'notice': 5,\n",
       "                               'given': 37,\n",
       "                               'reconsideration': 2,\n",
       "                               'sought': 6,\n",
       "                               'While': 12,\n",
       "                               'emphasizing': 1,\n",
       "                               'technical': 7,\n",
       "                               'details': 3,\n",
       "                               'fully': 6,\n",
       "                               'worked': 12,\n",
       "                               'seek': 12,\n",
       "                               'set': 51,\n",
       "                               'aside': 5,\n",
       "                               'privilege': 3,\n",
       "                               '87-31': 1,\n",
       "                               'similar': 17,\n",
       "                               'passed': 18,\n",
       "                               '29-5': 1,\n",
       "                               'As': 36,\n",
       "                               'word': 14,\n",
       "                               'offered': 11,\n",
       "                               'pointed': 9,\n",
       "                               'last': 161,\n",
       "                               'November': 10,\n",
       "                               'rejected': 8,\n",
       "                               'constitutional': 8,\n",
       "                               'amendment': 5,\n",
       "                               'allow': 5,\n",
       "                               'pay': 33,\n",
       "                               'raises': 3,\n",
       "                               'sessions': 6,\n",
       "                               'veteran': 11,\n",
       "                               'Jackson': 5,\n",
       "                               'legislator': 2,\n",
       "                               'ask': 7,\n",
       "                               'aid': 25,\n",
       "                               'education': 31,\n",
       "                               'something': 14,\n",
       "                               'consistently': 1,\n",
       "                               'opposed': 9,\n",
       "                               'past': 35,\n",
       "                               'Mac': 1,\n",
       "                               'Barber': 5,\n",
       "                               'Commerce': 7,\n",
       "                               'asking': 5,\n",
       "                               'endorse': 3,\n",
       "                               'increased': 10,\n",
       "                               'support': 24,\n",
       "                               'provided': 8,\n",
       "                               'expended': 1,\n",
       "                               '13th': 5,\n",
       "                               'members': 69,\n",
       "                               'congressional': 6,\n",
       "                               'delegation': 3,\n",
       "                               'Washington': 48,\n",
       "                               'like': 46,\n",
       "                               'see': 38,\n",
       "                               'But': 109,\n",
       "                               'congressmen': 3,\n",
       "                               'specifically': 1,\n",
       "                               'him': 93,\n",
       "                               'tossed': 1,\n",
       "                               'hopper': 1,\n",
       "                               'formally': 7,\n",
       "                               'read': 13,\n",
       "                               'event': 15,\n",
       "                               'Congress': 21,\n",
       "                               'does': 26,\n",
       "                               'Board': 17,\n",
       "                               'Education': 15,\n",
       "                               'directed': 8,\n",
       "                               'give': 32,\n",
       "                               'teacher': 9,\n",
       "                               'Colquitt': 2,\n",
       "                               'After': 24,\n",
       "                               'long': 39,\n",
       "                               'hot': 9,\n",
       "                               'controversy': 5,\n",
       "                               'Miller': 3,\n",
       "                               'school': 65,\n",
       "                               'superintendent': 9,\n",
       "                               'policeman': 2,\n",
       "                               'put': 27,\n",
       "                               'coolest': 2,\n",
       "                               'I': 179,\n",
       "                               'ever': 32,\n",
       "                               'saw': 17,\n",
       "                               'Harry': 10,\n",
       "                               'Davis': 13,\n",
       "                               'agriculture': 2,\n",
       "                               'defeated': 5,\n",
       "                               'Felix': 2,\n",
       "                               'Bush': 3,\n",
       "                               'principal': 9,\n",
       "                               'Democratic': 37,\n",
       "                               '1,119': 1,\n",
       "                               'votes': 7,\n",
       "                               \"Saturday's\": 2,\n",
       "                               'got': 45,\n",
       "                               '402': 1,\n",
       "                               'Ordinary': 2,\n",
       "                               'Carey': 5,\n",
       "                               'armed': 7,\n",
       "                               'pistol': 3,\n",
       "                               'stood': 4,\n",
       "                               'polls': 3,\n",
       "                               'insure': 2,\n",
       "                               'order': 19,\n",
       "                               'calmest': 1,\n",
       "                               'Policeman': 1,\n",
       "                               'Tom': 6,\n",
       "                               'Being': 1,\n",
       "                               'just': 42,\n",
       "                               'church': 16,\n",
       "                               \"didn't\": 15,\n",
       "                               'smell': 2,\n",
       "                               'drop': 6,\n",
       "                               'liquor': 4,\n",
       "                               'bit': 7,\n",
       "                               'trouble': 8,\n",
       "                               'leading': 11,\n",
       "                               'quiet': 5,\n",
       "                               'marked': 4,\n",
       "                               'anonymous': 4,\n",
       "                               'midnight': 4,\n",
       "                               'phone': 5,\n",
       "                               'calls': 13,\n",
       "                               'veiled': 3,\n",
       "                               'threats': 1,\n",
       "                               'violence': 3,\n",
       "                               'former': 27,\n",
       "                               'George': 23,\n",
       "                               'P.': 18,\n",
       "                               'Callan': 1,\n",
       "                               'shot': 14,\n",
       "                               'himself': 21,\n",
       "                               'death': 10,\n",
       "                               'March': 36,\n",
       "                               '18': 20,\n",
       "                               'four': 73,\n",
       "                               'days': 38,\n",
       "                               'post': 10,\n",
       "                               'dispute': 2,\n",
       "                               'board': 47,\n",
       "                               'During': 5,\n",
       "                               'reportedly': 4,\n",
       "                               'telephone': 8,\n",
       "                               'too': 37,\n",
       "                               'subjected': 2,\n",
       "                               'soon': 15,\n",
       "                               'scheduled': 14,\n",
       "                               'Many': 12,\n",
       "                               'local': 39,\n",
       "                               'feared': 1,\n",
       "                               'carry': 11,\n",
       "                               'gun': 2,\n",
       "                               'promised': 4,\n",
       "                               'Sheriff': 2,\n",
       "                               'Tabb': 1,\n",
       "                               'ordinary': 7,\n",
       "                               'good': 50,\n",
       "                               'promise': 3,\n",
       "                               'Everything': 1,\n",
       "                               'went': 37,\n",
       "                               'real': 24,\n",
       "                               'smooth': 1,\n",
       "                               'sheriff': 3,\n",
       "                               'There': 58,\n",
       "                               \"wasn't\": 3,\n",
       "                               'Austin': 15,\n",
       "                               'approval': 8,\n",
       "                               'Price': 3,\n",
       "                               \"Daniel's\": 1,\n",
       "                               'abandoned': 3,\n",
       "                               'seemed': 12,\n",
       "                               'certain': 18,\n",
       "                               'Thursday': 20,\n",
       "                               'despite': 11,\n",
       "                               'adamant': 2,\n",
       "                               'protests': 1,\n",
       "                               'bankers': 8,\n",
       "                               'Daniel': 5,\n",
       "                               'personally': 3,\n",
       "                               'led': 17,\n",
       "                               'fight': 14,\n",
       "                               'measure': 13,\n",
       "                               'watered': 1,\n",
       "                               'down': 50,\n",
       "                               'considerably': 5,\n",
       "                               'rejection': 3,\n",
       "                               'Legislatures': 1,\n",
       "                               'hearing': 14,\n",
       "                               'Revenue': 5,\n",
       "                               'Taxation': 1,\n",
       "                               'Under': 8,\n",
       "                               'rules': 11,\n",
       "                               'automatically': 3,\n",
       "                               'subcommittee': 1,\n",
       "                               'week': 86,\n",
       "                               'questions': 8,\n",
       "                               'taunted': 1,\n",
       "                               'appearing': 1,\n",
       "                               'witnesses': 7,\n",
       "                               'left': 39,\n",
       "                               'little': 35,\n",
       "                               'doubt': 6,\n",
       "                               'recommend': 4,\n",
       "                               'passage': 3,\n",
       "                               'termed': 4,\n",
       "                               'extremely': 2,\n",
       "                               'conservative': 5,\n",
       "                               'estimate': 3,\n",
       "                               'produce': 7,\n",
       "                               '17': 14,\n",
       "                               'dollars': 15,\n",
       "                               'help': 30,\n",
       "                               'erase': 1,\n",
       "                               'anticipated': 4,\n",
       "                               'deficit': 1,\n",
       "                               '63': 1,\n",
       "                               'current': 13,\n",
       "                               'fiscal': 5,\n",
       "                               '31': 6,\n",
       "                               'merely': 15,\n",
       "                               'means': 18,\n",
       "                               'enforcing': 1,\n",
       "                               'escheat': 2,\n",
       "                               'books': 12,\n",
       "                               'republic': 1,\n",
       "                               'permits': 4,\n",
       "                               'over': 115,\n",
       "                               'bank': 11,\n",
       "                               'accounts': 2,\n",
       "                               'stocks': 10,\n",
       "                               'personal': 12,\n",
       "                               'persons': 24,\n",
       "                               'missing': 3,\n",
       "                               'seven': 16,\n",
       "                               'bill': 45,\n",
       "                               'drafted': 1,\n",
       "                               'banks': 4,\n",
       "                               'insurance': 4,\n",
       "                               'firms': 15,\n",
       "                               'pipeline': 2,\n",
       "                               'companies': 18,\n",
       "                               'corporations': 2,\n",
       "                               'report': 25,\n",
       "                               'treasurer': 6,\n",
       "                               'cannot': 15,\n",
       "                               'enforced': 3,\n",
       "                               'now': 76,\n",
       "                               'because': 51,\n",
       "                               'almost': 24,\n",
       "                               'impossible': 4,\n",
       "                               'locate': 1,\n",
       "                               'declared': 15,\n",
       "                               'Dewey': 1,\n",
       "                               'Lawrence': 12,\n",
       "                               'Tyler': 2,\n",
       "                               'lawyer': 9,\n",
       "                               'representing': 8,\n",
       "                               'Bankers': 3,\n",
       "                               'sounded': 1,\n",
       "                               'opposition': 8,\n",
       "                               'keynote': 3,\n",
       "                               'violate': 2,\n",
       "                               'their': 219,\n",
       "                               'contractual': 1,\n",
       "                               'obligations': 4,\n",
       "                               'depositors': 1,\n",
       "                               'undermine': 1,\n",
       "                               'confidence': 6,\n",
       "                               'customers': 7,\n",
       "                               'If': 29,\n",
       "                               'you': 55,\n",
       "                               'destroy': 5,\n",
       "                               'economy': 9,\n",
       "                               'You': 11,\n",
       "                               'circulation': 2,\n",
       "                               'millions': 9,\n",
       "                               'Charles': 22,\n",
       "                               'Hughes': 22,\n",
       "                               'Sherman': 9,\n",
       "                               'sponsor': 4,\n",
       "                               'failure': 5,\n",
       "                               'enact': 1,\n",
       "                               'amount': 18,\n",
       "                               'gift': 5,\n",
       "                               \"taxpayers'\": 2,\n",
       "                               'pockets': 2,\n",
       "                               'contention': 2,\n",
       "                               'denied': 5,\n",
       "                               'several': 34,\n",
       "                               'including': 25,\n",
       "                               'Scott': 3,\n",
       "                               'Hudson': 2,\n",
       "                               'Gaynor': 1,\n",
       "                               'Jones': 22,\n",
       "                               'Houston': 15,\n",
       "                               'Brady': 1,\n",
       "                               'Harlingen': 1,\n",
       "                               'Howard': 13,\n",
       "                               'Cox': 4,\n",
       "                               'argued': 7,\n",
       "                               'probably': 19,\n",
       "                               'unconstitutional': 1,\n",
       "                               'impair': 1,\n",
       "                               'complained': 4,\n",
       "                               'enough': 27,\n",
       "                               'introduced': 10,\n",
       "                               'only': 103,\n",
       "                               'Senators': 4,\n",
       "                               'unanimously': 2,\n",
       "                               'Parkhouse': 5,\n",
       "                               'Dallas': 49,\n",
       "                               'authorizing': 2,\n",
       "                               'schools': 37,\n",
       "                               'deaf': 5,\n",
       "                               'designed': 16,\n",
       "                               'special': 41,\n",
       "                               'schooling': 2,\n",
       "                               ...}),\n",
       "                     'romance': FreqDist({'They': 69,\n",
       "                               'neither': 7,\n",
       "                               'liked': 12,\n",
       "                               'nor': 5,\n",
       "                               'disliked': 4,\n",
       "                               'the': 2758,\n",
       "                               'Old': 17,\n",
       "                               'Man': 13,\n",
       "                               '.': 3736,\n",
       "                               'To': 15,\n",
       "                               'them': 142,\n",
       "                               'he': 702,\n",
       "                               'could': 193,\n",
       "                               'have': 258,\n",
       "                               'been': 179,\n",
       "                               'broken': 8,\n",
       "                               'bell': 4,\n",
       "                               'in': 875,\n",
       "                               'church': 29,\n",
       "                               'tower': 1,\n",
       "                               'which': 104,\n",
       "                               'rang': 6,\n",
       "                               'before': 88,\n",
       "                               'and': 1776,\n",
       "                               'after': 58,\n",
       "                               'Mass': 1,\n",
       "                               ',': 3899,\n",
       "                               'at': 402,\n",
       "                               'noon': 4,\n",
       "                               'six': 11,\n",
       "                               'each': 24,\n",
       "                               'evening': 14,\n",
       "                               '--': 291,\n",
       "                               'its': 69,\n",
       "                               'tone': 9,\n",
       "                               'repetitive': 1,\n",
       "                               'monotonous': 1,\n",
       "                               'never': 84,\n",
       "                               'breaking': 4,\n",
       "                               'boredom': 3,\n",
       "                               'of': 1186,\n",
       "                               'streets': 5,\n",
       "                               'The': 230,\n",
       "                               'was': 993,\n",
       "                               'unimportant': 1,\n",
       "                               'Yet': 9,\n",
       "                               'if': 142,\n",
       "                               'were': 214,\n",
       "                               'not': 250,\n",
       "                               'there': 169,\n",
       "                               'they': 168,\n",
       "                               'would': 244,\n",
       "                               'missed': 5,\n",
       "                               'him': 339,\n",
       "                               'as': 282,\n",
       "                               'sounds': 12,\n",
       "                               'bees': 1,\n",
       "                               'buzzing': 4,\n",
       "                               'against': 42,\n",
       "                               'screen': 4,\n",
       "                               'door': 43,\n",
       "                               'early': 21,\n",
       "                               'June': 4,\n",
       "                               ';': 264,\n",
       "                               'or': 150,\n",
       "                               'smell': 3,\n",
       "                               'thick': 9,\n",
       "                               'tomato': 1,\n",
       "                               'paste': 1,\n",
       "                               'ripe': 3,\n",
       "                               'that': 583,\n",
       "                               'both': 28,\n",
       "                               'sweet': 8,\n",
       "                               'sour': 1,\n",
       "                               'rising': 8,\n",
       "                               'up': 211,\n",
       "                               'from': 202,\n",
       "                               'aluminum': 1,\n",
       "                               'trays': 1,\n",
       "                               'wrapped': 3,\n",
       "                               'fly-dotted': 1,\n",
       "                               'cheesecloth': 1,\n",
       "                               'Or': 15,\n",
       "                               'surging': 1,\n",
       "                               'whirling': 2,\n",
       "                               'bats': 2,\n",
       "                               'night': 54,\n",
       "                               'when': 126,\n",
       "                               'their': 114,\n",
       "                               'black': 32,\n",
       "                               'bodies': 1,\n",
       "                               'dived': 1,\n",
       "                               'into': 136,\n",
       "                               'blackness': 1,\n",
       "                               'above': 17,\n",
       "                               'below': 4,\n",
       "                               'amber': 1,\n",
       "                               'street': 14,\n",
       "                               'lights': 2,\n",
       "                               'bay': 1,\n",
       "                               'female': 4,\n",
       "                               'dogs': 3,\n",
       "                               'heat': 4,\n",
       "                               'called': 31,\n",
       "                               'by': 107,\n",
       "                               'name': 13,\n",
       "                               'although': 4,\n",
       "                               'had': 692,\n",
       "                               'one': 166,\n",
       "                               'Filippo': 1,\n",
       "                               'Rossi': 1,\n",
       "                               \"that's\": 21,\n",
       "                               'what': 121,\n",
       "                               'old': 73,\n",
       "                               'country': 10,\n",
       "                               'but': 252,\n",
       "                               'here': 65,\n",
       "                               'just': 100,\n",
       "                               'Signore': 1,\n",
       "                               'But': 135,\n",
       "                               'this': 149,\n",
       "                               'unusual': 5,\n",
       "                               'because': 85,\n",
       "                               'youth': 5,\n",
       "                               'these': 30,\n",
       "                               'quarters': 4,\n",
       "                               'always': 49,\n",
       "                               'pushed': 7,\n",
       "                               'a': 1335,\n",
       "                               'distance': 7,\n",
       "                               'elders': 1,\n",
       "                               'Youth': 1,\n",
       "                               'obeyed': 2,\n",
       "                               'commanded': 2,\n",
       "                               'It': 144,\n",
       "                               'went': 82,\n",
       "                               'to': 1502,\n",
       "                               'on': 362,\n",
       "                               'Sunday': 5,\n",
       "                               'Saturday': 4,\n",
       "                               'month': 6,\n",
       "                               'confession': 2,\n",
       "                               'asked': 45,\n",
       "                               'nothing': 47,\n",
       "                               'parents': 6,\n",
       "                               'touch': 7,\n",
       "                               'hand': 35,\n",
       "                               'kiss': 3,\n",
       "                               'given': 18,\n",
       "                               'passing': 5,\n",
       "                               'only': 106,\n",
       "                               'thing': 52,\n",
       "                               'about': 164,\n",
       "                               'long': 65,\n",
       "                               'since': 19,\n",
       "                               'happened': 19,\n",
       "                               'past': 15,\n",
       "                               'dead': 15,\n",
       "                               'present': 9,\n",
       "                               'Once': 9,\n",
       "                               'wife': 21,\n",
       "                               'And': 129,\n",
       "                               'once': 38,\n",
       "                               'she': 496,\n",
       "                               'too': 92,\n",
       "                               'ignored': 2,\n",
       "                               'With': 13,\n",
       "                               'tiny': 12,\n",
       "                               'fur-piece': 1,\n",
       "                               'around': 68,\n",
       "                               'her': 651,\n",
       "                               'shoulders': 7,\n",
       "                               'wiggled': 1,\n",
       "                               'satin-covered': 1,\n",
       "                               'buttocks': 1,\n",
       "                               'down': 127,\n",
       "                               \"didn't\": 101,\n",
       "                               'stop': 16,\n",
       "                               'In': 55,\n",
       "                               'clutched': 1,\n",
       "                               'hundred': 4,\n",
       "                               'dollar': 3,\n",
       "                               'bill': 3,\n",
       "                               'other': 70,\n",
       "                               'straw': 1,\n",
       "                               'suitcase': 4,\n",
       "                               'way': 83,\n",
       "                               'strutted': 1,\n",
       "                               'blind': 2,\n",
       "                               'noticed': 3,\n",
       "                               'Without': 2,\n",
       "                               'looking': 36,\n",
       "                               'without': 30,\n",
       "                               'anything': 42,\n",
       "                               'except': 10,\n",
       "                               'Drexel': 3,\n",
       "                               'Street': 5,\n",
       "                               'directly': 2,\n",
       "                               'front': 17,\n",
       "                               'climbed': 7,\n",
       "                               'those': 53,\n",
       "                               'orange': 6,\n",
       "                               'streetcars': 1,\n",
       "                               'rode': 4,\n",
       "                               'away': 64,\n",
       "                               'it': 573,\n",
       "                               'came': 75,\n",
       "                               'back': 126,\n",
       "                               '``': 1045,\n",
       "                               \"shouldn't\": 10,\n",
       "                               'come': 73,\n",
       "                               'first': 52,\n",
       "                               'place': 45,\n",
       "                               \"''\": 1044,\n",
       "                               'women': 22,\n",
       "                               'said': 330,\n",
       "                               'No': 40,\n",
       "                               'no': 123,\n",
       "                               'Not': 23,\n",
       "                               'She': 232,\n",
       "                               'thought': 105,\n",
       "                               'bigger': 1,\n",
       "                               'than': 65,\n",
       "                               'we': 78,\n",
       "                               'are': 72,\n",
       "                               'Torino': 2,\n",
       "                               'Eh': 2,\n",
       "                               '!': 316,\n",
       "                               'gave': 32,\n",
       "                               'herself': 40,\n",
       "                               'fancy': 1,\n",
       "                               'airs': 1,\n",
       "                               'Just': 28,\n",
       "                               'part': 18,\n",
       "                               'stage': 2,\n",
       "                               'carry': 9,\n",
       "                               'head': 46,\n",
       "                               'higher': 3,\n",
       "                               'ours': 1,\n",
       "                               'slapped': 2,\n",
       "                               'thighs': 2,\n",
       "                               \"It's\": 28,\n",
       "                               'for': 410,\n",
       "                               'making': 17,\n",
       "                               'pretty': 19,\n",
       "                               'speeches': 1,\n",
       "                               'Dante': 1,\n",
       "                               'actresses': 1,\n",
       "                               'get': 92,\n",
       "                               'paid': 9,\n",
       "                               'so': 174,\n",
       "                               'good': 65,\n",
       "                               'Henh': 1,\n",
       "                               'Calloused': 1,\n",
       "                               'fingers': 13,\n",
       "                               'caressed': 2,\n",
       "                               'smoothness': 2,\n",
       "                               'polished': 1,\n",
       "                               'rosaries': 2,\n",
       "                               'swayed': 4,\n",
       "                               'excitedly': 1,\n",
       "                               'beneath': 6,\n",
       "                               'puckered': 1,\n",
       "                               'chins': 1,\n",
       "                               'where': 54,\n",
       "                               'hairs': 1,\n",
       "                               'sprouted': 1,\n",
       "                               'be': 289,\n",
       "                               'tweezed': 1,\n",
       "                               'Mauve-colored': 1,\n",
       "                               'mouths': 1,\n",
       "                               'known': 10,\n",
       "                               'sweeter': 2,\n",
       "                               'taste': 9,\n",
       "                               'new': 31,\n",
       "                               'wine': 5,\n",
       "                               'passion': 5,\n",
       "                               \"man's\": 9,\n",
       "                               'tongue': 11,\n",
       "                               'smiled': 23,\n",
       "                               'condemned': 2,\n",
       "                               'again': 53,\n",
       "                               'Puttana': 1,\n",
       "                               'even': 73,\n",
       "                               'his': 559,\n",
       "                               'now': 83,\n",
       "                               'nobody': 11,\n",
       "                               'cared': 5,\n",
       "                               'fig': 2,\n",
       "                               'enough': 40,\n",
       "                               'people': 48,\n",
       "                               'know': 88,\n",
       "                               'time': 93,\n",
       "                               'looked': 72,\n",
       "                               'fleshy': 1,\n",
       "                               'suppleness': 1,\n",
       "                               'woman': 34,\n",
       "                               'consumed': 2,\n",
       "                               'watching': 20,\n",
       "                               'become': 6,\n",
       "                               'thinner': 3,\n",
       "                               'thin': 11,\n",
       "                               'seams': 1,\n",
       "                               'stockings': 3,\n",
       "                               'still': 62,\n",
       "                               'His': 44,\n",
       "                               'voice': 33,\n",
       "                               'questioned': 2,\n",
       "                               'why': 34,\n",
       "                               'seen': 20,\n",
       "                               'wave': 2,\n",
       "                               'an': 152,\n",
       "                               'exhausted': 2,\n",
       "                               'farewell': 2,\n",
       "                               'might': 51,\n",
       "                               'shooing': 1,\n",
       "                               'fleas': 1,\n",
       "                               'hopped': 1,\n",
       "                               'yellow': 13,\n",
       "                               'dog': 8,\n",
       "                               'onto': 6,\n",
       "                               '(': 21,\n",
       "                               'He': 366,\n",
       "                               ')': 21,\n",
       "                               'eyes': 76,\n",
       "                               'miniature': 3,\n",
       "                               'sundials': 1,\n",
       "                               'variegated': 1,\n",
       "                               'altered': 2,\n",
       "                               'expression': 1,\n",
       "                               'direction': 6,\n",
       "                               \"Man's\": 2,\n",
       "                               'very': 50,\n",
       "                               'soul': 6,\n",
       "                               'left': 49,\n",
       "                               'flown': 1,\n",
       "                               \"wouldn't\": 33,\n",
       "                               'anyone': 11,\n",
       "                               'Perhaps': 9,\n",
       "                               'then': 101,\n",
       "                               'taking': 19,\n",
       "                               'withered': 1,\n",
       "                               'wrinkled': 3,\n",
       "                               'sister': 7,\n",
       "                               'Rose': 4,\n",
       "                               'care': 19,\n",
       "                               'children': 20,\n",
       "                               'guessed': 6,\n",
       "                               'all': 209,\n",
       "                               'remember': 14,\n",
       "                               'memory': 6,\n",
       "                               'climbing': 2,\n",
       "                               'streetcar': 1,\n",
       "                               '?': 690,\n",
       "                               'There': 66,\n",
       "                               'seemed': 51,\n",
       "                               'contemptuous': 1,\n",
       "                               'purpose': 1,\n",
       "                               'sat': 32,\n",
       "                               'with': 460,\n",
       "                               'glued': 2,\n",
       "                               'opposition': 1,\n",
       "                               'behind': 15,\n",
       "                               'For': 31,\n",
       "                               'saw': 47,\n",
       "                               'see': 74,\n",
       "                               'town': 15,\n",
       "                               'Italy': 7,\n",
       "                               'outskirts': 1,\n",
       "                               'Philadelphia': 1,\n",
       "                               'Bari': 1,\n",
       "                               'Chieti': 1,\n",
       "                               'smelled': 8,\n",
       "                               'What': 50,\n",
       "                               'did': 115,\n",
       "                               'matter': 18,\n",
       "                               'park': 5,\n",
       "                               'foot': 7,\n",
       "                               'Ash': 1,\n",
       "                               'Road': 1,\n",
       "                               'stretched': 2,\n",
       "                               'elevated': 1,\n",
       "                               'trains': 1,\n",
       "                               'roared': 2,\n",
       "                               'stucco': 2,\n",
       "                               'station': 3,\n",
       "                               \"city's\": 1,\n",
       "                               'center': 7,\n",
       "                               'half-hour': 1,\n",
       "                               'intervals': 3,\n",
       "                               'creek': 1,\n",
       "                               'spun': 4,\n",
       "                               'silent': 11,\n",
       "                               'course': 36,\n",
       "                               'toward': 22,\n",
       "                               'Schuylkill': 1,\n",
       "                               'This': 38,\n",
       "                               'hatred': 4,\n",
       "                               'companion': 3,\n",
       "                               'aloneness': 1,\n",
       "                               'same': 30,\n",
       "                               'Sameness': 2,\n",
       "                               'framed': 1,\n",
       "                               'wall': 8,\n",
       "                               'ginkgo': 1,\n",
       "                               'trees': 7,\n",
       "                               'divided': 3,\n",
       "                               'city': 10,\n",
       "                               'lined': 1,\n",
       "                               'two-story': 1,\n",
       "                               'houses': 6,\n",
       "                               'color': 13,\n",
       "                               'ash': 3,\n",
       "                               'slashed': 1,\n",
       "                               'sloping': 2,\n",
       "                               'manure-scented': 1,\n",
       "                               'lawns': 1,\n",
       "                               'concrete': 3,\n",
       "                               'steps': 11,\n",
       "                               'upward': 2,\n",
       "                               'white': 30,\n",
       "                               'wooden': 3,\n",
       "                               'porches': 2,\n",
       "                               'wicker': 1,\n",
       "                               'swings': 1,\n",
       "                               'screeched': 2,\n",
       "                               'rusted': 1,\n",
       "                               'hinges': 1,\n",
       "                               'doors': 3,\n",
       "                               'Even': 13,\n",
       "                               'stable-garage': 1,\n",
       "                               'housed': 2,\n",
       "                               'scent': 2,\n",
       "                               'rot': 1,\n",
       "                               'lawn': 2,\n",
       "                               'coffee': 19,\n",
       "                               'shop': 8,\n",
       "                               'men': 29,\n",
       "                               'spent': 9,\n",
       "                               'evenings': 1,\n",
       "                               'Sundays': 1,\n",
       "                               'playing': 5,\n",
       "                               'cards': 5,\n",
       "                               'rose': 9,\n",
       "                               'hedge': 2,\n",
       "                               'window': 9,\n",
       "                               'reeked': 1,\n",
       "                               'dregs': 1,\n",
       "                               'thrown': 3,\n",
       "                               'Only': 8,\n",
       "                               'house': 36,\n",
       "                               'squatted': 1,\n",
       "                               'low': 10,\n",
       "                               'square': 4,\n",
       "                               'upon': 16,\n",
       "                               'sidewalk': 1,\n",
       "                               'heavy': 13,\n",
       "                               'iron': 3,\n",
       "                               'grating': 1,\n",
       "                               'supporting': 2,\n",
       "                               'glass': 7,\n",
       "                               'facade': 2,\n",
       "                               'That': 29,\n",
       "                               \"Bartoli's\": 1,\n",
       "                               'Above': 3,\n",
       "                               'second-story': 1,\n",
       "                               'showroom': 1,\n",
       "                               'angels': 1,\n",
       "                               'surveyed': 1,\n",
       "                               'neighborhood': 5,\n",
       "                               'Did': 12,\n",
       "                               'everywhere': 2,\n",
       "                               'else': 29,\n",
       "                               'sameness': 1,\n",
       "                               'wood': 5,\n",
       "                               'blocks': 2,\n",
       "                               'like': 185,\n",
       "                               'fortresses': 2,\n",
       "                               'perched': 1,\n",
       "                               'slant': 1,\n",
       "                               'hill': 4,\n",
       "                               'top': 8,\n",
       "                               'beyond': 9,\n",
       "                               'cemetery': 6,\n",
       "                               'paved': 1,\n",
       "                               'alleyways': 1,\n",
       "                               'tunneled': 1,\n",
       "                               'through': 56,\n",
       "                               'walls': 10,\n",
       "                               'mysterious': 3,\n",
       "                               'core': 1,\n",
       "                               'intimacy': 1,\n",
       "                               'backyards': 1,\n",
       "                               'owned': 5,\n",
       "                               'fences': 1,\n",
       "                               'property': 2,\n",
       "                               'blended': 1,\n",
       "                               'next': 43,\n",
       "                               'form': 3,\n",
       "                               'courtyards': 1,\n",
       "                               'knew': 69,\n",
       "                               'privacy': 2,\n",
       "                               'Love': 4,\n",
       "                               'fear': 4,\n",
       "                               'shaded': 2,\n",
       "                               'grape': 2,\n",
       "                               'vines': 1,\n",
       "                               'forked': 3,\n",
       "                               'gossip': 3,\n",
       "                               'licked': 2,\n",
       "                               'sinister': 2,\n",
       "                               'porch': 7,\n",
       "                               'silently': 3,\n",
       "                               'fed': 3,\n",
       "                               'kept': 26,\n",
       "                               'alive': 10,\n",
       "                               'waiting': 15,\n",
       "                               'Waiting': 1,\n",
       "                               'whom': 5,\n",
       "                               'tell': 37,\n",
       "                               'though': 29,\n",
       "                               'made': 62,\n",
       "                               'pact': 1,\n",
       "                               'devil': 3,\n",
       "                               'himself': 53,\n",
       "                               'yet': 21,\n",
       "                               'pay': 8,\n",
       "                               'price': 5,\n",
       "                               'holding': 7,\n",
       "                               'out': 217,\n",
       "                               'something': 59,\n",
       "                               'determined': 3,\n",
       "                               'hold': 12,\n",
       "                               'son': 33,\n",
       "                               'threw': 9,\n",
       "                               'belly': 3,\n",
       "                               'step': 5,\n",
       "                               'coolness': 4,\n",
       "                               'dreaming': 3,\n",
       "                               'day': 63,\n",
       "                               'rich': 6,\n",
       "                               'At': 29,\n",
       "                               'fifteen': 8,\n",
       "                               'mother': 44,\n",
       "                               \"couldn't\": 46,\n",
       "                               'face': 44,\n",
       "                               'Aunt': 2,\n",
       "                               'provided': 2,\n",
       "                               'named': 7,\n",
       "                               'Pompeii': 5,\n",
       "                               'tribute': 2,\n",
       "                               'heritage': 1,\n",
       "                               'less': 12,\n",
       "                               'either': 9,\n",
       "                               'life': 51,\n",
       "                               'restless': 2,\n",
       "                               'began': 23,\n",
       "                               'sun': 23,\n",
       "                               'ended': 1,\n",
       "                               'sleep': 10,\n",
       "                               'When': 37,\n",
       "                               'man': 87,\n",
       "                               'Americans': 2,\n",
       "                               'who': 89,\n",
       "                               'lived': 19,\n",
       "                               'white-columned': 1,\n",
       "                               'side': 17,\n",
       "                               'ride': 5,\n",
       "                               'eight-thirty': 1,\n",
       "                               'local': 1,\n",
       "                               'morning': 40,\n",
       "                               'brief': 4,\n",
       "                               'case': 10,\n",
       "                               'Nor': 3,\n",
       "                               'work': 32,\n",
       "                               'cane': 4,\n",
       "                               'sit': 6,\n",
       "                               'inside': 11,\n",
       "                               'pound': 1,\n",
       "                               'gloved': 1,\n",
       "                               'fist': 3,\n",
       "                               'table': 19,\n",
       "                               'girl': 26,\n",
       "                               'hear': 16,\n",
       "                               'running': 11,\n",
       "                               'bowing': 3,\n",
       "                               'calling': 5,\n",
       "                               'your': 106,\n",
       "                               'service': 6,\n",
       "                               'order': 8,\n",
       "                               'bring': 9,\n",
       "                               'take': 62,\n",
       "                               'vest': 1,\n",
       "                               'pocket': 6,\n",
       "                               'pipe': 6,\n",
       "                               'stuff': 5,\n",
       "                               'remove': 4,\n",
       "                               'gloves': 1,\n",
       "                               'light': 24,\n",
       "                               'smoke': 7,\n",
       "                               'do': 109,\n",
       "                               'Hey': 4,\n",
       "                               'Laura': 5,\n",
       "                               'ten': 11,\n",
       "                               'months': 11,\n",
       "                               'older': 7,\n",
       "                               'you': 456,\n",
       "                               'say': 60,\n",
       "                               'I': 951,\n",
       "                               'smoked': 3,\n",
       "                               'answer': 11,\n",
       "                               'leaned': 10,\n",
       "                               'unconcerned': 1,\n",
       "                               'fence': 3,\n",
       "                               'brushing': 2,\n",
       "                               'drying': 2,\n",
       "                               'wet': 10,\n",
       "                               'gilded': 1,\n",
       "                               'hair': 30,\n",
       "                               'One': 16,\n",
       "                               'lithe': 1,\n",
       "                               'leg': 7,\n",
       "                               'straddled': 1,\n",
       "                               'railing': 1,\n",
       "                               'swung': 4,\n",
       "                               'loosely': 1,\n",
       "                               'creaking': 1,\n",
       "                               'torn': 3,\n",
       "                               'pales': 1,\n",
       "                               'Her': 29,\n",
       "                               'tanned': 2,\n",
       "                               'whose': 9,\n",
       "                               'arch': 2,\n",
       "                               'swept': 2,\n",
       "                               'high': 20,\n",
       "                               'pointed': 7,\n",
       "                               'artfully': 1,\n",
       "                               'tapering': 1,\n",
       "                               'toes': 5,\n",
       "                               'tips': 1,\n",
       "                               'glowed': 1,\n",
       "                               'All': 33,\n",
       "                               'while': 48,\n",
       "                               'sinewy': 1,\n",
       "                               'arms': 13,\n",
       "                               'swirled': 1,\n",
       "                               'chest': 6,\n",
       "                               'showed': 7,\n",
       "                               'sign': 6,\n",
       "                               'having': 24,\n",
       "                               'heard': 31,\n",
       "                               'lost': 13,\n",
       "                               'childlike': 1,\n",
       "                               'softness': 1,\n",
       "                               'beginning': 9,\n",
       "                               'fold': 3,\n",
       "                               'within': 11,\n",
       "                               'fragile': 1,\n",
       "                               'features': 2,\n",
       "                               'harshness': 1,\n",
       "                               'belied': 1,\n",
       "                               'lyric': 1,\n",
       "                               'lines': 7,\n",
       "                               'contours': 1,\n",
       "                               'blue': 19,\n",
       "                               'somewhat': 7,\n",
       "                               'downcast': 1,\n",
       "                               'possessed': 1,\n",
       "                               'sullen': 3,\n",
       "                               'quality': 3,\n",
       "                               'boy': 38,\n",
       "                               'clouded': 1,\n",
       "                               'sure': 30,\n",
       "                               'fully': 3,\n",
       "                               'took': 48,\n",
       "                               'reached': 6,\n",
       "                               'screeching': 1,\n",
       "                               'rail': 1,\n",
       "                               'moving': 6,\n",
       "                               \"She's\": 10,\n",
       "                               'mood': 5,\n",
       "                               \"There's\": 8,\n",
       "                               \"doesn't\": 12,\n",
       "                               'Well': 34,\n",
       "                               'shining': 7,\n",
       "                               'dreams': 2,\n",
       "                               'dream': 8,\n",
       "                               'wanted': 44,\n",
       "                               'Suddenly': 6,\n",
       "                               'interrupted': 4,\n",
       "                               'daydreaming': 1,\n",
       "                               'warm': 10,\n",
       "                               'wetness': 1,\n",
       "                               'lapping': 2,\n",
       "                               'chin': 3,\n",
       "                               'opened': 13,\n",
       "                               'wide': 10,\n",
       "                               'sight': 6,\n",
       "                               \"goat's\": 2,\n",
       "                               'claret': 1,\n",
       "                               'feasting': 1,\n",
       "                               'salt': 1,\n",
       "                               'aged': 3,\n",
       "                               'eye': 11,\n",
       "                               'sallow': 1,\n",
       "                               'time-cast': 1,\n",
       "                               'encrusted': 1,\n",
       "                               'sphere': 2,\n",
       "                               'marbleized': 1,\n",
       "                               'pink': 17,\n",
       "                               'skin': 6,\n",
       "                               'stared': 14,\n",
       "                               'unfalteringly': 1,\n",
       "                               'Christ': 2,\n",
       "                               'sake': 6,\n",
       "                               'goat': 3,\n",
       "                               'git': 1,\n",
       "                               \"You're\": 16,\n",
       "                               'boiling': 3,\n",
       "                               'milk': 5,\n",
       "                               \"ain't\": 4,\n",
       "                               'Soothing': 1,\n",
       "                               'knowing': 11,\n",
       "                               'whiskered': 1,\n",
       "                               'jowls': 2,\n",
       "                               'swollen': 2,\n",
       "                               'teats': 2,\n",
       "                               'expectantly': 1,\n",
       "                               'rolled': 6,\n",
       "                               'over': 88,\n",
       "                               'undulated': 1,\n",
       "                               'gradually': 1,\n",
       "                               'covering': 1,\n",
       "                               'space': 7,\n",
       "                               'straining': 2,\n",
       "                               'taut': 3,\n",
       "                               'warmth': 3,\n",
       "                               'mouth': 11,\n",
       "                               'squirted': 1,\n",
       "                               'roof': 3,\n",
       "                               'savored': 1,\n",
       "                               'earthy': 1,\n",
       "                               \"boy's\": 4,\n",
       "                               'operated': 1,\n",
       "                               'skilled': 1,\n",
       "                               'unity': 1,\n",
       "                               'bagpipe': 1,\n",
       "                               'player': 3,\n",
       "                               'pressing': 1,\n",
       "                               'pulling': 1,\n",
       "                               'delighting': 1,\n",
       "                               'slid': 6,\n",
       "                               'evasive': 1,\n",
       "                               'shadow': 3,\n",
       "                               'storm': 2,\n",
       "                               'cloud': 1,\n",
       "                               'Its': 1,\n",
       "                               'figure': 7,\n",
       "                               'fluttering': 1,\n",
       "                               'soutane': 1,\n",
       "                               'near': 9,\n",
       "                               'corner': 9,\n",
       "                               'let': 39,\n",
       "                               'pass': 3,\n",
       "                               'sensing': 1,\n",
       "                               'portentous': 1,\n",
       "                               'also': 15,\n",
       "                               'raise': 3,\n",
       "                               'finger': 2,\n",
       "                               'smooth': 5,\n",
       "                               \"dog's\": 1,\n",
       "                               'perhaps': 15,\n",
       "                               'reassured': 2,\n",
       "                               'due': 4,\n",
       "                               'Time': 1,\n",
       "                               'give': 28,\n",
       "                               'meantime': 1,\n",
       "                               'sandals': 3,\n",
       "                               'stained': 1,\n",
       "                               'ocher': 1,\n",
       "                               \"Pompeii's\": 1,\n",
       "                               'shaved': 4,\n",
       "                               'edged': 1,\n",
       "                               'close': 16,\n",
       "                               'clapping': 1,\n",
       "                               'ecstatic': 1,\n",
       "                               'pleasure': 7,\n",
       "                               'quickly': 8,\n",
       "                               'released': 1,\n",
       "                               'pretended': 2,\n",
       "                               'examining': 3,\n",
       "                               'haunches': 1,\n",
       "                               'ticks': 1,\n",
       "                               'glance': 6,\n",
       "                               'biggest': 1,\n",
       "                               'belonged': 3,\n",
       "                               'Niobe': 1,\n",
       "                               'neatest': 1,\n",
       "                               'ones': 10,\n",
       "                               'Concetta': 1,\n",
       "                               'laced': 1,\n",
       "                               'Romeo': 1,\n",
       "                               \"Concetta's\": 2,\n",
       "                               'idiot': 1,\n",
       "                               'brother': 5,\n",
       "                               'expected': 6,\n",
       "                               \"Romeo's\": 1,\n",
       "                               'small': 31,\n",
       "                               'body': 19,\n",
       "                               'sink': 3,\n",
       "                               'closer': 6,\n",
       "                               'ground': 8,\n",
       "                               'reach': 5,\n",
       "                               'grasp': 1,\n",
       "                               'shrill': 3,\n",
       "                               'impetuous': 1,\n",
       "                               'sound': 23,\n",
       "                               'rotundity': 1,\n",
       "                               'disfigured': 2,\n",
       "                               'flesh': 7,\n",
       "                               'hearing': 9,\n",
       "                               'People': 2,\n",
       "                               'baby': 25,\n",
       "                               'room': 45,\n",
       "                               'filled': 5,\n",
       "                               \"Maggie's\": 3,\n",
       "                               'throbbed': 1,\n",
       "                               'excitement': 5,\n",
       "                               'fatigue': 1,\n",
       "                               'Stuart': 6,\n",
       "                               'such': 21,\n",
       "                               'happy': 8,\n",
       "                               'earnest': 1,\n",
       "                               'look': 54,\n",
       "                               'proud': 5,\n",
       "                               'possession': 2,\n",
       "                               'Maggie': 22,\n",
       "                               'bear': 4,\n",
       "                               'quench': 1,\n",
       "                               'Little': 5,\n",
       "                               'Anne': 23,\n",
       "                               'rapidly': 2,\n",
       "                               'outdistanced': 1,\n",
       "                               'recovery': 1,\n",
       "                               'two': 48,\n",
       "                               'became': 7,\n",
       "                               'fat': 5,\n",
       "                               'highly': 1,\n",
       "                               'social': 6,\n",
       "                               'fuzz': 1,\n",
       "                               'flaxen': 1,\n",
       "                               'stopped': 25,\n",
       "                               'flying': 4,\n",
       "                               'rages': 1,\n",
       "                               'started': 22,\n",
       "                               'digesting': 1,\n",
       "                               'food': 9,\n",
       "                               'developed': 5,\n",
       "                               'peaches': 1,\n",
       "                               'cream': 1,\n",
       "                               'complexion': 3,\n",
       "                               'sunny': 3,\n",
       "                               'disposition': 1,\n",
       "                               'more': 85,\n",
       "                               'dry': 4,\n",
       "                               'comfortable': 7,\n",
       "                               'huge': 2,\n",
       "                               'amounts': 1,\n",
       "                               'stated': 1,\n",
       "                               'carried': 7,\n",
       "                               'watch': 11,\n",
       "                               'activity': 3,\n",
       "                               'going': 60,\n",
       "                               'shook': 8,\n",
       "                               'lifting': 1,\n",
       "                               'seem': 10,\n",
       "                               'strength': 8,\n",
       "                               'catch': 3,\n",
       "                               ':': 56,\n",
       "                               'big': 36,\n",
       "                               'basket': 2,\n",
       "                               'clothes': 26,\n",
       "                               'coaxed': 1,\n",
       "                               'rackety': 1,\n",
       "                               'washer': 1,\n",
       "                               'lugged': 3,\n",
       "                               'daily': 1,\n",
       "                               'round': 7,\n",
       "                               'household': 2,\n",
       "                               'chores': 1,\n",
       "                               'insisted': 6,\n",
       "                               'participating': 1,\n",
       "                               'Worry': 1,\n",
       "                               'great': 30,\n",
       "                               'deal': 4,\n",
       "                               'laid': 5,\n",
       "                               'off': 56,\n",
       "                               'produce': 1,\n",
       "                               'company': 13,\n",
       "                               'go': 76,\n",
       "                               'sitting': 19,\n",
       "                               \"father's\": 5,\n",
       "                               'office': 13,\n",
       "                               'salary': 1,\n",
       "                               'father': 23,\n",
       "                               'Mr.': 33,\n",
       "                               'Clifton': 1,\n",
       "                               'preferred': 1,\n",
       "                               'death': 12,\n",
       "                               'bankruptcy': 1,\n",
       "                               'stay': 22,\n",
       "                               \"wife's\": 2,\n",
       "                               'contributing': 2,\n",
       "                               \"family's\": 1,\n",
       "                               'upkeep': 2,\n",
       "                               'besides': 3,\n",
       "                               'things': 30,\n",
       "                               'bought': 5,\n",
       "                               'juice': 4,\n",
       "                               'vitamins': 1,\n",
       "                               'soap': 2,\n",
       "                               'plain': 5,\n",
       "                               'pored': 1,\n",
       "                               'figures': 7,\n",
       "                               'every': 23,\n",
       "                               'trying': 23,\n",
       "                               'find': 34,\n",
       "                               'how': 60,\n",
       "                               'squeeze': 1,\n",
       "                               'few': 37,\n",
       "                               'pennies': 1,\n",
       "                               'desperation': 2,\n",
       "                               'consulted': 1,\n",
       "                               'Eugenia': 15,\n",
       "                               'afternoon': 12,\n",
       "                               'Do': 12,\n",
       "                               'think': 56,\n",
       "                               'me': 193,\n",
       "                               'home': 46,\n",
       "                               'make': 49,\n",
       "                               'some': 69,\n",
       "                               'money': 24,\n",
       "                               'rest': 17,\n",
       "                               'seems': 2,\n",
       "                               'is': 150,\n",
       "                               'washing': 4,\n",
       "                               'machine': 3,\n",
       "                               'stove': 5,\n",
       "                               'plenty': 8,\n",
       "                               'odd': 4,\n",
       "                               'moments': 9,\n",
       "                               'doing': 20,\n",
       "                               'feel': 36,\n",
       "                               'lot': 17,\n",
       "                               'better': 32,\n",
       "                               \"Woman's\": 1,\n",
       "                               'Exchange': 1,\n",
       "                               \"isn't\": 20,\n",
       "                               'baked': 2,\n",
       "                               'goods': 1,\n",
       "                               'any': 67,\n",
       "                               \"can't\": 24,\n",
       "                               'leave': 24,\n",
       "                               'Grandma': 10,\n",
       "                               'strong': 9,\n",
       "                               \"baby's\": 4,\n",
       "                               'young': 49,\n",
       "                               'put': 49,\n",
       "                               'nursery': 2,\n",
       "                               'should': 32,\n",
       "                               'can': 74,\n",
       "                               'keeping': 6,\n",
       "                               'child': 17,\n",
       "                               'starched': 1,\n",
       "                               'dresses': 3,\n",
       "                               'changed': 9,\n",
       "                               'nineteen': 1,\n",
       "                               'times': 14,\n",
       "                               'beautiful': 25,\n",
       "                               'keep': 26,\n",
       "                               'nice': 18,\n",
       "                               'picked': 16,\n",
       "                               'nuzzled': 1,\n",
       "                               'little': 99,\n",
       "                               'neck': 12,\n",
       "                               \"She'll\": 4,\n",
       "                               'ironed': 1,\n",
       "                               'Evadna': 3,\n",
       "                               'Mae': 3,\n",
       "                               'Evans': 8,\n",
       "                               'flannel': 2,\n",
       "                               'wrapper': 1,\n",
       "                               'until': 34,\n",
       "                               'nine': 4,\n",
       "                               'got': 89,\n",
       "                               \"Best's\": 1,\n",
       "                               'Liliputian': 1,\n",
       "                               'Bazaar': 1,\n",
       "                               'New': 15,\n",
       "                               'York': 13,\n",
       "                               ...})})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'romance']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd.conditions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Generating Random Text with Bigrams\n",
    "bigrams() function takes a list of words and builds a list of consecutive word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'the'),\n",
       " ('the', 'beginning'),\n",
       " ('beginning', 'God'),\n",
       " ('God', 'created'),\n",
       " ('created', 'the'),\n",
       " ('the', 'heaven'),\n",
       " ('heaven', 'and'),\n",
       " ('and', 'the'),\n",
       " ('the', 'earth'),\n",
       " ('earth', '.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.']\n",
    "list(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Wordlist Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['now', 'im', 'left', 'with', 'this', 'gay', 'name', ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.nps_chat.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords: high-frequency words like the, to and also that we sometimes want to filter out of a document\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be',\n",
       " 'bg',\n",
       " 'bs',\n",
       " 'ca',\n",
       " 'cs',\n",
       " 'cu',\n",
       " 'de',\n",
       " 'en',\n",
       " 'es',\n",
       " 'fr',\n",
       " 'hr',\n",
       " 'it',\n",
       " 'la',\n",
       " 'mk',\n",
       " 'nl',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'ro',\n",
       " 'ru',\n",
       " 'sk',\n",
       " 'sl',\n",
       " 'sr',\n",
       " 'sw',\n",
       " 'uk']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swadesh wordlists, lists of about 200 common words in several languages\n",
    "from nltk.corpus import swadesh\n",
    "swadesh.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'you (singular), thou',\n",
       " 'he',\n",
       " 'we',\n",
       " 'you (plural)',\n",
       " 'they',\n",
       " 'this',\n",
       " 'that',\n",
       " 'here',\n",
       " 'there',\n",
       " 'who',\n",
       " 'what',\n",
       " 'where',\n",
       " 'when',\n",
       " 'how',\n",
       " 'not',\n",
       " 'all',\n",
       " 'many',\n",
       " 'some',\n",
       " 'few',\n",
       " 'other',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'big',\n",
       " 'long',\n",
       " 'wide',\n",
       " 'thick',\n",
       " 'heavy',\n",
       " 'small',\n",
       " 'short',\n",
       " 'narrow',\n",
       " 'thin',\n",
       " 'woman',\n",
       " 'man (adult male)',\n",
       " 'man (human being)',\n",
       " 'child',\n",
       " 'wife',\n",
       " 'husband',\n",
       " 'mother',\n",
       " 'father',\n",
       " 'animal',\n",
       " 'fish',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'louse',\n",
       " 'snake',\n",
       " 'worm',\n",
       " 'tree',\n",
       " 'forest',\n",
       " 'stick',\n",
       " 'fruit',\n",
       " 'seed',\n",
       " 'leaf',\n",
       " 'root',\n",
       " 'bark (from tree)',\n",
       " 'flower',\n",
       " 'grass',\n",
       " 'rope',\n",
       " 'skin',\n",
       " 'meat',\n",
       " 'blood',\n",
       " 'bone',\n",
       " 'fat (noun)',\n",
       " 'egg',\n",
       " 'horn',\n",
       " 'tail',\n",
       " 'feather',\n",
       " 'hair',\n",
       " 'head',\n",
       " 'ear',\n",
       " 'eye',\n",
       " 'nose',\n",
       " 'mouth',\n",
       " 'tooth',\n",
       " 'tongue',\n",
       " 'fingernail',\n",
       " 'foot',\n",
       " 'leg',\n",
       " 'knee',\n",
       " 'hand',\n",
       " 'wing',\n",
       " 'belly',\n",
       " 'guts',\n",
       " 'neck',\n",
       " 'back',\n",
       " 'breast',\n",
       " 'heart',\n",
       " 'liver',\n",
       " 'drink',\n",
       " 'eat',\n",
       " 'bite',\n",
       " 'suck',\n",
       " 'spit',\n",
       " 'vomit',\n",
       " 'blow',\n",
       " 'breathe',\n",
       " 'laugh',\n",
       " 'see',\n",
       " 'hear',\n",
       " 'know (a fact)',\n",
       " 'think',\n",
       " 'smell',\n",
       " 'fear',\n",
       " 'sleep',\n",
       " 'live',\n",
       " 'die',\n",
       " 'kill',\n",
       " 'fight',\n",
       " 'hunt',\n",
       " 'hit',\n",
       " 'cut',\n",
       " 'split',\n",
       " 'stab',\n",
       " 'scratch',\n",
       " 'dig',\n",
       " 'swim',\n",
       " 'fly (verb)',\n",
       " 'walk',\n",
       " 'come',\n",
       " 'lie',\n",
       " 'sit',\n",
       " 'stand',\n",
       " 'turn',\n",
       " 'fall',\n",
       " 'give',\n",
       " 'hold',\n",
       " 'squeeze',\n",
       " 'rub',\n",
       " 'wash',\n",
       " 'wipe',\n",
       " 'pull',\n",
       " 'push',\n",
       " 'throw',\n",
       " 'tie',\n",
       " 'sew',\n",
       " 'count',\n",
       " 'say',\n",
       " 'sing',\n",
       " 'play',\n",
       " 'float',\n",
       " 'flow',\n",
       " 'freeze',\n",
       " 'swell',\n",
       " 'sun',\n",
       " 'moon',\n",
       " 'star',\n",
       " 'water',\n",
       " 'rain',\n",
       " 'river',\n",
       " 'lake',\n",
       " 'sea',\n",
       " 'salt',\n",
       " 'stone',\n",
       " 'sand',\n",
       " 'dust',\n",
       " 'earth',\n",
       " 'cloud',\n",
       " 'fog',\n",
       " 'sky',\n",
       " 'wind',\n",
       " 'snow',\n",
       " 'ice',\n",
       " 'smoke',\n",
       " 'fire',\n",
       " 'ashes',\n",
       " 'burn',\n",
       " 'road',\n",
       " 'mountain',\n",
       " 'red',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'white',\n",
       " 'black',\n",
       " 'night',\n",
       " 'day',\n",
       " 'year',\n",
       " 'warm',\n",
       " 'cold',\n",
       " 'full',\n",
       " 'new',\n",
       " 'old',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'rotten',\n",
       " 'dirty',\n",
       " 'straight',\n",
       " 'round',\n",
       " 'sharp',\n",
       " 'dull',\n",
       " 'smooth',\n",
       " 'wet',\n",
       " 'dry',\n",
       " 'correct',\n",
       " 'near',\n",
       " 'far',\n",
       " 'right',\n",
       " 'left',\n",
       " 'at',\n",
       " 'in',\n",
       " 'with',\n",
       " 'and',\n",
       " 'if',\n",
       " 'because',\n",
       " 'name']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swadesh.words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'je'),\n",
       " ('you (singular), thou', 'tu, vous'),\n",
       " ('he', 'il'),\n",
       " ('we', 'nous'),\n",
       " ('you (plural)', 'vous'),\n",
       " ('they', 'ils, elles'),\n",
       " ('this', 'ceci'),\n",
       " ('that', 'cela'),\n",
       " ('here', 'ici'),\n",
       " ('there', 'l'),\n",
       " ('who', 'qui'),\n",
       " ('what', 'quoi'),\n",
       " ('where', 'o'),\n",
       " ('when', 'quand'),\n",
       " ('how', 'comment'),\n",
       " ('not', 'ne...pas'),\n",
       " ('all', 'tout'),\n",
       " ('many', 'plusieurs'),\n",
       " ('some', 'quelques'),\n",
       " ('few', 'peu'),\n",
       " ('other', 'autre'),\n",
       " ('one', 'un'),\n",
       " ('two', 'deux'),\n",
       " ('three', 'trois'),\n",
       " ('four', 'quatre'),\n",
       " ('five', 'cinq'),\n",
       " ('big', 'grand'),\n",
       " ('long', 'long'),\n",
       " ('wide', 'large'),\n",
       " ('thick', 'pais'),\n",
       " ('heavy', 'lourd'),\n",
       " ('small', 'petit'),\n",
       " ('short', 'court'),\n",
       " ('narrow', 'troit'),\n",
       " ('thin', 'mince'),\n",
       " ('woman', 'femme'),\n",
       " ('man (adult male)', 'homme'),\n",
       " ('man (human being)', 'homme'),\n",
       " ('child', 'enfant'),\n",
       " ('wife', 'femme, pouse'),\n",
       " ('husband', 'mari, poux'),\n",
       " ('mother', 'mre'),\n",
       " ('father', 'pre'),\n",
       " ('animal', 'animal'),\n",
       " ('fish', 'poisson'),\n",
       " ('bird', 'oiseau'),\n",
       " ('dog', 'chien'),\n",
       " ('louse', 'pou'),\n",
       " ('snake', 'serpent'),\n",
       " ('worm', 'ver'),\n",
       " ('tree', 'arbre'),\n",
       " ('forest', 'fort'),\n",
       " ('stick', 'bton'),\n",
       " ('fruit', 'fruit'),\n",
       " ('seed', 'graine'),\n",
       " ('leaf', 'feuille'),\n",
       " ('root', 'racine'),\n",
       " ('bark (from tree)', 'corce'),\n",
       " ('flower', 'fleur'),\n",
       " ('grass', 'herbe'),\n",
       " ('rope', 'corde'),\n",
       " ('skin', 'peau'),\n",
       " ('meat', 'viande'),\n",
       " ('blood', 'sang'),\n",
       " ('bone', 'os'),\n",
       " ('fat (noun)', 'graisse'),\n",
       " ('egg', 'uf'),\n",
       " ('horn', 'corne'),\n",
       " ('tail', 'queue'),\n",
       " ('feather', 'plume'),\n",
       " ('hair', 'cheveu'),\n",
       " ('head', 'tte'),\n",
       " ('ear', 'oreille'),\n",
       " ('eye', 'il'),\n",
       " ('nose', 'nez'),\n",
       " ('mouth', 'bouche'),\n",
       " ('tooth', 'dent'),\n",
       " ('tongue', 'langue'),\n",
       " ('fingernail', 'ongle'),\n",
       " ('foot', 'pied'),\n",
       " ('leg', 'jambe'),\n",
       " ('knee', 'genou'),\n",
       " ('hand', 'main'),\n",
       " ('wing', 'aile'),\n",
       " ('belly', 'ventre'),\n",
       " ('guts', 'entrailles'),\n",
       " ('neck', 'cou'),\n",
       " ('back', 'dos'),\n",
       " ('breast', 'sein, poitrine'),\n",
       " ('heart', 'cur'),\n",
       " ('liver', 'foie'),\n",
       " ('drink', 'boire'),\n",
       " ('eat', 'manger'),\n",
       " ('bite', 'mordre'),\n",
       " ('suck', 'sucer'),\n",
       " ('spit', 'cracher'),\n",
       " ('vomit', 'vomir'),\n",
       " ('blow', 'souffler'),\n",
       " ('breathe', 'respirer'),\n",
       " ('laugh', 'rire'),\n",
       " ('see', 'voir'),\n",
       " ('hear', 'entendre'),\n",
       " ('know (a fact)', 'savoir'),\n",
       " ('think', 'penser'),\n",
       " ('smell', 'sentir'),\n",
       " ('fear', 'craindre, avoir peur'),\n",
       " ('sleep', 'dormir'),\n",
       " ('live', 'vivre'),\n",
       " ('die', 'mourir'),\n",
       " ('kill', 'tuer'),\n",
       " ('fight', 'se battre'),\n",
       " ('hunt', 'chasser'),\n",
       " ('hit', 'frapper'),\n",
       " ('cut', 'couper'),\n",
       " ('split', 'fendre'),\n",
       " ('stab', 'poignarder'),\n",
       " ('scratch', 'gratter'),\n",
       " ('dig', 'creuser'),\n",
       " ('swim', 'nager'),\n",
       " ('fly (verb)', 'voler'),\n",
       " ('walk', 'marcher'),\n",
       " ('come', 'venir'),\n",
       " ('lie', \"s'tendre\"),\n",
       " ('sit', \"s'asseoir\"),\n",
       " ('stand', 'se lever'),\n",
       " ('turn', 'tourner'),\n",
       " ('fall', 'tomber'),\n",
       " ('give', 'donner'),\n",
       " ('hold', 'tenir'),\n",
       " ('squeeze', 'serrer'),\n",
       " ('rub', 'frotter'),\n",
       " ('wash', 'laver'),\n",
       " ('wipe', 'essuyer'),\n",
       " ('pull', 'tirer'),\n",
       " ('push', 'pousser'),\n",
       " ('throw', 'jeter'),\n",
       " ('tie', 'lier'),\n",
       " ('sew', 'coudre'),\n",
       " ('count', 'compter'),\n",
       " ('say', 'dire'),\n",
       " ('sing', 'chanter'),\n",
       " ('play', 'jouer'),\n",
       " ('float', 'flotter'),\n",
       " ('flow', 'couler'),\n",
       " ('freeze', 'geler'),\n",
       " ('swell', 'gonfler'),\n",
       " ('sun', 'soleil'),\n",
       " ('moon', 'lune'),\n",
       " ('star', 'toile'),\n",
       " ('water', 'eau'),\n",
       " ('rain', 'pluie'),\n",
       " ('river', 'rivire'),\n",
       " ('lake', 'lac'),\n",
       " ('sea', 'mer'),\n",
       " ('salt', 'sel'),\n",
       " ('stone', 'pierre'),\n",
       " ('sand', 'sable'),\n",
       " ('dust', 'poussire'),\n",
       " ('earth', 'terre'),\n",
       " ('cloud', 'nuage'),\n",
       " ('fog', 'brouillard'),\n",
       " ('sky', 'ciel'),\n",
       " ('wind', 'vent'),\n",
       " ('snow', 'neige'),\n",
       " ('ice', 'glace'),\n",
       " ('smoke', 'fume'),\n",
       " ('fire', 'feu'),\n",
       " ('ashes', 'cendres'),\n",
       " ('burn', 'brler'),\n",
       " ('road', 'route'),\n",
       " ('mountain', 'montagne'),\n",
       " ('red', 'rouge'),\n",
       " ('green', 'vert'),\n",
       " ('yellow', 'jaune'),\n",
       " ('white', 'blanc'),\n",
       " ('black', 'noir'),\n",
       " ('night', 'nuit'),\n",
       " ('day', 'jour'),\n",
       " ('year', 'an, anne'),\n",
       " ('warm', 'chaud'),\n",
       " ('cold', 'froid'),\n",
       " ('full', 'plein'),\n",
       " ('new', 'nouveau'),\n",
       " ('old', 'vieux'),\n",
       " ('good', 'bon'),\n",
       " ('bad', 'mauvais'),\n",
       " ('rotten', 'pourri'),\n",
       " ('dirty', 'sale'),\n",
       " ('straight', 'droit'),\n",
       " ('round', 'rond'),\n",
       " ('sharp', 'tranchant, pointu, aigu'),\n",
       " ('dull', 'mouss'),\n",
       " ('smooth', 'lisse'),\n",
       " ('wet', 'mouill'),\n",
       " ('dry', 'sec'),\n",
       " ('correct', 'juste, correct'),\n",
       " ('near', 'proche'),\n",
       " ('far', 'loin'),\n",
       " ('right', ' droite'),\n",
       " ('left', ' gauche'),\n",
       " ('at', ''),\n",
       " ('in', 'dans'),\n",
       " ('with', 'avec'),\n",
       " ('and', 'et'),\n",
       " ('if', 'si'),\n",
       " ('because', 'parce que'),\n",
       " ('name', 'nom')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access cognate words from multiple languages using the entries() method\n",
    "en2fr = swadesh.entries(['en', 'fr'])\n",
    "en2fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chien'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate = dict(en2fr)\n",
    "translate['dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Senses and Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.01.auto'),\n",
       " Lemma('car.n.01.automobile'),\n",
       " Lemma('car.n.01.machine'),\n",
       " Lemma('car.n.01.motorcar')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the lemmas for a given synset\n",
    "wn.synset('car.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('car.n.01.automobile')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up a particular lemma\n",
    "wn.lemma('car.n.01.automobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('car.n.01')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the synset corresponding to a lemma\n",
    "wn.lemma('car.n.01.automobile').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the \"name\" of a lemma\n",
    "wn.lemma('car.n.01.automobile').name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
      "['car', 'railcar', 'railway_car', 'railroad_car']\n",
      "['car', 'gondola']\n",
      "['car', 'elevator_car']\n",
      "['cable_car', 'car']\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 The WordNet Hierarchy\n",
    "WordNet synsets correspond to abstract concepts, these concepts are linked together in a hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ambulance.n.01'),\n",
       " Synset('beach_wagon.n.01'),\n",
       " Synset('bus.n.04'),\n",
       " Synset('cab.n.03'),\n",
       " Synset('compact.n.03'),\n",
       " Synset('convertible.n.01'),\n",
       " Synset('coupe.n.01'),\n",
       " Synset('cruiser.n.01'),\n",
       " Synset('electric.n.01'),\n",
       " Synset('gas_guzzler.n.01'),\n",
       " Synset('hardtop.n.01'),\n",
       " Synset('hatchback.n.01'),\n",
       " Synset('horseless_carriage.n.01'),\n",
       " Synset('hot_rod.n.01'),\n",
       " Synset('jeep.n.01'),\n",
       " Synset('limousine.n.01'),\n",
       " Synset('loaner.n.02'),\n",
       " Synset('minicar.n.01'),\n",
       " Synset('minivan.n.01'),\n",
       " Synset('model_t.n.01'),\n",
       " Synset('pace_car.n.01'),\n",
       " Synset('racer.n.02'),\n",
       " Synset('roadster.n.01'),\n",
       " Synset('sedan.n.01'),\n",
       " Synset('sport_utility.n.01'),\n",
       " Synset('sports_car.n.01'),\n",
       " Synset('stanley_steamer.n.01'),\n",
       " Synset('stock_car.n.01'),\n",
       " Synset('subcompact.n.01'),\n",
       " Synset('touring_car.n.01'),\n",
       " Synset('used-car.n.01')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar = wn.synset('car.n.01')\n",
    "types_of_motorcar = motorcar.hyponyms()\n",
    "types_of_motorcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model_T',\n",
       " 'S.U.V.',\n",
       " 'SUV',\n",
       " 'Stanley_Steamer',\n",
       " 'ambulance',\n",
       " 'beach_waggon',\n",
       " 'beach_wagon',\n",
       " 'bus',\n",
       " 'cab',\n",
       " 'compact',\n",
       " 'compact_car',\n",
       " 'convertible',\n",
       " 'coupe',\n",
       " 'cruiser',\n",
       " 'electric',\n",
       " 'electric_automobile',\n",
       " 'electric_car',\n",
       " 'estate_car',\n",
       " 'gas_guzzler',\n",
       " 'hack',\n",
       " 'hardtop',\n",
       " 'hatchback',\n",
       " 'heap',\n",
       " 'horseless_carriage',\n",
       " 'hot-rod',\n",
       " 'hot_rod',\n",
       " 'jalopy',\n",
       " 'jeep',\n",
       " 'landrover',\n",
       " 'limo',\n",
       " 'limousine',\n",
       " 'loaner',\n",
       " 'minicar',\n",
       " 'minivan',\n",
       " 'pace_car',\n",
       " 'patrol_car',\n",
       " 'phaeton',\n",
       " 'police_car',\n",
       " 'police_cruiser',\n",
       " 'prowl_car',\n",
       " 'race_car',\n",
       " 'racer',\n",
       " 'racing_car',\n",
       " 'roadster',\n",
       " 'runabout',\n",
       " 'saloon',\n",
       " 'secondhand_car',\n",
       " 'sedan',\n",
       " 'sport_car',\n",
       " 'sport_utility',\n",
       " 'sport_utility_vehicle',\n",
       " 'sports_car',\n",
       " 'squad_car',\n",
       " 'station_waggon',\n",
       " 'station_wagon',\n",
       " 'stock_car',\n",
       " 'subcompact',\n",
       " 'subcompact_car',\n",
       " 'taxi',\n",
       " 'taxicab',\n",
       " 'tourer',\n",
       " 'touring_car',\n",
       " 'two-seater',\n",
       " 'used-car',\n",
       " 'waggon',\n",
       " 'wagon']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the (immediate) hyponyms\n",
    "sorted(lemma.name() for synset in types_of_motorcar for lemma in synset.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also navigate up the hierarchy by visiting hypernyms. Some words have multiple paths, because they can be classified in more than one way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('entity.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('artifact.n.01'),\n",
       "  Synset('instrumentality.n.03'),\n",
       "  Synset('container.n.01'),\n",
       "  Synset('wheeled_vehicle.n.01'),\n",
       "  Synset('self-propelled_vehicle.n.01'),\n",
       "  Synset('motor_vehicle.n.01'),\n",
       "  Synset('car.n.01')],\n",
       " [Synset('entity.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('artifact.n.01'),\n",
       "  Synset('instrumentality.n.03'),\n",
       "  Synset('conveyance.n.03'),\n",
       "  Synset('vehicle.n.01'),\n",
       "  Synset('wheeled_vehicle.n.01'),\n",
       "  Synset('self-propelled_vehicle.n.01'),\n",
       "  Synset('motor_vehicle.n.01'),\n",
       "  Synset('car.n.01')]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = motorcar.hypernym_paths()\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'container.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'conveyance.n.03',\n",
       " 'vehicle.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the most general hypernyms (or root hypernyms) of a synset\n",
    "motorcar.root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.n.02: (often followed by `of') a large number or amount or extent\n",
      "mint.n.02: any north temperate plant of the genus Mentha with aromatic leaves and small mauve flowers\n",
      "mint.n.03: any member of the mint family of plants\n",
      "mint.n.04: the leaves of a mint plant used fresh or candied\n",
      "mint.n.05: a candy that is flavored with a mint oil\n",
      "mint.n.06: a plant where money is coined by authority of the government\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('mint', wn.NOUN):\n",
    "    print(synset.name() + ':', synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('mint.n.02')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mint.n.04 is part of mint.n.02\n",
    "wn.synset('mint.n.04').part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('mint.n.05')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mint.n.04 is the substance from which mint.n.05 is made\n",
    "wn.synset('mint.n.04').substance_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chew.v.01'), Synset('swallow.v.01')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relationships between verbs\n",
    "wn.synset('eat.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('demand.n.02.demand')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lexical relationships hold between lemmas\n",
    "wn.lemma('supply.n.02.supply').antonyms()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
